{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1183e735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "# RUNNING STAGE 1: COLOR EXTRACTION\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "STAGE 1: COLOR EXTRACTION (adaptive domain handling)\n",
      "======================================================================\n",
      "Timeout: 15s | Retries: 1 (transient only)\n",
      "Adaptive thresholds: HEAD-check < 40% success, skip < 5% success (after 30 samples)\n",
      "\n",
      "Existing cache: 5,619 products -- will resume.\n",
      "\n",
      "Loading data...\n",
      "  Loaded 21,436 products\n",
      "Filtering categories...\n",
      "  Remaining: 12,832 products\n",
      "Extracting gender labels...\n",
      "  none: 10,913\n",
      "  female: 1,075\n",
      "  male: 844\n",
      "Selecting products...\n",
      "  Domain breakdown:\n",
      "    digitalcontent.api.tesco.com: 6,973\n",
      "    groceries.morrisons.com: 5,517\n",
      "    ui.assets-asda.com:443: 342\n",
      "  To process (after resume filter): 7,210\n",
      "\n",
      "Extracting colors (top 3 per image)...\n",
      "\n",
      "  1/7,210 | OK: 0 (0%) | 159.8 img/s | ETA: 1 min\n",
      "  [domain tracker] Skipping digitalcontent.api.tesco.com (success rate 0% after 30 attempts)\n",
      "  100/7,210 | OK: 0 (0%) | 4.9 img/s | ETA: 24 min\n",
      "  200/7,210 | OK: 0 (0%) | 9.7 img/s | ETA: 12 min\n",
      "  300/7,210 | OK: 0 (0%) | 14.6 img/s | ETA: 8 min\n",
      "  400/7,210 | OK: 0 (0%) | 19.5 img/s | ETA: 6 min\n",
      "  500/7,210 | OK: 0 (0%) | 24.3 img/s | ETA: 5 min\n",
      "  600/7,210 | OK: 0 (0%) | 29.2 img/s | ETA: 4 min\n",
      "  700/7,210 | OK: 0 (0%) | 34.0 img/s | ETA: 3 min\n",
      "  800/7,210 | OK: 0 (0%) | 38.9 img/s | ETA: 3 min\n",
      "  900/7,210 | OK: 0 (0%) | 43.7 img/s | ETA: 2 min\n",
      "  1,000/7,210 | OK: 0 (0%) | 48.6 img/s | ETA: 2 min\n",
      "  1,100/7,210 | OK: 0 (0%) | 53.4 img/s | ETA: 2 min\n",
      "  1,200/7,210 | OK: 0 (0%) | 58.3 img/s | ETA: 2 min\n",
      "  1,300/7,210 | OK: 0 (0%) | 63.1 img/s | ETA: 2 min\n",
      "  1,400/7,210 | OK: 0 (0%) | 68.0 img/s | ETA: 1 min\n",
      "  1,500/7,210 | OK: 0 (0%) | 72.8 img/s | ETA: 1 min\n",
      "  1,600/7,210 | OK: 0 (0%) | 77.6 img/s | ETA: 1 min\n",
      "  1,700/7,210 | OK: 0 (0%) | 82.5 img/s | ETA: 1 min\n",
      "  1,800/7,210 | OK: 0 (0%) | 87.3 img/s | ETA: 1 min\n",
      "  1,900/7,210 | OK: 0 (0%) | 92.2 img/s | ETA: 1 min\n",
      "  2,000/7,210 | OK: 0 (0%) | 97.0 img/s | ETA: 1 min\n",
      "  2,100/7,210 | OK: 0 (0%) | 101.8 img/s | ETA: 1 min\n",
      "  2,200/7,210 | OK: 0 (0%) | 106.7 img/s | ETA: 1 min\n",
      "  2,300/7,210 | OK: 0 (0%) | 111.4 img/s | ETA: 1 min\n",
      "  2,400/7,210 | OK: 0 (0%) | 116.2 img/s | ETA: 1 min\n",
      "  2,500/7,210 | OK: 0 (0%) | 121.1 img/s | ETA: 1 min\n",
      "  2,600/7,210 | OK: 0 (0%) | 125.9 img/s | ETA: 1 min\n",
      "  2,700/7,210 | OK: 0 (0%) | 130.7 img/s | ETA: 1 min\n",
      "  2,800/7,210 | OK: 0 (0%) | 135.5 img/s | ETA: 1 min\n",
      "  2,900/7,210 | OK: 0 (0%) | 140.3 img/s | ETA: 1 min\n",
      "  3,000/7,210 | OK: 0 (0%) | 145.1 img/s | ETA: 0 min\n",
      "  3,100/7,210 | OK: 0 (0%) | 150.0 img/s | ETA: 0 min\n",
      "  3,200/7,210 | OK: 0 (0%) | 154.8 img/s | ETA: 0 min\n",
      "  3,300/7,210 | OK: 0 (0%) | 159.6 img/s | ETA: 0 min\n",
      "  3,400/7,210 | OK: 0 (0%) | 164.4 img/s | ETA: 0 min\n",
      "  3,500/7,210 | OK: 0 (0%) | 169.2 img/s | ETA: 0 min\n",
      "  3,600/7,210 | OK: 0 (0%) | 174.0 img/s | ETA: 0 min\n",
      "  3,700/7,210 | OK: 0 (0%) | 178.8 img/s | ETA: 0 min\n",
      "  3,800/7,210 | OK: 0 (0%) | 183.6 img/s | ETA: 0 min\n",
      "  3,900/7,210 | OK: 0 (0%) | 188.4 img/s | ETA: 0 min\n",
      "  4,000/7,210 | OK: 0 (0%) | 193.2 img/s | ETA: 0 min\n",
      "  4,100/7,210 | OK: 0 (0%) | 198.0 img/s | ETA: 0 min\n",
      "  4,200/7,210 | OK: 0 (0%) | 202.8 img/s | ETA: 0 min\n",
      "  4,300/7,210 | OK: 0 (0%) | 207.6 img/s | ETA: 0 min\n",
      "  4,400/7,210 | OK: 0 (0%) | 212.4 img/s | ETA: 0 min\n",
      "  4,500/7,210 | OK: 0 (0%) | 217.2 img/s | ETA: 0 min\n",
      "  4,600/7,210 | OK: 0 (0%) | 222.0 img/s | ETA: 0 min\n",
      "  4,700/7,210 | OK: 0 (0%) | 226.8 img/s | ETA: 0 min\n",
      "  4,800/7,210 | OK: 0 (0%) | 231.6 img/s | ETA: 0 min\n",
      "  4,900/7,210 | OK: 0 (0%) | 236.4 img/s | ETA: 0 min\n",
      "  5,000/7,210 | OK: 0 (0%) | 241.2 img/s | ETA: 0 min\n",
      "  5,100/7,210 | OK: 0 (0%) | 245.9 img/s | ETA: 0 min\n",
      "  5,200/7,210 | OK: 0 (0%) | 250.7 img/s | ETA: 0 min\n",
      "  5,300/7,210 | OK: 0 (0%) | 255.5 img/s | ETA: 0 min\n",
      "  5,400/7,210 | OK: 0 (0%) | 260.3 img/s | ETA: 0 min\n",
      "  5,500/7,210 | OK: 0 (0%) | 265.1 img/s | ETA: 0 min\n",
      "  5,600/7,210 | OK: 0 (0%) | 269.8 img/s | ETA: 0 min\n",
      "  5,700/7,210 | OK: 0 (0%) | 274.6 img/s | ETA: 0 min\n",
      "  5,800/7,210 | OK: 0 (0%) | 279.4 img/s | ETA: 0 min\n",
      "  5,900/7,210 | OK: 0 (0%) | 284.1 img/s | ETA: 0 min\n",
      "  6,000/7,210 | OK: 0 (0%) | 288.9 img/s | ETA: 0 min\n",
      "  6,100/7,210 | OK: 0 (0%) | 293.6 img/s | ETA: 0 min\n",
      "  6,200/7,210 | OK: 0 (0%) | 298.4 img/s | ETA: 0 min\n",
      "  6,300/7,210 | OK: 0 (0%) | 303.2 img/s | ETA: 0 min\n",
      "  6,400/7,210 | OK: 0 (0%) | 307.9 img/s | ETA: 0 min\n",
      "  6,500/7,210 | OK: 0 (0%) | 312.7 img/s | ETA: 0 min\n",
      "  6,600/7,210 | OK: 0 (0%) | 317.4 img/s | ETA: 0 min\n",
      "  6,700/7,210 | OK: 0 (0%) | 322.2 img/s | ETA: 0 min\n",
      "  6,800/7,210 | OK: 0 (0%) | 326.9 img/s | ETA: 0 min\n",
      "  [domain tracker] Skipping ui.assets-asda.com:443 (success rate 0% after 30 attempts)\n",
      "  6,900/7,210 | OK: 0 (0%) | 134.5 img/s | ETA: 0 min\n",
      "  7,000/7,210 | OK: 0 (0%) | 136.4 img/s | ETA: 0 min\n",
      "  7,100/7,210 | OK: 0 (0%) | 138.3 img/s | ETA: 0 min\n",
      "  7,200/7,210 | OK: 0 (0%) | 140.3 img/s | ETA: 0 min\n",
      "\n",
      "Saving...\n",
      "  Failed URLs log -> /Users/leoss/Desktop/Portfolio/Website-/UK pink tax/Outputs/failed_urls.csv\n",
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "Processed: 7,210\n",
      "Extracted: 0 (0.0%)\n",
      "Failed:    7,210 (100.0%)\n",
      "\n",
      "Failure breakdown:\n",
      "  adaptive_skip: 7150 (99.2%)\n",
      "  http_404: 30 (0.4%)\n",
      "  connection_error: 30 (0.4%)\n",
      "\n",
      "Per-domain results:\n",
      "  domain                                      ok / total    rate\n",
      "  ------------------------------------------------------------\n",
      "  digitalcontent.api.tesco.com                 0 /  6868     0%\n",
      "  ui.assets-asda.com:443                       0 /   342     0%\n",
      "\n",
      "######################################################################\n",
      "# RUNNING STAGE 2: ML GENDER PREDICTION\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "STAGE 2: ML GENDER PREDICTION PIPELINE\n",
      "======================================================================\n",
      "Main dataset: 21,436 products\n",
      "Human-coded: 259 products\n",
      "Your labeled: 44 products\n",
      "Filtered: 21,436 -> 12,832 (excluded 8,604)\n",
      "Label distribution: {'none': 10913, 'female': 1075, 'male': 844}\n",
      "Human labels merged: 200\n",
      "Color cache: 5,619 products\n",
      "  Matched to filtered data: 5,619 / 5,619\n",
      "\n",
      "Explicitly female: 1075, male: 844\n",
      "Balancing to: 844 per class\n",
      "Training data: 2532 (classes: {0: 850, 1: 845, 2: 837})\n",
      "Train: 1905, Test: 639\n",
      "Breadcrumb TF-IDF: 80 features\n",
      "Description TF-IDF: 150 features\n",
      "Color lookup built: 5,619 products\n",
      "  Color features filled for 840/1905 rows\n",
      "  Color features filled for 300/639 rows\n",
      "Color features: 93 (available for 840/1905 train samples)\n",
      "X_train: (1905, 329), X_test: (639, 329)\n",
      "\n",
      "--- Logistic Regression (L1) ---\n",
      "Accuracy: 0.6495, F1: 0.6462\n",
      "\n",
      "--- Logistic Regression (L2) ---\n",
      "Accuracy: 0.7293, F1: 0.7295\n",
      "\n",
      "--- Random Forest ---\n",
      "Accuracy: 0.7230, F1: 0.7216\n",
      "\n",
      "--- Histogram Gradient Boosting ---\n",
      "Accuracy: 0.7934, F1: 0.7929\n",
      "\n",
      "--- SVM (RBF) ---\n",
      "Accuracy: 0.7308, F1: 0.7293\n",
      "\n",
      "======================================================================\n",
      "MODEL COMPARISON\n",
      "======================================================================\n",
      "                 Model  Accuracy  F1_weighted\n",
      "Hist Gradient Boosting  0.793427     0.792913\n",
      "            L2 (Ridge)  0.729264     0.729505\n",
      "                   SVM  0.730829     0.729285\n",
      "         Random Forest  0.723005     0.721612\n",
      "            L1 (LASSO)  0.649452     0.646213\n",
      "\n",
      "Best model: Hist Gradient Boosting\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.79      0.76      0.77       217\n",
      "        male       0.82      0.77      0.79       213\n",
      "        none       0.77      0.86      0.81       209\n",
      "\n",
      "    accuracy                           0.79       639\n",
      "   macro avg       0.79      0.79      0.79       639\n",
      "weighted avg       0.79      0.79      0.79       639\n",
      "\n",
      "Confusion Matrix:\n",
      "            Predicted\n",
      "            female  male  none\n",
      "Actual female   164    25    28\n",
      "Actual male      25   164    24\n",
      "Actual none      18    12   179\n",
      "\n",
      "Top 15 FEMALE features:\n",
      "  bc_removal                              : +1.0512\n",
      "  bc_period                               : +0.9376\n",
      "  bc_intimate                             : +0.8811\n",
      "  desc_protection                         : +0.7017\n",
      "  bc_products                             : +0.6692\n",
      "  bc_supplements                          : +0.4957\n",
      "  bc_shaving                              : +0.3945\n",
      "  desc_skin                               : +0.3930\n",
      "  bc_entertainment                        : +0.3678\n",
      "  bc_birthday                             : +0.3650\n",
      "  bc_sets                                 : +0.3564\n",
      "  desc_body                               : +0.3520\n",
      "  desc_vitamin                            : +0.3463\n",
      "  feat_color1_lavender                    : +0.3320\n",
      "  bc_pads                                 : +0.3293\n",
      "\n",
      "Top 15 MALE features:\n",
      "  bc_toiletries                           : +1.8591\n",
      "  desc_lynx                               : +1.0390\n",
      "  bc_gel                                  : +0.8697\n",
      "  bc_razors                               : +0.8218\n",
      "  bc_blades                               : +0.6705\n",
      "  bc_deodorants                           : +0.6273\n",
      "  bc_skincare                             : +0.6231\n",
      "  desc_shave                              : +0.5808\n",
      "  feat_color1_black                       : +0.5577\n",
      "  bc_body                                 : +0.4495\n",
      "  bc_deodorant                            : +0.4465\n",
      "  bc_wash                                 : +0.4343\n",
      "  desc_gel                                : +0.3897\n",
      "  bc_foam                                 : +0.3835\n",
      "  bc_aftershaves                          : +0.3379\n",
      "\n",
      "Top 15 NONE features:\n",
      "  bc_accessories                          : +0.7833\n",
      "  bc_conditioner                          : +0.6619\n",
      "  bc_marketplace                          : +0.6474\n",
      "  bc_dine                                 : +0.6471\n",
      "  bc_cook                                 : +0.6471\n",
      "  bc_toothpaste                           : +0.6047\n",
      "  bc_frozen                               : +0.6015\n",
      "  bc_care                                 : +0.5201\n",
      "  bc_baby                                 : +0.4769\n",
      "  bc_bath                                 : +0.4737\n",
      "  bc_sweets                               : +0.3985\n",
      "  bc_shampoo                              : +0.3880\n",
      "  bc_wellbeing                            : +0.3447\n",
      "  bc_toys                                 : +0.3343\n",
      "  bc_chocolate                            : +0.3337\n",
      "\n",
      "Prediction distribution:\n",
      "ml_pred_label\n",
      "none      9185\n",
      "female    2255\n",
      "male      1392\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Color impact:\n",
      "  WITH colors:    Accuracy=0.6495, F1=0.6462\n",
      "  WITHOUT colors: Accuracy=0.6275, F1=0.6223\n",
      "  Delta:          Accuracy +2.19pp, F1 +2.39pp\n",
      "\n",
      "Morrisons-only color ablation (HGB):  train=840, test=300\n",
      "  HGB WITH colors:    Accuracy=0.8300, F1=0.8302\n",
      "  HGB WITHOUT colors: Accuracy=0.8133, F1=0.8130\n",
      "  Delta (Morrisons HGB): Accuracy +1.67pp, F1 +1.71pp\n",
      "\n",
      "Products with human labels: 200\n",
      "Accuracy vs human: 0.7000\n",
      "\n",
      "Implicit female (>50% conf): 533\n",
      "Implicit male (>50% conf): 278\n",
      "\n",
      "Available for validation: 12,632\n",
      "  Sampled 85 female\n",
      "  Sampled 85 male\n",
      "  Sampled 85 none\n",
      "Saved validation sample: 255 products\n",
      "\n",
      "Pipeline complete. Outputs in /Users/leoss/Desktop/Portfolio/Website-/UK pink tax/Outputs/charts/ml_pipeline_v4\n",
      "\n",
      "######################################################################\n",
      "# RUNNING STAGE 3: REGRESSION ANALYSIS\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "STAGE 3: REGRESSION ANALYSIS\n",
      "======================================================================\n",
      "Products with valid prices: 12,832\n",
      "\n",
      "Gender distribution:\n",
      "  female: 1,075  (mean 7.03, median 4.00)\n",
      "  male: 844  (mean 8.15, median 4.50)\n",
      "  none: 10,913  (mean 10.66, median 5.00)\n",
      "\n",
      "Gendered sample: N = 1,919 (F: 1075, M: 844)\n",
      "\n",
      "Spec 1: Raw gap\n",
      "  (1) Raw gap: coef=-0.0975 (-9.3%), SE=0.0411, p=0.0178**, R2=0.003, N=1919\n",
      "\n",
      "Spec 2: + Store FE\n",
      "  (2) + Store FE: coef=-0.1036 (-9.8%), SE=0.0412, p=0.0118**, R2=0.006, N=1919\n",
      "\n",
      "Spec 3: + Broad cat FE (N cats: 96)\n",
      "  (3) + Broad cat FE: coef=+0.0803 (+8.4%), SE=0.0851, p=0.3454, R2=0.672, N=1374\n",
      "\n",
      "Spec 4: + Mid cat FE (N cats: 96)\n",
      "  (4) + Mid cat FE: coef=+0.0803 (+8.4%), SE=0.0851, p=0.3454, R2=0.672, N=1374\n",
      "\n",
      "Spec 5: + Fine cat FE (N cats: 96)\n",
      "  (5) + Fine cat FE: coef=+0.0803 (+8.4%), SE=0.0851, p=0.3454, R2=0.672, N=1374\n",
      "\n",
      "Spec 6: + Description TF-IDF\n",
      "  (6) + Description: coef=+0.0367 (+3.7%), SE=0.0675, p=0.5868, R2=0.738\n",
      "\n",
      "Spec 7: Female x Store interaction\n",
      "  Main effect (is_female): -0.0412 (p=0.5918)\n",
      "  Store 3: total female effect = -0.7046 (-50.6%), interaction p=0.0000\n",
      "  Store 4: total female effect = +0.2767 (+31.9%), interaction p=0.0969\n",
      "\n",
      "Spec 8: Unit price regression\n",
      "  (8) Unit price: coef=+0.0067 (+0.7%), SE=0.0677, p=0.9218, R2=0.854, N=743\n",
      "\n",
      "Spec 9: Three-way comparison (none = reference)\n",
      "  is_female: -0.1794 (p=0.0000)\n",
      "  is_male:   -0.0299 (p=0.3745)\n",
      "\n",
      "======================================================================\n",
      "QUANTILE REGRESSION\n",
      "======================================================================\n",
      "  Q0.10: coef=-0.1285 (-12.1%), p=0.0440**\n",
      "  Q0.25: coef=-0.0000 (-0.0%), p=0.9999\n",
      "  Q0.50: coef=-0.1054 (-10.0%), p=0.0217**\n",
      "  Q0.75: coef=+0.0000 (+0.0%), p=1.0000\n",
      "  Q0.90: coef=-0.2226 (-20.0%), p=0.0023***\n",
      "\n",
      "  With mid-category controls:\n",
      "  Q0.10: coef=+0.3578 (+43.0%), p=0.0000***\n",
      "  Q0.25: coef=+0.2231 (+25.0%), p=0.0002***\n",
      "  Q0.50: coef=+0.0000 (+0.0%), p=1.0000\n",
      "  Q0.75: coef=+0.0000 (+0.0%), p=1.0000\n",
      "  Q0.90: coef=+0.0000 (+0.0%), p=1.0000\n",
      "\n",
      "======================================================================\n",
      "WITHIN-CATEGORY ANALYSIS (bootstrap CIs)\n",
      "======================================================================\n",
      "Categories with both genders (>=3 each): 11\n",
      "  Weighted mean: +26.2%\n",
      "  Median: +7.4%\n",
      "\n",
      "======================================================================\n",
      "PINK TAX BY STORE\n",
      "======================================================================\n",
      "  Store 4         F: 449 M: 404 gap=   +0.8% p=0.8938\n",
      "  Store 3         F:  29 M:  34 gap=   -5.1% p=0.8036\n",
      "  Store 1         F: 597 M: 406 gap=  -18.6% p=0.0003***\n",
      "\n",
      "======================================================================\n",
      "REGRESSION SUMMARY\n",
      "======================================================================\n",
      "Spec                          Coef     %gap             95% CI        p     R2      N\n",
      "(1) Raw gap               -0.0975    -9.3% [ -16.3,   -1.7]  0.0178**  0.003   1919\n",
      "(2) + Store FE            -0.1036    -9.8% [ -16.8,   -2.3]  0.0118**  0.006   1919\n",
      "(3) + Broad cat FE        +0.0803    +8.4% [  -8.3,  +28.0]  0.3454    0.672   1374\n",
      "(4) + Mid cat FE          +0.0803    +8.4% [  -8.3,  +28.0]  0.3454    0.672   1374\n",
      "(5) + Fine cat FE         +0.0803    +8.4% [  -8.3,  +28.0]  0.3454    0.672   1374\n",
      "(6) + Description         +0.0367    +3.7% [  -9.1,  +18.4]  0.5868    0.738   1374\n",
      "(8) Unit price            +0.0067    +0.7% [ -11.8,  +15.0]  0.9218    0.854    743\n",
      "\n",
      "======================================================================\n",
      "GENERATING CHARTS\n",
      "======================================================================\n",
      "  01_coefficient_plot.png\n",
      "  02_quantile_regression.png\n",
      "  03_within_category_gaps.png\n",
      "  04_price_distributions.png\n",
      "  05_by_store.png\n",
      "  06_scatter_by_category.png\n",
      "  07_three_way_comparison.png\n",
      "  08_category_composition.png\n",
      "  09_gap_distribution.png\n",
      "  10_r2_progression.png\n",
      "  12_summary_dashboard.png\n",
      "  13_waterfall_decomposition.png\n",
      "\n",
      "All outputs saved to /Users/leoss/Desktop/Portfolio/Website-/UK pink tax/Outputs/charts/pink_tax_regression_v2\n",
      "\n",
      "######################################################################\n",
      "# RUNNING STAGE 4: COLOR VISUALISATIONS\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "STAGE 4: COLOR VISUALISATIONS\n",
      "======================================================================\n",
      "Color cache: 5,619 products\n",
      "Feature importance: 329 features\n",
      "Colors with >1% share: 21\n",
      "\n",
      "Generating color distribution chart...\n",
      "  color_distribution_by_gender.png\n",
      "\n",
      "Generating color importance chart...\n",
      "  color_importance.png\n",
      "\n",
      "Generating color importance heatmap...\n",
      "  color_importance_heatmap.png\n",
      "\n",
      "Generating female vs male color comparison...\n",
      "  color_comparison_butterfly.png\n",
      "\n",
      "All charts saved to /Users/leoss/Desktop/Portfolio/Website-/UK pink tax/Outputs/charts/validation\n",
      "Usage: run_pipeline(stages) where stages = 1, 2, 3, 4, or 'all'\n",
      "  e.g. run_pipeline(2)  or  run_pipeline([2, 3])  or  run_pipeline('all')\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PINK TAX ANALYSIS - UNIFIED PIPELINE\n",
    "# ============================================================================\n",
    "#\n",
    "# Consolidates four previously separate scripts into one modular codebase:\n",
    "#   Stage 1: Color extraction from product images (adaptive domain handling)\n",
    "#   Stage 2: ML-based gender prediction (L1/L2/RF/HGB/SVM)\n",
    "#   Stage 3: Regression analysis (OLS, quantile, within-category, by-store)\n",
    "#   Stage 4: Color visualisations for portfolio\n",
    "#\n",
    "# Usage:\n",
    "#   python pink_tax_pipeline.py --stage [1|2|3|4|all]\n",
    "#\n",
    "# ============================================================================\n",
    "\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "BASE_DIR = Path('/Users/leoss')\n",
    "DATA_DIR = BASE_DIR / 'Downloads'\n",
    "OUTPUT_BASE = BASE_DIR / 'Desktop/Portfolio/Website-/UK pink tax/Outputs'\n",
    "\n",
    "# Input files\n",
    "PATH_MAIN_DATA = DATA_DIR / 'items_fin.csv'\n",
    "PATH_HUMAN_CODED = DATA_DIR / 'items_prices_description_gender_humancode_sample.csv'\n",
    "PATH_YOUR_LABELED = DATA_DIR / 'available_validation.xlsx'\n",
    "\n",
    "# Output directories\n",
    "COLOR_CACHE_PATH = OUTPUT_BASE / 'color_features_cache_v3_filtered.csv'\n",
    "FAILED_URLS_PATH = OUTPUT_BASE / 'failed_urls.csv'\n",
    "ML_OUTPUT_DIR = OUTPUT_BASE / 'charts/ml_pipeline_v4'\n",
    "REG_OUTPUT_DIR = OUTPUT_BASE / 'charts/pink_tax_regression_v2'\n",
    "VIS_OUTPUT_DIR = OUTPUT_BASE / 'charts/validation'\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# ---- Column names ----\n",
    "COL_PRODUCT_ID = 'product_id'\n",
    "COL_IMAGE = 'image_url'\n",
    "COL_BREADCRUMB = 'standardized_breadcrumbs'\n",
    "COL_NAME = 'product_title_x'\n",
    "COL_DESC = 'description'\n",
    "COL_PRICE = 'price'\n",
    "COL_UNIT_PRICE = 'unit_price'\n",
    "COL_STORE = 'store_id'\n",
    "COL_URL = 'product_url_x'\n",
    "\n",
    "# ---- Gender keywords ----\n",
    "FEMALE_KEYWORDS = [\n",
    "    'women', 'woman', 'female', 'ladies', 'lady', 'girls',\n",
    "    'womens', \"women's\", 'femme', 'her', 'feminine', 'fem',\n",
    "]\n",
    "MALE_KEYWORDS = [\n",
    "    'men', 'man', 'male', 'gentleman', 'gentlemen', 'boys',\n",
    "    'mens', \"men's\", 'homme', 'his', 'masculine',\n",
    "]\n",
    "ALL_GENDER_KEYWORDS = set(FEMALE_KEYWORDS + MALE_KEYWORDS)\n",
    "\n",
    "# ---- Category exclusions ----\n",
    "EXCLUDE_CATEGORIES = [\n",
    "    'food', 'grocery', 'groceries', 'snacks', 'drinks', 'beverages',\n",
    "    'pet food', 'pet supplies', 'cleaning', 'household', 'kitchen',\n",
    "    'office', 'stationery', 'electronics', 'tech', 'garden', 'automotive',\n",
    "]\n",
    "\n",
    "# ---- Color definitions ----\n",
    "STANDARD_COLORS = {\n",
    "    'dark_red': (139, 0, 0), 'red': (255, 0, 0), 'coral': (255, 127, 80),\n",
    "    'salmon': (250, 128, 114), 'crimson': (220, 20, 60), 'brown': (139, 69, 19),\n",
    "    'tan': (210, 180, 140), 'orange': (255, 165, 0), 'gold': (255, 215, 0),\n",
    "    'yellow': (255, 255, 0), 'khaki': (240, 230, 140), 'dark_green': (0, 100, 0),\n",
    "    'green': (0, 128, 0), 'lime': (50, 205, 50), 'olive': (128, 128, 0),\n",
    "    'teal': (0, 128, 128), 'navy': (0, 0, 128), 'blue': (0, 0, 255),\n",
    "    'royal_blue': (65, 105, 225), 'sky_blue': (135, 206, 235), 'cyan': (0, 255, 255),\n",
    "    'purple': (128, 0, 128), 'magenta': (255, 0, 255), 'violet': (238, 130, 238),\n",
    "    'lavender': (230, 230, 250), 'pink': (255, 192, 203), 'hot_pink': (255, 105, 180),\n",
    "    'gray': (128, 128, 128), 'silver': (192, 192, 192),\n",
    "    'black': (0, 0, 0), 'white': (255, 255, 255),\n",
    "}\n",
    "\n",
    "# ---- Stage 1 settings ----\n",
    "N_COLORS = 3\n",
    "TIMEOUT = 15\n",
    "MAX_SAMPLES = 20000\n",
    "PRIORITIZE_GENDERED = False\n",
    "MAX_RETRIES = 1\n",
    "RETRY_DELAY = 1\n",
    "SAVE_EVERY = 200\n",
    "MIN_DOMAIN_SAMPLES = 30\n",
    "HEAD_CHECK_THRESHOLD = 0.40\n",
    "SKIP_THRESHOLD = 0.05\n",
    "\n",
    "# ---- Stage 2 settings ----\n",
    "TEST_SIZE = 0.25\n",
    "CV_FOLDS = 5\n",
    "MIN_CLASS_SIZE = 50\n",
    "MIN_TEST_SAMPLES = 10\n",
    "\n",
    "# ---- Stage 3 settings ----\n",
    "N_BOOTSTRAP = 1000\n",
    "\n",
    "# ---- Chart style ----\n",
    "PALETTE = {'female': '#c44e52', 'male': '#4c72b0', 'none': '#8c8c8c'}\n",
    "\n",
    "# ---- Global chart style (portfolio-ready: no titles, clean axes) ----\n",
    "CHART_STYLE = {\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.sans-serif': ['IBM Plex Sans', 'Helvetica Neue', 'Arial'],\n",
    "    'font.size': 11,\n",
    "    'axes.titlesize': 0,       # suppress titles (handled by HTML captions)\n",
    "    'axes.labelsize': 11,\n",
    "    'axes.linewidth': 0.6,\n",
    "    'axes.spines.top': False,\n",
    "    'axes.spines.right': False,\n",
    "    'axes.grid': False,\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "    'figure.facecolor': 'white',\n",
    "    'savefig.facecolor': 'white',\n",
    "    'savefig.dpi': 200,\n",
    "    'savefig.bbox': 'tight',\n",
    "    'legend.fontsize': 10,\n",
    "    'legend.framealpha': 0.9,\n",
    "    'legend.edgecolor': '#cccccc',\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# SHARED UTILITIES\n",
    "# ============================================================================\n",
    "\n",
    "def load_main_data(path=PATH_MAIN_DATA):\n",
    "    \"\"\"Load and normalise the main product dataset.\"\"\"\n",
    "    df = pd.read_csv(path, encoding='latin-1')\n",
    "    df.columns = df.columns.str.lower().str.strip().str.replace(' ', '_')\n",
    "    if 'unnamed:_0' in df.columns:\n",
    "        df = df.drop(columns=['unnamed:_0'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def contains_excluded_category(text):\n",
    "    \"\"\"Check whether a breadcrumb string matches any excluded category.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return False\n",
    "    text_lower = str(text).lower()\n",
    "    return any(cat in text_lower for cat in EXCLUDE_CATEGORIES)\n",
    "\n",
    "\n",
    "def filter_excluded_categories(df):\n",
    "    \"\"\"Remove products in excluded categories. Returns filtered copy.\"\"\"\n",
    "    mask = df[COL_BREADCRUMB].apply(contains_excluded_category)\n",
    "    return df[~mask].copy().reset_index(drop=True)\n",
    "\n",
    "\n",
    "def extract_gender_from_text(text):\n",
    "    \"\"\"Return 'female', 'male', 'both', or 'none' from a single text field.\"\"\"\n",
    "    if pd.isna(text) or str(text).strip() == '':\n",
    "        return 'none'\n",
    "    text_lower = str(text).lower()\n",
    "    has_female = any(re.search(r'\\b' + kw + r'\\b', text_lower) for kw in FEMALE_KEYWORDS)\n",
    "    has_male = any(re.search(r'\\b' + kw + r'\\b', text_lower) for kw in MALE_KEYWORDS)\n",
    "    if has_female and not has_male:\n",
    "        return 'female'\n",
    "    if has_male and not has_female:\n",
    "        return 'male'\n",
    "    if has_female and has_male:\n",
    "        return 'both'\n",
    "    return 'none'\n",
    "\n",
    "\n",
    "def extract_gender_label(row):\n",
    "    \"\"\"Combine gender signals from breadcrumb, title, and description.\"\"\"\n",
    "    for col in [COL_BREADCRUMB, COL_NAME, COL_DESC]:\n",
    "        if col in row.index:\n",
    "            gender = extract_gender_from_text(row[col])\n",
    "            if gender in ('female', 'male'):\n",
    "                return gender\n",
    "    return 'none'\n",
    "\n",
    "\n",
    "def add_gender_labels(df):\n",
    "    \"\"\"Add per-field and combined gender labels to the dataframe in place.\"\"\"\n",
    "    df['label_bc'] = df[COL_BREADCRUMB].apply(extract_gender_from_text)\n",
    "    df['label_name'] = df[COL_NAME].apply(extract_gender_from_text)\n",
    "    df['label_desc'] = df[COL_DESC].apply(extract_gender_from_text)\n",
    "    df['label_extracted'] = df.apply(extract_gender_label, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_text_remove_gender(text, remove_words=ALL_GENDER_KEYWORDS):\n",
    "    \"\"\"Lowercase, strip gender keywords and punctuation.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    text = str(text).lower()\n",
    "    for word in remove_words:\n",
    "        text = re.sub(r'\\b' + word + r'\\b', '', text)\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_domain(url):\n",
    "    try:\n",
    "        return str(url).split('/')[2]\n",
    "    except (IndexError, AttributeError):\n",
    "        return 'unknown'\n",
    "\n",
    "\n",
    "def parse_breadcrumb(text):\n",
    "    \"\"\"Extract clean category levels from a breadcrumb string.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return 'unknown', 'unknown', 'unknown'\n",
    "    text = str(text).strip()\n",
    "    if ' > ' in text:\n",
    "        parts = [p.strip().lower() for p in text.split(' > ') if p.strip()]\n",
    "    elif ' / ' in text:\n",
    "        parts = [p.strip().lower() for p in text.split(' / ') if p.strip()]\n",
    "    else:\n",
    "        parts = [text.strip().lower()]\n",
    "\n",
    "    known_stores = {'morrisons', 'tesco', 'asda', 'groceries', 'marketplace'}\n",
    "    while parts and parts[0] in known_stores:\n",
    "        parts = parts[1:]\n",
    "\n",
    "    level1 = parts[0] if len(parts) > 0 else 'unknown'\n",
    "    level2 = parts[1] if len(parts) > 1 else 'unknown'\n",
    "    level3 = parts[2] if len(parts) > 2 else 'unknown'\n",
    "    return level1, level2, level3\n",
    "\n",
    "\n",
    "# ---- Color helpers ----\n",
    "\n",
    "def color_distance(c1, c2):\n",
    "    return np.sqrt(sum((a - b) ** 2 for a, b in zip(c1, c2)))\n",
    "\n",
    "\n",
    "def closest_standard_color(rgb):\n",
    "    min_dist = float('inf')\n",
    "    closest = 'gray'\n",
    "    for name, std_rgb in STANDARD_COLORS.items():\n",
    "        dist = color_distance(rgb, std_rgb)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            closest = name\n",
    "    return closest\n",
    "\n",
    "\n",
    "def is_background_color(rgb):\n",
    "    r, g, b = rgb\n",
    "    if r > 240 and g > 240 and b > 240:\n",
    "        return True\n",
    "    if r < 15 and g < 15 and b < 15:\n",
    "        return True\n",
    "    max_diff = max(abs(r - g), abs(g - b), abs(r - b))\n",
    "    avg = (r + g + b) / 3\n",
    "    if max_diff < 20 and 100 < avg < 160:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def rgb_norm(name):\n",
    "    \"\"\"Normalised RGB tuple for matplotlib.\"\"\"\n",
    "    r, g, b = STANDARD_COLORS.get(name, (128, 128, 128))\n",
    "    return (r / 255, g / 255, b / 255)\n",
    "\n",
    "\n",
    "def text_color_for_bg(name):\n",
    "    \"\"\"Black or white text depending on background luminance.\"\"\"\n",
    "    r, g, b = STANDARD_COLORS.get(name, (128, 128, 128))\n",
    "    lum = 0.299 * r + 0.587 * g + 0.114 * b\n",
    "    return 'white' if lum < 140 else '#1a1a1a'\n",
    "\n",
    "\n",
    "def edge_color_for(name):\n",
    "    \"\"\"Light colors get a visible border.\"\"\"\n",
    "    r, g, b = STANDARD_COLORS.get(name, (128, 128, 128))\n",
    "    lum = 0.299 * r + 0.587 * g + 0.114 * b\n",
    "    return '#aaaaaa' if lum > 200 else 'none'\n",
    "\n",
    "\n",
    "def save_incremental(new_results, cache_path):\n",
    "    \"\"\"Append new results to the cache CSV, deduplicating on product_id.\"\"\"\n",
    "    if not new_results:\n",
    "        return 0\n",
    "    new_df = pd.DataFrame(new_results)\n",
    "    if cache_path.exists():\n",
    "        existing = pd.read_csv(cache_path)\n",
    "        combined = pd.concat([existing, new_df]).drop_duplicates(subset=[COL_PRODUCT_ID])\n",
    "    else:\n",
    "        combined = new_df\n",
    "    combined.to_csv(cache_path, index=False)\n",
    "    return len(combined)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STAGE 1: COLOR EXTRACTION\n",
    "# ============================================================================\n",
    "\n",
    "class DomainTracker:\n",
    "    \"\"\"\n",
    "    Tracks per-domain success/failure rates during extraction.\n",
    "    After MIN_DOMAIN_SAMPLES attempts, adjusts strategy:\n",
    "      - success rate < HEAD_CHECK_THRESHOLD: HEAD pre-check before GET\n",
    "      - success rate < SKIP_THRESHOLD: skip entirely\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, min_samples, head_threshold, skip_threshold):\n",
    "        self.min_samples = min_samples\n",
    "        self.head_threshold = head_threshold\n",
    "        self.skip_threshold = skip_threshold\n",
    "        self.attempts = Counter()\n",
    "        self.successes = Counter()\n",
    "        self._notified_head = set()\n",
    "        self._notified_skip = set()\n",
    "\n",
    "    def record(self, domain, success):\n",
    "        self.attempts[domain] += 1\n",
    "        if success:\n",
    "            self.successes[domain] += 1\n",
    "\n",
    "    def success_rate(self, domain):\n",
    "        total = self.attempts[domain]\n",
    "        return self.successes[domain] / total if total else 1.0\n",
    "\n",
    "    def should_skip(self, domain):\n",
    "        if self.attempts[domain] < self.min_samples:\n",
    "            return False\n",
    "        skip = self.success_rate(domain) < self.skip_threshold\n",
    "        if skip and domain not in self._notified_skip:\n",
    "            rate = self.success_rate(domain)\n",
    "            print(f\"  [domain tracker] Skipping {domain} \"\n",
    "                  f\"(success rate {rate:.0%} after {self.attempts[domain]} attempts)\")\n",
    "            self._notified_skip.add(domain)\n",
    "        return skip\n",
    "\n",
    "    def should_head_check(self, domain):\n",
    "        if self.attempts[domain] < self.min_samples:\n",
    "            return False\n",
    "        rate = self.success_rate(domain)\n",
    "        head_check = rate < self.head_threshold and rate >= self.skip_threshold\n",
    "        if head_check and domain not in self._notified_head:\n",
    "            print(f\"  [domain tracker] HEAD pre-checking {domain} \"\n",
    "                  f\"(success rate {rate:.0%} after {self.attempts[domain]} attempts)\")\n",
    "            self._notified_head.add(domain)\n",
    "        return head_check\n",
    "\n",
    "    def summary(self):\n",
    "        out = {}\n",
    "        for domain in sorted(self.attempts, key=lambda d: self.attempts[d], reverse=True):\n",
    "            total = self.attempts[domain]\n",
    "            ok = self.successes[domain]\n",
    "            out[domain] = (ok, total, ok / total if total else 0)\n",
    "        return out\n",
    "\n",
    "\n",
    "def _build_session():\n",
    "    import requests\n",
    "    session = requests.Session()\n",
    "    session.headers.update({\n",
    "        'User-Agent': (\n",
    "            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) '\n",
    "            'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
    "            'Chrome/91.0.4472.124 Safari/537.36'\n",
    "        ),\n",
    "        'Accept': 'image/avif,image/webp,image/apng,image/*,*/*;q=0.8',\n",
    "        'Accept-Language': 'en-US,en;q=0.9',\n",
    "    })\n",
    "    return session\n",
    "\n",
    "\n",
    "def _head_check_alive(session, url, timeout=5):\n",
    "    import requests\n",
    "    try:\n",
    "        resp = session.head(url, timeout=timeout, allow_redirects=True)\n",
    "        return resp.status_code == 200\n",
    "    except requests.RequestException:\n",
    "        return False\n",
    "\n",
    "\n",
    "def _is_transient_error(status_code):\n",
    "    if status_code is None:\n",
    "        return True\n",
    "    return status_code >= 500 or status_code == 429\n",
    "\n",
    "\n",
    "def extract_colors_from_url(session, domain_tracker, image_url,\n",
    "                            n_colors=3, timeout=15, max_retries=1):\n",
    "    \"\"\"\n",
    "    Download an image and extract dominant colors via KMeans.\n",
    "    Returns (colors_list | None, error_reason | None).\n",
    "    \"\"\"\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    from sklearn.cluster import KMeans\n",
    "\n",
    "    url = str(image_url).strip()\n",
    "    domain = get_domain(url)\n",
    "\n",
    "    if domain_tracker.should_skip(domain):\n",
    "        return None, 'adaptive_skip'\n",
    "    if domain_tracker.should_head_check(domain):\n",
    "        if not _head_check_alive(session, url, timeout=5):\n",
    "            return None, 'head_check_dead'\n",
    "\n",
    "    last_error = None\n",
    "    for attempt in range(max_retries + 1):\n",
    "        try:\n",
    "            response = session.get(url, timeout=timeout, allow_redirects=True)\n",
    "            if response.status_code != 200:\n",
    "                last_error = f'http_{response.status_code}'\n",
    "                if _is_transient_error(response.status_code) and attempt < max_retries:\n",
    "                    time.sleep(RETRY_DELAY)\n",
    "                    continue\n",
    "                return None, last_error\n",
    "\n",
    "            img = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "            img = img.resize((100, 100))\n",
    "            pixels = np.array(img).reshape(-1, 3)\n",
    "\n",
    "            non_bg = np.array([p for p in pixels if not is_background_color(tuple(p))])\n",
    "            if len(non_bg) < 50:\n",
    "                non_bg = pixels\n",
    "\n",
    "            n_clusters = min(n_colors + 2, len(non_bg))\n",
    "            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "            kmeans.fit(non_bg)\n",
    "\n",
    "            counts = Counter(kmeans.labels_)\n",
    "            total = len(kmeans.labels_)\n",
    "            colors = []\n",
    "            for cluster_id, count in sorted(counts.items(), key=lambda x: x[1], reverse=True):\n",
    "                rgb = tuple(int(c) for c in kmeans.cluster_centers_[cluster_id])\n",
    "                if not is_background_color(rgb):\n",
    "                    colors.append({'name': closest_standard_color(rgb), 'weight': count / total})\n",
    "                if len(colors) >= n_colors:\n",
    "                    break\n",
    "\n",
    "            return (colors, None) if colors else (None, 'no_non_bg_colors')\n",
    "\n",
    "        except requests.exceptions.Timeout:\n",
    "            last_error = 'timeout'\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            last_error = 'connection_error'\n",
    "        except requests.exceptions.RequestException:\n",
    "            last_error = 'request_error'\n",
    "        except Exception:\n",
    "            last_error = 'processing_error'\n",
    "\n",
    "        if attempt < max_retries:\n",
    "            time.sleep(RETRY_DELAY)\n",
    "\n",
    "    return None, last_error\n",
    "\n",
    "\n",
    "def run_color_extraction():\n",
    "    \"\"\"Stage 1: extract dominant colors from product images.\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"STAGE 1: COLOR EXTRACTION (adaptive domain handling)\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Timeout: {TIMEOUT}s | Retries: {MAX_RETRIES} (transient only)\")\n",
    "    print(f\"Adaptive thresholds: HEAD-check < {HEAD_CHECK_THRESHOLD:.0%} \"\n",
    "          f\"success, skip < {SKIP_THRESHOLD:.0%} success \"\n",
    "          f\"(after {MIN_DOMAIN_SAMPLES} samples)\")\n",
    "    print()\n",
    "\n",
    "    OUTPUT_BASE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    session = _build_session()\n",
    "    domain_tracker = DomainTracker(MIN_DOMAIN_SAMPLES, HEAD_CHECK_THRESHOLD, SKIP_THRESHOLD)\n",
    "\n",
    "    # Resume support\n",
    "    already_done = set()\n",
    "    if COLOR_CACHE_PATH.exists():\n",
    "        existing = pd.read_csv(COLOR_CACHE_PATH)\n",
    "        if COL_PRODUCT_ID in existing.columns:\n",
    "            already_done = set(existing[COL_PRODUCT_ID].astype(str))\n",
    "            print(f\"Existing cache: {len(already_done):,} products -- will resume.\\n\")\n",
    "\n",
    "    # Load and filter\n",
    "    print(\"Loading data...\")\n",
    "    df = load_main_data()\n",
    "    print(f\"  Loaded {len(df):,} products\")\n",
    "\n",
    "    print(\"Filtering categories...\")\n",
    "    df = filter_excluded_categories(df)\n",
    "    print(f\"  Remaining: {len(df):,} products\")\n",
    "\n",
    "    print(\"Extracting gender labels...\")\n",
    "    df = add_gender_labels(df)\n",
    "    for label, count in df['label_extracted'].value_counts().items():\n",
    "        print(f\"  {label}: {count:,}\")\n",
    "\n",
    "    print(\"Selecting products...\")\n",
    "    df_with_images = df[df[COL_IMAGE].notna()].copy()\n",
    "\n",
    "    df_with_images['_domain'] = df_with_images[COL_IMAGE].apply(get_domain)\n",
    "    print(\"  Domain breakdown:\")\n",
    "    for domain, count in df_with_images['_domain'].value_counts().items():\n",
    "        print(f\"    {domain}: {count:,}\")\n",
    "\n",
    "    to_extract = df_with_images.copy()\n",
    "    if len(to_extract) > MAX_SAMPLES:\n",
    "        to_extract = to_extract.sample(n=MAX_SAMPLES, random_state=RANDOM_STATE)\n",
    "\n",
    "    to_extract = to_extract[~to_extract[COL_PRODUCT_ID].astype(str).isin(already_done)]\n",
    "    print(f\"  To process (after resume filter): {len(to_extract):,}\")\n",
    "\n",
    "    # Extract\n",
    "    print(f\"\\nExtracting colors (top {N_COLORS} per image)...\\n\")\n",
    "\n",
    "    color_results = []\n",
    "    failed_records = []\n",
    "    error_counter = Counter()\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (row_idx, row) in enumerate(to_extract.iterrows()):\n",
    "        if (idx + 1) % 100 == 0 or idx == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            rate = (idx + 1) / elapsed if elapsed > 0 else 0\n",
    "            remaining = (len(to_extract) - idx - 1) / rate if rate > 0 else 0\n",
    "            ok = len(color_results)\n",
    "            total_so_far = idx + 1\n",
    "            pct = 100 * ok / total_so_far if total_so_far else 0\n",
    "            print(f\"  {idx+1:,}/{len(to_extract):,} \"\n",
    "                  f\"| OK: {ok} ({pct:.0f}%) \"\n",
    "                  f\"| {rate:.1f} img/s \"\n",
    "                  f\"| ETA: {remaining/60:.0f} min\")\n",
    "\n",
    "        url = row[COL_IMAGE]\n",
    "        domain = get_domain(str(url))\n",
    "\n",
    "        colors, error = extract_colors_from_url(\n",
    "            session, domain_tracker, url,\n",
    "            n_colors=N_COLORS, timeout=TIMEOUT, max_retries=MAX_RETRIES,\n",
    "        )\n",
    "\n",
    "        success = colors is not None\n",
    "        domain_tracker.record(domain, success)\n",
    "\n",
    "        if success:\n",
    "            entry = {\n",
    "                'original_index': row_idx,\n",
    "                COL_PRODUCT_ID: row[COL_PRODUCT_ID],\n",
    "                'label_extracted': row['label_extracted'],\n",
    "            }\n",
    "            for i, c in enumerate(colors):\n",
    "                entry[f'color{i+1}_name'] = c['name']\n",
    "                entry[f'color{i+1}_weight'] = c['weight']\n",
    "            color_results.append(entry)\n",
    "        else:\n",
    "            error_counter[error] += 1\n",
    "            failed_records.append({\n",
    "                'product_id': row[COL_PRODUCT_ID],\n",
    "                'url': url,\n",
    "                'label': row['label_extracted'],\n",
    "                'error': error,\n",
    "            })\n",
    "\n",
    "        if (idx + 1) % SAVE_EVERY == 0 and color_results:\n",
    "            total_in_cache = save_incremental(color_results, COLOR_CACHE_PATH)\n",
    "            print(f\"  [checkpoint] {total_in_cache:,} products in cache\")\n",
    "\n",
    "    # Final save\n",
    "    print(f\"\\nSaving...\")\n",
    "    if color_results:\n",
    "        total_in_cache = save_incremental(color_results, COLOR_CACHE_PATH)\n",
    "        print(f\"  Cache: {total_in_cache:,} products -> {COLOR_CACHE_PATH}\")\n",
    "\n",
    "    if failed_records:\n",
    "        pd.DataFrame(failed_records).to_csv(FAILED_URLS_PATH, index=False)\n",
    "        print(f\"  Failed URLs log -> {FAILED_URLS_PATH}\")\n",
    "\n",
    "    # Summary\n",
    "    total = len(to_extract)\n",
    "    success_count = len(color_results)\n",
    "    success_rate = 100 * success_count / total if total else 0\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"SUMMARY\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Processed: {total:,}\")\n",
    "    print(f\"Extracted: {success_count:,} ({success_rate:.1f}%)\")\n",
    "    print(f\"Failed:    {total - success_count:,} ({100 - success_rate:.1f}%)\")\n",
    "\n",
    "    print(\"\\nFailure breakdown:\")\n",
    "    for error, count in error_counter.most_common(10):\n",
    "        print(f\"  {error}: {count} ({100*count/total:.1f}%)\")\n",
    "\n",
    "    print(\"\\nPer-domain results:\")\n",
    "    print(f\"  {'domain':<40s} {'ok':>5s} / {'total':>5s}  {'rate':>6s}\")\n",
    "    print(f\"  {'-'*60}\")\n",
    "    for domain, (ok, tot, rate) in domain_tracker.summary().items():\n",
    "        print(f\"  {domain:<40s} {ok:>5d} / {tot:>5d}  {rate:>5.0%}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STAGE 2: ML GENDER PREDICTION\n",
    "# ============================================================================\n",
    "\n",
    "def run_ml_pipeline():\n",
    "    \"\"\"Stage 2: train classifiers, predict gender, export validation sample.\"\"\"\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.linear_model import LogisticRegressionCV\n",
    "    from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "    from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "    ML_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\"STAGE 2: ML GENDER PREDICTION PIPELINE\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # ---- Load data ----\n",
    "    df = load_main_data()\n",
    "    print(f\"Main dataset: {len(df):,} products\")\n",
    "\n",
    "    human_coded = pd.read_csv(PATH_HUMAN_CODED, encoding='latin-1')\n",
    "    human_coded.columns = human_coded.columns.str.lower().str.strip().str.replace(' ', '_')\n",
    "    if 'unnamed:_0' in human_coded.columns:\n",
    "        human_coded = human_coded.drop(columns=['unnamed:_0'])\n",
    "    print(f\"Human-coded: {len(human_coded)} products\")\n",
    "\n",
    "    try:\n",
    "        your_labeled = pd.read_excel(PATH_YOUR_LABELED)\n",
    "        your_labeled.columns = your_labeled.columns.str.lower().str.strip().str.replace(' ', '_')\n",
    "        print(f\"Your labeled: {len(your_labeled)} products\")\n",
    "    except FileNotFoundError:\n",
    "        your_labeled = pd.DataFrame()\n",
    "        print(\"Your labeled file not found (optional)\")\n",
    "\n",
    "    # ---- Filter and label ----\n",
    "    original_count = len(df)\n",
    "    df = filter_excluded_categories(df)\n",
    "    excluded_count = original_count - len(df)\n",
    "    print(f\"Filtered: {original_count:,} -> {len(df):,} (excluded {excluded_count:,})\")\n",
    "\n",
    "    df = add_gender_labels(df)\n",
    "    print(f\"Label distribution: {df['label_extracted'].value_counts().to_dict()}\")\n",
    "\n",
    "    # Merge human labels\n",
    "    if 'human_gender_label' in human_coded.columns and COL_PRODUCT_ID in human_coded.columns:\n",
    "        human_labels = human_coded[[COL_PRODUCT_ID, 'human_gender_label']].drop_duplicates()\n",
    "        human_labels.columns = [COL_PRODUCT_ID, 'label_human']\n",
    "        human_labels['label_human'] = human_labels['label_human'].str.lower().str.strip()\n",
    "        df = df.merge(human_labels, on=COL_PRODUCT_ID, how='left')\n",
    "    else:\n",
    "        df['label_human'] = None\n",
    "    print(f\"Human labels merged: {df['label_human'].notna().sum()}\")\n",
    "\n",
    "    # ---- Load color cache ----\n",
    "    if COLOR_CACHE_PATH.exists():\n",
    "        color_df = pd.read_csv(COLOR_CACHE_PATH)\n",
    "        print(f\"Color cache: {len(color_df):,} products\")\n",
    "        matched = color_df[COL_PRODUCT_ID].isin(df[COL_PRODUCT_ID]).sum()\n",
    "        print(f\"  Matched to filtered data: {matched:,} / {len(color_df):,}\")\n",
    "    else:\n",
    "        print(\"No color cache found -- proceeding without color features\")\n",
    "        color_df = pd.DataFrame()\n",
    "\n",
    "    # ---- Training data ----\n",
    "    female_all = df[df['label_extracted'] == 'female'].copy()\n",
    "    male_all = df[df['label_extracted'] == 'male'].copy()\n",
    "    print(f\"\\nExplicitly female: {len(female_all)}, male: {len(male_all)}\")\n",
    "\n",
    "    if len(female_all) < MIN_CLASS_SIZE or len(male_all) < MIN_CLASS_SIZE:\n",
    "        raise ValueError(f\"Insufficient gendered samples (need >= {MIN_CLASS_SIZE} per class).\")\n",
    "\n",
    "    human_none = df[df['label_human'] == 'none'].copy()\n",
    "    extracted_none = df[(df['label_extracted'] == 'none') & (df['label_human'].isna())].copy()\n",
    "    min_gendered = min(len(female_all), len(male_all))\n",
    "    target_none = min_gendered\n",
    "\n",
    "    if len(human_none) >= target_none:\n",
    "        none_all = human_none.sample(n=target_none, random_state=RANDOM_STATE)\n",
    "    else:\n",
    "        remaining = target_none - len(human_none)\n",
    "        sampled_none = extracted_none.sample(\n",
    "            n=min(remaining, len(extracted_none)), random_state=RANDOM_STATE)\n",
    "        none_all = pd.concat([human_none, sampled_none])\n",
    "\n",
    "    min_class = min(len(female_all), len(male_all), len(none_all))\n",
    "    print(f\"Balancing to: {min_class} per class\")\n",
    "\n",
    "    female_balanced = female_all.sample(n=min_class, random_state=RANDOM_STATE)\n",
    "    male_balanced = male_all.sample(n=min_class, random_state=RANDOM_STATE)\n",
    "    none_balanced = none_all.sample(n=min_class, random_state=RANDOM_STATE)\n",
    "\n",
    "    ml_data = pd.concat([female_balanced, male_balanced, none_balanced]).copy()\n",
    "    ml_data['target'] = ml_data['label_extracted'].map({'female': 0, 'male': 1})\n",
    "    ml_data.loc[ml_data['target'].isna(), 'target'] = 2\n",
    "    ml_data['target'] = ml_data['target'].astype(int)\n",
    "    print(f\"Training data: {len(ml_data)} (classes: {ml_data['target'].value_counts().sort_index().to_dict()})\")\n",
    "\n",
    "    # ---- Train/test split ----\n",
    "    train_idx, test_idx = train_test_split(\n",
    "        ml_data.index, test_size=TEST_SIZE,\n",
    "        random_state=RANDOM_STATE, stratify=ml_data['target'],\n",
    "    )\n",
    "    train_data = ml_data.loc[train_idx].copy()\n",
    "    test_data = ml_data.loc[test_idx].copy()\n",
    "    print(f\"Train: {len(train_data)}, Test: {len(test_data)}\")\n",
    "\n",
    "    # ---- Feature engineering ----\n",
    "    all_datasets = [train_data, test_data, df]\n",
    "    for dataset in all_datasets:\n",
    "        dataset['breadcrumb_clean'] = dataset[COL_BREADCRUMB].apply(clean_text_remove_gender)\n",
    "        dataset['description_clean'] = dataset[COL_DESC].apply(clean_text_remove_gender)\n",
    "\n",
    "    # Price features\n",
    "    price_features = ['feat_price_log', 'feat_unit_price']\n",
    "    for dataset in all_datasets:\n",
    "        dataset['feat_price'] = pd.to_numeric(dataset[COL_PRICE], errors='coerce')\n",
    "        dataset['feat_price_log'] = np.log1p(dataset['feat_price'])\n",
    "        if COL_UNIT_PRICE in dataset.columns:\n",
    "            dataset['feat_unit_price'] = (\n",
    "                dataset[COL_UNIT_PRICE].astype(str).str.extract(r'([\\d.]+)')[0].astype(float))\n",
    "        else:\n",
    "            dataset['feat_unit_price'] = 0\n",
    "\n",
    "    # Store encoding\n",
    "    store_encoder = LabelEncoder()\n",
    "    all_stores = pd.concat([d[COL_STORE] for d in all_datasets]).fillna('unknown')\n",
    "    store_encoder.fit(all_stores.unique())\n",
    "\n",
    "    def encode_stores(data, encoder):\n",
    "        stores = data[COL_STORE].fillna('unknown')\n",
    "        encoded = []\n",
    "        for s in stores:\n",
    "            if s in encoder.classes_:\n",
    "                encoded.append(encoder.transform([s])[0])\n",
    "            else:\n",
    "                encoded.append(-1)\n",
    "        return np.array(encoded)\n",
    "\n",
    "    for dataset in all_datasets:\n",
    "        dataset['store_encoded'] = encode_stores(dataset, store_encoder)\n",
    "    n_stores = len(store_encoder.classes_) + 1\n",
    "\n",
    "    # TF-IDF (fit on train only)\n",
    "    breadcrumb_vectorizer = TfidfVectorizer(\n",
    "        max_features=80, min_df=8, max_df=0.8, ngram_range=(1, 1), stop_words='english')\n",
    "    breadcrumb_vectorizer.fit(train_data['breadcrumb_clean'])\n",
    "\n",
    "    description_vectorizer = TfidfVectorizer(\n",
    "        max_features=150, min_df=8, max_df=0.8, ngram_range=(1, 1), stop_words='english')\n",
    "    description_vectorizer.fit(train_data['description_clean'])\n",
    "\n",
    "    print(f\"Breadcrumb TF-IDF: {len(breadcrumb_vectorizer.get_feature_names_out())} features\")\n",
    "    print(f\"Description TF-IDF: {len(description_vectorizer.get_feature_names_out())} features\")\n",
    "\n",
    "    # Color features\n",
    "    color_feature_cols = []\n",
    "    for color_name in STANDARD_COLORS.keys():\n",
    "        for i in range(1, N_COLORS + 1):\n",
    "            color_feature_cols.append(f'feat_color{i}_{color_name}')\n",
    "\n",
    "    for dataset in all_datasets:\n",
    "        for col in color_feature_cols:\n",
    "            dataset[col] = 0.0\n",
    "\n",
    "    color_lookup = {}\n",
    "    if len(color_df) > 0 and COL_PRODUCT_ID in color_df.columns:\n",
    "        for _, row in color_df.iterrows():\n",
    "            pid = row[COL_PRODUCT_ID]\n",
    "            feats = {}\n",
    "            for i in range(1, N_COLORS + 1):\n",
    "                cname = row.get(f'color{i}_name')\n",
    "                cweight = row.get(f'color{i}_weight')\n",
    "                if pd.notna(cname) and cname in STANDARD_COLORS and pd.notna(cweight):\n",
    "                    feats[f'feat_color{i}_{cname}'] = cweight\n",
    "            if feats:\n",
    "                color_lookup[pid] = feats\n",
    "\n",
    "        print(f\"Color lookup built: {len(color_lookup):,} products\")\n",
    "        for dataset in all_datasets:\n",
    "            matched = 0\n",
    "            for idx_row, row in dataset.iterrows():\n",
    "                pid = row[COL_PRODUCT_ID]\n",
    "                if pid in color_lookup:\n",
    "                    for col, val in color_lookup[pid].items():\n",
    "                        dataset.at[idx_row, col] = val\n",
    "                    matched += 1\n",
    "            if len(dataset) < 10000:\n",
    "                print(f\"  Color features filled for {matched}/{len(dataset)} rows\")\n",
    "\n",
    "    train_has_color = sum(1 for _, r in train_data.iterrows() if r[COL_PRODUCT_ID] in color_lookup)\n",
    "    print(f\"Color features: {len(color_feature_cols)} \"\n",
    "          f\"(available for {train_has_color}/{len(train_data)} train samples)\")\n",
    "\n",
    "    # ---- Build feature matrices ----\n",
    "    def build_feature_matrix(data, bc_vec, desc_vec, color_cols, p_features,\n",
    "                             ns, include_colors=True):\n",
    "        feature_names = []\n",
    "        blocks = []\n",
    "\n",
    "        X_price = data[p_features].fillna(0).values\n",
    "        blocks.append(csr_matrix(X_price))\n",
    "        feature_names.extend(p_features)\n",
    "\n",
    "        store_enc = data['store_encoded'].values\n",
    "        X_store = np.zeros((len(data), ns))\n",
    "        for i, s in enumerate(store_enc):\n",
    "            if s >= 0:\n",
    "                X_store[i, s] = 1\n",
    "            else:\n",
    "                X_store[i, -1] = 1\n",
    "        blocks.append(csr_matrix(X_store))\n",
    "        feature_names.extend([f'store_{i}' for i in range(ns)])\n",
    "\n",
    "        X_bc = bc_vec.transform(data['breadcrumb_clean'])\n",
    "        blocks.append(X_bc)\n",
    "        feature_names.extend([f'bc_{f}' for f in bc_vec.get_feature_names_out()])\n",
    "\n",
    "        X_desc = desc_vec.transform(data['description_clean'])\n",
    "        blocks.append(X_desc)\n",
    "        feature_names.extend([f'desc_{f}' for f in desc_vec.get_feature_names_out()])\n",
    "\n",
    "        if include_colors:\n",
    "            X_color = data[color_cols].values\n",
    "            blocks.append(csr_matrix(X_color))\n",
    "            feature_names.extend(color_cols)\n",
    "\n",
    "        return hstack(blocks), feature_names\n",
    "\n",
    "    X_train, feature_names = build_feature_matrix(\n",
    "        train_data, breadcrumb_vectorizer, description_vectorizer,\n",
    "        color_feature_cols, price_features, n_stores)\n",
    "    X_test, _ = build_feature_matrix(\n",
    "        test_data, breadcrumb_vectorizer, description_vectorizer,\n",
    "        color_feature_cols, price_features, n_stores)\n",
    "\n",
    "    y_train = train_data['target'].values\n",
    "    y_test = test_data['target'].values\n",
    "    print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "\n",
    "    # ---- Train models ----\n",
    "    results = []\n",
    "\n",
    "    print(\"\\n--- Logistic Regression (L1) ---\")\n",
    "    model_l1 = LogisticRegressionCV(\n",
    "        cv=CV_FOLDS, penalty='l1', solver='saga', max_iter=2000,\n",
    "        multi_class='multinomial', class_weight='balanced', random_state=RANDOM_STATE)\n",
    "    model_l1.fit(X_train, y_train)\n",
    "    y_pred_l1 = model_l1.predict(X_test)\n",
    "    acc_l1 = accuracy_score(y_test, y_pred_l1)\n",
    "    f1_l1 = f1_score(y_test, y_pred_l1, average='weighted')\n",
    "    print(f\"Accuracy: {acc_l1:.4f}, F1: {f1_l1:.4f}\")\n",
    "    results.append({'Model': 'L1 (LASSO)', 'Accuracy': acc_l1, 'F1_weighted': f1_l1})\n",
    "\n",
    "    print(\"\\n--- Logistic Regression (L2) ---\")\n",
    "    model_l2 = LogisticRegressionCV(\n",
    "        cv=CV_FOLDS, penalty='l2', solver='lbfgs', max_iter=2000,\n",
    "        multi_class='multinomial', class_weight='balanced', random_state=RANDOM_STATE)\n",
    "    model_l2.fit(X_train, y_train)\n",
    "    y_pred_l2 = model_l2.predict(X_test)\n",
    "    acc_l2 = accuracy_score(y_test, y_pred_l2)\n",
    "    f1_l2 = f1_score(y_test, y_pred_l2, average='weighted')\n",
    "    print(f\"Accuracy: {acc_l2:.4f}, F1: {f1_l2:.4f}\")\n",
    "    results.append({'Model': 'L2 (Ridge)', 'Accuracy': acc_l2, 'F1_weighted': f1_l2})\n",
    "\n",
    "    print(\"\\n--- Random Forest ---\")\n",
    "    model_rf = RandomForestClassifier(\n",
    "        n_estimators=200, max_depth=15, min_samples_split=10, min_samples_leaf=5,\n",
    "        class_weight='balanced', random_state=RANDOM_STATE, n_jobs=-1)\n",
    "    model_rf.fit(X_train, y_train)\n",
    "    y_pred_rf = model_rf.predict(X_test)\n",
    "    acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "    f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "    print(f\"Accuracy: {acc_rf:.4f}, F1: {f1_rf:.4f}\")\n",
    "    results.append({'Model': 'Random Forest', 'Accuracy': acc_rf, 'F1_weighted': f1_rf})\n",
    "\n",
    "    print(\"\\n--- Histogram Gradient Boosting ---\")\n",
    "    MAX_HGB_SAMPLES = 50000\n",
    "    if X_train.shape[0] > MAX_HGB_SAMPLES:\n",
    "        sample_idx = np.random.choice(X_train.shape[0], MAX_HGB_SAMPLES, replace=False)\n",
    "        X_train_hgb = X_train[sample_idx].toarray()\n",
    "        y_train_hgb = y_train[sample_idx]\n",
    "    else:\n",
    "        X_train_hgb = X_train.toarray()\n",
    "        y_train_hgb = y_train\n",
    "\n",
    "    model_hgb = HistGradientBoostingClassifier(\n",
    "        max_iter=200, max_depth=10, learning_rate=0.1, random_state=RANDOM_STATE)\n",
    "    model_hgb.fit(X_train_hgb, y_train_hgb)\n",
    "    y_pred_hgb = model_hgb.predict(X_test.toarray())\n",
    "    acc_hgb = accuracy_score(y_test, y_pred_hgb)\n",
    "    f1_hgb = f1_score(y_test, y_pred_hgb, average='weighted')\n",
    "    print(f\"Accuracy: {acc_hgb:.4f}, F1: {f1_hgb:.4f}\")\n",
    "    results.append({'Model': 'Hist Gradient Boosting', 'Accuracy': acc_hgb, 'F1_weighted': f1_hgb})\n",
    "\n",
    "    print(\"\\n--- SVM (RBF) ---\")\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    model_svm = SVC(\n",
    "        kernel='rbf', C=1.0, gamma='scale', class_weight='balanced',\n",
    "        probability=True, random_state=RANDOM_STATE)\n",
    "    model_svm.fit(X_train_scaled, y_train)\n",
    "    y_pred_svm = model_svm.predict(X_test_scaled)\n",
    "    acc_svm = accuracy_score(y_test, y_pred_svm)\n",
    "    f1_svm = f1_score(y_test, y_pred_svm, average='weighted')\n",
    "    print(f\"Accuracy: {acc_svm:.4f}, F1: {f1_svm:.4f}\")\n",
    "    results.append({'Model': 'SVM', 'Accuracy': acc_svm, 'F1_weighted': f1_svm})\n",
    "\n",
    "    results_df = pd.DataFrame(results).sort_values('F1_weighted', ascending=False)\n",
    "    print(f\"\\n{'='*70}\\nMODEL COMPARISON\\n{'='*70}\")\n",
    "    print(results_df.to_string(index=False))\n",
    "    results_df.to_csv(ML_OUTPUT_DIR / 'model_comparison.csv', index=False)\n",
    "\n",
    "    # ---- Best model analysis ----\n",
    "    best_name = results_df.iloc[0]['Model']\n",
    "    print(f\"\\nBest model: {best_name}\")\n",
    "\n",
    "    model_map = {\n",
    "        'L1': (model_l1, y_pred_l1), 'L2': (model_l2, y_pred_l2),\n",
    "        'Random': (model_rf, y_pred_rf), 'Hist': (model_hgb, y_pred_hgb),\n",
    "        'SVM': (model_svm, y_pred_svm),\n",
    "    }\n",
    "    best_model, y_pred_best = model_l1, y_pred_l1  # default\n",
    "    for key, (model, preds) in model_map.items():\n",
    "        if key in best_name:\n",
    "            best_model, y_pred_best = model, preds\n",
    "            break\n",
    "\n",
    "    if len(np.unique(y_test)) == 3:\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred_best, target_names=['female', 'male', 'none']))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred_best, labels=[0, 1, 2])\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(f\"            Predicted\")\n",
    "    print(f\"            female  male  none\")\n",
    "    for i, label in enumerate(['female', 'male', 'none']):\n",
    "        row = cm[i] if i < len(cm) else [0, 0, 0]\n",
    "        print(f\"Actual {label:6s}  {row[0]:4d}  {row[1]:4d}  {row[2]:4d}\")\n",
    "\n",
    "    # ---- Feature importance ----\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'coef_female': model_l1.coef_[0],\n",
    "        'coef_male': model_l1.coef_[1],\n",
    "        'coef_none': model_l1.coef_[2],\n",
    "    })\n",
    "    importance_df['max_abs'] = importance_df[['coef_female', 'coef_male', 'coef_none']].abs().max(axis=1)\n",
    "    importance_df = importance_df.sort_values('max_abs', ascending=False)\n",
    "\n",
    "    for label, col in [('FEMALE', 'coef_female'), ('MALE', 'coef_male'), ('NONE', 'coef_none')]:\n",
    "        top = importance_df[importance_df[col] > 0].nlargest(15, col)\n",
    "        print(f\"\\nTop 15 {label} features:\")\n",
    "        for _, row in top.iterrows():\n",
    "            print(f\"  {row['feature']:40s}: {row[col]:+.4f}\")\n",
    "\n",
    "    importance_df.to_csv(ML_OUTPUT_DIR / 'feature_importance.csv', index=False)\n",
    "\n",
    "    # ---- Predict on all products ----\n",
    "    X_all, _ = build_feature_matrix(\n",
    "        df, breadcrumb_vectorizer, description_vectorizer,\n",
    "        color_feature_cols, price_features, n_stores)\n",
    "\n",
    "    df['ml_prob_female'] = model_l1.predict_proba(X_all)[:, 0]\n",
    "    df['ml_prob_male'] = model_l1.predict_proba(X_all)[:, 1]\n",
    "    df['ml_prob_none'] = model_l1.predict_proba(X_all)[:, 2]\n",
    "    df['ml_pred'] = model_l1.predict(X_all)\n",
    "    df['ml_pred_label'] = df['ml_pred'].map({0: 'female', 1: 'male', 2: 'none'})\n",
    "    df['ml_confidence'] = df[['ml_prob_female', 'ml_prob_male', 'ml_prob_none']].max(axis=1)\n",
    "\n",
    "    print(f\"\\nPrediction distribution:\\n{df['ml_pred_label'].value_counts()}\")\n",
    "\n",
    "    # ---- Color feature impact ----\n",
    "    X_train_no_color, _ = build_feature_matrix(\n",
    "        train_data, breadcrumb_vectorizer, description_vectorizer,\n",
    "        color_feature_cols, price_features, n_stores, include_colors=False)\n",
    "    X_test_no_color, _ = build_feature_matrix(\n",
    "        test_data, breadcrumb_vectorizer, description_vectorizer,\n",
    "        color_feature_cols, price_features, n_stores, include_colors=False)\n",
    "\n",
    "    model_no_color = LogisticRegressionCV(\n",
    "        cv=CV_FOLDS, penalty='l1', solver='saga', max_iter=2000,\n",
    "        multi_class='multinomial', class_weight='balanced', random_state=RANDOM_STATE)\n",
    "    model_no_color.fit(X_train_no_color, y_train)\n",
    "    y_pred_no_color = model_no_color.predict(X_test_no_color)\n",
    "\n",
    "    acc_no_color = accuracy_score(y_test, y_pred_no_color)\n",
    "    f1_no_color = f1_score(y_test, y_pred_no_color, average='weighted')\n",
    "    print(f\"\\nColor impact:\")\n",
    "    print(f\"  WITH colors:    Accuracy={acc_l1:.4f}, F1={f1_l1:.4f}\")\n",
    "    print(f\"  WITHOUT colors: Accuracy={acc_no_color:.4f}, F1={f1_no_color:.4f}\")\n",
    "    print(f\"  Delta:          Accuracy {(acc_l1-acc_no_color)*100:+.2f}pp, \"\n",
    "          f\"F1 {(f1_l1-f1_no_color)*100:+.2f}pp\")\n",
    "\n",
    "    # ---- Morrisons-only HGB color ablation (fairer test) ----\n",
    "    # The above comparison underestimates color's contribution because:\n",
    "    #   - It uses L1 (weakest model) instead of HGB (best model)\n",
    "    #   - Most training rows have zero-filled color columns (Tesco/ASDA)\n",
    "    # Here we restrict to products with actual color data and use HGB.\n",
    "    morrisons_pids = set(color_df[COL_PRODUCT_ID].values) if len(color_df) > 0 else set()\n",
    "    train_morr = train_data[train_data[COL_PRODUCT_ID].isin(morrisons_pids)]\n",
    "    test_morr = test_data[test_data[COL_PRODUCT_ID].isin(morrisons_pids)]\n",
    "\n",
    "    if len(train_morr) >= 30 and len(test_morr) >= 10:\n",
    "        print(f\"\\nMorrisons-only color ablation (HGB):  train={len(train_morr)}, test={len(test_morr)}\")\n",
    "        y_train_morr = train_morr['target'].values\n",
    "        y_test_morr = test_morr['target'].values\n",
    "\n",
    "        # With color\n",
    "        X_train_morr_wc, _ = build_feature_matrix(\n",
    "            train_morr, breadcrumb_vectorizer, description_vectorizer,\n",
    "            color_feature_cols, price_features, n_stores, include_colors=True)\n",
    "        X_test_morr_wc, _ = build_feature_matrix(\n",
    "            test_morr, breadcrumb_vectorizer, description_vectorizer,\n",
    "            color_feature_cols, price_features, n_stores, include_colors=True)\n",
    "\n",
    "        hgb_morr_wc = HistGradientBoostingClassifier(\n",
    "            max_iter=200, max_depth=10, learning_rate=0.1, random_state=RANDOM_STATE)\n",
    "        hgb_morr_wc.fit(X_train_morr_wc.toarray(), y_train_morr)\n",
    "        pred_morr_wc = hgb_morr_wc.predict(X_test_morr_wc.toarray())\n",
    "        acc_morr_wc = accuracy_score(y_test_morr, pred_morr_wc)\n",
    "        f1_morr_wc = f1_score(y_test_morr, pred_morr_wc, average='weighted')\n",
    "\n",
    "        # Without color\n",
    "        X_train_morr_nc, _ = build_feature_matrix(\n",
    "            train_morr, breadcrumb_vectorizer, description_vectorizer,\n",
    "            color_feature_cols, price_features, n_stores, include_colors=False)\n",
    "        X_test_morr_nc, _ = build_feature_matrix(\n",
    "            test_morr, breadcrumb_vectorizer, description_vectorizer,\n",
    "            color_feature_cols, price_features, n_stores, include_colors=False)\n",
    "\n",
    "        hgb_morr_nc = HistGradientBoostingClassifier(\n",
    "            max_iter=200, max_depth=10, learning_rate=0.1, random_state=RANDOM_STATE)\n",
    "        hgb_morr_nc.fit(X_train_morr_nc.toarray(), y_train_morr)\n",
    "        pred_morr_nc = hgb_morr_nc.predict(X_test_morr_nc.toarray())\n",
    "        acc_morr_nc = accuracy_score(y_test_morr, pred_morr_nc)\n",
    "        f1_morr_nc = f1_score(y_test_morr, pred_morr_nc, average='weighted')\n",
    "\n",
    "        morr_delta_acc = (acc_morr_wc - acc_morr_nc) * 100\n",
    "        morr_delta_f1 = (f1_morr_wc - f1_morr_nc) * 100\n",
    "\n",
    "        print(f\"  HGB WITH colors:    Accuracy={acc_morr_wc:.4f}, F1={f1_morr_wc:.4f}\")\n",
    "        print(f\"  HGB WITHOUT colors: Accuracy={acc_morr_nc:.4f}, F1={f1_morr_nc:.4f}\")\n",
    "        print(f\"  Delta (Morrisons HGB): Accuracy {morr_delta_acc:+.2f}pp, F1 {morr_delta_f1:+.2f}pp\")\n",
    "\n",
    "        # Save to summary later\n",
    "        morr_color_ablation = {\n",
    "            'n_train': int(len(train_morr)),\n",
    "            'n_test': int(len(test_morr)),\n",
    "            'hgb_with_colors_acc': float(acc_morr_wc),\n",
    "            'hgb_with_colors_f1': float(f1_morr_wc),\n",
    "            'hgb_without_colors_acc': float(acc_morr_nc),\n",
    "            'hgb_without_colors_f1': float(f1_morr_nc),\n",
    "            'delta_acc_pp': float(morr_delta_acc),\n",
    "            'delta_f1_pp': float(morr_delta_f1),\n",
    "        }\n",
    "    else:\n",
    "        print(f\"\\nMorrisons-only ablation skipped: insufficient data \"\n",
    "              f\"(train={len(train_morr)}, test={len(test_morr)})\")\n",
    "        morr_color_ablation = None\n",
    "\n",
    "    # ---- Validation vs human labels ----\n",
    "    human_labeled = df[df['label_human'].notna()].copy()\n",
    "    print(f\"\\nProducts with human labels: {len(human_labeled)}\")\n",
    "    if len(human_labeled) > 0:\n",
    "        human_labeled['human_encoded'] = human_labeled['label_human'].map(\n",
    "            {'female': 0, 'male': 1, 'none': 2})\n",
    "        valid = human_labeled[human_labeled['human_encoded'].notna()]\n",
    "        if len(valid) >= MIN_TEST_SAMPLES:\n",
    "            acc_human = accuracy_score(valid['human_encoded'], valid['ml_pred'])\n",
    "            print(f\"Accuracy vs human: {acc_human:.4f}\")\n",
    "\n",
    "    # ---- Implicit gendering ----\n",
    "    implicit_female = df[\n",
    "        (df['label_extracted'] == 'none') &\n",
    "        (df['ml_pred_label'] == 'female') &\n",
    "        (df['ml_confidence'] > 0.5)]\n",
    "    implicit_male = df[\n",
    "        (df['label_extracted'] == 'none') &\n",
    "        (df['ml_pred_label'] == 'male') &\n",
    "        (df['ml_confidence'] > 0.5)]\n",
    "\n",
    "    print(f\"\\nImplicit female (>50% conf): {len(implicit_female):,}\")\n",
    "    print(f\"Implicit male (>50% conf): {len(implicit_male):,}\")\n",
    "\n",
    "    # ---- Export validation sample ----\n",
    "    already_labeled = set()\n",
    "    if COL_PRODUCT_ID in human_coded.columns:\n",
    "        already_labeled.update(human_coded[COL_PRODUCT_ID].values)\n",
    "    if len(your_labeled) > 0 and COL_PRODUCT_ID in your_labeled.columns:\n",
    "        already_labeled.update(your_labeled[COL_PRODUCT_ID].values)\n",
    "\n",
    "    available = df[\n",
    "        (~df[COL_PRODUCT_ID].isin(already_labeled)) & (df[COL_IMAGE].notna())].copy()\n",
    "    print(f\"\\nAvailable for validation: {len(available):,}\")\n",
    "\n",
    "    if len(available) > 0:\n",
    "        N_PER = 85\n",
    "        samples = []\n",
    "        for pred, label in [(0, 'female'), (1, 'male'), (2, 'none')]:\n",
    "            pool = available[available['ml_pred'] == pred]\n",
    "            n = min(N_PER, len(pool))\n",
    "            if n > 0:\n",
    "                samples.append(pool.sample(n=n, random_state=RANDOM_STATE))\n",
    "                print(f\"  Sampled {n} {label}\")\n",
    "\n",
    "        if samples:\n",
    "            validation = pd.concat(samples).sample(frac=1, random_state=RANDOM_STATE)\n",
    "            export_cols = [\n",
    "                COL_PRODUCT_ID, COL_NAME, COL_DESC, COL_BREADCRUMB, COL_IMAGE,\n",
    "                COL_URL, COL_PRICE, 'label_extracted', 'ml_pred_label',\n",
    "                'ml_prob_female', 'ml_prob_male', 'ml_prob_none', 'ml_confidence',\n",
    "            ]\n",
    "            export_cols = [c for c in export_cols if c in validation.columns]\n",
    "            validation_export = validation[export_cols].copy()\n",
    "            validation_export['manual_gender'] = ''\n",
    "            validation_export['manual_confidence'] = ''\n",
    "            validation_export['manual_notes'] = ''\n",
    "            validation_export.to_csv(ML_OUTPUT_DIR / 'validation_sample.csv', index=True)\n",
    "            print(f\"Saved validation sample: {len(validation_export)} products\")\n",
    "\n",
    "    # ---- Summary ----\n",
    "    summary = {\n",
    "        'version': '4.0',\n",
    "        'data': {\n",
    "            'original': original_count,\n",
    "            'filtered': int(len(df)),\n",
    "            'excluded': int(excluded_count),\n",
    "            'training_samples': int(len(ml_data)),\n",
    "            'color_samples': int(len(color_df)),\n",
    "            'color_coverage_note': 'Morrisons only; Tesco/ASDA CDN links expired',\n",
    "        },\n",
    "        'models': results,\n",
    "        'color_impact': {\n",
    "            'full_sample_l1': {\n",
    "                'with_colors_f1': float(f1_l1),\n",
    "                'without_colors_f1': float(f1_no_color),\n",
    "            },\n",
    "            'morrisons_only_hgb': morr_color_ablation,\n",
    "        },\n",
    "        'predictions': {\n",
    "            'female': int((df['ml_pred_label'] == 'female').sum()),\n",
    "            'male': int((df['ml_pred_label'] == 'male').sum()),\n",
    "            'none': int((df['ml_pred_label'] == 'none').sum()),\n",
    "        },\n",
    "    }\n",
    "    with open(ML_OUTPUT_DIR / 'summary.json', 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    print(f\"\\nPipeline complete. Outputs in {ML_OUTPUT_DIR}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STAGE 3: REGRESSION ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "def run_regression_analysis():\n",
    "    \"\"\"Stage 3: OLS, quantile, within-category, and by-store regressions.\"\"\"\n",
    "    import statsmodels.api as sm\n",
    "    import statsmodels.formula.api as smf\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.gridspec as gridspec\n",
    "    import seaborn as sns\n",
    "\n",
    "    REG_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    plt.rcParams.update({\n",
    "        'figure.facecolor': 'white', 'axes.facecolor': '#fafafa',\n",
    "        'axes.grid': True, 'grid.alpha': 0.3, 'grid.linestyle': '--',\n",
    "        'font.size': 10, 'axes.titlesize': 12, 'axes.labelsize': 10,\n",
    "    })\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\"STAGE 3: REGRESSION ANALYSIS\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # ---- Load and prepare ----\n",
    "    df = load_main_data()\n",
    "    df = filter_excluded_categories(df)\n",
    "\n",
    "    for col_label, col_source in [('label_bc', COL_BREADCRUMB),\n",
    "                                   ('label_name', COL_NAME),\n",
    "                                   ('label_desc', COL_DESC)]:\n",
    "        df[col_label] = df[col_source].apply(extract_gender_from_text)\n",
    "\n",
    "    def combine_labels(row):\n",
    "        for col in ['label_bc', 'label_name', 'label_desc']:\n",
    "            if row[col] in ('female', 'male'):\n",
    "                return row[col]\n",
    "        return 'none'\n",
    "\n",
    "    df['gender'] = df.apply(combine_labels, axis=1)\n",
    "\n",
    "    df['price_num'] = pd.to_numeric(df[COL_PRICE], errors='coerce')\n",
    "    df = df[df['price_num'].notna() & (df['price_num'] > 0)].copy()\n",
    "    df['log_price'] = np.log(df['price_num'])\n",
    "\n",
    "    if COL_UNIT_PRICE in df.columns:\n",
    "        df['unit_price_num'] = df[COL_UNIT_PRICE].astype(str).str.extract(r'([\\d.]+)')[0].astype(float)\n",
    "\n",
    "    df['store'] = df[COL_STORE].fillna('unknown').astype(str)\n",
    "\n",
    "    # Infer store names\n",
    "    store_names = {}\n",
    "    for sid in df['store'].unique():\n",
    "        sub = df[df['store'] == sid]\n",
    "        bc_sample = sub[COL_BREADCRUMB].dropna().head(10).str.lower()\n",
    "        if bc_sample.str.contains('morrisons').any():\n",
    "            store_names[sid] = 'Morrisons'\n",
    "        elif bc_sample.str.contains('tesco').any():\n",
    "            store_names[sid] = 'Tesco'\n",
    "        elif bc_sample.str.contains('asda').any():\n",
    "            store_names[sid] = 'ASDA'\n",
    "        else:\n",
    "            store_names[sid] = f'Store {sid}'\n",
    "    df['store_name'] = df['store'].map(store_names)\n",
    "\n",
    "    # Breadcrumb parsing\n",
    "    df[['cat1', 'cat2', 'cat3']] = df[COL_BREADCRUMB].apply(\n",
    "        lambda x: pd.Series(parse_breadcrumb(x)))\n",
    "    df['cat_broad'] = df['cat1']\n",
    "    df['cat_mid'] = df['cat1'] + ' > ' + df['cat2']\n",
    "    df['cat_fine'] = df['cat1'] + ' > ' + df['cat2'] + ' > ' + df['cat3']\n",
    "\n",
    "    print(f\"Products with valid prices: {len(df):,}\")\n",
    "    print(f\"\\nGender distribution:\")\n",
    "    for g in ['female', 'male', 'none', 'both']:\n",
    "        sub = df[df['gender'] == g]\n",
    "        if len(sub) > 0:\n",
    "            print(f\"  {g}: {len(sub):,}  (mean {sub['price_num'].mean():.2f}, \"\n",
    "                  f\"median {sub['price_num'].median():.2f})\")\n",
    "\n",
    "    # ---- Analysis sample ----\n",
    "    gendered = df[df['gender'].isin(['female', 'male'])].copy()\n",
    "    gendered['is_female'] = (gendered['gender'] == 'female').astype(int)\n",
    "    print(f\"\\nGendered sample: N = {len(gendered):,} \"\n",
    "          f\"(F: {gendered['is_female'].sum()}, M: {(1-gendered['is_female']).sum()})\")\n",
    "\n",
    "    # ---- Regressions ----\n",
    "    results_table = []\n",
    "\n",
    "    def run_and_record(name, formula, data, controls, coef_name='is_female'):\n",
    "        model = smf.ols(formula, data=data).fit(cov_type='HC1')\n",
    "        coef = model.params[coef_name]\n",
    "        se = model.bse[coef_name]\n",
    "        pval = model.pvalues[coef_name]\n",
    "        pct = (np.exp(coef) - 1) * 100\n",
    "        ci_lo = coef - 1.96 * se\n",
    "        ci_hi = coef + 1.96 * se\n",
    "        results_table.append({\n",
    "            'spec': name, 'coef': coef, 'se': se, 'p': pval, 'pct': pct,\n",
    "            'ci_lo': ci_lo, 'ci_hi': ci_hi,\n",
    "            'pct_lo': (np.exp(ci_lo) - 1) * 100,\n",
    "            'pct_hi': (np.exp(ci_hi) - 1) * 100,\n",
    "            'r2': model.rsquared, 'n': int(model.nobs), 'controls': controls,\n",
    "        })\n",
    "        sig = '***' if pval < 0.01 else ('**' if pval < 0.05 else ('*' if pval < 0.1 else ''))\n",
    "        print(f\"  {name}: coef={coef:+.4f} ({pct:+.1f}%), SE={se:.4f}, \"\n",
    "              f\"p={pval:.4f}{sig}, R2={model.rsquared:.3f}, N={int(model.nobs)}\")\n",
    "        return model\n",
    "\n",
    "    print(\"\\nSpec 1: Raw gap\")\n",
    "    spec1 = run_and_record('(1) Raw gap', 'log_price ~ is_female', gendered, 'None')\n",
    "\n",
    "    print(\"\\nSpec 2: + Store FE\")\n",
    "    run_and_record('(2) + Store FE', 'log_price ~ is_female + C(store)', gendered, 'Store')\n",
    "\n",
    "    # Broad category\n",
    "    cat_counts = gendered['cat_broad'].value_counts()\n",
    "    valid_broad = cat_counts[cat_counts >= 5].index\n",
    "    gen_broad = gendered[gendered['cat_broad'].isin(valid_broad)].copy()\n",
    "    print(f\"\\nSpec 3: + Broad cat FE (N cats: {len(valid_broad)})\")\n",
    "    run_and_record('(3) + Broad cat FE',\n",
    "                   'log_price ~ is_female + C(store) + C(cat_broad)',\n",
    "                   gen_broad, 'Store + Broad cat')\n",
    "\n",
    "    # Mid category\n",
    "    cat_counts = gendered['cat_mid'].value_counts()\n",
    "    valid_mid = cat_counts[cat_counts >= 5].index\n",
    "    gen_mid = gendered[gendered['cat_mid'].isin(valid_mid)].copy()\n",
    "    print(f\"\\nSpec 4: + Mid cat FE (N cats: {len(valid_mid)})\")\n",
    "    run_and_record('(4) + Mid cat FE',\n",
    "                   'log_price ~ is_female + C(store) + C(cat_mid)',\n",
    "                   gen_mid, 'Store + Mid cat')\n",
    "\n",
    "    # Fine category\n",
    "    cat_counts = gendered['cat_fine'].value_counts()\n",
    "    valid_fine = cat_counts[cat_counts >= 5].index\n",
    "    gen_fine = gendered[gendered['cat_fine'].isin(valid_fine)].copy()\n",
    "    print(f\"\\nSpec 5: + Fine cat FE (N cats: {len(valid_fine)})\")\n",
    "    if len(valid_fine) > 0 and len(gen_fine) > 50:\n",
    "        run_and_record('(5) + Fine cat FE',\n",
    "                       'log_price ~ is_female + C(store) + C(cat_fine)',\n",
    "                       gen_fine, 'Store + Fine cat')\n",
    "\n",
    "    # Description TF-IDF\n",
    "    gen_mid['desc_clean'] = gen_mid[COL_DESC].apply(clean_text_remove_gender)\n",
    "    desc_vec = TfidfVectorizer(max_features=100, min_df=5, max_df=0.9,\n",
    "                                ngram_range=(1, 2), stop_words='english')\n",
    "    X_desc = desc_vec.fit_transform(gen_mid['desc_clean'])\n",
    "\n",
    "    y6 = gen_mid['log_price'].values\n",
    "    X6_parts = [\n",
    "        gen_mid[['is_female']].values,\n",
    "        pd.get_dummies(gen_mid['store'], prefix='store', drop_first=True).values,\n",
    "        pd.get_dummies(gen_mid['cat_mid'], prefix='cat', drop_first=True).values,\n",
    "        X_desc.toarray(),\n",
    "    ]\n",
    "    X6 = sm.add_constant(np.hstack(X6_parts))\n",
    "    spec6_model = sm.OLS(y6, X6).fit(cov_type='HC1')\n",
    "\n",
    "    coef6 = spec6_model.params[1]\n",
    "    se6 = spec6_model.bse[1]\n",
    "    pval6 = spec6_model.pvalues[1]\n",
    "    results_table.append({\n",
    "        'spec': '(6) + Description', 'coef': coef6, 'se': se6, 'p': pval6,\n",
    "        'pct': (np.exp(coef6) - 1) * 100,\n",
    "        'ci_lo': coef6 - 1.96 * se6, 'ci_hi': coef6 + 1.96 * se6,\n",
    "        'pct_lo': (np.exp(coef6 - 1.96 * se6) - 1) * 100,\n",
    "        'pct_hi': (np.exp(coef6 + 1.96 * se6) - 1) * 100,\n",
    "        'r2': spec6_model.rsquared, 'n': int(spec6_model.nobs),\n",
    "        'controls': 'Store + Mid cat + Description',\n",
    "    })\n",
    "    sig6 = '***' if pval6 < 0.01 else ('**' if pval6 < 0.05 else ('*' if pval6 < 0.1 else ''))\n",
    "    print(f\"\\nSpec 6: + Description TF-IDF\")\n",
    "    print(f\"  (6) + Description: coef={coef6:+.4f} ({(np.exp(coef6)-1)*100:+.1f}%), \"\n",
    "          f\"SE={se6:.4f}, p={pval6:.4f}{sig6}, R2={spec6_model.rsquared:.3f}\")\n",
    "\n",
    "    # Female x Store interaction\n",
    "    print(f\"\\nSpec 7: Female x Store interaction\")\n",
    "    spec7 = smf.ols('log_price ~ is_female * C(store) + C(cat_mid)',\n",
    "                     data=gen_mid).fit(cov_type='HC1')\n",
    "    print(f\"  Main effect (is_female): {spec7.params['is_female']:+.4f} \"\n",
    "          f\"(p={spec7.pvalues['is_female']:.4f})\")\n",
    "    for param in spec7.params.index:\n",
    "        if 'is_female:' in param:\n",
    "            store_id = param.split('[T.')[1].rstrip(']')\n",
    "            sname = store_names.get(store_id, store_id)\n",
    "            total_effect = spec7.params['is_female'] + spec7.params[param]\n",
    "            pct_effect = (np.exp(total_effect) - 1) * 100\n",
    "            print(f\"  {sname}: total female effect = {total_effect:+.4f} ({pct_effect:+.1f}%), \"\n",
    "                  f\"interaction p={spec7.pvalues[param]:.4f}\")\n",
    "\n",
    "    # Unit price\n",
    "    print(f\"\\nSpec 8: Unit price regression\")\n",
    "    if 'unit_price_num' in gen_mid.columns:\n",
    "        gen_unit = gen_mid[gen_mid['unit_price_num'].notna() & (gen_mid['unit_price_num'] > 0)].copy()\n",
    "        gen_unit['log_unit_price'] = np.log(gen_unit['unit_price_num'])\n",
    "        if len(gen_unit) >= 50:\n",
    "            run_and_record('(8) Unit price',\n",
    "                           'log_unit_price ~ is_female + C(store) + C(cat_mid)',\n",
    "                           gen_unit, 'Store + Mid cat (unit price)')\n",
    "\n",
    "    # Three-way comparison\n",
    "    print(f\"\\nSpec 9: Three-way comparison (none = reference)\")\n",
    "    df_valid = df.copy()\n",
    "    df_valid['is_female'] = (df_valid['gender'] == 'female').astype(int)\n",
    "    df_valid['is_male'] = (df_valid['gender'] == 'male').astype(int)\n",
    "    spec9 = smf.ols('log_price ~ is_female + is_male + C(store)',\n",
    "                     data=df_valid).fit(cov_type='HC1')\n",
    "    print(f\"  is_female: {spec9.params['is_female']:+.4f} (p={spec9.pvalues['is_female']:.4f})\")\n",
    "    print(f\"  is_male:   {spec9.params['is_male']:+.4f} (p={spec9.pvalues['is_male']:.4f})\")\n",
    "\n",
    "    # ---- Quantile regression ----\n",
    "    print(f\"\\n{'='*70}\\nQUANTILE REGRESSION\\n{'='*70}\")\n",
    "    quantiles = [0.10, 0.25, 0.50, 0.75, 0.90]\n",
    "    qreg_results = []\n",
    "\n",
    "    for q in quantiles:\n",
    "        qmodel = smf.quantreg('log_price ~ is_female + C(store)', data=gendered).fit(q=q)\n",
    "        coef_q = qmodel.params['is_female']\n",
    "        se_q = qmodel.bse['is_female']\n",
    "        pval_q = qmodel.pvalues['is_female']\n",
    "        pct_q = (np.exp(coef_q) - 1) * 100\n",
    "        qreg_results.append({\n",
    "            'quantile': q, 'coef': coef_q, 'se': se_q, 'p': pval_q, 'pct': pct_q,\n",
    "            'ci_lo': coef_q - 1.96 * se_q, 'ci_hi': coef_q + 1.96 * se_q,\n",
    "        })\n",
    "        sig = '***' if pval_q < 0.01 else ('**' if pval_q < 0.05 else ('*' if pval_q < 0.1 else ''))\n",
    "        print(f\"  Q{q:.2f}: coef={coef_q:+.4f} ({pct_q:+.1f}%), p={pval_q:.4f}{sig}\")\n",
    "\n",
    "    qreg_df = pd.DataFrame(qreg_results)\n",
    "\n",
    "    print(\"\\n  With mid-category controls:\")\n",
    "    qreg_cat_results = []\n",
    "    for q in quantiles:\n",
    "        try:\n",
    "            qmodel = smf.quantreg('log_price ~ is_female + C(store) + C(cat_mid)',\n",
    "                                    data=gen_mid).fit(q=q, max_iter=5000)\n",
    "            coef_q = qmodel.params['is_female']\n",
    "            se_q = qmodel.bse['is_female']\n",
    "            pval_q = qmodel.pvalues['is_female']\n",
    "            pct_q = (np.exp(coef_q) - 1) * 100\n",
    "            qreg_cat_results.append({\n",
    "                'quantile': q, 'coef': coef_q, 'se': se_q, 'p': pval_q, 'pct': pct_q,\n",
    "                'ci_lo': coef_q - 1.96 * se_q, 'ci_hi': coef_q + 1.96 * se_q,\n",
    "            })\n",
    "            sig = '***' if pval_q < 0.01 else ('**' if pval_q < 0.05 else ('*' if pval_q < 0.1 else ''))\n",
    "            print(f\"  Q{q:.2f}: coef={coef_q:+.4f} ({pct_q:+.1f}%), p={pval_q:.4f}{sig}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Q{q:.2f}: failed ({e})\")\n",
    "    qreg_cat_df = pd.DataFrame(qreg_cat_results) if qreg_cat_results else pd.DataFrame()\n",
    "\n",
    "    # ---- Within-category analysis (bootstrap CIs) ----\n",
    "    print(f\"\\n{'='*70}\\nWITHIN-CATEGORY ANALYSIS (bootstrap CIs)\\n{'='*70}\")\n",
    "    rng = np.random.default_rng(RANDOM_STATE)\n",
    "    category_gaps = []\n",
    "\n",
    "    for cat in gendered['cat_mid'].unique():\n",
    "        sub = gendered[gendered['cat_mid'] == cat]\n",
    "        fem = sub[sub['is_female'] == 1]['price_num']\n",
    "        mal = sub[sub['is_female'] == 0]['price_num']\n",
    "\n",
    "        if len(fem) >= 3 and len(mal) >= 3:\n",
    "            gap_pct = (fem.mean() / mal.mean() - 1) * 100\n",
    "            log_gap = np.log(fem).mean() - np.log(mal).mean()\n",
    "\n",
    "            boot_gaps = []\n",
    "            for _ in range(N_BOOTSTRAP):\n",
    "                f_boot = rng.choice(fem.values, size=len(fem), replace=True)\n",
    "                m_boot = rng.choice(mal.values, size=len(mal), replace=True)\n",
    "                if m_boot.mean() > 0:\n",
    "                    boot_gaps.append((f_boot.mean() / m_boot.mean() - 1) * 100)\n",
    "\n",
    "            ci_lo = np.percentile(boot_gaps, 2.5) if boot_gaps else np.nan\n",
    "            ci_hi = np.percentile(boot_gaps, 97.5) if boot_gaps else np.nan\n",
    "\n",
    "            category_gaps.append({\n",
    "                'category': cat, 'n_female': len(fem), 'n_male': len(mal),\n",
    "                'n_total': len(fem) + len(mal),\n",
    "                'mean_female': fem.mean(), 'mean_male': mal.mean(),\n",
    "                'gap_pct': gap_pct, 'log_gap': log_gap,\n",
    "                'ci_lo': ci_lo, 'ci_hi': ci_hi,\n",
    "                'significant': (ci_lo > 0 and ci_hi > 0) or (ci_lo < 0 and ci_hi < 0),\n",
    "            })\n",
    "\n",
    "    gaps_df = pd.DataFrame(category_gaps).sort_values('gap_pct', ascending=False)\n",
    "\n",
    "    if len(gaps_df) > 0:\n",
    "        print(f\"Categories with both genders (>=3 each): {len(gaps_df)}\")\n",
    "        weighted_gap = np.average(gaps_df['gap_pct'], weights=gaps_df['n_total'])\n",
    "        median_gap = gaps_df['gap_pct'].median()\n",
    "        print(f\"  Weighted mean: {weighted_gap:+.1f}%\")\n",
    "        print(f\"  Median: {median_gap:+.1f}%\")\n",
    "        gaps_df.to_csv(REG_OUTPUT_DIR / 'within_category_gaps.csv', index=False)\n",
    "    else:\n",
    "        median_gap = 0\n",
    "\n",
    "    # ---- By-store analysis ----\n",
    "    print(f\"\\n{'='*70}\\nPINK TAX BY STORE\\n{'='*70}\")\n",
    "    store_results = []\n",
    "    for store_id in gendered['store'].unique():\n",
    "        sub = gendered[gendered['store'] == store_id]\n",
    "        fem = sub[sub['is_female'] == 1]\n",
    "        mal = sub[sub['is_female'] == 0]\n",
    "        sname = store_names.get(store_id, store_id)\n",
    "        if len(fem) >= 10 and len(mal) >= 10:\n",
    "            model = smf.ols('log_price ~ is_female', data=sub).fit(cov_type='HC1')\n",
    "            coef = model.params['is_female']\n",
    "            pval = model.pvalues['is_female']\n",
    "            store_results.append({\n",
    "                'store': sname, 'store_id': store_id,\n",
    "                'n_female': len(fem), 'n_male': len(mal),\n",
    "                'mean_f': fem['price_num'].mean(), 'mean_m': mal['price_num'].mean(),\n",
    "                'coef': coef, 'pct_gap': (np.exp(coef) - 1) * 100,\n",
    "                'p_value': pval, 'significant': pval < 0.05,\n",
    "            })\n",
    "\n",
    "    store_df = pd.DataFrame(store_results).sort_values('pct_gap', ascending=False)\n",
    "    if len(store_df) > 0:\n",
    "        for _, row in store_df.iterrows():\n",
    "            sig = '***' if row['p_value'] < 0.01 else ('**' if row['p_value'] < 0.05 else '')\n",
    "            print(f\"  {row['store']:<15s} F:{row['n_female']:>4.0f} M:{row['n_male']:>4.0f} \"\n",
    "                  f\"gap={row['pct_gap']:>+7.1f}% p={row['p_value']:.4f}{sig}\")\n",
    "        store_df.to_csv(REG_OUTPUT_DIR / 'pink_tax_by_store.csv', index=False)\n",
    "\n",
    "    # ---- Summary table ----\n",
    "    summary_df = pd.DataFrame(results_table)\n",
    "    print(f\"\\n{'='*70}\\nREGRESSION SUMMARY\\n{'='*70}\")\n",
    "    print(f\"{'Spec':<25s} {'Coef':>8s} {'%gap':>8s} {'95% CI':>18s} {'p':>8s} {'R2':>6s} {'N':>6s}\")\n",
    "    for _, row in summary_df.iterrows():\n",
    "        sig = '***' if row['p'] < 0.01 else ('**' if row['p'] < 0.05 else ('*' if row['p'] < 0.1 else ''))\n",
    "        print(f\"{row['spec']:<25s} {row['coef']:>+7.4f} {row['pct']:>+7.1f}% \"\n",
    "              f\"[{row['pct_lo']:>+6.1f}, {row['pct_hi']:>+6.1f}] \"\n",
    "              f\"{row['p']:>7.4f}{sig:<3s} {row['r2']:>5.3f} {row['n']:>6.0f}\")\n",
    "    summary_df.to_csv(REG_OUTPUT_DIR / 'regression_summary.csv', index=False)\n",
    "\n",
    "    # ---- Charts (12 visualisations) ----\n",
    "    print(f\"\\n{'='*70}\\nGENERATING CHARTS\\n{'='*70}\")\n",
    "    plt.rcParams.update(CHART_STYLE)\n",
    "\n",
    "    # 1. Coefficient plot\n",
    "    fig, ax = plt.subplots(figsize=(9, 5))\n",
    "    specs = summary_df['spec'].values\n",
    "    coefs = summary_df['coef'].values\n",
    "    ci_los = summary_df['ci_lo'].values\n",
    "    ci_his = summary_df['ci_hi'].values\n",
    "    y_pos = np.arange(len(specs))\n",
    "    colors = [PALETTE['female'] if c > 0 else PALETTE['male'] for c in coefs]\n",
    "    ax.barh(y_pos, coefs, color=colors, alpha=0.75, edgecolor='#333333', linewidth=0.4, height=0.55)\n",
    "    ax.errorbar(coefs, y_pos, xerr=[coefs - ci_los, ci_his - coefs],\n",
    "                fmt='none', color='#333333', capsize=3, linewidth=1.0, capthick=0.8)\n",
    "    ax.axvline(x=0, color='#1a1a2e', linewidth=0.8, zorder=0)\n",
    "    ax.grid(axis='x', alpha=0.12, linewidth=0.5)\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(specs)\n",
    "    ax.set_xlabel('Coefficient on female indicator (log price)')\n",
    "    ax.invert_yaxis()\n",
    "    for i, (c, p) in enumerate(zip(coefs, summary_df['pct'].values)):\n",
    "        ax.text(ci_his[i] + 0.01, i, f'{p:+.1f}%', va='center', ha='left', fontsize=9,\n",
    "                fontweight='bold' if summary_df.iloc[i]['p'] < 0.05 else 'normal')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(REG_OUTPUT_DIR / '01_coefficient_plot.png', dpi=200, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"  01_coefficient_plot.png\")\n",
    "\n",
    "    # 2. Quantile regression\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "    ax = axes[0]\n",
    "    ax.fill_between(qreg_df['quantile'], qreg_df['ci_lo'], qreg_df['ci_hi'],\n",
    "                    alpha=0.2, color=PALETTE['female'])\n",
    "    ax.plot(qreg_df['quantile'], qreg_df['coef'], 'o-', color=PALETTE['female'], linewidth=2)\n",
    "    ax.axhline(y=0, color='black', linewidth=0.8, linestyle='--')\n",
    "    ax.set_xlabel('Quantile')\n",
    "    ax.set_ylabel('Coefficient on female (log price)')\n",
    "    ax.set_xticks(quantiles)\n",
    "\n",
    "    if len(qreg_cat_df) > 0:\n",
    "        ax = axes[1]\n",
    "        ax.fill_between(qreg_cat_df['quantile'], qreg_cat_df['ci_lo'], qreg_cat_df['ci_hi'],\n",
    "                        alpha=0.2, color=PALETTE['female'])\n",
    "        ax.plot(qreg_cat_df['quantile'], qreg_cat_df['coef'], 'o-',\n",
    "                color=PALETTE['female'], linewidth=2)\n",
    "        ax.axhline(y=0, color='black', linewidth=0.8, linestyle='--')\n",
    "        ax.set_xlabel('Quantile')\n",
    "        ax.set_ylabel('Coefficient on female (log price)')\n",
    "        ax.set_xticks(quantiles)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(REG_OUTPUT_DIR / '02_quantile_regression.png', dpi=200, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"  02_quantile_regression.png\")\n",
    "\n",
    "    # 3. Within-category gaps\n",
    "    if len(gaps_df) > 0:\n",
    "        fig, ax = plt.subplots(figsize=(10, max(5, len(gaps_df) * 0.5)))\n",
    "        gaps_sorted = gaps_df.sort_values('gap_pct')\n",
    "        y_pos = np.arange(len(gaps_sorted))\n",
    "        colors = [PALETTE['female'] if g > 0 else PALETTE['male'] for g in gaps_sorted['gap_pct']]\n",
    "        edge = ['black' if s else 'gray' for s in gaps_sorted['significant']]\n",
    "        bars = ax.barh(y_pos, gaps_sorted['gap_pct'], color=colors, alpha=0.6, height=0.7)\n",
    "        for bar, ec in zip(bars, edge):\n",
    "            bar.set_edgecolor(ec)\n",
    "            bar.set_linewidth(1 if ec == 'black' else 0.3)\n",
    "        ax.errorbar(gaps_sorted['gap_pct'].values, y_pos,\n",
    "                    xerr=[gaps_sorted['gap_pct'].values - gaps_sorted['ci_lo'].values,\n",
    "                          gaps_sorted['ci_hi'].values - gaps_sorted['gap_pct'].values],\n",
    "                    fmt='none', color='black', capsize=3, linewidth=0.8)\n",
    "        ax.axvline(x=0, color='black', linewidth=1)\n",
    "        ax.set_yticks(y_pos)\n",
    "        labels = [f\"{r['category'][:42]} (F:{r['n_female']:.0f}, M:{r['n_male']:.0f})\"\n",
    "                  for _, r in gaps_sorted.iterrows()]\n",
    "        ax.set_yticklabels(labels, fontsize=8)\n",
    "        ax.set_xlabel('Female price premium (%)')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(REG_OUTPUT_DIR / '03_within_category_gaps.png', dpi=200, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"  03_within_category_gaps.png\")\n",
    "\n",
    "    # 4. Price distributions (4 panels)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    for gender, color in [('female', PALETTE['female']), ('male', PALETTE['male'])]:\n",
    "        sub = gendered[gendered['gender'] == gender]\n",
    "        axes[0, 0].hist(sub['price_num'], bins=50, alpha=0.5, color=color,\n",
    "                        label=f'{gender.title()} (n={len(sub)})', density=True)\n",
    "        axes[0, 1].hist(sub['log_price'], bins=50, alpha=0.5, color=color,\n",
    "                        label=f'{gender.title()} (n={len(sub)})', density=True)\n",
    "    axes[0, 0].set_xlabel('Price')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].set_xlim(0, gendered['price_num'].quantile(0.95))\n",
    "    axes[0, 1].set_xlabel('Log price')\n",
    "    axes[0, 1].legend()\n",
    "\n",
    "    data_box = [gendered[gendered['gender'] == 'female']['price_num'],\n",
    "                gendered[gendered['gender'] == 'male']['price_num']]\n",
    "    bp = axes[1, 0].boxplot(data_box, labels=['Female', 'Male'], patch_artist=True,\n",
    "                            showfliers=False, widths=0.5)\n",
    "    bp['boxes'][0].set_facecolor(PALETTE['female'])\n",
    "    bp['boxes'][1].set_facecolor(PALETTE['male'])\n",
    "    for box in bp['boxes']:\n",
    "        box.set_alpha(0.6)\n",
    "    axes[1, 0].set_ylabel('Price')\n",
    "\n",
    "    for gender, color in [('female', PALETTE['female']), ('male', PALETTE['male'])]:\n",
    "        sub = gendered[gendered['gender'] == gender]['price_num'].sort_values()\n",
    "        cdf = np.arange(1, len(sub) + 1) / len(sub)\n",
    "        axes[1, 1].plot(sub, cdf, color=color, label=gender.title(), linewidth=1.5)\n",
    "    axes[1, 1].set_xlabel('Price')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].set_xlim(0, gendered['price_num'].quantile(0.95))\n",
    "    for ax_flat in axes.flat:\n",
    "        ax_flat.grid(axis='y', alpha=0.1, linewidth=0.5)\n",
    "        ax_flat.set_axisbelow(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(REG_OUTPUT_DIR / '04_price_distributions.png', dpi=200, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"  04_price_distributions.png\")\n",
    "\n",
    "    # 5. By store\n",
    "    if len(store_df) > 0:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        store_sorted = store_df.sort_values('pct_gap')\n",
    "        y_pos = np.arange(len(store_sorted))\n",
    "        colors = [PALETTE['female'] if g > 0 else PALETTE['male'] for g in store_sorted['pct_gap']]\n",
    "        edge_w = [2 if s else 0.5 for s in store_sorted['significant']]\n",
    "        bars = axes[0].barh(y_pos, store_sorted['pct_gap'], color=colors, alpha=0.7, height=0.5)\n",
    "        for bar, lw in zip(bars, edge_w):\n",
    "            bar.set_edgecolor('black')\n",
    "            bar.set_linewidth(lw)\n",
    "        axes[0].axvline(x=0, color='black', linewidth=1)\n",
    "        axes[0].set_yticks(y_pos)\n",
    "        axes[0].set_yticklabels(store_sorted['store'].values)\n",
    "        axes[0].set_xlabel('Female price premium (%)')\n",
    "\n",
    "        x = np.arange(len(store_df))\n",
    "        w = 0.35\n",
    "        axes[1].bar(x - w/2, store_df['mean_f'], w, color=PALETTE['female'],\n",
    "                    alpha=0.7, label='Female', edgecolor='black', linewidth=0.3)\n",
    "        axes[1].bar(x + w/2, store_df['mean_m'], w, color=PALETTE['male'],\n",
    "                    alpha=0.7, label='Male', edgecolor='black', linewidth=0.3)\n",
    "        axes[1].set_xticks(x)\n",
    "        axes[1].set_xticklabels(store_df['store'].values)\n",
    "        axes[1].set_ylabel('Mean price')\n",
    "        axes[1].legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(REG_OUTPUT_DIR / '05_by_store.png', dpi=200, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"  05_by_store.png\")\n",
    "\n",
    "    # 6. Scatter by category\n",
    "    if len(gaps_df) > 0:\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        ax.scatter(gaps_df['mean_male'], gaps_df['mean_female'],\n",
    "                   s=gaps_df['n_total'] * 5, alpha=0.6,\n",
    "                   c=[PALETTE['female'] if g > 0 else PALETTE['male'] for g in gaps_df['gap_pct']],\n",
    "                   edgecolors='black', linewidth=0.5)\n",
    "        lim_max = max(gaps_df['mean_male'].max(), gaps_df['mean_female'].max()) * 1.1\n",
    "        ax.plot([0, lim_max], [0, lim_max], 'k--', linewidth=0.8, alpha=0.5, label='Equal price')\n",
    "        ax.set_xlabel('Mean male price')\n",
    "        ax.set_ylabel('Mean female price')\n",
    "        ax.legend()\n",
    "        ax.set_aspect('equal')\n",
    "        for _, row in gaps_df.nlargest(3, 'gap_pct').iterrows():\n",
    "            ax.annotate(row['category'][:30], (row['mean_male'], row['mean_female']),\n",
    "                        fontsize=7, alpha=0.8, xytext=(5, 5), textcoords='offset points')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(REG_OUTPUT_DIR / '06_scatter_by_category.png', dpi=200, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"  06_scatter_by_category.png\")\n",
    "\n",
    "    # 7. Three-way comparison\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "    for gender, color in [('female', PALETTE['female']), ('male', PALETTE['male']),\n",
    "                           ('none', PALETTE['none'])]:\n",
    "        sub = df[df['gender'] == gender]\n",
    "        axes[0].hist(sub['log_price'], bins=60, alpha=0.4, color=color, density=True,\n",
    "                     label=f'{gender.title()} (n={len(sub):,})')\n",
    "    axes[0].set_xlabel('Log price')\n",
    "    axes[0].legend()\n",
    "\n",
    "    groups = ['female', 'male', 'none']\n",
    "    data_3way = [df[df['gender'] == g]['price_num'] for g in groups]\n",
    "    bp = axes[1].boxplot(data_3way, labels=[g.title() for g in groups],\n",
    "                         patch_artist=True, showfliers=False, widths=0.5)\n",
    "    for i, box in enumerate(bp['boxes']):\n",
    "        box.set_facecolor(PALETTE[groups[i]])\n",
    "        box.set_alpha(0.6)\n",
    "    axes[1].set_ylabel('Price')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(REG_OUTPUT_DIR / '07_three_way_comparison.png', dpi=200, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"  07_three_way_comparison.png\")\n",
    "\n",
    "    # 8. Category composition\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    for ax_idx, (gender, title) in enumerate([('female', 'Female'), ('male', 'Male')]):\n",
    "        sub = gendered[gendered['gender'] == gender]\n",
    "        top_cats = sub['cat_mid'].value_counts().head(12)\n",
    "        y_pos = np.arange(len(top_cats))\n",
    "        axes[ax_idx].barh(y_pos, top_cats.values, color=PALETTE[gender], alpha=0.7,\n",
    "                          edgecolor='black', linewidth=0.3)\n",
    "        axes[ax_idx].set_yticks(y_pos)\n",
    "        axes[ax_idx].set_yticklabels([c[:40] for c in top_cats.index], fontsize=8)\n",
    "        axes[ax_idx].set_xlabel('Number of products')\n",
    "        axes[ax_idx].invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(REG_OUTPUT_DIR / '08_category_composition.png', dpi=200, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"  08_category_composition.png\")\n",
    "\n",
    "    # 9. Gap distribution\n",
    "    if len(gaps_df) > 0:\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        ax.hist(gaps_df['gap_pct'], bins=max(5, len(gaps_df) // 2), alpha=0.6,\n",
    "                color=PALETTE['female'], edgecolor='black', linewidth=0.5)\n",
    "        ax.axvline(x=0, color='black', linewidth=1.5)\n",
    "        ax.axvline(x=gaps_df['gap_pct'].median(), color=PALETTE['female'],\n",
    "                   linewidth=1.5, linestyle='--',\n",
    "                   label=f'Median: {gaps_df[\"gap_pct\"].median():+.1f}%')\n",
    "        ax.set_xlabel('Female price premium (%)')\n",
    "        ax.set_ylabel('Number of categories')\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(REG_OUTPUT_DIR / '09_gap_distribution.png', dpi=200, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"  09_gap_distribution.png\")\n",
    "\n",
    "    # 10. R2 progression\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    y_pos = np.arange(len(summary_df))\n",
    "    ax.barh(y_pos, summary_df['r2'], color='#555555', alpha=0.7,\n",
    "            edgecolor='black', linewidth=0.5, height=0.6)\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(summary_df['spec'])\n",
    "    ax.set_xlabel('R2')\n",
    "    ax.invert_yaxis()\n",
    "    for i, r2 in enumerate(summary_df['r2']):\n",
    "        ax.text(r2 + 0.01, i, f'{r2:.3f}', va='center', fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(REG_OUTPUT_DIR / '10_r2_progression.png', dpi=200, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"  10_r2_progression.png\")\n",
    "\n",
    "    # 11. Heatmap: category x store\n",
    "    heatmap_data = []\n",
    "    for cat in gendered['cat_mid'].unique():\n",
    "        for store_id in gendered['store'].unique():\n",
    "            sub = gendered[(gendered['cat_mid'] == cat) & (gendered['store'] == store_id)]\n",
    "            fem = sub[sub['is_female'] == 1]\n",
    "            mal = sub[sub['is_female'] == 0]\n",
    "            if len(fem) >= 2 and len(mal) >= 2:\n",
    "                gap = (fem['price_num'].mean() / mal['price_num'].mean() - 1) * 100\n",
    "                heatmap_data.append({\n",
    "                    'category': cat[:35],\n",
    "                    'store': store_names.get(store_id, store_id),\n",
    "                    'gap': gap, 'n': len(fem) + len(mal),\n",
    "                })\n",
    "\n",
    "    if heatmap_data:\n",
    "        heat_df = pd.DataFrame(heatmap_data)\n",
    "        pivot = heat_df.pivot_table(values='gap', index='category', columns='store', aggfunc='mean')\n",
    "        pivot = pivot.dropna(thresh=2)\n",
    "        if len(pivot) > 0:\n",
    "            fig, ax = plt.subplots(figsize=(8, max(5, len(pivot) * 0.45)))\n",
    "            sns.heatmap(pivot, cmap='RdBu_r', center=0, annot=True, fmt='.0f',\n",
    "                        linewidths=0.5, ax=ax, cbar_kws={'label': 'F vs M gap (%)'})\n",
    "            ax.set_ylabel('')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(REG_OUTPUT_DIR / '11_heatmap_category_store.png', dpi=200, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(\"  11_heatmap_category_store.png\")\n",
    "\n",
    "    # 12. Summary dashboard\n",
    "    fig = plt.figure(figsize=(14, 8))\n",
    "    gs = gridspec.GridSpec(2, 3, figure=fig, hspace=0.4, wspace=0.35)\n",
    "\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, 0.85, 'KEY FINDING', ha='center', fontsize=14, fontweight='bold')\n",
    "    ax.text(0.5, 0.60, f'Raw gap: {(np.exp(spec1.params[\"is_female\"])-1)*100:+.1f}%',\n",
    "            ha='center', fontsize=18, color=PALETTE['male'], fontweight='bold')\n",
    "    ax.text(0.5, 0.40, '(female products cheaper)', ha='center', fontsize=10, color='gray')\n",
    "    ax.text(0.5, 0.15, f'After controls: {summary_df.iloc[-1][\"pct\"]:+.1f}%\\n(not significant)',\n",
    "            ha='center', fontsize=12, color='gray')\n",
    "\n",
    "    ax = fig.add_subplot(gs[0, 1])\n",
    "    y_pos = np.arange(len(summary_df))\n",
    "    colors = [PALETTE['female'] if c > 0 else PALETTE['male'] for c in summary_df['coef']]\n",
    "    ax.barh(y_pos, summary_df['pct'], color=colors, alpha=0.7, height=0.6)\n",
    "    ax.axvline(x=0, color='black', linewidth=1)\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels([s[:18] for s in summary_df['spec']], fontsize=8)\n",
    "    ax.set_xlabel('% gap')\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    ax = fig.add_subplot(gs[0, 2])\n",
    "    ax.barh(y_pos, summary_df['r2'], color='#666', alpha=0.7, height=0.6)\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels([s[:18] for s in summary_df['spec']], fontsize=8)\n",
    "    ax.set_xlabel('R2')\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    ax = fig.add_subplot(gs[1, 0])\n",
    "    for gender, color in [('female', PALETTE['female']), ('male', PALETTE['male'])]:\n",
    "        sub = gendered[gendered['gender'] == gender]\n",
    "        ax.hist(sub['log_price'], bins=40, alpha=0.5, color=color, density=True, label=gender.title())\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.set_xlabel('Log price')\n",
    "\n",
    "    ax = fig.add_subplot(gs[1, 1])\n",
    "    ax.fill_between(qreg_df['quantile'], qreg_df['ci_lo'], qreg_df['ci_hi'],\n",
    "                    alpha=0.2, color=PALETTE['female'])\n",
    "    ax.plot(qreg_df['quantile'], qreg_df['coef'], 'o-', color=PALETTE['female'], linewidth=2)\n",
    "    ax.axhline(y=0, color='black', linewidth=0.8, linestyle='--')\n",
    "    ax.set_xlabel('Quantile')\n",
    "    ax.set_ylabel('Coefficient')\n",
    "\n",
    "    if len(store_df) > 0:\n",
    "        ax = fig.add_subplot(gs[1, 2])\n",
    "        y_pos = np.arange(len(store_df))\n",
    "        colors = [PALETTE['female'] if g > 0 else PALETTE['male'] for g in store_df['pct_gap']]\n",
    "        ax.barh(y_pos, store_df['pct_gap'], color=colors, alpha=0.7, height=0.5)\n",
    "        ax.axvline(x=0, color='black', linewidth=1)\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels(store_df['store'].values, fontsize=9)\n",
    "        ax.set_xlabel('% gap')\n",
    "\n",
    "    plt.savefig(REG_OUTPUT_DIR / '12_summary_dashboard.png', dpi=200, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"  12_summary_dashboard.png\")\n",
    "\n",
    "    # 13. Waterfall decomposition chart\n",
    "    # Shows how each layer of controls shifts the female coefficient\n",
    "    if len(summary_df) >= 4:\n",
    "        fig, ax = plt.subplots(figsize=(10, 5.5))\n",
    "\n",
    "        # Extract the key specs in order\n",
    "        spec_labels = summary_df['spec'].values\n",
    "        pct_gaps = summary_df['pct'].values\n",
    "        p_vals = summary_df['p'].values\n",
    "\n",
    "        # Build waterfall: each bar shows the CHANGE from the previous spec\n",
    "        n = len(spec_labels)\n",
    "        starts = np.zeros(n)\n",
    "        deltas = np.zeros(n)\n",
    "        deltas[0] = pct_gaps[0]  # first bar starts from 0\n",
    "        starts[0] = 0\n",
    "        for i in range(1, n):\n",
    "            deltas[i] = pct_gaps[i] - pct_gaps[i - 1]\n",
    "            starts[i] = pct_gaps[i - 1]\n",
    "\n",
    "        # Colors: negative deltas (moving toward male premium) in blue,\n",
    "        # positive (moving toward female premium) in red\n",
    "        bar_colors = []\n",
    "        for i in range(n):\n",
    "            if i == 0:\n",
    "                bar_colors.append(PALETTE['male'] if pct_gaps[0] < 0 else PALETTE['female'])\n",
    "            elif i == n - 1:\n",
    "                # Final bar: show the total level\n",
    "                bar_colors.append('#555555')\n",
    "            else:\n",
    "                bar_colors.append(PALETTE['female'] if deltas[i] > 0 else PALETTE['male'])\n",
    "\n",
    "        y_pos = np.arange(n)\n",
    "\n",
    "        # Draw connecting lines between bars\n",
    "        for i in range(n - 1):\n",
    "            ax.plot([pct_gaps[i], pct_gaps[i]], [i + 0.35, i + 0.65],\n",
    "                    color='#999999', linewidth=0.8, linestyle=':', zorder=0)\n",
    "\n",
    "        # For the last bar, draw it as a total (from 0 to final value)\n",
    "        bars = ax.barh(y_pos[:-1], deltas[:-1], left=starts[:-1],\n",
    "                       color=bar_colors[:-1], alpha=0.75, height=0.55,\n",
    "                       edgecolor='#333333', linewidth=0.4)\n",
    "        # Final \"total\" bar from 0\n",
    "        ax.barh(y_pos[-1], pct_gaps[-1], left=0,\n",
    "                color=bar_colors[-1], alpha=0.75, height=0.55,\n",
    "                edgecolor='#333333', linewidth=0.4)\n",
    "\n",
    "        ax.axvline(x=0, color='#1a1a2e', linewidth=0.8, zorder=0)\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels(spec_labels, fontsize=9.5)\n",
    "        ax.set_xlabel('Female price gap (%)')\n",
    "        ax.invert_yaxis()\n",
    "        ax.grid(axis='x', alpha=0.12, linewidth=0.5)\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "        # Annotate each bar with the cumulative value\n",
    "        for i in range(n):\n",
    "            sig_mark = '' if p_vals[i] < 0.05 else ' (n.s.)'\n",
    "            x_pos = pct_gaps[i]\n",
    "            ha = 'left' if x_pos >= 0 else 'right'\n",
    "            offset = 0.8 if x_pos >= 0 else -0.8\n",
    "            ax.text(x_pos + offset, i, f'{pct_gaps[i]:+.1f}%{sig_mark}',\n",
    "                    va='center', ha=ha, fontsize=9, fontweight='600',\n",
    "                    color='#333333')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(REG_OUTPUT_DIR / '13_waterfall_decomposition.png',\n",
    "                    dpi=200, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"  13_waterfall_decomposition.png\")\n",
    "\n",
    "    # Save full summary JSON\n",
    "    full_summary = {\n",
    "        'raw_gap_pct': float((np.exp(spec1.params['is_female']) - 1) * 100),\n",
    "        'raw_gap_p': float(spec1.pvalues['is_female']),\n",
    "        'controlled_gap_pct': float(summary_df.iloc[-1]['pct']),\n",
    "        'controlled_gap_p': float(summary_df.iloc[-1]['p']),\n",
    "        'within_category_median_gap': float(median_gap) if len(gaps_df) > 0 else None,\n",
    "        'n_gendered_products': int(len(gendered)),\n",
    "        'n_female': int(gendered['is_female'].sum()),\n",
    "        'n_male': int((1 - gendered['is_female']).sum()),\n",
    "        'quantile_results': qreg_df.to_dict('records'),\n",
    "        'store_results': store_df.to_dict('records') if len(store_df) > 0 else [],\n",
    "    }\n",
    "    with open(REG_OUTPUT_DIR / 'full_summary.json', 'w') as f:\n",
    "        json.dump(full_summary, f, indent=2, default=str)\n",
    "\n",
    "    print(f\"\\nAll outputs saved to {REG_OUTPUT_DIR}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# STAGE 4: COLOR VISUALISATIONS\n",
    "# ============================================================================\n",
    "\n",
    "def run_color_charts():\n",
    "    \"\"\"Stage 4: color distribution, importance, and comparison charts.\"\"\"\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.colors as mcolors\n",
    "\n",
    "    VIS_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    plt.rcParams.update(CHART_STYLE)\n",
    "    IMPORTANCE_PATH = ML_OUTPUT_DIR / 'feature_importance.csv'\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\"STAGE 4: COLOR VISUALISATIONS\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    color_df = pd.read_csv(COLOR_CACHE_PATH)\n",
    "    print(f\"Color cache: {len(color_df):,} products\")\n",
    "\n",
    "    has_importance = IMPORTANCE_PATH.exists()\n",
    "    if has_importance:\n",
    "        importance_df = pd.read_csv(IMPORTANCE_PATH)\n",
    "        print(f\"Feature importance: {len(importance_df)} features\")\n",
    "    else:\n",
    "        importance_df = None\n",
    "        print(\"No feature_importance.csv found -- will skip LASSO charts\")\n",
    "\n",
    "    # Build frequency table by gender\n",
    "    color_gender = color_df[['label_extracted', 'color1_name']].copy()\n",
    "    color_gender = color_gender[color_gender['label_extracted'].isin(['female', 'male', 'none'])]\n",
    "    color_gender = color_gender.rename(columns={'color1_name': 'color'})\n",
    "\n",
    "    freq = color_gender.groupby(['label_extracted', 'color']).size().unstack(fill_value=0)\n",
    "    freq_pct = freq.div(freq.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    mask = (freq_pct > 1).any(axis=0)\n",
    "    freq_pct_filtered = freq_pct.loc[:, mask].copy()\n",
    "    col_order = freq_pct_filtered.sum().sort_values(ascending=False).index\n",
    "    freq_pct_filtered = freq_pct_filtered[col_order]\n",
    "    print(f\"Colors with >1% share: {len(col_order)}\")\n",
    "\n",
    "    # ---- Chart 1: Color distribution by gender ----\n",
    "    print(\"\\nGenerating color distribution chart...\")\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 6), sharey=False)\n",
    "    fig.patch.set_facecolor('white')\n",
    "\n",
    "    gender_labels = {'female': 'Female Products', 'male': 'Male Products', 'none': 'Neutral Products'}\n",
    "    gender_accent = {'female': '#c44e52', 'male': '#4c72b0', 'none': '#777777'}\n",
    "\n",
    "    for ax_idx, gender in enumerate(['female', 'male', 'none']):\n",
    "        ax = axes[ax_idx]\n",
    "        if gender not in freq_pct_filtered.index:\n",
    "            ax.set_visible(False)\n",
    "            continue\n",
    "\n",
    "        row = freq_pct_filtered.loc[gender].sort_values(ascending=True).tail(15)\n",
    "        colors_list = row.index.tolist()\n",
    "        values = row.values\n",
    "\n",
    "        bars = ax.barh(range(len(colors_list)), values,\n",
    "                       color=[rgb_norm(c) for c in colors_list],\n",
    "                       edgecolor=[edge_color_for(c) for c in colors_list],\n",
    "                       linewidth=0.8, height=0.7)\n",
    "\n",
    "        for i, (val, cname) in enumerate(zip(values, colors_list)):\n",
    "            if val > 5:\n",
    "                ax.text(val - 0.5, i, f'{val:.1f}%', va='center', ha='right',\n",
    "                        fontsize=8, color=text_color_for_bg(cname), fontweight='500')\n",
    "            else:\n",
    "                ax.text(val + 0.3, i, f'{val:.1f}%', va='center', ha='left',\n",
    "                        fontsize=8, color='#333333')\n",
    "\n",
    "        ax.set_yticks(range(len(colors_list)))\n",
    "        ax.set_yticklabels([c.replace('_', ' ').title() for c in colors_list], fontsize=9)\n",
    "        ax.set_xlabel('Share of products (%)', fontsize=9)\n",
    "        ax.text(0.5, 1.02, gender_labels[gender], transform=ax.transAxes,\n",
    "                ha='center', fontsize=11, fontweight='600', color=gender_accent[gender])\n",
    "        ax.set_xlim(0, max(values) * 1.25)\n",
    "        ax.grid(axis='x', alpha=0.2, linestyle='--')\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "\n",
    "        n = int(freq.loc[gender].sum()) if gender in freq.index else 0\n",
    "        ax.text(0.97, 0.03, f'n = {n:,}', transform=ax.transAxes,\n",
    "                ha='right', va='bottom', fontsize=8, color='#999999')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(VIS_OUTPUT_DIR / 'color_distribution_by_gender.png', dpi=180,\n",
    "                bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "    print(\"  color_distribution_by_gender.png\")\n",
    "\n",
    "    # ---- Chart 2: Color importance (LASSO coefficients) ----\n",
    "    if has_importance:\n",
    "        print(\"\\nGenerating color importance chart...\")\n",
    "        color_feats = importance_df[importance_df['feature'].str.startswith('feat_color1_')].copy()\n",
    "        color_feats['color_name'] = color_feats['feature'].str.replace('feat_color1_', '', regex=False)\n",
    "        color_feats['max_coef'] = color_feats[['coef_female', 'coef_male', 'coef_none']].abs().max(axis=1)\n",
    "        color_feats = color_feats[color_feats['max_coef'] > 0.01].sort_values('max_coef', ascending=False)\n",
    "\n",
    "        if len(color_feats) == 0:\n",
    "            for slot in ['color2_', 'color3_']:\n",
    "                extra = importance_df[importance_df['feature'].str.startswith(f'feat_{slot}')].copy()\n",
    "                extra['color_name'] = extra['feature'].str.replace(f'feat_{slot}', '', regex=False)\n",
    "                extra['max_coef'] = extra[['coef_female', 'coef_male', 'coef_none']].abs().max(axis=1)\n",
    "                color_feats = pd.concat([color_feats, extra[extra['max_coef'] > 0.01]])\n",
    "\n",
    "        if len(color_feats) > 0:\n",
    "            agg = color_feats.groupby('color_name')[['coef_female', 'coef_male', 'coef_none']].sum()\n",
    "            agg['max_abs'] = agg.abs().max(axis=1)\n",
    "            agg = agg.sort_values('max_abs', ascending=False).head(18)\n",
    "\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(16, 7), sharey=True)\n",
    "            fig.patch.set_facecolor('white')\n",
    "            coef_cols = [('coef_female', 'Female', '#c44e52'),\n",
    "                         ('coef_male', 'Male', '#4c72b0'),\n",
    "                         ('coef_none', 'Neutral', '#777777')]\n",
    "\n",
    "            for ax_idx, (col, label, accent) in enumerate(coef_cols):\n",
    "                ax = axes[ax_idx]\n",
    "                sorted_data = agg[col].sort_values()\n",
    "                colors_list = sorted_data.index.tolist()\n",
    "                values = sorted_data.values\n",
    "\n",
    "                ax.barh(range(len(colors_list)), values,\n",
    "                        color=[rgb_norm(c) for c in colors_list],\n",
    "                        edgecolor=[edge_color_for(c) for c in colors_list],\n",
    "                        linewidth=0.8, height=0.7)\n",
    "\n",
    "                for i, (val, cname) in enumerate(zip(values, colors_list)):\n",
    "                    if abs(val) > 0.02:\n",
    "                        side = 'left' if val > 0 else 'right'\n",
    "                        ax.text(val + (0.02 if val > 0 else -0.02), i,\n",
    "                                f'{val:+.2f}', va='center', ha=side, fontsize=7.5, color='#444444')\n",
    "\n",
    "                ax.axvline(x=0, color='#1a1a1a', linewidth=0.8)\n",
    "                ax.set_yticks(range(len(colors_list)))\n",
    "                ax.set_yticklabels([c.replace('_', ' ').title() for c in colors_list], fontsize=9)\n",
    "                ax.set_xlabel('LASSO coefficient', fontsize=9)\n",
    "                ax.text(0.5, 1.02, f'{label} Predictors', transform=ax.transAxes,\n",
    "                        ha='center', fontsize=11, fontweight='600', color=accent)\n",
    "                ax.grid(axis='x', alpha=0.2, linestyle='--')\n",
    "                ax.set_axisbelow(True)\n",
    "                ax.spines['top'].set_visible(False)\n",
    "                ax.spines['right'].set_visible(False)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(VIS_OUTPUT_DIR / 'color_importance.png', dpi=180,\n",
    "                        bbox_inches='tight', facecolor='white')\n",
    "            plt.close()\n",
    "            print(\"  color_importance.png\")\n",
    "\n",
    "    # ---- Chart 3: Color importance heatmap ----\n",
    "    if has_importance:\n",
    "        print(\"\\nGenerating color importance heatmap...\")\n",
    "        all_color = []\n",
    "        for slot in range(1, 4):\n",
    "            prefix = f'feat_color{slot}_'\n",
    "            sub = importance_df[importance_df['feature'].str.startswith(prefix)].copy()\n",
    "            sub['color_name'] = sub['feature'].str.replace(prefix, '', regex=False)\n",
    "            sub['slot'] = slot\n",
    "            all_color.append(sub)\n",
    "\n",
    "        all_color_df = pd.concat(all_color)\n",
    "        heatmap_data = all_color_df.groupby('color_name')[\n",
    "            ['coef_female', 'coef_male', 'coef_none']].sum()\n",
    "        heatmap_data.columns = ['Female', 'Male', 'Neutral']\n",
    "        heatmap_data['max_abs'] = heatmap_data.abs().max(axis=1)\n",
    "        heatmap_data = heatmap_data[heatmap_data['max_abs'] > 0.01].drop(columns='max_abs')\n",
    "        heatmap_data = heatmap_data.sort_values('Female', ascending=True)\n",
    "\n",
    "        if len(heatmap_data) > 0:\n",
    "            n_colors = len(heatmap_data)\n",
    "            fig, ax = plt.subplots(figsize=(8, max(5, n_colors * 0.42)))\n",
    "            fig.patch.set_facecolor('white')\n",
    "\n",
    "            cmap = plt.cm.RdBu_r\n",
    "            max_val = max(abs(heatmap_data.values.min()), abs(heatmap_data.values.max()))\n",
    "            norm = mcolors.TwoSlopeNorm(vmin=-max_val, vcenter=0, vmax=max_val)\n",
    "\n",
    "            data = heatmap_data.values\n",
    "            row_labels = heatmap_data.index.tolist()\n",
    "            col_labels = heatmap_data.columns.tolist()\n",
    "\n",
    "            for i in range(data.shape[0]):\n",
    "                for j in range(data.shape[1]):\n",
    "                    val = data[i, j]\n",
    "                    color = cmap(norm(val))\n",
    "                    rect = plt.Rectangle((j, i), 1, 1, facecolor=color,\n",
    "                                         edgecolor='white', linewidth=1.5)\n",
    "                    ax.add_patch(rect)\n",
    "                    txt_color = 'white' if abs(val) > max_val * 0.45 else '#333333'\n",
    "                    if abs(val) > 0.01:\n",
    "                        ax.text(j + 0.5, i + 0.5, f'{val:+.2f}', ha='center', va='center',\n",
    "                                fontsize=8.5, color=txt_color, fontweight='500')\n",
    "\n",
    "            ax.set_xlim(0, data.shape[1])\n",
    "            ax.set_ylim(0, data.shape[0])\n",
    "            ax.set_xticks([j + 0.5 for j in range(len(col_labels))])\n",
    "            ax.set_xticklabels(col_labels, fontsize=10, fontweight='600')\n",
    "            ax.xaxis.set_ticks_position('top')\n",
    "            ax.set_yticks([i + 0.5 for i in range(len(row_labels))])\n",
    "            ax.set_yticklabels([c.replace('_', ' ').title() for c in row_labels], fontsize=9)\n",
    "\n",
    "            for i, cname in enumerate(row_labels):\n",
    "                swatch = plt.Rectangle((-0.6, i + 0.15), 0.45, 0.7,\n",
    "                                       facecolor=rgb_norm(cname),\n",
    "                                       edgecolor='#aaaaaa' if edge_color_for(cname) != 'none' else 'none',\n",
    "                                       linewidth=0.5, clip_on=False)\n",
    "                ax.add_patch(swatch)\n",
    "\n",
    "            ax.set_xlim(-0.7, data.shape[1])\n",
    "            ax.invert_yaxis()\n",
    "\n",
    "            sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "            sm.set_array([])\n",
    "            cbar = plt.colorbar(sm, ax=ax, fraction=0.03, pad=0.04)\n",
    "            cbar.set_label('L1 coefficient (summed across color slots)', fontsize=9)\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_visible(False)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(VIS_OUTPUT_DIR / 'color_importance_heatmap.png', dpi=180,\n",
    "                        bbox_inches='tight', facecolor='white')\n",
    "            plt.close()\n",
    "            print(\"  color_importance_heatmap.png\")\n",
    "\n",
    "    # ---- Chart 4: Female vs male butterfly chart ----\n",
    "    print(\"\\nGenerating female vs male color comparison...\")\n",
    "    if 'female' in freq_pct_filtered.index and 'male' in freq_pct_filtered.index:\n",
    "        fem = freq_pct_filtered.loc['female']\n",
    "        mal = freq_pct_filtered.loc['male']\n",
    "        all_colors = sorted(set(fem.index) | set(mal.index),\n",
    "                            key=lambda c: fem.get(c, 0) + mal.get(c, 0), reverse=True)[:18]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, max(5, len(all_colors) * 0.38)))\n",
    "        fig.patch.set_facecolor('white')\n",
    "        bar_height = 0.38\n",
    "\n",
    "        for i, cname in enumerate(all_colors):\n",
    "            f_val = fem.get(cname, 0)\n",
    "            m_val = mal.get(cname, 0)\n",
    "            ax.barh(i + bar_height / 2, -f_val, height=bar_height,\n",
    "                    color=rgb_norm(cname), edgecolor=edge_color_for(cname),\n",
    "                    linewidth=0.6, alpha=0.85)\n",
    "            ax.barh(i - bar_height / 2, m_val, height=bar_height,\n",
    "                    color=rgb_norm(cname), edgecolor=edge_color_for(cname),\n",
    "                    linewidth=0.6, alpha=0.85)\n",
    "            if f_val > 1:\n",
    "                ax.text(-f_val - 0.3, i + bar_height / 2, f'{f_val:.1f}%',\n",
    "                        va='center', ha='right', fontsize=7.5, color='#555')\n",
    "            if m_val > 1:\n",
    "                ax.text(m_val + 0.3, i - bar_height / 2, f'{m_val:.1f}%',\n",
    "                        va='center', ha='left', fontsize=7.5, color='#555')\n",
    "\n",
    "        ax.set_yticks(np.arange(len(all_colors)))\n",
    "        ax.set_yticklabels([c.replace('_', ' ').title() for c in all_colors], fontsize=9)\n",
    "        ax.axvline(x=0, color='#1a1a1a', linewidth=0.8)\n",
    "        ax.text(-2, -1.2, '<- Female', fontsize=10, fontweight='600', color='#c44e52',\n",
    "                ha='center', va='center')\n",
    "        ax.text(2, -1.2, 'Male ->', fontsize=10, fontweight='600', color='#4c72b0',\n",
    "                ha='center', va='center')\n",
    "        ax.set_xlabel('Share of products (%)', fontsize=9)\n",
    "        ax.grid(axis='x', alpha=0.15, linestyle='--')\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.invert_yaxis()\n",
    "        x_max = max(fem.max(), mal.max()) * 1.3\n",
    "        ax.set_xlim(-x_max, x_max)\n",
    "        ticks = ax.get_xticks()\n",
    "        ax.set_xticklabels([f'{abs(t):.0f}' for t in ticks])\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(VIS_OUTPUT_DIR / 'color_comparison_butterfly.png', dpi=180,\n",
    "                    bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "        print(\"  color_comparison_butterfly.png\")\n",
    "\n",
    "    print(f\"\\nAll charts saved to {VIS_OUTPUT_DIR}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN ENTRY POINT\n",
    "# ============================================================================\n",
    "\n",
    "STAGE_MAP = {\n",
    "    '1': ('Color extraction', run_color_extraction),\n",
    "    '2': ('ML gender prediction', run_ml_pipeline),\n",
    "    '3': ('Regression analysis', run_regression_analysis),\n",
    "    '4': ('Color visualisations', run_color_charts),\n",
    "}\n",
    "\n",
    "\n",
    "def run_pipeline(stages='all'):\n",
    "    \"\"\"\n",
    "    Run one or more pipeline stages.\n",
    "\n",
    "    Args:\n",
    "        stages: '1', '2', '3', '4', 'all', or a list like ['2', '3'].\n",
    "                Can also pass ints: run_pipeline(3) or run_pipeline([2, 3]).\n",
    "    \n",
    "    Examples (notebook):\n",
    "        run_pipeline('all')\n",
    "        run_pipeline(2)\n",
    "        run_pipeline([2, 3])\n",
    "        run_pipeline('3,4')\n",
    "    \"\"\"\n",
    "    if stages == 'all':\n",
    "        stage_list = ['1', '2', '3', '4']\n",
    "    elif isinstance(stages, (list, tuple)):\n",
    "        stage_list = [str(s) for s in stages]\n",
    "    elif isinstance(stages, int):\n",
    "        stage_list = [str(stages)]\n",
    "    else:\n",
    "        stage_list = [s.strip() for s in str(stages).split(',')]\n",
    "\n",
    "    for stage in stage_list:\n",
    "        if stage not in STAGE_MAP:\n",
    "            print(f\"Unknown stage: {stage}. Choose from 1, 2, 3, 4, or 'all'.\")\n",
    "            continue\n",
    "        name, func = STAGE_MAP[stage]\n",
    "        print(f\"\\n{'#' * 70}\")\n",
    "        print(f\"# RUNNING STAGE {stage}: {name.upper()}\")\n",
    "        print(f\"{'#' * 70}\\n\")\n",
    "        try:\n",
    "            func()\n",
    "        except KeyboardInterrupt:\n",
    "            print(f\"\\nStage {stage} interrupted.\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nStage {stage} failed: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_pipeline('all')\n",
    "    print(\"Usage: run_pipeline(stages) where stages = 1, 2, 3, 4, or 'all'\")\n",
    "    print(\"  e.g. run_pipeline(2)  or  run_pipeline([2, 3])  or  run_pipeline('all')\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
