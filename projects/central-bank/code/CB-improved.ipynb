{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19a103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Shared Infrastructure\n",
    "=====================\n",
    "Data loading, feature engineering, and Markov-switching regime detection.\n",
    "Run this cell first; all subsequent cells depend on the objects created here.\n",
    "\n",
    "Data: 8 monthly US economic series from FRED (1954-2025), merged into a\n",
    "single panel with 833 observations after computing derived variables.\n",
    "\n",
    "Key methodological choices:\n",
    "  - CBO NAIRU (NROU, quarterly, interpolated monthly) for unemployment gap\n",
    "  - Michigan Survey expected inflation (MICH, from 1978); adaptive proxy before\n",
    "  - Hamilton (1989) 2-state Markov-switching model for regime identification\n",
    "\"\"\"\n",
    "\n",
    "import os, warnings, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "import statsmodels.api as sm\n",
    "from scipy.optimize import least_squares\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, roc_auc_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SEED = 42; random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "DATA_PATH  = '/Users/leoss/Desktop/Portfolio/Website-/Central bank/data'\n",
    "OUTPUT_PATH = '/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs'\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "C1, C2, C3, C4, C5 = \"#2563eb\", \"#dc2626\", \"#7c3aed\", \"#f59e0b\", \"#10b981\"\n",
    "C_BG = \"#fafafa\"\n",
    "plt.rcParams.update({\n",
    "    \"figure.facecolor\": C_BG, \"axes.facecolor\": C_BG,\n",
    "    \"axes.grid\": True, \"grid.color\": \"#e5e7eb\", \"grid.linewidth\": 0.5,\n",
    "    \"font.size\": 11, \"axes.spines.top\": False, \"axes.spines.right\": False,\n",
    "})\n",
    "\n",
    "RECESSIONS = [\n",
    "    (\"1973-11\",\"1975-03\"),(\"1980-01\",\"1980-07\"),(\"1981-07\",\"1982-11\"),\n",
    "    (\"1990-07\",\"1991-03\"),(\"2001-03\",\"2001-11\"),(\"2007-12\",\"2009-06\"),(\"2020-02\",\"2020-04\"),\n",
    "]\n",
    "FED_CHAIRS = [\n",
    "    (\"Burns\",\"1970-02\",\"1978-01\"),(\"Miller\",\"1978-03\",\"1979-08\"),\n",
    "    (\"Volcker\",\"1979-08\",\"1987-08\"),(\"Greenspan\",\"1987-08\",\"2006-01\"),\n",
    "    (\"Bernanke\",\"2006-02\",\"2014-01\"),(\"Yellen\",\"2014-02\",\"2018-02\"),(\"Powell\",\"2018-02\",\"2024-12\"),\n",
    "]\n",
    "CHAIR_DATES  = [(ch, pd.Timestamp(s), pd.Timestamp(e)) for ch, s, e in FED_CHAIRS]\n",
    "CHAIR_COLORS = {\"Burns\":\"#dbeafe\",\"Miller\":\"#fee2e2\",\"Volcker\":\"#ede9fe\",\n",
    "                \"Greenspan\":\"#fef3c7\",\"Bernanke\":\"#d1fae5\",\"Yellen\":\"#fce7f3\",\"Powell\":\"#e0e7ff\"}\n",
    "REGIME_COLORS = [C5, C2]\n",
    "\n",
    "def shade_recessions(ax):\n",
    "    for s, e in RECESSIONS:\n",
    "        ax.axvspan(pd.Timestamp(s), pd.Timestamp(e), alpha=0.10, color=\"#fca5a5\", zorder=0)\n",
    "\n",
    "def load_data(path=DATA_PATH):\n",
    "    def _read(names):\n",
    "        for n in names:\n",
    "            p = os.path.join(path, n)\n",
    "            if os.path.exists(p):\n",
    "                return pd.read_csv(p, parse_dates=[\"observation_date\"], index_col=\"observation_date\")\n",
    "        raise FileNotFoundError(f\"None of {names} in {path}\")\n",
    "    cpi    = _read([\"CPIAUCSL.csv\"])\n",
    "    unrate = _read([\"UNRATE.csv\"])\n",
    "    ff     = _read([\"FEDFUNDS.csv\", \"FEDFUNDS-1.csv\"])\n",
    "    tcu    = _read([\"TCU.csv\"])\n",
    "    gs10   = _read([\"GS10.csv\"])\n",
    "    nfci   = _read([\"NFCI.csv\"]).resample(\"MS\").last()\n",
    "    nrou_q = _read([\"NROU.csv\", \"NROUST.csv\"])\n",
    "    nrou_q.index = pd.DatetimeIndex(nrou_q.index)\n",
    "    nrou_m = nrou_q.resample(\"MS\").interpolate(\"linear\")\n",
    "    try: mich = _read([\"MICH.csv\"])\n",
    "    except FileNotFoundError: mich = None\n",
    "    merged = pd.concat([\n",
    "        cpi.rename(columns={cpi.columns[0]: \"cpi\"}),\n",
    "        unrate.rename(columns={unrate.columns[0]: \"unemployment\"}),\n",
    "        ff.rename(columns={ff.columns[0]: \"fed_funds\"}),\n",
    "        tcu.rename(columns={tcu.columns[0]: \"capacity_util\"}),\n",
    "        gs10.rename(columns={gs10.columns[0]: \"treasury_10y\"}),\n",
    "        nfci.rename(columns={nfci.columns[0]: \"fin_conditions\"}),\n",
    "        nrou_m.rename(columns={nrou_m.columns[0]: \"nrou\"}),\n",
    "    ], axis=1).dropna(subset=[\"cpi\",\"unemployment\",\"fed_funds\",\"nrou\"])\n",
    "    if mich is not None:\n",
    "        merged = merged.join(mich.rename(columns={mich.columns[0]: \"expected_inflation\"}), how=\"left\")\n",
    "    else: merged[\"expected_inflation\"] = np.nan\n",
    "    return merged\n",
    "\n",
    "def engineer_features(data):\n",
    "    df = data.copy()\n",
    "    df[\"inflation\"]     = df[\"cpi\"].pct_change(12) * 100\n",
    "    df[\"unemp_gap\"]     = df[\"unemployment\"] - df[\"nrou\"]\n",
    "    df[\"capacity_gap\"]  = df[\"capacity_util\"] - 100.0\n",
    "    df[\"term_spread\"]   = df[\"treasury_10y\"] - df[\"fed_funds\"]\n",
    "    df[\"real_rate\"]     = df[\"fed_funds\"] - df[\"inflation\"]\n",
    "    df[\"delta_ff\"]      = df[\"fed_funds\"].diff()\n",
    "    df[\"delta_pi\"]      = df[\"inflation\"].diff()\n",
    "    df[\"delta_u\"]       = df[\"unemployment\"].diff()\n",
    "    df[\"ff_lag1\"]       = df[\"fed_funds\"].shift(1)\n",
    "    df[\"adaptive_pi_e\"] = df[\"inflation\"].rolling(12).mean()\n",
    "    df[\"pi_expected\"]   = df[\"expected_inflation\"].fillna(df[\"adaptive_pi_e\"])\n",
    "    for var in [\"inflation\",\"unemp_gap\",\"capacity_gap\",\"fed_funds\",\"term_spread\",\"fin_conditions\"]:\n",
    "        for lag in [1, 3, 6, 12]:\n",
    "            df[f\"L{lag}_{var}\"] = df[var].shift(lag)\n",
    "    for h in [1, 3, 6, 12]:\n",
    "        df[f\"inflation_{h}m_ahead\"] = df[\"inflation\"].shift(-h)\n",
    "    df[\"recession\"] = 0\n",
    "    for start, end in RECESSIONS:\n",
    "        df.loc[(df.index >= start) & (df.index <= end), \"recession\"] = 1\n",
    "    df = df.dropna(subset=[\"inflation\",\"L12_inflation\"])\n",
    "    df.index = pd.DatetimeIndex(df.index)\n",
    "    return df\n",
    "\n",
    "def fit_regimes(df, n_regimes=2):\n",
    "    endog = df[\"inflation\"].copy()\n",
    "    exog  = sm.add_constant(df[[\"unemployment\"]].copy())\n",
    "    mod   = sm.tsa.MarkovRegression(endog, k_regimes=n_regimes, exog=exog,\n",
    "                switching_variance=True, switching_exog=True)\n",
    "    best_res, best_llf = None, -np.inf\n",
    "    for attempt in range(8):\n",
    "        try:\n",
    "            res = mod.fit(search_reps=30, random_state=SEED+attempt, disp=False, maxiter=500)\n",
    "            if res.llf > best_llf: best_llf, best_res = res.llf, res\n",
    "        except Exception: continue\n",
    "    if best_res is None: raise RuntimeError(\"MS model failed\")\n",
    "    res = best_res; smoothed = res.smoothed_marginal_probabilities\n",
    "    regime_means = {}\n",
    "    for r in range(n_regimes):\n",
    "        mask = smoothed[r] > 0.5\n",
    "        regime_means[r] = df.loc[mask, \"inflation\"].mean() if mask.sum() > 0 else 0.0\n",
    "    sorted_regimes = sorted(regime_means, key=regime_means.get)\n",
    "    rdf = df.copy()\n",
    "    for new_r in range(n_regimes):\n",
    "        rdf[f\"p_regime_{new_r}\"] = smoothed[sorted_regimes[new_r]].values\n",
    "    rdf[\"regime\"] = np.argmax(\n",
    "        np.column_stack([rdf[f\"p_regime_{r}\"].values for r in range(n_regimes)]), axis=1)\n",
    "    sorted_means = [regime_means[sorted_regimes[r]] for r in range(n_regimes)]\n",
    "    labels = [\"Low\",\"High\"] if n_regimes == 2 else [f\"R{r}\" for r in range(n_regimes)]\n",
    "    regime_names = {r: f\"{labels[r]} inflation ({sorted_means[r]:.1f}%)\" for r in range(n_regimes)}\n",
    "    tm = res.regime_transition\n",
    "    tm_avg = tm.mean(axis=2) if tm.ndim == 3 else tm\n",
    "    return rdf, regime_names, n_regimes, {\n",
    "        \"result\": res, \"sorted_regimes\": sorted_regimes,\n",
    "        \"durations\": res.expected_durations, \"transition_matrix\": tm_avg}\n",
    "\n",
    "print(\"Loading data...\")\n",
    "raw_data = load_data()\n",
    "df = engineer_features(raw_data)\n",
    "print(f\"  {len(df)} observations ({df.index.min():%Y-%m} to {df.index.max():%Y-%m})\")\n",
    "\n",
    "print(\"\\nFitting 2-state Markov-switching model...\")\n",
    "regime_df, regime_names, n_regimes, ms_info = fit_regimes(df, 2)\n",
    "for r in range(n_regimes):\n",
    "    sub = regime_df[regime_df[\"regime\"] == r]\n",
    "    dur = ms_info[\"durations\"][ms_info[\"sorted_regimes\"][r]]\n",
    "    print(f\"  {regime_names[r]}: N={len(sub)}, mean u={sub['unemployment'].mean():.1f}%, \"\n",
    "          f\"mean FFR={sub['fed_funds'].mean():.1f}%, E[dur]={dur:.1f}m ({dur/12:.1f}y)\")\n",
    "tm = ms_info[\"transition_matrix\"]\n",
    "print(f\"\\n  P(stay low)={tm[0,0]:.4f}, P(stay high)={tm[1,1]:.4f}\")\n",
    "print(f\"\\nInfrastructure ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f710f393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Component 1: Markov-Switching Regime Detection\n",
    "===============================================\n",
    "Uses Hamilton (1989) Markov-switching regression via statsmodels.\n",
    "Now includes pre-2020 robustness check to assess COVID-era distortion.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ── Markov-Switching Model ─────────────────────────────────────────\n",
    "def fit_markov_switching(df, n_regimes=2, label=\"\"):\n",
    "    prefix = f\"[{label}] \" if label else \"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"{prefix}MARKOV-SWITCHING REGIME MODEL ({n_regimes} regimes, n={len(df)})\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    endog = df[\"inflation\"].copy()\n",
    "    exog = sm.add_constant(df[[\"unemployment\"]].copy())\n",
    "\n",
    "    mod = sm.tsa.MarkovRegression(\n",
    "        endog, k_regimes=n_regimes, exog=exog,\n",
    "        switching_variance=True, switching_exog=True,\n",
    "    )\n",
    "\n",
    "    best_res, best_llf = None, -np.inf\n",
    "    for attempt in range(8):\n",
    "        try:\n",
    "            res = mod.fit(search_reps=30, random_state=SEED+attempt, disp=False, maxiter=500)\n",
    "            if res.llf > best_llf:\n",
    "                best_llf = res.llf; best_res = res\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    if best_res is None:\n",
    "        print(\"  Model failed to converge.\")\n",
    "        return None\n",
    "\n",
    "    res = best_res\n",
    "    print(f\"\\n  Log-likelihood: {res.llf:.1f}  |  AIC: {res.aic:.1f}  |  BIC: {res.bic:.1f}\")\n",
    "\n",
    "    tm = res.regime_transition\n",
    "    tm_avg = tm.mean(axis=2) if tm.ndim == 3 else tm\n",
    "    print(f\"\\n  Transition matrix (columns = from, rows = to):\")\n",
    "    header = \"  \" + \" \"*12 + \"\".join([f\"  From R{j}\" for j in range(n_regimes)])\n",
    "    print(header)\n",
    "    for i in range(n_regimes):\n",
    "        row = f\"  To R{i}:     \"\n",
    "        for j in range(n_regimes):\n",
    "            row += f\"  {tm_avg[i,j]:7.4f}\"\n",
    "        print(row)\n",
    "\n",
    "    durations = res.expected_durations\n",
    "    print(f\"\\n  Expected durations:\")\n",
    "    for r in range(n_regimes):\n",
    "        print(f\"    Regime {r}: {durations[r]:.1f} months ({durations[r]/12:.1f} years)\")\n",
    "\n",
    "    smoothed = res.smoothed_marginal_probabilities\n",
    "    regime_df = df.copy()\n",
    "\n",
    "    regime_means = {}\n",
    "    for r in range(n_regimes):\n",
    "        mask = smoothed[r] > 0.5\n",
    "        regime_means[r] = df.loc[mask, \"inflation\"].mean() if mask.sum() > 0 else 0.0\n",
    "\n",
    "    sorted_regimes = sorted(regime_means, key=regime_means.get)\n",
    "    for new_r in range(n_regimes):\n",
    "        old_r = sorted_regimes[new_r]\n",
    "        regime_df[f\"p_regime_{new_r}\"] = smoothed[old_r].values\n",
    "\n",
    "    regime_df[\"regime\"] = np.argmax(\n",
    "        np.column_stack([regime_df[f\"p_regime_{r}\"].values for r in range(n_regimes)]),\n",
    "        axis=1)\n",
    "\n",
    "    sorted_means = [regime_means[sorted_regimes[r]] for r in range(n_regimes)]\n",
    "    if n_regimes == 2:\n",
    "        labels = [\"Low\", \"High\"]\n",
    "    elif n_regimes == 3:\n",
    "        labels = [\"Low\", \"Medium\", \"High\"]\n",
    "    else:\n",
    "        labels = [f\"Regime {r}\" for r in range(n_regimes)]\n",
    "    regime_names = {r: f\"{labels[r]} inflation ({sorted_means[r]:.1f}%)\" for r in range(n_regimes)}\n",
    "\n",
    "    print(f\"\\n  {'Regime':<30s}  {'N':>5s}  {'pi':>7s}  {'u':>7s}  {'ff':>7s}  {'spread':>7s}  {'E[dur]':>8s}\")\n",
    "    print(f\"  {'-'*80}\")\n",
    "    for r in range(n_regimes):\n",
    "        sub = regime_df[regime_df[\"regime\"] == r]\n",
    "        dur = durations[sorted_regimes[r]]\n",
    "        print(f\"  {regime_names[r]:<30s}  {len(sub):>5d}  {sub['inflation'].mean():>7.2f}  \"\n",
    "              f\"{sub['unemployment'].mean():>7.2f}  {sub['fed_funds'].mean():>7.2f}  \"\n",
    "              f\"{sub['term_spread'].mean():>7.2f}  {dur:>7.1f}m\")\n",
    "\n",
    "    print(f\"\\n{res.summary()}\")\n",
    "    return res, regime_df, regime_names, n_regimes, sorted_regimes, durations\n",
    "\n",
    "\n",
    "def select_n_regimes(df, max_k=4):\n",
    "    print(f\"\\n  Model selection by BIC:\")\n",
    "    results = {}\n",
    "    for k in range(2, max_k + 1):\n",
    "        endog = df[\"inflation\"].copy()\n",
    "        exog = sm.add_constant(df[[\"unemployment\"]].copy())\n",
    "        mod = sm.tsa.MarkovRegression(endog, k_regimes=k, exog=exog,\n",
    "            switching_variance=True, switching_exog=True)\n",
    "        best_res, best_llf = None, -np.inf\n",
    "        for attempt in range(5):\n",
    "            try:\n",
    "                res = mod.fit(search_reps=20, random_state=SEED+attempt, disp=False, maxiter=500)\n",
    "                if res.llf > best_llf:\n",
    "                    best_llf = res.llf; best_res = res\n",
    "            except:\n",
    "                continue\n",
    "        if best_res:\n",
    "            results[k] = best_res\n",
    "            print(f\"    k={k}: LL={best_res.llf:>8.1f}  AIC={best_res.aic:>8.1f}  BIC={best_res.bic:>8.1f}\")\n",
    "    if not results:\n",
    "        return 2\n",
    "    best_k = min(results, key=lambda k: results[k].bic)\n",
    "    print(f\"    -> Selected: k={best_k}\")\n",
    "    return best_k\n",
    "\n",
    "\n",
    "# ── Pre-2020 robustness check ──────────────────────────────────────\n",
    "def robustness_pre2020(df):\n",
    "    \"\"\"Re-estimate MS model ending sample at 2019:12 to check COVID distortion.\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"ROBUSTNESS: PRE-2020 SAMPLE (excluding COVID-era)\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    df_pre = df.loc[:\"2019-12\"].copy()\n",
    "    print(f\"  Pre-2020 sample: {len(df_pre)} obs ({df_pre.index.min():%Y-%m} to {df_pre.index.max():%Y-%m})\")\n",
    "\n",
    "    result_pre = fit_markov_switching(df_pre, n_regimes=2, label=\"Pre-2020\")\n",
    "    if result_pre is None:\n",
    "        print(\"  Pre-2020 model failed.\")\n",
    "        return None\n",
    "\n",
    "    _, rdf_pre, rn_pre, _, _, dur_pre = result_pre\n",
    "\n",
    "    # Compare to full sample\n",
    "    print(f\"\\n  --- Comparison: Pre-2020 vs Full sample ---\")\n",
    "    return result_pre\n",
    "\n",
    "\n",
    "# ── Visualization ──────────────────────────────────────────────────\n",
    "def plot_regimes(df, regime_df, regime_names, n_regimes, sorted_regimes, durations,\n",
    "                 output_path, suffix=\"\"):\n",
    "    regime_colors = [C5, C1, C4, C2, \"#94a3b8\"][:n_regimes]\n",
    "    sfx = f\"_{suffix}\" if suffix else \"\"\n",
    "\n",
    "    # Fig 1: Smoothed probabilities\n",
    "    n_panels = n_regimes + 1\n",
    "    fig, axes = plt.subplots(n_panels, 1, figsize=(16, 2.5 + 2.2*n_regimes), sharex=True)\n",
    "    if n_panels == 1: axes = [axes]\n",
    "    fig.suptitle(f\"Markov-Switching Inflation Regimes ({n_regimes} states): Smoothed Probabilities\",\n",
    "                 fontweight=\"bold\", fontsize=14, y=0.995)\n",
    "\n",
    "    ax = axes[0]; shade_recessions(ax)\n",
    "    for r in range(n_regimes):\n",
    "        mask = regime_df[\"regime\"] == r\n",
    "        ax.scatter(regime_df.index[mask], regime_df[\"inflation\"][mask],\n",
    "                   c=regime_colors[r], s=6, alpha=0.7, label=regime_names[r], zorder=2)\n",
    "    ax.axhline(2, color=\"grey\", ls=\"--\", lw=1, alpha=0.5)\n",
    "    ax.set_ylabel(\"Inflation (%)\"); ax.set_title(\"Inflation by most likely regime\", fontweight=\"bold\")\n",
    "    ax.legend(frameon=True, fontsize=7, markerscale=2, loc=\"upper right\")\n",
    "\n",
    "    for r in range(n_regimes):\n",
    "        ax = axes[r + 1]; shade_recessions(ax)\n",
    "        ax.fill_between(regime_df.index, regime_df[f\"p_regime_{r}\"], 0,\n",
    "                        alpha=0.4, color=regime_colors[r])\n",
    "        ax.plot(regime_df.index, regime_df[f\"p_regime_{r}\"], lw=1, color=regime_colors[r])\n",
    "        ax.axhline(0.5, color=\"grey\", ls=\"--\", lw=0.8, alpha=0.5)\n",
    "        ax.set_ylabel(\"P(regime)\")\n",
    "        dur = durations[sorted_regimes[r]]\n",
    "        ax.set_title(f\"P({regime_names[r]}) | E[duration]: {dur:.0f} months\",\n",
    "                     fontweight=\"bold\", fontsize=10)\n",
    "        ax.set_ylim(-0.05, 1.05)\n",
    "\n",
    "    axes[-1].set_xlabel(\"Year\")\n",
    "    fig.tight_layout()\n",
    "    path1 = f\"{output_path}/ms_regime_probabilities{sfx}.png\"\n",
    "    fig.savefig(path1, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "    print(f\"  Saved: {path1}\")\n",
    "\n",
    "    # Fig 2: Regime timeline + macro context\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(16, 12), sharex=True,\n",
    "                              gridspec_kw={\"height_ratios\": [1, 2, 2, 2]})\n",
    "    fig.suptitle(\"Inflation Regimes in Macroeconomic Context\",\n",
    "                 fontweight=\"bold\", fontsize=14, y=0.995)\n",
    "\n",
    "    ax = axes[0]\n",
    "    for r in range(n_regimes):\n",
    "        mask = regime_df[\"regime\"] == r\n",
    "        for d in regime_df.index[mask]:\n",
    "            ax.axvspan(d, d + pd.DateOffset(months=1), color=regime_colors[r], alpha=0.8)\n",
    "    for i, (ch, s, e) in enumerate(FED_CHAIRS):\n",
    "        mid = pd.Timestamp(s) + (pd.Timestamp(e)-pd.Timestamp(s))/2\n",
    "        if regime_df.index[0] <= mid <= regime_df.index[-1]:\n",
    "            ax.text(mid, 0.5, ch, ha=\"center\", va=\"center\", fontsize=8,\n",
    "                    fontstyle=\"italic\", alpha=0.7)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(\"Regime assignment with Fed chairs\", fontweight=\"bold\")\n",
    "    legend_elements = [Patch(facecolor=regime_colors[r], alpha=0.8, label=regime_names[r])\n",
    "                       for r in range(n_regimes)]\n",
    "    ax.legend(handles=legend_elements, frameon=True, fontsize=7, loc=\"upper left\",\n",
    "              ncol=min(n_regimes,3))\n",
    "\n",
    "    ax = axes[1]; shade_recessions(ax)\n",
    "    ax.plot(regime_df.index, regime_df[\"inflation\"], lw=1.5, color=\"#374151\")\n",
    "    ax.axhline(2, color=C2, ls=\"--\", lw=1, alpha=0.5, label=\"2% target\")\n",
    "    ax.set_ylabel(\"Inflation (%)\"); ax.set_title(\"YoY Inflation\", fontweight=\"bold\")\n",
    "    ax.legend(frameon=False, fontsize=8)\n",
    "\n",
    "    ax = axes[2]; shade_recessions(ax)\n",
    "    ax.plot(regime_df.index, regime_df[\"fed_funds\"], lw=1.5, color=C1, label=\"Fed funds\")\n",
    "    ax.plot(regime_df.index, regime_df[\"treasury_10y\"], lw=1.2, color=C2, alpha=0.6, label=\"10Y Treasury\")\n",
    "    ax.set_ylabel(\"Rate (%)\"); ax.set_title(\"Interest rates\", fontweight=\"bold\")\n",
    "    ax.legend(frameon=False, fontsize=8)\n",
    "\n",
    "    ax = axes[3]; shade_recessions(ax)\n",
    "    ax.plot(regime_df.index, regime_df[\"unemployment\"], lw=1.5, color=C3, label=\"Unemployment\")\n",
    "    ax.plot(regime_df.index, regime_df[\"nrou\"], lw=1.2, color=C4, ls=\"--\",\n",
    "            alpha=0.7, label=\"CBO NAIRU\")\n",
    "    ax.set_ylabel(\"Rate (%)\"); ax.set_xlabel(\"Year\")\n",
    "    ax.set_title(\"Unemployment rate vs CBO natural rate\", fontweight=\"bold\")\n",
    "    ax.legend(frameon=False, fontsize=8)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    path2 = f\"{output_path}/ms_regime_context{sfx}.png\"\n",
    "    fig.savefig(path2, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "    print(f\"  Saved: {path2}\")\n",
    "\n",
    "    # Fig 3: Distributions by regime\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(16, 8))\n",
    "    fig.suptitle(\"Regime Characteristics\", fontweight=\"bold\", fontsize=14, y=1.01)\n",
    "\n",
    "    for ax, (var, label) in zip(axes.flat, [\n",
    "        (\"inflation\",\"Inflation (%)\"), (\"unemployment\",\"Unemployment (%)\"),\n",
    "        (\"fed_funds\",\"Fed funds (%)\"), (\"real_rate\",\"Real rate (%)\"),\n",
    "        (\"term_spread\",\"Term spread (pp)\"), (\"unemp_gap\",\"Unemployment gap (pp, CBO NAIRU)\")]):\n",
    "\n",
    "        data_list = [regime_df.loc[regime_df[\"regime\"]==r, var].dropna().values\n",
    "                     for r in range(n_regimes)]\n",
    "        bp = ax.boxplot(data_list, patch_artist=True, widths=0.6,\n",
    "                        labels=[f\"R{r}\" for r in range(n_regimes)],\n",
    "                        medianprops=dict(color=\"black\", lw=1.5))\n",
    "        for r, patch in enumerate(bp[\"boxes\"]):\n",
    "            patch.set_facecolor(regime_colors[r]); patch.set_alpha(0.6)\n",
    "        ax.set_title(label, fontweight=\"bold\", fontsize=10)\n",
    "        ax.axhline(0, color=\"grey\", lw=0.5, alpha=0.3)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    path3 = f\"{output_path}/ms_regime_distributions{sfx}.png\"\n",
    "    fig.savefig(path3, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "    print(f\"  Saved: {path3}\")\n",
    "\n",
    "    return [path1, path2, path3]\n",
    "\n",
    "\n",
    "# ── Data overview plot ─────────────────────────────────────────────\n",
    "def plot_data_overview(df, output_path):\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(16, 10), sharex=True)\n",
    "    fig.suptitle(\"US Economic Indicators, 1971-2024\", fontweight=\"bold\", fontsize=14, y=1.0)\n",
    "\n",
    "    panels = [\n",
    "        (\"inflation\", \"CPI Inflation (%)\", C1),\n",
    "        (\"unemployment\", \"Unemployment (%)\", C3),\n",
    "        (\"fed_funds\", \"Fed Funds Rate (%)\", C2),\n",
    "        (\"capacity_util\", \"Capacity Utilisation (%)\", C4),\n",
    "        (\"treasury_10y\", \"10-Year Treasury (%)\", C5),\n",
    "        (\"fin_conditions\", \"Financial Conditions (NFCI)\", \"#6b7280\"),\n",
    "    ]\n",
    "    for ax, (var, title, color) in zip(axes.flat, panels):\n",
    "        shade_recessions(ax)\n",
    "        ax.plot(df.index, df[var], lw=1.2, color=color)\n",
    "        ax.set_title(title, fontweight=\"bold\", fontsize=10)\n",
    "\n",
    "    # Add NAIRU to unemployment panel\n",
    "    axes[0, 1].plot(df.index, df[\"nrou\"], lw=1, color=C4, ls=\"--\", alpha=0.6, label=\"CBO NAIRU\")\n",
    "    axes[0, 1].legend(frameon=False, fontsize=7)\n",
    "\n",
    "    axes[-1, 0].set_xlabel(\"Year\"); axes[-1, 1].set_xlabel(\"Year\")\n",
    "    fig.tight_layout()\n",
    "    path = f\"{output_path}/data_overview.png\"\n",
    "    fig.savefig(path, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "    print(f\"  Saved: {path}\")\n",
    "    return path\n",
    "\n",
    "\n",
    "# ── Main ───────────────────────────────────────────────────────────\n",
    "\n",
    "# Data overview\n",
    "plot_data_overview(df, OUTPUT_PATH)\n",
    "\n",
    "# Model selection\n",
    "best_k = select_n_regimes(df, max_k=4)\n",
    "\n",
    "# Main model\n",
    "result = fit_markov_switching(df, n_regimes=best_k, label=\"Full sample\")\n",
    "all_paths = []\n",
    "if result is not None:\n",
    "    res, regime_df, regime_names, n_regimes, sorted_regimes, durations = result\n",
    "    paths = plot_regimes(df, regime_df, regime_names, n_regimes,\n",
    "                        sorted_regimes, durations, OUTPUT_PATH, suffix=f\"k{best_k}\")\n",
    "    all_paths.extend(paths)\n",
    "\n",
    "# Always show 2-regime for comparison\n",
    "if best_k != 2:\n",
    "    print(\"\\n\\n--- 2-regime baseline for comparison ---\")\n",
    "    result2 = fit_markov_switching(df, n_regimes=2, label=\"2-regime baseline\")\n",
    "    if result2 is not None:\n",
    "        res2, rdf2, rn2, n2, sr2, dur2 = result2\n",
    "        paths2 = plot_regimes(df, rdf2, rn2, n2, sr2, dur2, OUTPUT_PATH, suffix=\"k2\")\n",
    "        all_paths.extend(paths2)\n",
    "\n",
    "# Pre-2020 robustness\n",
    "result_pre = robustness_pre2020(df)\n",
    "if result_pre is not None:\n",
    "    res_pre, rdf_pre, rn_pre, n_pre, sr_pre, dur_pre = result_pre\n",
    "    paths_pre = plot_regimes(df.loc[:\"2019-12\"], rdf_pre, rn_pre, n_pre,\n",
    "                             sr_pre, dur_pre, OUTPUT_PATH, suffix=\"pre2020\")\n",
    "    all_paths.extend(paths_pre)\n",
    "\n",
    "print(f\"\\nAll outputs: {all_paths}\")\n",
    "print(\"Done.\")\n",
    "\n",
    "# ── Within-regime Phillips curves ─────────────────────────────\n",
    "print(\"\\n--- Within-regime Phillips curves (HAC SE) ---\")\n",
    "for r in range(n_regimes):\n",
    "    rsub = regime_df[regime_df[\"regime\"]==r][[\"inflation\",\"unemp_gap\"]].dropna()\n",
    "    X_pc = sm.add_constant(rsub[\"unemp_gap\"])\n",
    "    res_pc = sm.OLS(rsub[\"inflation\"], X_pc).fit(cov_type=\"HAC\", cov_kwds={\"maxlags\": 12})\n",
    "    print(f\"  {regime_names[r]}: beta={res_pc.params['unemp_gap']:.3f}, \"\n",
    "          f\"t={res_pc.tvalues['unemp_gap']:.2f}, R2={res_pc.rsquared:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806b04ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Component 2: Regime-Conditional Taylor Rules\n",
    "=============================================\n",
    "Key changes from original:\n",
    "- CBO NAIRU replaces hardcoded 5% unemployment gap\n",
    "- Expected inflation (MICH / adaptive proxy) specification alongside realized\n",
    "- HAC standard errors via block bootstrap\n",
    "- Pre-2020 robustness check\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ── Get regimes from Markov-switching ──────────────────────────────\n",
    "\n",
    "# ── Taylor Rule NLS (CBO NAIRU) ───────────────────────────────────\n",
    "def taylor_resid(params, y, pi, u_gap, ff_lag):\n",
    "    \"\"\"Residuals for structural Taylor rule using unemployment gap directly.\"\"\"\n",
    "    rho, r_star, a_pi, a_u = params\n",
    "    target = r_star + pi + a_pi * (pi - 2.0) + a_u * u_gap\n",
    "    return y - (rho * ff_lag + (1 - rho) * target)\n",
    "\n",
    "\n",
    "def taylor_resid_expected(params, y, pi_e, u_gap, ff_lag):\n",
    "    \"\"\"Residuals using expected inflation instead of realized.\"\"\"\n",
    "    rho, r_star, a_pi, a_u = params\n",
    "    target = r_star + pi_e + a_pi * (pi_e - 2.0) + a_u * u_gap\n",
    "    return y - (rho * ff_lag + (1 - rho) * target)\n",
    "\n",
    "\n",
    "def fit_taylor_nls(sub, label=\"\", use_expected=False):\n",
    "    \"\"\"Fit structural Taylor rule via NLS. Uses CBO NAIRU for unemployment gap.\"\"\"\n",
    "    y = sub[\"fed_funds\"].values\n",
    "    u_gap = sub[\"unemp_gap\"].values  # already unemployment - NAIRU\n",
    "    ff_lag = sub[\"ff_lag1\"].values\n",
    "\n",
    "    if use_expected:\n",
    "        pi = sub[\"pi_expected\"].values\n",
    "        valid = ~np.isnan(pi)\n",
    "        if valid.sum() < 30:\n",
    "            return None\n",
    "        y, pi, u_gap, ff_lag = y[valid], pi[valid], u_gap[valid], ff_lag[valid]\n",
    "        resid_fn = taylor_resid_expected\n",
    "    else:\n",
    "        pi = sub[\"inflation\"].values\n",
    "        resid_fn = taylor_resid\n",
    "\n",
    "    res = least_squares(resid_fn, [0.85, 2.0, 0.5, 0.5],\n",
    "        args=(y, pi, u_gap, ff_lag),\n",
    "        bounds=([0, -5, -2, -5], [0.999, 10, 5, 5]))\n",
    "\n",
    "    rho, rstar, a_pi, a_u = res.x\n",
    "    n = len(y)\n",
    "    sigma2 = np.sum(res.fun**2) / (n - 4)\n",
    "    J = res.jac\n",
    "    try:\n",
    "        cov = sigma2 * np.linalg.inv(J.T @ J)\n",
    "        se = np.sqrt(np.diag(cov))\n",
    "    except:\n",
    "        se = [np.nan]*4\n",
    "\n",
    "    target = rstar + pi + a_pi * (pi - 2.0) + a_u * u_gap\n",
    "    prescribed = np.maximum(target, 0.0)\n",
    "    ssr = np.sum(res.fun**2)\n",
    "\n",
    "    return {\n",
    "        \"label\": label, \"n\": n, \"use_expected\": use_expected,\n",
    "        \"rho\": rho, \"rstar\": rstar, \"a_pi\": a_pi, \"a_u\": a_u,\n",
    "        \"se\": se, \"ssr\": ssr, \"sigma2\": sigma2,\n",
    "        \"prescribed\": prescribed, \"actual\": y,\n",
    "        \"taylor_principle\": 1 + a_pi,\n",
    "    }\n",
    "\n",
    "\n",
    "# ── HAC standard errors via block bootstrap ───────────────────────\n",
    "def bootstrap_taylor_se(sub, n_boot=500, block_size=12, use_expected=False):\n",
    "    \"\"\"Block bootstrap for HAC-robust standard errors on NLS Taylor rule.\"\"\"\n",
    "    n = len(sub)\n",
    "    boot_params = []\n",
    "\n",
    "    for b in range(n_boot):\n",
    "        # Block bootstrap indices\n",
    "        n_blocks = int(np.ceil(n / block_size))\n",
    "        block_starts = np.random.randint(0, n - block_size + 1, size=n_blocks)\n",
    "        indices = np.concatenate([np.arange(s, s + block_size) for s in block_starts])[:n]\n",
    "\n",
    "        boot_sub = sub.iloc[indices].copy()\n",
    "        y = boot_sub[\"fed_funds\"].values\n",
    "        u_gap = boot_sub[\"unemp_gap\"].values\n",
    "        ff_lag = boot_sub[\"ff_lag1\"].values\n",
    "\n",
    "        if use_expected:\n",
    "            pi = boot_sub[\"pi_expected\"].values\n",
    "            valid = ~np.isnan(pi)\n",
    "            if valid.sum() < 30:\n",
    "                continue\n",
    "            y, pi, u_gap, ff_lag = y[valid], pi[valid], u_gap[valid], ff_lag[valid]\n",
    "            resid_fn = taylor_resid_expected\n",
    "        else:\n",
    "            pi = boot_sub[\"inflation\"].values\n",
    "            resid_fn = taylor_resid\n",
    "\n",
    "        try:\n",
    "            res = least_squares(resid_fn, [0.85, 2.0, 0.5, 0.5],\n",
    "                args=(y, pi, u_gap, ff_lag),\n",
    "                bounds=([0, -5, -2, -5], [0.999, 10, 5, 5]),\n",
    "                max_nfev=300)\n",
    "            boot_params.append(res.x)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    if len(boot_params) < 50:\n",
    "        return [np.nan]*4\n",
    "\n",
    "    boot_params = np.array(boot_params)\n",
    "    return np.std(boot_params, axis=0)\n",
    "\n",
    "\n",
    "# ── Chow test ─────────────────────────────────────────────────────\n",
    "def chow_test(df, break_date, dep=\"delta_ff\", regressors=[\"inflation\",\"unemp_gap\"]):\n",
    "    sub = df[[dep] + regressors].dropna()\n",
    "    before = sub.loc[:break_date]\n",
    "    after = sub.loc[break_date:]\n",
    "    if len(before) < 10 or len(after) < 10:\n",
    "        return np.nan, np.nan\n",
    "    k = len(regressors) + 1\n",
    "    X_pool = sm.add_constant(sub[regressors].values); y_pool = sub[dep].values\n",
    "    res_pool = sm.OLS(y_pool, X_pool).fit()\n",
    "    X1 = sm.add_constant(before[regressors].values); y1 = before[dep].values\n",
    "    res1 = sm.OLS(y1, X1).fit()\n",
    "    X2 = sm.add_constant(after[regressors].values); y2 = after[dep].values\n",
    "    res2 = sm.OLS(y2, X2).fit()\n",
    "    n = len(sub)\n",
    "    F = ((res_pool.ssr - res1.ssr - res2.ssr) / k) / ((res1.ssr + res2.ssr) / (n - 2*k))\n",
    "    p_val = 1 - stats.f.cdf(F, k, n - 2*k)\n",
    "    return F, p_val\n",
    "\n",
    "\n",
    "# ── Expanding-window Taylor prescription ───────────────────────────\n",
    "def expanding_taylor(df, min_window=60):\n",
    "    dates_out, prescribed_out, actual_out = [], [], []\n",
    "    for end in range(min_window, len(df)):\n",
    "        window = df.iloc[:end+1]\n",
    "        current = df.iloc[end]\n",
    "        try:\n",
    "            y = window[\"fed_funds\"].values\n",
    "            pi = window[\"inflation\"].values\n",
    "            u_gap = window[\"unemp_gap\"].values\n",
    "            ff_lag = window[\"ff_lag1\"].values\n",
    "            res = least_squares(taylor_resid, [0.85, 2.0, 0.5, 0.5],\n",
    "                args=(y, pi, u_gap, ff_lag),\n",
    "                bounds=([0, -5, -2, -5], [0.999, 10, 5, 5]),\n",
    "                max_nfev=500)\n",
    "            rho, rstar, a_pi, a_u = res.x\n",
    "            target = rstar + current[\"inflation\"] + a_pi*(current[\"inflation\"]-2.0) + a_u*current[\"unemp_gap\"]\n",
    "            prescribed_out.append(max(0, target))\n",
    "        except:\n",
    "            prescribed_out.append(np.nan)\n",
    "        dates_out.append(df.index[end])\n",
    "        actual_out.append(current[\"fed_funds\"])\n",
    "    return pd.DataFrame({\"date\": dates_out, \"prescribed\": prescribed_out,\n",
    "                          \"actual\": actual_out}).set_index(\"date\")\n",
    "\n",
    "\n",
    "# ── Main analysis ──────────────────────────────────────────────────\n",
    "def run_analysis(df, regime_df, regime_names, n_regimes):\n",
    "    print(\"=\"*70)\n",
    "    print(\"REGIME-CONDITIONAL TAYLOR RULES\")\n",
    "    print(\"  Using CBO NAIRU for unemployment gap\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    sub = regime_df[[\"fed_funds\",\"ff_lag1\",\"inflation\",\"unemployment\",\n",
    "                     \"unemp_gap\",\"pi_expected\",\"regime\"]].dropna(\n",
    "                         subset=[\"fed_funds\",\"ff_lag1\",\"inflation\",\"unemp_gap\"])\n",
    "\n",
    "    # ── A. Full-sample Taylor rule (realized inflation) ──\n",
    "    print(\"\\n--- A. Full-sample structural Taylor rule (realized inflation, CBO NAIRU) ---\")\n",
    "    full = fit_taylor_nls(sub, \"Full sample (realized pi)\")\n",
    "    print(f\"\\n  {'Parameter':<20s}  {'Estimate':>10s}  {'OLS SE':>8s}\")\n",
    "    print(f\"  {'-'*42}\")\n",
    "    for nm, v, se in zip([\"rho (smoothing)\",\"r* (neutral)\",\"a_pi (inflation)\",\"a_u (unemp gap)\"],\n",
    "                          [full[\"rho\"],full[\"rstar\"],full[\"a_pi\"],full[\"a_u\"]], full[\"se\"]):\n",
    "        print(f\"  {nm:<20s}  {v:>10.3f}  {se:>8.3f}\")\n",
    "    print(f\"  Taylor principle: 1 + a_pi = {full['taylor_principle']:.2f}\")\n",
    "\n",
    "    # HAC standard errors\n",
    "    print(\"\\n  Computing block bootstrap HAC standard errors (500 reps)...\")\n",
    "    hac_se = bootstrap_taylor_se(sub, n_boot=500, block_size=12, use_expected=False)\n",
    "    full[\"hac_se\"] = hac_se\n",
    "    print(f\"  {'Parameter':<20s}  {'Estimate':>10s}  {'OLS SE':>8s}  {'HAC SE':>8s}\")\n",
    "    print(f\"  {'-'*52}\")\n",
    "    for nm, v, se, hse in zip([\"rho\",\"r*\",\"a_pi\",\"a_u\"],\n",
    "                               [full[\"rho\"],full[\"rstar\"],full[\"a_pi\"],full[\"a_u\"]],\n",
    "                               full[\"se\"], hac_se):\n",
    "        print(f\"  {nm:<20s}  {v:>10.3f}  {se:>8.3f}  {hse:>8.3f}\")\n",
    "\n",
    "    # ── A2. Expected inflation specification ──\n",
    "    print(\"\\n--- A2. Full-sample Taylor rule (expected inflation, CBO NAIRU) ---\")\n",
    "    full_exp = fit_taylor_nls(sub, \"Full sample (expected pi)\", use_expected=True)\n",
    "    if full_exp is not None:\n",
    "        print(f\"\\n  {'Parameter':<20s}  {'Estimate':>10s}  {'SE':>8s}\")\n",
    "        print(f\"  {'-'*42}\")\n",
    "        for nm, v, se in zip([\"rho\",\"r*\",\"a_pi\",\"a_u\"],\n",
    "                              [full_exp[\"rho\"],full_exp[\"rstar\"],full_exp[\"a_pi\"],full_exp[\"a_u\"]],\n",
    "                              full_exp[\"se\"]):\n",
    "            print(f\"  {nm:<20s}  {v:>10.3f}  {se:>8.3f}\")\n",
    "        print(f\"  Taylor principle (expected pi): 1 + a_pi = {full_exp['taylor_principle']:.2f}\")\n",
    "\n",
    "        hac_se_exp = bootstrap_taylor_se(sub, n_boot=500, block_size=12, use_expected=True)\n",
    "        full_exp[\"hac_se\"] = hac_se_exp\n",
    "        print(f\"\\n  HAC SE: {['%.3f' % s for s in hac_se_exp]}\")\n",
    "    else:\n",
    "        print(\"  Not enough expected inflation data.\")\n",
    "\n",
    "    # ── B. Regime-conditional Taylor rules ──\n",
    "    print(f\"\\n--- B. Regime-conditional Taylor rules ---\")\n",
    "    regime_results = {}\n",
    "    regime_results_exp = {}\n",
    "    for r in range(n_regimes):\n",
    "        rsub = sub[sub[\"regime\"] == r]\n",
    "        if len(rsub) < 30:\n",
    "            print(f\"  {regime_names[r]}: too few obs ({len(rsub)}), skipping\")\n",
    "            continue\n",
    "\n",
    "        # Realized inflation\n",
    "        result = fit_taylor_nls(rsub, regime_names[r])\n",
    "        regime_results[r] = result\n",
    "        hac = bootstrap_taylor_se(rsub, n_boot=500, block_size=12)\n",
    "        result[\"hac_se\"] = hac\n",
    "\n",
    "        # Expected inflation\n",
    "        result_exp = fit_taylor_nls(rsub, f\"{regime_names[r]} (exp pi)\", use_expected=True)\n",
    "        if result_exp is not None:\n",
    "            regime_results_exp[r] = result_exp\n",
    "            hac_exp = bootstrap_taylor_se(rsub, n_boot=500, block_size=12, use_expected=True)\n",
    "            result_exp[\"hac_se\"] = hac_exp\n",
    "\n",
    "    if regime_results:\n",
    "        print(f\"\\n  === Realized inflation specification ===\")\n",
    "        print(f\"  {'Regime':<30s}  {'rho':>6s}  {'r*':>6s}  {'a_pi':>6s}  {'a_u':>6s}  {'1+a_pi':>7s}  {'N':>4s}\")\n",
    "        print(f\"  {'-'*70}\")\n",
    "        for r, res in regime_results.items():\n",
    "            tp = res[\"taylor_principle\"]\n",
    "            print(f\"  {res['label']:<30s}  {res['rho']:>6.3f}  {res['rstar']:>6.3f}  \"\n",
    "                  f\"{res['a_pi']:>6.3f}  {res['a_u']:>6.3f}  {tp:>7.2f}  {res['n']:>4d}\")\n",
    "\n",
    "        print(f\"\\n  HAC standard errors (block bootstrap, 12-month blocks):\")\n",
    "        print(f\"  {'Regime':<30s}  {'se(rho)':>8s}  {'se(r*)':>8s}  {'se(a_pi)':>8s}  {'se(a_u)':>8s}\")\n",
    "        print(f\"  {'-'*70}\")\n",
    "        for r, res in regime_results.items():\n",
    "            hse = res[\"hac_se\"]\n",
    "            print(f\"  {res['label']:<30s}  {hse[0]:>8.3f}  {hse[1]:>8.3f}  {hse[2]:>8.3f}  {hse[3]:>8.3f}\")\n",
    "\n",
    "    if regime_results_exp:\n",
    "        print(f\"\\n  === Expected inflation specification ===\")\n",
    "        print(f\"  {'Regime':<30s}  {'rho':>6s}  {'r*':>6s}  {'a_pi':>6s}  {'a_u':>6s}  {'1+a_pi':>7s}  {'N':>4s}\")\n",
    "        print(f\"  {'-'*70}\")\n",
    "        for r, res in regime_results_exp.items():\n",
    "            tp = res[\"taylor_principle\"]\n",
    "            print(f\"  {res['label']:<30s}  {res['rho']:>6.3f}  {res['rstar']:>6.3f}  \"\n",
    "                  f\"{res['a_pi']:>6.3f}  {res['a_u']:>6.3f}  {tp:>7.2f}  {res['n']:>4d}\")\n",
    "\n",
    "    # ── C. Structural break tests (using CBO NAIRU gap) ──\n",
    "    print(f\"\\n--- C. Chow tests at regime transition dates ---\")\n",
    "    transitions = []\n",
    "    prev_regime = regime_df[\"regime\"].iloc[0]\n",
    "    for i in range(1, len(regime_df)):\n",
    "        curr = regime_df[\"regime\"].iloc[i]\n",
    "        if curr != prev_regime:\n",
    "            transitions.append({\n",
    "                \"date\": regime_df.index[i],\n",
    "                \"from\": regime_names.get(prev_regime, f\"R{prev_regime}\"),\n",
    "                \"to\": regime_names.get(curr, f\"R{curr}\"),\n",
    "            })\n",
    "        prev_regime = curr\n",
    "\n",
    "    if transitions:\n",
    "        tested_dates = set()\n",
    "        print(f\"\\n  {'Date':<12s}  {'Transition':<40s}  {'F-stat':>8s}  {'p-value':>8s}\")\n",
    "        print(f\"  {'-'*72}\")\n",
    "        for tr in transitions:\n",
    "            d = tr[\"date\"]\n",
    "            if any(abs((d - td).days) < 365 for td in tested_dates):\n",
    "                continue\n",
    "            tested_dates.add(d)\n",
    "            test_df = regime_df[[\"delta_ff\",\"inflation\",\"unemp_gap\"]].dropna()\n",
    "            F, p = chow_test(test_df, d.strftime(\"%Y-%m-%d\"),\n",
    "                             regressors=[\"inflation\",\"unemp_gap\"])\n",
    "            sig = \"***\" if p < 0.01 else \"**\" if p < 0.05 else \"*\" if p < 0.10 else \"\"\n",
    "            print(f\"  {d:%Y-%m}      {tr['from'][:18]:>18s} -> {tr['to'][:18]:<18s}  {F:>8.2f}  {p:>7.4f} {sig}\")\n",
    "\n",
    "    # ── D. Expanding-window Taylor prescription ──\n",
    "    print(f\"\\n--- D. Expanding-window Taylor rule prescription ---\")\n",
    "    expand_df = expanding_taylor(regime_df, min_window=60)\n",
    "    expand_df[\"gap\"] = expand_df[\"actual\"] - expand_df[\"prescribed\"]\n",
    "    expand_df[\"regime\"] = regime_df.loc[expand_df.index, \"regime\"]\n",
    "\n",
    "    print(f\"  Computed {len(expand_df)} real-time prescriptions\")\n",
    "    print(f\"  Mean discretionary gap: {expand_df['gap'].mean():+.2f} pp\")\n",
    "    for r in range(n_regimes):\n",
    "        rsub = expand_df[expand_df[\"regime\"] == r]\n",
    "        if len(rsub) > 0:\n",
    "            print(f\"  {regime_names[r]}: mean gap = {rsub['gap'].mean():+.2f}\")\n",
    "\n",
    "    return full, full_exp, regime_results, regime_results_exp, expand_df, transitions\n",
    "\n",
    "\n",
    "# ── Visualization ──────────────────────────────────────────────────\n",
    "def plot_results(regime_df, regime_names, n_regimes, full, full_exp,\n",
    "                 regime_results, regime_results_exp, expand_df, output_path):\n",
    "    regime_colors = [C5, C1, C4, C2, \"#94a3b8\"][:n_regimes]\n",
    "\n",
    "    # ── Fig 1: Regime-conditional Taylor parameters (with HAC SE) ──\n",
    "    if len(regime_results) >= 2:\n",
    "        fig, axes = plt.subplots(1, 4, figsize=(16, 5))\n",
    "        fig.suptitle(\"Taylor Rule Parameters by Inflation Regime (CBO NAIRU, HAC SE)\",\n",
    "                     fontweight=\"bold\", fontsize=14, y=1.02)\n",
    "\n",
    "        params = [\"rho\", \"rstar\", \"a_pi\", \"a_u\"]\n",
    "        titles = [\"Smoothing (rho)\", \"Neutral rate (r*)\",\n",
    "                  \"Inflation response (a_pi)\", \"Unemp gap response (a_u)\"]\n",
    "\n",
    "        for ax, param, title in zip(axes, params, titles):\n",
    "            labels_list = []; vals = []; colors = []; errors = []\n",
    "            idx = params.index(param)\n",
    "\n",
    "            # Full sample\n",
    "            labels_list.append(\"Full sample\"); vals.append(full[param])\n",
    "            colors.append(\"#6b7280\")\n",
    "            hse = full.get(\"hac_se\", full[\"se\"])\n",
    "            errors.append(1.96 * hse[idx] if not np.isnan(hse[idx]) else 0)\n",
    "\n",
    "            for r in sorted(regime_results.keys()):\n",
    "                res = regime_results[r]\n",
    "                labels_list.append(regime_names[r][:20]); vals.append(res[param])\n",
    "                colors.append(regime_colors[r])\n",
    "                hse_r = res.get(\"hac_se\", res[\"se\"])\n",
    "                errors.append(1.96 * hse_r[idx] if not np.isnan(hse_r[idx]) else 0)\n",
    "\n",
    "            y_pos = np.arange(len(labels_list))\n",
    "            ax.barh(y_pos, vals, xerr=errors, color=colors, alpha=0.75,\n",
    "                    edgecolor=\"white\", lw=1, capsize=4, height=0.6)\n",
    "            ax.set_yticks(y_pos); ax.set_yticklabels(labels_list, fontsize=8)\n",
    "            ax.axvline(0, color=\"grey\", lw=0.5)\n",
    "            ax.set_title(title, fontweight=\"bold\", fontsize=10)\n",
    "            ax.invert_yaxis()\n",
    "            if param == \"a_pi\":\n",
    "                ax.axvline(0, color=C2, ls=\"--\", lw=1, alpha=0.5)\n",
    "\n",
    "        fig.tight_layout()\n",
    "        path1 = f\"{output_path}/taylor_by_regime.png\"\n",
    "        fig.savefig(path1, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "        print(f\"  Saved: {path1}\")\n",
    "    else:\n",
    "        path1 = None\n",
    "\n",
    "    # ── Fig 2: Taylor prescription vs actual ──\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(16, 12), sharex=True,\n",
    "                              gridspec_kw={\"height_ratios\": [1, 3, 2]})\n",
    "    fig.suptitle(\"Taylor Rule Prescription vs Actual Fed Funds Rate (CBO NAIRU)\",\n",
    "                 fontweight=\"bold\", fontsize=14, y=0.995)\n",
    "\n",
    "    ax = axes[0]\n",
    "    for r in range(n_regimes):\n",
    "        mask = regime_df.loc[expand_df.index, \"regime\"] == r\n",
    "        for d in expand_df.index[mask]:\n",
    "            ax.axvspan(d, d + pd.DateOffset(months=1), color=regime_colors[r], alpha=0.8)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(\"Inflation regime\", fontweight=\"bold\", fontsize=10)\n",
    "    legend_elements = [Patch(facecolor=regime_colors[r], alpha=0.8, label=regime_names[r])\n",
    "                       for r in range(n_regimes)]\n",
    "    ax.legend(handles=legend_elements, frameon=True, fontsize=7, loc=\"upper left\",\n",
    "              ncol=min(n_regimes,3))\n",
    "\n",
    "    ax = axes[1]; shade_recessions(ax)\n",
    "    ax.plot(expand_df.index, expand_df[\"actual\"], lw=2, color=C1, label=\"Actual fed funds\", zorder=3)\n",
    "    ax.plot(expand_df.index, expand_df[\"prescribed\"], lw=1.5, color=C2, alpha=0.8,\n",
    "            label=\"Taylor rule prescription\", zorder=2)\n",
    "    ax.fill_between(expand_df.index, expand_df[\"actual\"], expand_df[\"prescribed\"],\n",
    "                    where=expand_df[\"actual\"] > expand_df[\"prescribed\"],\n",
    "                    alpha=0.15, color=C2, label=\"Too tight\")\n",
    "    ax.fill_between(expand_df.index, expand_df[\"actual\"], expand_df[\"prescribed\"],\n",
    "                    where=expand_df[\"actual\"] < expand_df[\"prescribed\"],\n",
    "                    alpha=0.15, color=C1, label=\"Too loose\")\n",
    "    ax.set_ylabel(\"Rate (%)\")\n",
    "    ax.set_title(\"Fed funds: actual vs Taylor rule prescription\", fontweight=\"bold\")\n",
    "    ax.legend(frameon=True, fontsize=8, loc=\"upper right\")\n",
    "    ax.set_ylim(bottom=-1)\n",
    "\n",
    "    ax = axes[2]; shade_recessions(ax)\n",
    "    gap = expand_df[\"gap\"]\n",
    "    ax.fill_between(expand_df.index, gap, 0, where=gap > 0, alpha=0.4, color=C2, label=\"Tighter than rule\")\n",
    "    ax.fill_between(expand_df.index, gap, 0, where=gap < 0, alpha=0.4, color=C1, label=\"Looser than rule\")\n",
    "    ax.axhline(0, color=\"grey\", lw=1)\n",
    "    ax.set_ylabel(\"Gap (pp)\"); ax.set_xlabel(\"Year\")\n",
    "    ax.set_title(\"Discretionary gap (actual minus prescribed)\", fontweight=\"bold\")\n",
    "    ax.legend(frameon=True, fontsize=8)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    path2 = f\"{output_path}/taylor_prescription_vs_actual.png\"\n",
    "    fig.savefig(path2, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "    print(f\"  Saved: {path2}\")\n",
    "\n",
    "    # ── Fig 3: Taylor principle by regime (realized vs expected) ──\n",
    "    if len(regime_results) >= 2:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        fig.suptitle(\"Taylor Principle: Realized vs Expected Inflation\",\n",
    "                     fontweight=\"bold\", fontsize=14, y=1.02)\n",
    "\n",
    "        for ax, (results_dict, title_suffix) in zip(axes, [\n",
    "            (regime_results, \"Realized inflation\"),\n",
    "            (regime_results_exp, \"Expected inflation (MICH/adaptive)\")]):\n",
    "\n",
    "            if not results_dict:\n",
    "                ax.text(0.5, 0.5, \"Not enough data\", ha=\"center\", va=\"center\",\n",
    "                        transform=ax.transAxes)\n",
    "                ax.set_title(title_suffix, fontweight=\"bold\")\n",
    "                continue\n",
    "\n",
    "            labels_list = [\"Full sample\"] + [regime_names[r][:25] for r in sorted(results_dict.keys())]\n",
    "            ref = full if \"Realized\" in title_suffix else full_exp\n",
    "            if ref is None:\n",
    "                continue\n",
    "            tp_vals = [ref[\"taylor_principle\"]] + \\\n",
    "                      [results_dict[r][\"taylor_principle\"] for r in sorted(results_dict.keys())]\n",
    "            colors_bar = [\"#6b7280\"] + [regime_colors[r] for r in sorted(results_dict.keys())]\n",
    "\n",
    "            # HAC-based error bars\n",
    "            errs = []\n",
    "            hse = ref.get(\"hac_se\", ref[\"se\"])\n",
    "            errs.append(1.96 * hse[2] if not np.isnan(hse[2]) else 0)\n",
    "            for r in sorted(results_dict.keys()):\n",
    "                hse_r = results_dict[r].get(\"hac_se\", results_dict[r][\"se\"])\n",
    "                errs.append(1.96 * hse_r[2] if not np.isnan(hse_r[2]) else 0)\n",
    "\n",
    "            bars = ax.bar(labels_list, tp_vals, yerr=errs, color=colors_bar,\n",
    "                          alpha=0.75, edgecolor=\"white\", lw=1, width=0.6, capsize=5)\n",
    "            ax.axhline(1.0, color=C2, ls=\"--\", lw=2, alpha=0.7, label=\"Taylor principle = 1\")\n",
    "            ax.set_ylabel(\"1 + a_pi\")\n",
    "            ax.set_title(title_suffix, fontweight=\"bold\")\n",
    "            ax.legend(frameon=False, fontsize=9)\n",
    "            for bar, val in zip(bars, tp_vals):\n",
    "                ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(errs)*0.1 + 0.02,\n",
    "                        f\"{val:.2f}\", ha=\"center\", va=\"bottom\", fontsize=10, fontweight=\"bold\")\n",
    "\n",
    "        fig.tight_layout()\n",
    "        path3 = f\"{output_path}/taylor_principle_by_regime.png\"\n",
    "        fig.savefig(path3, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "        print(f\"  Saved: {path3}\")\n",
    "    else:\n",
    "        path3 = None\n",
    "\n",
    "    return [p for p in [path1, path2, path3] if p]\n",
    "\n",
    "\n",
    "# ── Main ───────────────────────────────────────────────────────────\n",
    "\n",
    "\n",
    "full, full_exp, regime_results, regime_results_exp, expand_df, transitions = \\\n",
    "    run_analysis(df, regime_df, regime_names, n_regimes)\n",
    "\n",
    "paths = plot_results(regime_df, regime_names, n_regimes, full, full_exp,\n",
    "                     regime_results, regime_results_exp, expand_df, OUTPUT_PATH)\n",
    "\n",
    "print(f\"\\nOutputs: {paths}\")\n",
    "print(\"Done.\")\n",
    "\n",
    "# ── Granger causality: inflation -> delta_ff ──────────────────\n",
    "print(\"\\n--- Granger causality: inflation -> delta_ff ---\")\n",
    "gdf = regime_df[[\"delta_ff\",\"inflation\"]].dropna()\n",
    "for ml in [3, 6, 12]:\n",
    "    y_g = gdf[\"delta_ff\"].values\n",
    "    Xr = sm.add_constant(np.column_stack([gdf[\"delta_ff\"].shift(l).values for l in range(1,ml+1)]))\n",
    "    Xu = sm.add_constant(np.column_stack(\n",
    "        [gdf[\"delta_ff\"].shift(l).values for l in range(1,ml+1)] +\n",
    "        [gdf[\"inflation\"].shift(l).values for l in range(1,ml+1)]))\n",
    "    v = ~np.isnan(Xu).any(axis=1) & ~np.isnan(y_g)\n",
    "    rr_ = sm.OLS(y_g[v], Xr[v]).fit()\n",
    "    ru_ = sm.OLS(y_g[v], Xu[v]).fit()\n",
    "    Fg = ((rr_.ssr - ru_.ssr)/ml) / (ru_.ssr/(v.sum() - Xu.shape[1]))\n",
    "    pg = 1 - stats.f.cdf(Fg, ml, v.sum() - Xu.shape[1])\n",
    "    sg = \"***\" if pg<0.01 else \"**\" if pg<0.05 else \"*\" if pg<0.10 else \"\"\n",
    "    print(f\"  {ml} lags: F={Fg:.2f}, p={pg:.4f} {sg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f8d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Component 3: Structural Break Detection & Yield Curve Analysis\n",
    "==============================================================\n",
    "Updated: uses CBO NAIRU-based unemployment gap in break detection.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# PART A: STRUCTURAL BREAK DETECTION (now uses CBO NAIRU gap)\n",
    "# ================================================================\n",
    "def sup_wald_break_test(df, dep=\"delta_ff\", regressors=[\"inflation\",\"unemp_gap\"],\n",
    "                        min_frac=0.15):\n",
    "    sub = df[[dep] + regressors].dropna()\n",
    "    n = len(sub); trim = int(n * min_frac); k = len(regressors) + 1\n",
    "    X_pool = sm.add_constant(sub[regressors].values)\n",
    "    y_pool = sub[dep].values\n",
    "    res_pool = sm.OLS(y_pool, X_pool).fit()\n",
    "    ssr_pool = res_pool.ssr\n",
    "\n",
    "    dates_test, f_stats = [], []\n",
    "    for t in range(trim, n - trim):\n",
    "        X1 = sm.add_constant(sub[regressors].values[:t])\n",
    "        y1 = sub[dep].values[:t]\n",
    "        X2 = sm.add_constant(sub[regressors].values[t:])\n",
    "        y2 = sub[dep].values[t:]\n",
    "        try:\n",
    "            res1 = sm.OLS(y1, X1).fit(); res2 = sm.OLS(y2, X2).fit()\n",
    "            F = ((ssr_pool - res1.ssr - res2.ssr) / k) / ((res1.ssr + res2.ssr) / (n - 2*k))\n",
    "            f_stats.append(F)\n",
    "        except:\n",
    "            f_stats.append(0)\n",
    "        dates_test.append(sub.index[t])\n",
    "\n",
    "    f_stats = np.array(f_stats)\n",
    "    dates_test = pd.DatetimeIndex(dates_test)\n",
    "    best_idx = np.argmax(f_stats)\n",
    "\n",
    "    # Andrews (1993) critical values for sup-Wald, k=3, 15% trimming\n",
    "    cv_10 = 7.12; cv_05 = 8.68; cv_01 = 12.16\n",
    "    best_F = f_stats[best_idx]\n",
    "    sig = \"***\" if best_F > cv_01 else \"**\" if best_F > cv_05 else \"*\" if best_F > cv_10 else \"\"\n",
    "\n",
    "    return {\n",
    "        \"best_date\": dates_test[best_idx], \"best_F\": best_F, \"sig\": sig,\n",
    "        \"cv\": {\"1%\": cv_01, \"5%\": cv_05, \"10%\": cv_10},\n",
    "        \"dates\": dates_test, \"f_stats\": f_stats,\n",
    "    }\n",
    "\n",
    "\n",
    "def sequential_breaks(df, dep=\"delta_ff\", regressors=[\"inflation\",\"unemp_gap\"],\n",
    "                      max_breaks=4, min_frac=0.15):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"STRUCTURAL BREAK DETECTION (Sequential sup-Wald)\")\n",
    "    print(f\"  Using CBO NAIRU-based unemployment gap\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"  DV: {dep}  |  Regressors: {regressors}\")\n",
    "\n",
    "    sub = df[[dep] + regressors].dropna()\n",
    "    breaks = []\n",
    "    segments = [(sub.index[0], sub.index[-1])]\n",
    "\n",
    "    for b in range(max_breaks):\n",
    "        best_overall = None\n",
    "        for seg_start, seg_end in segments:\n",
    "            seg = sub.loc[seg_start:seg_end]\n",
    "            if len(seg) < int(len(sub) * min_frac * 2):\n",
    "                continue\n",
    "            result = sup_wald_break_test(seg, dep, regressors, min_frac)\n",
    "            if result[\"best_F\"] > result[\"cv\"][\"5%\"]:\n",
    "                if best_overall is None or result[\"best_F\"] > best_overall[\"best_F\"]:\n",
    "                    best_overall = result\n",
    "                    best_overall[\"segment\"] = (seg_start, seg_end)\n",
    "\n",
    "        if best_overall is None:\n",
    "            print(f\"\\n  Break {b+1}: no further significant breaks found.\")\n",
    "            break\n",
    "\n",
    "        breaks.append(best_overall)\n",
    "        bd = best_overall[\"best_date\"]\n",
    "        print(f\"\\n  Break {b+1}: {bd:%Y-%m}  (F = {best_overall['best_F']:.2f}{best_overall['sig']})\")\n",
    "\n",
    "        seg_s, seg_e = best_overall[\"segment\"]\n",
    "        new_segments = []\n",
    "        for s, e in segments:\n",
    "            if s == seg_s and e == seg_e:\n",
    "                new_segments.append((s, bd)); new_segments.append((bd, e))\n",
    "            else:\n",
    "                new_segments.append((s, e))\n",
    "        segments = new_segments\n",
    "\n",
    "    print(f\"\\n  Detected breaks vs chair transitions:\")\n",
    "    print(f\"  {'Break date':<14s}  {'Nearest chair transition':<30s}  {'Distance':>10s}\")\n",
    "    print(f\"  {'-'*58}\")\n",
    "    for brk in breaks:\n",
    "        bd = brk[\"best_date\"]\n",
    "        nearest = min(CHAIR_DATES, key=lambda x: min(abs((bd-x[1]).days), abs((bd-x[2]).days)))\n",
    "        d1 = abs((bd - nearest[1]).days); d2 = abs((bd - nearest[2]).days)\n",
    "        if d1 < d2:\n",
    "            chair_event = f\"{nearest[0]} start ({nearest[1]:%Y-%m})\"; dist_months = d1/30\n",
    "        else:\n",
    "            chair_event = f\"{nearest[0]} end ({nearest[2]:%Y-%m})\"; dist_months = d2/30\n",
    "        print(f\"  {bd:%Y-%m}        {chair_event:<30s}  {dist_months:>8.1f}m\")\n",
    "\n",
    "    return breaks, segments\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# PART B: YIELD CURVE AND REGIME TRANSITIONS\n",
    "# ================================================================\n",
    "def yield_curve_regime_analysis(regime_df, regime_names, n_regimes):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"YIELD CURVE AND REGIME TRANSITIONS\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    transitions = []\n",
    "    prev = regime_df[\"regime\"].iloc[0]\n",
    "    for i in range(1, len(regime_df)):\n",
    "        curr = regime_df[\"regime\"].iloc[i]\n",
    "        if curr != prev:\n",
    "            transitions.append({\"date\": regime_df.index[i], \"from_regime\": prev,\n",
    "                                \"to_regime\": curr,\n",
    "                                \"direction\": \"up\" if curr > prev else \"down\"})\n",
    "        prev = curr\n",
    "\n",
    "    filtered = []\n",
    "    for tr in transitions:\n",
    "        if not filtered or (tr[\"date\"] - filtered[-1][\"date\"]).days > 365:\n",
    "            filtered.append(tr)\n",
    "    transitions = filtered\n",
    "\n",
    "    print(f\"\\n  Major regime transitions: {len(transitions)}\")\n",
    "    print(f\"\\n  {'Date':<12s}  {'Direction':<8s}  {'Spread at t':>12s}  {'Spread t-6':>12s}  {'Spread t-12':>12s}\")\n",
    "    print(f\"  {'-'*60}\")\n",
    "\n",
    "    for tr in transitions:\n",
    "        d = tr[\"date\"]\n",
    "        spread_at = regime_df.loc[:d, \"term_spread\"].iloc[-1]\n",
    "        d_6 = d - pd.DateOffset(months=6)\n",
    "        mask_6 = (regime_df.index >= d_6) & (regime_df.index < d)\n",
    "        spread_6 = regime_df.loc[mask_6, \"term_spread\"].mean() if mask_6.sum() > 0 else np.nan\n",
    "        d_12 = d - pd.DateOffset(months=12)\n",
    "        mask_12 = (regime_df.index >= d_12) & (regime_df.index < d)\n",
    "        spread_12 = regime_df.loc[mask_12, \"term_spread\"].mean() if mask_12.sum() > 0 else np.nan\n",
    "        tr[\"spread_at\"] = spread_at; tr[\"spread_6m\"] = spread_6; tr[\"spread_12m\"] = spread_12\n",
    "        print(f\"  {d:%Y-%m}      {tr['direction']:<8s}  {spread_at:>12.2f}  {spread_6:>12.2f}  {spread_12:>12.2f}\")\n",
    "\n",
    "    # Logit test\n",
    "    rdf = regime_df.copy()\n",
    "    rdf[\"regime_change\"] = (rdf[\"regime\"].diff() != 0).astype(int)\n",
    "    rdf[\"regime_change_12m\"] = rdf[\"regime_change\"].rolling(12).max().shift(-12)\n",
    "    test_df = rdf[[\"term_spread\",\"regime_change_12m\"]].dropna()\n",
    "    if len(test_df) > 50:\n",
    "        X = sm.add_constant(test_df[\"term_spread\"].values)\n",
    "        y = test_df[\"regime_change_12m\"].values\n",
    "        try:\n",
    "            logit = sm.Logit(y, X).fit(disp=False)\n",
    "            print(f\"\\n  Logit: P(regime change in 12m) ~ term_spread\")\n",
    "            print(f\"  Spread coefficient: {logit.params[1]:.4f} (p={logit.pvalues[1]:.4f})\")\n",
    "            if logit.pvalues[1] < 0.05:\n",
    "                print(f\"  -> Term spread significantly predicts regime transitions\")\n",
    "            else:\n",
    "                print(f\"  -> Term spread does NOT significantly predict regime transitions\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return transitions\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# PART C: RECESSION MODEL ROBUSTNESS\n",
    "# ================================================================\n",
    "def leave_one_recession_out(df):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"RECESSION MODEL: LEAVE-ONE-RECESSION-OUT CV\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    rec_features = [\"term_spread\",\"inflation\",\"unemp_gap\",\"fed_funds\",\n",
    "                    \"capacity_gap\",\"fin_conditions\",\"real_rate\"]\n",
    "\n",
    "    df = df.copy()\n",
    "    for h in [6,12,18]:\n",
    "        col = f\"recession_{h}m_ahead\"\n",
    "        if col not in df.columns:\n",
    "            df[col] = df[\"recession\"].rolling(h).max().shift(-h)\n",
    "\n",
    "    recession_episodes = [\n",
    "        (\"1973-74 Oil\", \"1973-11\", \"1975-03\"),\n",
    "        (\"1980 Volcker I\", \"1980-01\", \"1980-07\"),\n",
    "        (\"1981-82 Volcker II\", \"1981-07\", \"1982-11\"),\n",
    "        (\"1990-91\", \"1990-07\", \"1991-03\"),\n",
    "        (\"2001 Dot-com\", \"2001-03\", \"2001-11\"),\n",
    "        (\"2007-09 GFC\", \"2007-12\", \"2009-06\"),\n",
    "        (\"2020 COVID\", \"2020-02\", \"2020-04\"),\n",
    "    ]\n",
    "\n",
    "    for h in [6, 12]:\n",
    "        target = f\"recession_{h}m_ahead\"\n",
    "        rec_df = df[rec_features + [target]].dropna()\n",
    "        y_full = rec_df[target].astype(int).values\n",
    "        X_full = rec_df[rec_features].values\n",
    "\n",
    "        print(f\"\\n  --- {h}-month horizon ---\")\n",
    "        print(f\"  {'Left out':<22s}  {'Train N':>8s}  {'Test N':>8s}  {'AUC (full)':>10s}  {'AUC (spread)':>12s}\")\n",
    "        print(f\"  {'-'*66}\")\n",
    "\n",
    "        tr_mask = rec_df.index <= \"2015-12\"; te_mask = ~tr_mask\n",
    "        if te_mask.sum() > 0 and len(np.unique(y_full[te_mask])) > 1:\n",
    "            sc = StandardScaler(); X_tr = sc.fit_transform(X_full[tr_mask]); X_te = sc.transform(X_full[te_mask])\n",
    "            clf = LogisticRegression(C=1.0, max_iter=1000, random_state=SEED)\n",
    "            clf.fit(X_tr, y_full[tr_mask])\n",
    "            ref_auc = roc_auc_score(y_full[te_mask], clf.predict_proba(X_te)[:,1])\n",
    "            print(f\"  {'Time-split ref':<22s}  {tr_mask.sum():>8d}  {te_mask.sum():>8d}  {ref_auc:>10.3f}\")\n",
    "        print()\n",
    "\n",
    "        results_loro = []\n",
    "        for name, rs, re in recession_episodes:\n",
    "            pre_start = pd.Timestamp(rs) - pd.DateOffset(months=18)\n",
    "            test_mask = (rec_df.index >= pre_start) & (rec_df.index <= re)\n",
    "            train_mask = ~test_mask\n",
    "            y_tr = y_full[train_mask]; X_tr_raw = X_full[train_mask]\n",
    "            y_te = y_full[test_mask]; X_te_raw = X_full[test_mask]\n",
    "            if len(y_te) < 5 or len(np.unique(y_te)) < 2:\n",
    "                print(f\"  {name:<22s}  {train_mask.sum():>8d}  {test_mask.sum():>8d}  {'skip':>10s}\")\n",
    "                continue\n",
    "            sc = StandardScaler()\n",
    "            X_tr = sc.fit_transform(X_tr_raw); X_te = sc.transform(X_te_raw)\n",
    "            clf_full = LogisticRegression(C=1.0, max_iter=1000, random_state=SEED)\n",
    "            clf_full.fit(X_tr, y_tr)\n",
    "            auc_full = roc_auc_score(y_te, clf_full.predict_proba(X_te)[:,1])\n",
    "            si = rec_features.index(\"term_spread\")\n",
    "            clf_sp = LogisticRegression(C=1.0, max_iter=1000, random_state=SEED)\n",
    "            clf_sp.fit(X_tr[:,si:si+1], y_tr)\n",
    "            auc_sp = roc_auc_score(y_te, clf_sp.predict_proba(X_te[:,si:si+1])[:,1])\n",
    "            results_loro.append({\"name\": name, \"auc_full\": auc_full, \"auc_spread\": auc_sp})\n",
    "            print(f\"  {name:<22s}  {train_mask.sum():>8d}  {test_mask.sum():>8d}  {auc_full:>10.3f}  {auc_sp:>12.3f}\")\n",
    "\n",
    "        if results_loro:\n",
    "            avg_full = np.mean([r[\"auc_full\"] for r in results_loro])\n",
    "            avg_sp = np.mean([r[\"auc_spread\"] for r in results_loro])\n",
    "            print(f\"\\n  {'Average LORO':<22s}  {'':>8s}  {'':>8s}  {avg_full:>10.3f}  {avg_sp:>12.3f}\")\n",
    "\n",
    "    return results_loro\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# VISUALIZATION\n",
    "# ================================================================\n",
    "def plot_results(df, regime_df, regime_names, n_regimes, breaks, transitions, output_path):\n",
    "    regime_colors = [C5, C1, C4, C2][:n_regimes]\n",
    "    chair_colors_map = {\"Burns\":\"#dbeafe\",\"Miller\":\"#fee2e2\",\"Volcker\":\"#ede9fe\",\n",
    "                        \"Greenspan\":\"#fef3c7\",\"Bernanke\":\"#d1fae5\",\"Yellen\":\"#fce7f3\",\"Powell\":\"#e0e7ff\"}\n",
    "\n",
    "    # ── Fig 1: Sup-Wald F-statistic ──\n",
    "    if breaks:\n",
    "        first_break = breaks[0]\n",
    "        fig, axes = plt.subplots(3, 1, figsize=(16, 10), sharex=True,\n",
    "                                  gridspec_kw={\"height_ratios\": [1, 2, 2]})\n",
    "        fig.suptitle(\"Structural Break Detection in Fed Reaction Function (CBO NAIRU gap)\",\n",
    "                     fontweight=\"bold\", fontsize=14, y=0.995)\n",
    "\n",
    "        ax = axes[0]\n",
    "        for ch, cs, ce in CHAIR_DATES:\n",
    "            color = chair_colors_map.get(ch, \"#e5e7eb\")\n",
    "            ax.axvspan(cs, ce, color=color, alpha=0.5)\n",
    "            mid = cs + (ce - cs)/2\n",
    "            if df.index[0] <= mid <= df.index[-1]:\n",
    "                ax.text(mid, 0.5, ch, ha=\"center\", va=\"center\", fontsize=8, fontstyle=\"italic\")\n",
    "        ax.set_yticks([]); ax.set_title(\"Fed chair tenures\", fontweight=\"bold\", fontsize=10)\n",
    "\n",
    "        ax = axes[1]\n",
    "        ax.plot(first_break[\"dates\"], first_break[\"f_stats\"], lw=2, color=C1)\n",
    "        ax.axhline(first_break[\"cv\"][\"5%\"], color=C2, ls=\"--\", lw=1.5,\n",
    "                    label=f'5% critical value ({first_break[\"cv\"][\"5%\"]:.1f})')\n",
    "        ax.axhline(first_break[\"cv\"][\"1%\"], color=C2, ls=\":\", lw=1,\n",
    "                    label=f'1% critical value ({first_break[\"cv\"][\"1%\"]:.1f})')\n",
    "        for brk in breaks:\n",
    "            ax.axvline(brk[\"best_date\"], color=C3, ls=\"-\", lw=2, alpha=0.7)\n",
    "            ax.text(brk[\"best_date\"], ax.get_ylim()[1]*0.9,\n",
    "                    f' {brk[\"best_date\"]:%Y-%m}', fontsize=9, color=C3, fontweight=\"bold\")\n",
    "        for ch, cs, ce in CHAIR_DATES:\n",
    "            if first_break[\"dates\"][0] <= cs <= first_break[\"dates\"][-1]:\n",
    "                ax.axvline(cs, color=\"#9ca3af\", ls=\"--\", lw=1, alpha=0.5)\n",
    "        ax.set_ylabel(\"F-statistic\")\n",
    "        ax.set_title(\"Sup-Wald F-statistic (testing every possible break date)\", fontweight=\"bold\")\n",
    "        ax.legend(frameon=True, fontsize=8)\n",
    "\n",
    "        ax = axes[2]; shade_recessions(ax)\n",
    "        test_df = df[[\"delta_ff\"]].dropna()\n",
    "        ax.plot(test_df.index, test_df[\"delta_ff\"], lw=1, color=\"#374151\", alpha=0.7)\n",
    "        for brk in breaks:\n",
    "            ax.axvline(brk[\"best_date\"], color=C3, ls=\"-\", lw=2, alpha=0.7)\n",
    "        ax.axhline(0, color=\"grey\", lw=0.8)\n",
    "        ax.set_ylabel(\"Monthly change (pp)\")\n",
    "        ax.set_title(\"Fed funds rate changes (dependent variable)\", fontweight=\"bold\")\n",
    "        ax.set_xlabel(\"Year\")\n",
    "\n",
    "        fig.tight_layout()\n",
    "        path1 = f\"{output_path}/structural_breaks.png\"\n",
    "        fig.savefig(path1, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "        print(f\"  Saved: {path1}\")\n",
    "    else:\n",
    "        path1 = None\n",
    "\n",
    "    # ── Fig 2: Term spread around regime transitions ──\n",
    "    if transitions:\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(16, 8), sharex=True)\n",
    "        fig.suptitle(\"Yield Curve Behaviour Around Inflation Regime Transitions\",\n",
    "                     fontweight=\"bold\", fontsize=14, y=0.995)\n",
    "\n",
    "        ax = axes[0]; shade_recessions(ax)\n",
    "        ax.plot(regime_df.index, regime_df[\"term_spread\"], lw=1.5, color=C1)\n",
    "        ax.axhline(0, color=C2, ls=\"--\", lw=1.5, alpha=0.7, label=\"Inversion threshold\")\n",
    "        for tr in transitions:\n",
    "            color = C2 if tr[\"direction\"] == \"up\" else C5\n",
    "            ax.axvline(tr[\"date\"], color=color, ls=\"-\", lw=2, alpha=0.7)\n",
    "        ax.set_ylabel(\"Term spread (pp)\")\n",
    "        ax.set_title(\"10Y-FFR spread with regime transition dates\", fontweight=\"bold\")\n",
    "        legend_elements = [\n",
    "            Line2D([0],[0], color=C2, ls=\"-\", lw=2, label=\"Transition to high inflation\"),\n",
    "            Line2D([0],[0], color=C5, ls=\"-\", lw=2, label=\"Transition to low inflation\"),\n",
    "            Line2D([0],[0], color=C2, ls=\"--\", lw=1.5, label=\"Inversion threshold\"),\n",
    "        ]\n",
    "        ax.legend(handles=legend_elements, frameon=True, fontsize=8)\n",
    "\n",
    "        ax = axes[1]\n",
    "        for r in range(n_regimes):\n",
    "            mask = regime_df[\"regime\"] == r\n",
    "            for d in regime_df.index[mask]:\n",
    "                ax.axvspan(d, d + pd.DateOffset(months=1), color=regime_colors[r], alpha=0.8)\n",
    "        ax.set_yticks([]); ax.set_xlabel(\"Year\")\n",
    "        ax.set_title(\"Inflation regime\", fontweight=\"bold\")\n",
    "        legend_elements = [Patch(facecolor=regime_colors[r], alpha=0.8, label=regime_names[r])\n",
    "                           for r in range(n_regimes)]\n",
    "        ax.legend(handles=legend_elements, frameon=True, fontsize=7, loc=\"upper left\")\n",
    "\n",
    "        fig.tight_layout()\n",
    "        path2 = f\"{output_path}/yield_curve_regimes.png\"\n",
    "        fig.savefig(path2, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "        print(f\"  Saved: {path2}\")\n",
    "    else:\n",
    "        path2 = None\n",
    "\n",
    "    return [p for p in [path1, path2] if p]\n",
    "\n",
    "\n",
    "# ── Main ───────────────────────────────────────────────────────────\n",
    "\n",
    "\n",
    "breaks, segments = sequential_breaks(\n",
    "    regime_df, dep=\"delta_ff\", regressors=[\"inflation\",\"unemp_gap\"],\n",
    "    max_breaks=3, min_frac=0.15)\n",
    "\n",
    "transitions = yield_curve_regime_analysis(regime_df, regime_names, n_regimes)\n",
    "loro_results = leave_one_recession_out(df)\n",
    "\n",
    "paths = plot_results(df, regime_df, regime_names, n_regimes,\n",
    "                     breaks, transitions, OUTPUT_PATH)\n",
    "\n",
    "print(f\"\\nOutputs: {paths}\")\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd7e4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Component 4: Regime-Aware Inflation Forecasting\n",
    "================================================\n",
    "Updated: uses CBO NAIRU-based unemployment gap throughout.\n",
    "Removed synthetic data fallback.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# FORECASTING\n",
    "# ================================================================\n",
    "\n",
    "BASE_FEATURES = [\"L1_inflation\",\"L3_inflation\",\"L6_inflation\",\"L12_inflation\"]\n",
    "EXTENDED_FEATURES = BASE_FEATURES + [\n",
    "    \"L1_fed_funds\",\"L3_fed_funds\",\"L6_fed_funds\",\n",
    "    \"L6_unemp_gap\",\"L6_term_spread\",\"L6_fin_conditions\"\n",
    "]\n",
    "\n",
    "CV_FOLDS = [\n",
    "    {\"train_end\":\"1990-12\",\"test_start\":\"1991-01\",\"test_end\":\"1995-12\",\"name\":\"Early 1990s\"},\n",
    "    {\"train_end\":\"1995-12\",\"test_start\":\"1996-01\",\"test_end\":\"2000-12\",\"name\":\"Late 1990s\"},\n",
    "    {\"train_end\":\"2000-12\",\"test_start\":\"2001-01\",\"test_end\":\"2007-12\",\"name\":\"2000s\"},\n",
    "    {\"train_end\":\"2007-12\",\"test_start\":\"2008-01\",\"test_end\":\"2015-12\",\"name\":\"GFC & after\"},\n",
    "    {\"train_end\":\"2015-12\",\"test_start\":\"2016-01\",\"test_end\":\"2023-01\",\"name\":\"Recent\"},\n",
    "]\n",
    "\n",
    "HORIZONS = [1, 3, 6, 12]\n",
    "\n",
    "\n",
    "def run_forecasting(regime_df, regime_names, n_regimes):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"REGIME-AWARE INFLATION FORECASTING (CBO NAIRU gap)\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    base_f = [f for f in BASE_FEATURES if f in regime_df.columns]\n",
    "    ext_f = [f for f in EXTENDED_FEATURES if f in regime_df.columns]\n",
    "\n",
    "    all_results = {}\n",
    "\n",
    "    for h in HORIZONS:\n",
    "        target = f\"inflation_{h}m_ahead\"\n",
    "        if target not in regime_df.columns:\n",
    "            regime_df[target] = regime_df[\"inflation\"].shift(-h)\n",
    "\n",
    "        fc_df = regime_df[ext_f + [target, \"regime\"] +\n",
    "                          [f\"p_regime_{r}\" for r in range(n_regimes)]].dropna()\n",
    "\n",
    "        print(f\"\\n  === {h}-month horizon ({len(fc_df)} obs) ===\")\n",
    "\n",
    "        models = {\n",
    "            \"Random walk\": {\"features\": None, \"regime_aware\": False, \"fn\": None},\n",
    "        \"AR (lags only)\": {\"features\": base_f, \"regime_aware\": False,\n",
    "                \"fn\": lambda: Ridge(alpha=1.0)},\n",
    "            \"Pooled Ridge\": {\"features\": ext_f, \"regime_aware\": False,\n",
    "                \"fn\": lambda: Ridge(alpha=10.0)},\n",
    "            \"Ridge + regime\": {\"features\": ext_f + [\"regime\"], \"regime_aware\": False,\n",
    "                \"fn\": lambda: Ridge(alpha=10.0)},\n",
    "            \"Ridge + regime prob\": {\"features\": ext_f + [f\"p_regime_{r}\" for r in range(n_regimes)],\n",
    "                \"regime_aware\": False, \"fn\": lambda: Ridge(alpha=10.0)},\n",
    "            \"Regime-conditional\": {\"features\": ext_f, \"regime_aware\": True,\n",
    "                \"fn\": lambda: Ridge(alpha=10.0)},\n",
    "            \"RF pooled\": {\"features\": ext_f, \"regime_aware\": False,\n",
    "                \"fn\": lambda: RandomForestRegressor(n_estimators=200, max_depth=6,\n",
    "                    min_samples_leaf=10, random_state=SEED)},\n",
    "        }\n",
    "\n",
    "        horizon_results = {}\n",
    "\n",
    "        for mname, spec in models.items():\n",
    "            fold_results = []\n",
    "\n",
    "            for fold in CV_FOLDS:\n",
    "                tr = fc_df.loc[:fold[\"train_end\"]]\n",
    "                te = fc_df.loc[fold[\"test_start\"]:fold[\"test_end\"]]\n",
    "                if len(te) < 6 or len(tr) < 30:\n",
    "                    continue\n",
    "\n",
    "                # Random walk benchmark\n",
    "                if spec[\"fn\"] is None:\n",
    "                    preds = te[\"inflation\"].values\n",
    "                    fold_results.append({\"mse\": mean_squared_error(te[target].values, preds),\n",
    "                        \"r2\": r2_score(te[target].values, preds),\n",
    "                        \"mae\": mean_absolute_error(te[target].values, preds),\n",
    "                        \"fold\": fold[\"name\"]})\n",
    "                    continue\n",
    "\n",
    "                feats = [f for f in spec[\"features\"] if f in fc_df.columns]\n",
    "\n",
    "                if spec[\"regime_aware\"]:\n",
    "                    preds = np.full(len(te), np.nan)\n",
    "                    for r in range(n_regimes):\n",
    "                        tr_r = tr[tr[\"regime\"] == r]\n",
    "                        te_r_mask = te[\"regime\"] == r\n",
    "                        if te_r_mask.sum() == 0:\n",
    "                            continue\n",
    "                        if len(tr_r) < 15:\n",
    "                            sc = StandardScaler()\n",
    "                            Xtr = sc.fit_transform(tr[feats])\n",
    "                            Xte = sc.transform(te.loc[te_r_mask, feats])\n",
    "                            m = spec[\"fn\"](); m.fit(Xtr, tr[target].values)\n",
    "                            preds[te_r_mask.values] = m.predict(Xte)\n",
    "                            continue\n",
    "                        sc = StandardScaler()\n",
    "                        Xtr = sc.fit_transform(tr_r[feats])\n",
    "                        Xte = sc.transform(te.loc[te_r_mask, feats])\n",
    "                        m = spec[\"fn\"](); m.fit(Xtr, tr_r[target].values)\n",
    "                        preds[te_r_mask.values] = m.predict(Xte)\n",
    "\n",
    "                    valid = ~np.isnan(preds)\n",
    "                    if valid.sum() < 6: continue\n",
    "                    mse = mean_squared_error(te[target].values[valid], preds[valid])\n",
    "                    r2 = r2_score(te[target].values[valid], preds[valid])\n",
    "                    mae = mean_absolute_error(te[target].values[valid], preds[valid])\n",
    "                else:\n",
    "                    sc = StandardScaler()\n",
    "                    Xtr = sc.fit_transform(tr[feats])\n",
    "                    Xte = sc.transform(te[feats])\n",
    "                    m = spec[\"fn\"](); m.fit(Xtr, tr[target].values)\n",
    "                    preds = m.predict(Xte)\n",
    "                    mse = mean_squared_error(te[target].values, preds)\n",
    "                    r2 = r2_score(te[target].values, preds)\n",
    "                    mae = mean_absolute_error(te[target].values, preds)\n",
    "\n",
    "                fold_results.append({\"mse\": mse, \"r2\": r2, \"mae\": mae, \"fold\": fold[\"name\"]})\n",
    "\n",
    "            if fold_results:\n",
    "                horizon_results[mname] = {\n",
    "                    \"avg_mse\": np.mean([f[\"mse\"] for f in fold_results]),\n",
    "                    \"avg_r2\": np.mean([f[\"r2\"] for f in fold_results]),\n",
    "                    \"avg_mae\": np.mean([f[\"mae\"] for f in fold_results]),\n",
    "                    \"folds\": fold_results\n",
    "                }\n",
    "\n",
    "        print(f\"\\n  {'Model':<25s}  {'MSE':>8s}  {'MAE':>8s}  {'R2':>8s}\")\n",
    "        print(f\"  {'-'*53}\")\n",
    "        for mname in models:\n",
    "            if mname in horizon_results:\n",
    "                r = horizon_results[mname]\n",
    "                print(f\"  {mname:<25s}  {r['avg_mse']:>8.3f}  {r['avg_mae']:>8.3f}  {r['avg_r2']:>+8.3f}\")\n",
    "\n",
    "        all_results[h] = horizon_results\n",
    "\n",
    "    return all_results\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# SUBSAMPLE STABILITY\n",
    "# ================================================================\n",
    "def subsample_stability(regime_df):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"SUBSAMPLE STABILITY: WHY 12-MONTH FORECASTING FAILS\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    print(f\"\\n  Inflation autocorrelation by regime:\")\n",
    "    print(f\"  {'Regime':<25s}\", end=\"\")\n",
    "    for lag in [1, 3, 6, 12]:\n",
    "        print(f\"  {'AC('+str(lag)+')':>7s}\", end=\"\")\n",
    "    print()\n",
    "    print(f\"  {'-'*60}\")\n",
    "\n",
    "    for r in sorted(regime_df[\"regime\"].unique()):\n",
    "        sub = regime_df[regime_df[\"regime\"] == r][\"inflation\"]\n",
    "        print(f\"  {'R'+str(r)+' (n='+str(len(sub))+')' :<25s}\", end=\"\")\n",
    "        for lag in [1, 3, 6, 12]:\n",
    "            ac = sub.autocorr(lag=lag)\n",
    "            print(f\"  {ac:>7.3f}\", end=\"\")\n",
    "        print()\n",
    "\n",
    "    full = regime_df[\"inflation\"]\n",
    "    print(f\"  {'Full sample':<25s}\", end=\"\")\n",
    "    for lag in [1, 3, 6, 12]:\n",
    "        print(f\"  {full.autocorr(lag=lag):>7.3f}\", end=\"\")\n",
    "    print()\n",
    "\n",
    "    ext_f = [f for f in EXTENDED_FEATURES if f in regime_df.columns]\n",
    "    target = \"inflation_12m_ahead\"\n",
    "    if target not in regime_df.columns:\n",
    "        regime_df[target] = regime_df[\"inflation\"].shift(-12)\n",
    "    fc_df = regime_df[ext_f + [target]].dropna()\n",
    "\n",
    "    periods = [\n",
    "        (\"Pre-Volcker\", \"1973-01\", \"1979-12\"),\n",
    "        (\"Volcker disinflation\", \"1980-01\", \"1986-12\"),\n",
    "        (\"Great Moderation I\", \"1987-01\", \"1999-12\"),\n",
    "        (\"Great Moderation II\", \"2000-01\", \"2007-12\"),\n",
    "        (\"Post-GFC\", \"2008-01\", \"2019-12\"),\n",
    "        (\"COVID+\", \"2020-01\", \"2023-01\"),\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n  {'Period':<25s}  {'N':>5s}  {'Var(pi)':>8s}  {'AR R2':>8s}  {'Ridge R2':>9s}\")\n",
    "    print(f\"  {'-'*60}\")\n",
    "\n",
    "    period_results = []\n",
    "    for pname, ps, pe in periods:\n",
    "        tr = fc_df.loc[:ps]; te = fc_df.loc[ps:pe]\n",
    "        if len(tr) < 30 or len(te) < 6: continue\n",
    "        var_pi = te[target].var()\n",
    "\n",
    "        base_f = [f for f in BASE_FEATURES if f in fc_df.columns]\n",
    "        sc = StandardScaler()\n",
    "        Xtr = sc.fit_transform(tr[base_f]); Xte = sc.transform(te[base_f])\n",
    "        m_ar = Ridge(alpha=1.0); m_ar.fit(Xtr, tr[target].values)\n",
    "        r2_ar = r2_score(te[target].values, m_ar.predict(Xte))\n",
    "\n",
    "        sc2 = StandardScaler()\n",
    "        Xtr2 = sc2.fit_transform(tr[ext_f]); Xte2 = sc2.transform(te[ext_f])\n",
    "        m_ridge = Ridge(alpha=10.0); m_ridge.fit(Xtr2, tr[target].values)\n",
    "        r2_ridge = r2_score(te[target].values, m_ridge.predict(Xte2))\n",
    "\n",
    "        period_results.append({\"period\": pname, \"n\": len(te), \"var_pi\": var_pi,\n",
    "                               \"r2_ar\": r2_ar, \"r2_ridge\": r2_ridge})\n",
    "        print(f\"  {pname:<25s}  {len(te):>5d}  {var_pi:>8.2f}  {r2_ar:>+8.3f}  {r2_ridge:>+9.3f}\")\n",
    "\n",
    "    return period_results\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# VISUALIZATION\n",
    "# ================================================================\n",
    "def plot_results(all_results, period_results, output_path):\n",
    "    model_colors = {\"AR (lags only)\": \"#6b7280\", \"Pooled Ridge\": C1,\n",
    "                    \"Ridge + regime\": C3, \"Ridge + regime prob\": C4,\n",
    "                    \"Regime-conditional\": C2, \"RF pooled\": C5}\n",
    "\n",
    "    # ── Fig 1: MSE and R2 by horizon ──\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    fig.suptitle(\"Inflation Forecasting: Does Regime Awareness Help?\",\n",
    "                 fontweight=\"bold\", fontsize=14, y=1.02)\n",
    "\n",
    "    model_names = list(all_results[HORIZONS[0]].keys())\n",
    "    x = np.arange(len(HORIZONS)); w = 0.8 / len(model_names)\n",
    "\n",
    "    for i, mname in enumerate(model_names):\n",
    "        mses = [all_results[h].get(mname, {}).get(\"avg_mse\", np.nan) for h in HORIZONS]\n",
    "        color = model_colors.get(mname, f\"C{i}\")\n",
    "        axes[0].bar(x + i*w, mses, w, label=mname, color=color, alpha=0.75,\n",
    "                    edgecolor=\"white\", lw=1)\n",
    "    axes[0].set_xticks(x + w*(len(model_names)-1)/2)\n",
    "    axes[0].set_xticklabels([f\"{h}m\" for h in HORIZONS])\n",
    "    axes[0].set_ylabel(\"Test MSE (lower = better)\")\n",
    "    axes[0].set_title(\"Forecast MSE by horizon\", fontweight=\"bold\")\n",
    "    axes[0].legend(frameon=True, fontsize=7)\n",
    "\n",
    "    for i, mname in enumerate(model_names):\n",
    "        r2s = [all_results[h].get(mname, {}).get(\"avg_r2\", np.nan) for h in HORIZONS]\n",
    "        color = model_colors.get(mname, f\"C{i}\")\n",
    "        axes[1].bar(x + i*w, r2s, w, label=mname, color=color, alpha=0.75,\n",
    "                    edgecolor=\"white\", lw=1)\n",
    "    axes[1].set_xticks(x + w*(len(model_names)-1)/2)\n",
    "    axes[1].set_xticklabels([f\"{h}m\" for h in HORIZONS])\n",
    "    axes[1].set_ylabel(\"Test R2\"); axes[1].axhline(0, color=\"grey\", lw=1, alpha=0.5)\n",
    "    axes[1].set_title(\"Forecast R2 by horizon\", fontweight=\"bold\")\n",
    "    axes[1].legend(frameon=True, fontsize=7)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    path1 = f\"{output_path}/forecast_regime_comparison.png\"\n",
    "    fig.savefig(path1, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "    print(f\"  Saved: {path1}\")\n",
    "\n",
    "    # ── Fig 2: Regime improvement ──\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    fig.suptitle(\"Regime Awareness: Improvement Over Pooled Ridge\",\n",
    "                 fontweight=\"bold\", fontsize=14, y=1.02)\n",
    "\n",
    "    regime_models = [\"Ridge + regime\", \"Ridge + regime prob\", \"Regime-conditional\"]\n",
    "    x = np.arange(len(HORIZONS)); w = 0.8 / len(regime_models)\n",
    "    for i, mname in enumerate(regime_models):\n",
    "        deltas = []\n",
    "        for h in HORIZONS:\n",
    "            pooled = all_results[h].get(\"Pooled Ridge\", {}).get(\"avg_mse\", np.nan)\n",
    "            regime = all_results[h].get(mname, {}).get(\"avg_mse\", np.nan)\n",
    "            delta_pct = (regime - pooled) / pooled * 100 if pooled > 0 else np.nan\n",
    "            deltas.append(delta_pct)\n",
    "        color = model_colors.get(mname, f\"C{i}\")\n",
    "        ax.bar(x + i*w, deltas, w, label=mname, color=color, alpha=0.75,\n",
    "               edgecolor=\"white\", lw=1)\n",
    "    ax.set_xticks(x + w*(len(regime_models)-1)/2)\n",
    "    ax.set_xticklabels([f\"{h}m\" for h in HORIZONS])\n",
    "    ax.axhline(0, color=\"grey\", lw=1.5)\n",
    "    ax.set_ylabel(\"% change in MSE vs Pooled Ridge (negative = better)\")\n",
    "    ax.set_title(\"Does conditioning on regimes reduce forecast error?\", fontweight=\"bold\")\n",
    "    ax.legend(frameon=True, fontsize=9)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    path2 = f\"{output_path}/forecast_regime_improvement.png\"\n",
    "    fig.savefig(path2, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "    print(f\"  Saved: {path2}\")\n",
    "\n",
    "    # ── Fig 3: Subsample stability ──\n",
    "    if period_results:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        fig.suptitle(\"Why 12-Month Inflation Forecasting Fails: Subsample Analysis\",\n",
    "                     fontweight=\"bold\", fontsize=14, y=1.02)\n",
    "\n",
    "        pnames = [p[\"period\"] for p in period_results]\n",
    "        r2_ars = [p[\"r2_ar\"] for p in period_results]\n",
    "        r2_ridges = [p[\"r2_ridge\"] for p in period_results]\n",
    "        var_pis = [p[\"var_pi\"] for p in period_results]\n",
    "\n",
    "        ax = axes[0]\n",
    "        ax.scatter(var_pis, r2_ridges, s=80, color=C1, zorder=3, edgecolors=\"white\", lw=1)\n",
    "        for p, vp, r2 in zip(pnames, var_pis, r2_ridges):\n",
    "            ax.annotate(p, (vp, r2), fontsize=8, textcoords=\"offset points\", xytext=(5, 5))\n",
    "        ax.axhline(0, color=\"grey\", ls=\"--\", lw=1)\n",
    "        ax.set_xlabel(\"Inflation variance in test period\")\n",
    "        ax.set_ylabel(\"12-month forecast R2\")\n",
    "        ax.set_title(\"Forecast quality vs inflation variability\", fontweight=\"bold\")\n",
    "\n",
    "        ax = axes[1]\n",
    "        x_p = np.arange(len(pnames))\n",
    "        ax.bar(x_p - 0.2, r2_ars, 0.35, label=\"AR\", color=\"#6b7280\", alpha=0.75, edgecolor=\"white\")\n",
    "        ax.bar(x_p + 0.2, r2_ridges, 0.35, label=\"Ridge\", color=C1, alpha=0.75, edgecolor=\"white\")\n",
    "        ax.set_xticks(x_p); ax.set_xticklabels(pnames, rotation=30, ha=\"right\", fontsize=9)\n",
    "        ax.axhline(0, color=\"grey\", ls=\"--\", lw=1)\n",
    "        ax.set_ylabel(\"12-month forecast R2\")\n",
    "        ax.set_title(\"R2 by test period\", fontweight=\"bold\")\n",
    "        ax.legend(frameon=True, fontsize=9)\n",
    "\n",
    "        fig.tight_layout()\n",
    "        path3 = f\"{output_path}/forecast_subsample_stability.png\"\n",
    "        fig.savefig(path3, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "        print(f\"  Saved: {path3}\")\n",
    "    else:\n",
    "        path3 = None\n",
    "\n",
    "    return [p for p in [path1, path2, path3] if p]\n",
    "\n",
    "\n",
    "# ── Main ───────────────────────────────────────────────────────────\n",
    "\n",
    "\n",
    "all_results = run_forecasting(regime_df, regime_names, n_regimes)\n",
    "period_results = subsample_stability(regime_df)\n",
    "paths = plot_results(all_results, period_results, OUTPUT_PATH)\n",
    "\n",
    "print(f\"\\nOutputs: {paths}\")\n",
    "print(\"Done.\")\n",
    "\n",
    "# ── Simpson's paradox quantification ─────────────────────────\n",
    "ac12_full = regime_df[\"inflation\"].autocorr(lag=12)\n",
    "ac12_within = np.average(\n",
    "    [regime_df[regime_df[\"regime\"]==r][\"inflation\"].autocorr(lag=12) for r in range(n_regimes)],\n",
    "    weights=[len(regime_df[regime_df[\"regime\"]==r]) for r in range(n_regimes)])\n",
    "comp = (ac12_full - ac12_within) / ac12_full * 100\n",
    "print(f\"\\n  Full-sample AC(12)={ac12_full:.3f}, within-regime={ac12_within:.3f}\")\n",
    "print(f\"  Compositional share: {comp:.0f}% of apparent persistence is from mixing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2c77fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Summary.\"\"\"\n",
    "import glob\n",
    "print(\"=\"*70)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "1. REGIMES: Low ~2.4%, High ~7.4%. Stable pre/post 2020.\n",
    "2. TAYLOR RULES: Specification-dependent. HAC SE 2-3x OLS.\n",
    "3. BREAKS: None survive sup-Wald with CBO NAIRU.\n",
    "4. FORECASTING: Random walk competitive. All fail beyond 3m.\n",
    "5. YIELD CURVE: No regime-transition signal. Recession LORO AUC~0.74.\n",
    "\"\"\")\n",
    "outputs = sorted(glob.glob(f\"{OUTPUT_PATH}/*.png\"))\n",
    "print(f\"Outputs ({len(outputs)}):\")\n",
    "for p in outputs: print(f\"  {os.path.basename(p)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
