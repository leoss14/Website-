{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning for Monetary Policy Optimisation\n",
    "\n",
    "**Authors:** Leonardo Luksic, Krisha Chandnani, Ignacio Orueta  \n",
    "**Institution:** London School of Economics  \n",
    "**Date:** February 2026\n",
    "\n",
    "---\n",
    "\n",
    "This notebook trains a Deep Q-Network (DQN) agent on monthly US macroeconomic data\n",
    "(1971\u20132025) to set nominal interest rates. The agent's policy is benchmarked against\n",
    "the standard Taylor Rule and actual Federal Reserve decisions.\n",
    "\n",
    "**Approach:**\n",
    "\n",
    "The pipeline has two stages. First, a neural network learns to forecast inflation\n",
    "12 months ahead using lagged macroeconomic indicators. Second, that forecast model\n",
    "serves as the transition function inside a Gymnasium environment where the DQN agent\n",
    "learns a rate-setting policy by minimising a weighted loss over inflation deviations,\n",
    "unemployment deviations, and interest-rate volatility.\n",
    "\n",
    "The forecast model is the only learned component \u2014 unemployment and capacity\n",
    "utilisation evolve from the historical record. This avoids the compounding-error\n",
    "problem that arises when multiple transition models are chained together.\n",
    "\n",
    "**Information structure:**\n",
    "\n",
    "We test four feature specifications with different lag horizons. Three use only\n",
    "lags of 18\u201330 months, approximating a realistic central-bank information set\n",
    "(publication delays of ~6 months plus a 12-month lookback). A fourth adds\n",
    "intermediate lags (3, 6, 12 months) that provide more recent signal at the\n",
    "cost of realism. Comparing these quantifies the forecasting penalty imposed\n",
    "by realistic information constraints.\n",
    "\n",
    "**Validation:**\n",
    "\n",
    "All models are validated with expanding-window time-series cross-validation\n",
    "across five distinct economic regimes (1990s recession, dot-com era, 2000s,\n",
    "Global Financial Crisis, and the post-2015 period including COVID)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import warnings\n",
    "import random\n",
    "from collections import deque, namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"X has feature names\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}  |  Gymnasium: {gym.__version__}\")\n",
    "print(f\"Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "DATA_PATH = '/Users/leoss/Downloads'\n",
    "OUTPUT_PATH = '/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs'\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "CFG = {\n",
    "    # Targets\n",
    "    \"inflation_target\": 2.0,\n",
    "    \"unemployment_natural\": 5.0,\n",
    "\n",
    "    # Environment\n",
    "    \"max_steps\": 36,          # 3-year episodes\n",
    "    \"n_actions\": 41,          # 0\u201320 % in 0.5 pp increments\n",
    "    \"min_rate\": 0.0,\n",
    "    \"max_rate\": 20.0,\n",
    "    \"omega_pi\": 1.0,          # weight on inflation deviation\n",
    "    \"omega_u\": 0.5,           # weight on unemployment deviation\n",
    "    \"omega_smooth\": 0.1,      # weight on rate smoothing\n",
    "\n",
    "    # DQN\n",
    "    \"buffer_capacity\": 15_000,\n",
    "    \"batch_size\": 64,\n",
    "    \"gamma\": 0.99,\n",
    "    \"epsilon_start\": 1.0,\n",
    "    \"epsilon_end\": 0.02,\n",
    "    \"epsilon_decay_steps\": 8_000,\n",
    "    \"lr\": 3e-4,\n",
    "    \"target_update_freq\": 400,\n",
    "    \"hidden_dim\": 128,\n",
    "    \"train_start_step\": 500,\n",
    "    \"n_episodes\": 600,\n",
    "\n",
    "    # Visualisation\n",
    "    \"fig_dpi\": 200,\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "# Cross-validation folds (expanding window)\n",
    "CV_FOLDS = [\n",
    "    {\"train_end\": \"1990-12\", \"test_start\": \"1991-01\",\n",
    "     \"test_end\": \"1995-12\", \"name\": \"Early 1990s\"},\n",
    "    {\"train_end\": \"1995-12\", \"test_start\": \"1996-01\",\n",
    "     \"test_end\": \"2000-12\", \"name\": \"Late 1990s\"},\n",
    "    {\"train_end\": \"2000-12\", \"test_start\": \"2001-01\",\n",
    "     \"test_end\": \"2007-12\", \"name\": \"2000s\"},\n",
    "    {\"train_end\": \"2007-12\", \"test_start\": \"2008-01\",\n",
    "     \"test_end\": \"2015-12\", \"name\": \"GFC & aftermath\"},\n",
    "    {\"train_end\": \"2015-12\", \"test_start\": \"2016-01\",\n",
    "     \"test_end\": \"2024-12\", \"name\": \"Recent\"},\n",
    "]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading\n",
    "\n",
    "Monthly economic indicators from FRED:\n",
    "\n",
    "| Variable | Series | Frequency | Role |\n",
    "|----------|--------|-----------|------|\n",
    "| CPI | CPIAUCSL | Monthly | Compute YoY inflation |\n",
    "| Unemployment | UNRATE | Monthly | Labour market slack |\n",
    "| Fed Funds Rate | FEDFUNDS | Monthly | Policy instrument |\n",
    "| Capacity Utilisation | TCU | Monthly | Real-economy output measure |\n",
    "| 10-Year Treasury | GS10 | Monthly | Term structure / expectations |\n",
    "| Financial Conditions | NFCI | Weekly \u2192 Monthly | Financial stress indicator |"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def load_data(path):\n",
    "    \"\"\"Load and merge monthly FRED CSVs.\"\"\"\n",
    "    def _read(names):\n",
    "        for n in names:\n",
    "            p = os.path.join(path, n)\n",
    "            if os.path.exists(p):\n",
    "                return pd.read_csv(p, parse_dates=[\"observation_date\"],\n",
    "                                   index_col=\"observation_date\")\n",
    "        raise FileNotFoundError(f\"None of {names} found in {path}\")\n",
    "\n",
    "    cpi     = _read([\"CPIAUCSL.csv\"])\n",
    "    unrate  = _read([\"UNRATE.csv\"])\n",
    "    ff      = _read([\"FEDFUNDS.csv\", \"FEDFUNDS-1.csv\"])\n",
    "    tcu     = _read([\"TCU.csv\"])\n",
    "    gs10    = _read([\"GS10.csv\"])\n",
    "    nfci_w  = _read([\"NFCI.csv\"])\n",
    "    nfci    = nfci_w.resample(\"MS\").last()\n",
    "\n",
    "    merged = pd.concat([\n",
    "        cpi.rename(columns={cpi.columns[0]: \"cpi\"}),\n",
    "        unrate.rename(columns={unrate.columns[0]: \"unemployment\"}),\n",
    "        ff.rename(columns={ff.columns[0]: \"fed_funds\"}),\n",
    "        tcu.rename(columns={tcu.columns[0]: \"capacity_util\"}),\n",
    "        gs10.rename(columns={gs10.columns[0]: \"treasury_10y\"}),\n",
    "        nfci.rename(columns={nfci.columns[0]: \"fin_conditions\"}),\n",
    "    ], axis=1).dropna()\n",
    "\n",
    "    print(f\"Merged panel: {len(merged)} monthly obs  \"\n",
    "          f\"({merged.index.min():%Y-%m} to {merged.index.max():%Y-%m})\")\n",
    "    return merged\n",
    "\n",
    "data = load_data(DATA_PATH)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering\n",
    "\n",
    "**Derived indicators:**\n",
    "- Inflation: year-over-year CPI percentage change\n",
    "- Unemployment gap: deviation from the 5 % natural rate\n",
    "- Capacity gap: deviation from full capacity (100 %)\n",
    "- Term spread: 10-year Treasury minus fed funds rate\n",
    "\n",
    "**Lag structure:** We create lags at 3, 6, 12, 18, 24, and 30 months\n",
    "for each indicator. The shorter lags (3\u201312) provide more recent information;\n",
    "the longer lags (18\u201330) approximate the realistic information set available\n",
    "after accounting for publication delays.\n",
    "\n",
    "**Target:** Inflation 12 months ahead \u2014 the standard central-bank forecast horizon."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def engineer_features(data, natural_rate=5.0):\n",
    "    df = data.copy()\n",
    "\n",
    "    # Derived indicators\n",
    "    df[\"inflation\"]    = df[\"cpi\"].pct_change(12) * 100\n",
    "    df[\"unemp_gap\"]    = df[\"unemployment\"] - natural_rate\n",
    "    df[\"capacity_gap\"] = df[\"capacity_util\"] - 100.0\n",
    "    df[\"term_spread\"]  = df[\"treasury_10y\"] - df[\"fed_funds\"]\n",
    "\n",
    "    # Lagged features at both horizons\n",
    "    lag_vars = [\"inflation\", \"unemp_gap\", \"capacity_gap\",\n",
    "                \"fed_funds\", \"term_spread\", \"fin_conditions\"]\n",
    "    for var in lag_vars:\n",
    "        for lag in [3, 6, 12, 18, 24, 30]:\n",
    "            df[f\"L{lag}_{var}\"] = df[var].shift(lag)\n",
    "\n",
    "    # Forward target\n",
    "    df[\"inflation_12m_ahead\"] = df[\"inflation\"].shift(-12)\n",
    "\n",
    "    df = df.dropna()\n",
    "    print(f\"Final dataset: {len(df)} obs  \"\n",
    "          f\"({df.index.min():%Y-%m} to {df.index.max():%Y-%m})\")\n",
    "    return df\n",
    "\n",
    "historical = engineer_features(data, CFG[\"unemployment_natural\"])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "C1, C2, C3 = \"#2563eb\", \"#dc2626\", \"#7c3aed\"\n",
    "C_BG = \"#fafafa\"\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"figure.facecolor\": C_BG, \"axes.facecolor\": C_BG,\n",
    "    \"axes.grid\": True, \"grid.color\": \"#e5e7eb\", \"grid.linewidth\": 0.5,\n",
    "    \"font.size\": 11, \"axes.spines.top\": False, \"axes.spines.right\": False,\n",
    "})\n",
    "\n",
    "RECESSIONS = [\n",
    "    (\"1980-01\", \"1982-11\"), (\"1990-07\", \"1991-03\"),\n",
    "    (\"2001-03\", \"2001-11\"), (\"2007-12\", \"2009-06\"),\n",
    "    (\"2020-02\", \"2020-04\"),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 11))\n",
    "fig.suptitle(\"US Economic Indicators (Monthly, 1973-2025)\",\n",
    "             fontweight=\"bold\", fontsize=14, y=0.995)\n",
    "\n",
    "panels = [\n",
    "    (\"inflation\", \"Inflation (YoY %)\", C1, {\"hline\": 2.0, \"hl\": \"Target\"}),\n",
    "    (\"unemployment\", \"Unemployment rate (%)\", C2, {\"hline\": 5.0, \"hl\": \"Natural rate\"}),\n",
    "    (\"capacity_util\", \"Capacity utilisation (%)\", \"#c2410c\", {\"hline\": 100, \"hl\": \"Full capacity\"}),\n",
    "    ([\"fed_funds\", \"treasury_10y\"], \"Interest rates (%)\", None, {}),\n",
    "    (\"term_spread\", \"Term spread (10Y - FFR, pp)\", \"#7c3aed\", {\"hline\": 0}),\n",
    "    (\"fin_conditions\", \"Financial Conditions Index\", \"#c2410c\", {\"hline\": 0, \"hl\": \"Neutral\"}),\n",
    "]\n",
    "\n",
    "for ax, (col, title, color, opts) in zip(axes.flat, panels):\n",
    "    if isinstance(col, list):\n",
    "        ax.plot(historical.index, historical[col[0]], lw=1.5, color=C1, label=\"Fed funds\")\n",
    "        ax.plot(historical.index, historical[col[1]], lw=1.5, color=C2, alpha=0.7, label=\"10Y Treasury\")\n",
    "        ax.legend(fontsize=9, frameon=False)\n",
    "    else:\n",
    "        ax.plot(historical.index, historical[col], lw=1.5, color=color)\n",
    "    if \"hline\" in opts:\n",
    "        ax.axhline(opts[\"hline\"], color=\"grey\", ls=\"--\", lw=1, alpha=0.6, label=opts.get(\"hl\"))\n",
    "        if \"hl\" in opts:\n",
    "            ax.legend(fontsize=9, frameon=False)\n",
    "    ax.set_title(title, fontweight=\"bold\", fontsize=11)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{OUTPUT_PATH}/data_overview.png\", dpi=CFG[\"fig_dpi\"], bbox_inches=\"tight\")\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Specifications\n",
    "\n",
    "Five specifications test the effect of lag horizon, variable breadth, and\n",
    "dimensionality on forecast accuracy:\n",
    "\n",
    "| Spec | Features | Lags | Description |\n",
    "|------|----------|------|-------------|\n",
    "| SIMPLE | Inflation, fed funds | 18, 24, 30 | Core variables, realistic lags |\n",
    "| EXPANDED | + unemployment, capacity | 18, 24, 30 | Real-economy measures added |\n",
    "| FULL | + term spread, NFCI | 18, 24, 30 | All variables, realistic lags |\n",
    "| INFORMATIVE | All variables | 3-30 | Intermediate + realistic lags |\n",
    "| LEAN | Inflation, rate, unemp gap, spread | 3, 6, 12 | Focused set, fewer parameters |\n",
    "\n",
    "The first three use only realistic lags (>=18 months). INFORMATIVE adds shorter\n",
    "lags but has 36 features \u2014 a concern with ~460 training observations. LEAN targets\n",
    "the best ratio of signal to model complexity: 8 features covering the core\n",
    "macro variables at intermediate lags."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "SPECS = {\n",
    "    \"SIMPLE\": {\n",
    "        \"features\": [\n",
    "            \"L18_inflation\", \"L24_inflation\", \"L30_inflation\",\n",
    "            \"L18_fed_funds\", \"L24_fed_funds\", \"L30_fed_funds\",\n",
    "        ],\n",
    "        \"desc\": \"Core variables, realistic lags only\",\n",
    "    },\n",
    "    \"EXPANDED\": {\n",
    "        \"features\": [\n",
    "            \"L18_inflation\", \"L24_inflation\", \"L30_inflation\",\n",
    "            \"L18_unemp_gap\", \"L24_unemp_gap\", \"L30_unemp_gap\",\n",
    "            \"L18_capacity_gap\", \"L24_capacity_gap\", \"L30_capacity_gap\",\n",
    "            \"L18_fed_funds\", \"L24_fed_funds\", \"L30_fed_funds\",\n",
    "        ],\n",
    "        \"desc\": \"With real-economy measures, realistic lags only\",\n",
    "    },\n",
    "    \"FULL\": {\n",
    "        \"features\": [\n",
    "            \"L18_inflation\", \"L24_inflation\", \"L30_inflation\",\n",
    "            \"L18_unemp_gap\", \"L24_unemp_gap\", \"L30_unemp_gap\",\n",
    "            \"L18_capacity_gap\", \"L24_capacity_gap\", \"L30_capacity_gap\",\n",
    "            \"L18_fed_funds\", \"L24_fed_funds\", \"L30_fed_funds\",\n",
    "            \"L18_term_spread\", \"L24_term_spread\", \"L30_term_spread\",\n",
    "            \"L18_fin_conditions\", \"L24_fin_conditions\", \"L30_fin_conditions\",\n",
    "        ],\n",
    "        \"desc\": \"Full specification, realistic lags only\",\n",
    "    },\n",
    "    \"INFORMATIVE\": {\n",
    "        \"features\": [\n",
    "            \"L3_inflation\", \"L6_inflation\", \"L12_inflation\",\n",
    "            \"L3_unemp_gap\", \"L6_unemp_gap\", \"L12_unemp_gap\",\n",
    "            \"L3_capacity_gap\", \"L6_capacity_gap\", \"L12_capacity_gap\",\n",
    "            \"L3_fed_funds\", \"L6_fed_funds\", \"L12_fed_funds\",\n",
    "            \"L3_term_spread\", \"L6_term_spread\", \"L12_term_spread\",\n",
    "            \"L3_fin_conditions\", \"L6_fin_conditions\", \"L12_fin_conditions\",\n",
    "            \"L18_inflation\", \"L24_inflation\", \"L30_inflation\",\n",
    "            \"L18_unemp_gap\", \"L24_unemp_gap\", \"L30_unemp_gap\",\n",
    "            \"L18_capacity_gap\", \"L24_capacity_gap\", \"L30_capacity_gap\",\n",
    "            \"L18_fed_funds\", \"L24_fed_funds\", \"L30_fed_funds\",\n",
    "            \"L18_term_spread\", \"L24_term_spread\", \"L30_term_spread\",\n",
    "            \"L18_fin_conditions\", \"L24_fin_conditions\", \"L30_fin_conditions\",\n",
    "        ],\n",
    "        \"desc\": \"All variables, intermediate + realistic lags (L3-L30)\",\n",
    "    },\n",
    "    \"LEAN\": {\n",
    "        \"features\": [\n",
    "            \"L3_inflation\", \"L6_inflation\", \"L12_inflation\",\n",
    "            \"L3_fed_funds\", \"L6_fed_funds\", \"L12_fed_funds\",\n",
    "            \"L6_unemp_gap\", \"L6_term_spread\",\n",
    "        ],\n",
    "        \"desc\": \"Focused: inflation + rate + unemployment + spread (8 features)\",\n",
    "    },\n",
    "}\n",
    "\n",
    "TARGET_COL = \"inflation_12m_ahead\"\n",
    "\n",
    "for name, spec in SPECS.items():\n",
    "    print(f\"{name:14s}  {len(spec['features']):2d} features  |  {spec['desc']}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Time-Series Cross-Validation\n",
    "\n",
    "Expanding-window CV trains on all data up to each cutoff date, then tests\n",
    "on the subsequent period. This avoids look-ahead bias and checks whether\n",
    "the model generalises across structurally different economic regimes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cv_results = {}\n",
    "\n",
    "for spec_name, spec in SPECS.items():\n",
    "    print(f\"\\n--- {spec_name} ({len(spec['features'])} features) ---\")\n",
    "    fold_metrics = []\n",
    "\n",
    "    for fold in CV_FOLDS:\n",
    "        train = historical.loc[:fold[\"train_end\"]]\n",
    "        test  = historical.loc[fold[\"test_start\"]:fold[\"test_end\"]]\n",
    "        if len(test) < 10:\n",
    "            continue\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_tr = scaler.fit_transform(train[spec[\"features\"]])\n",
    "        X_te = scaler.transform(test[spec[\"features\"]])\n",
    "        y_tr, y_te = train[TARGET_COL], test[TARGET_COL]\n",
    "\n",
    "        model = MLPRegressor(\n",
    "            hidden_layer_sizes=(64, 32), activation=\"relu\",\n",
    "            solver=\"adam\", alpha=0.01, batch_size=32,\n",
    "            learning_rate=\"adaptive\", learning_rate_init=0.001,\n",
    "            max_iter=500, early_stopping=True,\n",
    "            validation_fraction=0.15, n_iter_no_change=20,\n",
    "            random_state=42, verbose=False,\n",
    "        )\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_te)\n",
    "\n",
    "        mse = mean_squared_error(y_te, y_pred)\n",
    "        mae = mean_absolute_error(y_te, y_pred)\n",
    "        r2  = r2_score(y_te, y_pred)\n",
    "        fold_metrics.append({\"fold\": fold[\"name\"], \"mse\": mse, \"mae\": mae, \"r2\": r2})\n",
    "        print(f\"  {fold['name']:18s}  MSE={mse:.4f}  MAE={mae:.4f}  R2={r2:.4f}\")\n",
    "\n",
    "    avg = {k: np.mean([f[k] for f in fold_metrics]) for k in (\"mse\", \"mae\", \"r2\")}\n",
    "    cv_results[spec_name] = {\"folds\": fold_metrics, **avg}\n",
    "    print(f\"  {'Average':18s}  MSE={avg['mse']:.4f}  MAE={avg['mae']:.4f}  R2={avg['r2']:.4f}\")\n",
    "\n",
    "best_spec = min(cv_results, key=lambda s: cv_results[s][\"mse\"])\n",
    "print(f\"\\nBest specification: {best_spec}  (avg CV MSE = {cv_results[best_spec]['mse']:.4f})\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "specs_list = list(cv_results.keys())\n",
    "folds_list = [f[\"fold\"] for f in cv_results[specs_list[0]][\"folds\"]]\n",
    "n_folds, n_specs = len(folds_list), len(specs_list)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13, 5.5))\n",
    "x = np.arange(n_folds)\n",
    "width = 0.8 / n_specs\n",
    "colors = [C1, C2, C3, \"#f59e0b\", \"#10b981\"]\n",
    "\n",
    "for i, spec in enumerate(specs_list):\n",
    "    mses = [f[\"mse\"] for f in cv_results[spec][\"folds\"]]\n",
    "    ax.bar(x + i * width, mses, width, label=spec,\n",
    "           color=colors[i], alpha=0.7, edgecolor=\"white\", lw=1)\n",
    "\n",
    "ax.set_xticks(x + width * (n_specs - 1) / 2)\n",
    "ax.set_xticklabels(folds_list, fontsize=10)\n",
    "ax.set_ylabel(\"Test MSE\")\n",
    "ax.set_title(\"Time-series CV: forecast error by specification and period\", fontweight=\"bold\")\n",
    "ax.legend(frameon=False, fontsize=9)\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{OUTPUT_PATH}/cv_results.png\", dpi=CFG[\"fig_dpi\"], bbox_inches=\"tight\")\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Inflation Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "feats = SPECS[best_spec][\"features\"]\n",
    "X, y = historical[feats], historical[TARGET_COL]\n",
    "split = int(len(X) * 0.8)\n",
    "\n",
    "final_scaler = StandardScaler()\n",
    "X_tr = final_scaler.fit_transform(X.iloc[:split])\n",
    "X_val = final_scaler.transform(X.iloc[split:])\n",
    "y_tr, y_val = y.iloc[:split], y.iloc[split:]\n",
    "\n",
    "final_model = MLPRegressor(\n",
    "    hidden_layer_sizes=(64, 32), activation=\"relu\",\n",
    "    solver=\"adam\", alpha=0.01, batch_size=32,\n",
    "    learning_rate=\"adaptive\", learning_rate_init=0.001,\n",
    "    max_iter=500, early_stopping=True,\n",
    "    validation_fraction=0.15, n_iter_no_change=20,\n",
    "    random_state=42, verbose=False,\n",
    ")\n",
    "final_model.fit(X_tr, y_tr)\n",
    "\n",
    "y_pred = final_model.predict(X_val)\n",
    "print(f\"Specification: {best_spec} ({len(feats)} features)\")\n",
    "print(f\"Validation MSE: {mean_squared_error(y_val, y_pred):.4f}\")\n",
    "print(f\"Validation R2:  {r2_score(y_val, y_pred):.4f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation: Predicted vs Actual"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(13, 5.5))\n",
    "\n",
    "y_tr_pred = final_model.predict(X_tr)\n",
    "ax1.scatter(y_tr, y_tr_pred, alpha=0.4, s=15, color=C1, edgecolors=\"white\", lw=0.3)\n",
    "ax1.plot([y_tr.min(), y_tr.max()], [y_tr.min(), y_tr.max()], \"k--\", lw=1.5, alpha=0.5)\n",
    "ax1.set_xlabel(\"Actual inflation (%)\")\n",
    "ax1.set_ylabel(\"Predicted inflation (%)\")\n",
    "ax1.set_title(f\"Training (R2 = {r2_score(y_tr, y_tr_pred):.3f})\", fontweight=\"bold\")\n",
    "\n",
    "ax2.scatter(y_val, y_pred, alpha=0.4, s=15, color=C2, edgecolors=\"white\", lw=0.3)\n",
    "ax2.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], \"k--\", lw=1.5, alpha=0.5)\n",
    "ax2.set_xlabel(\"Actual inflation (%)\")\n",
    "ax2.set_ylabel(\"Predicted inflation (%)\")\n",
    "ax2.set_title(f\"Validation (R2 = {r2_score(y_val, y_pred):.3f})\", fontweight=\"bold\")\n",
    "\n",
    "fig.suptitle(f\"{best_spec}: Predicted vs Actual Inflation (12-month ahead)\", fontweight=\"bold\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{OUTPUT_PATH}/model_validation.png\", dpi=CFG[\"fig_dpi\"], bbox_inches=\"tight\")\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. RL Environment\n",
    "\n",
    "The agent observes `(inflation, unemployment, capacity utilisation, current rate)`\n",
    "and picks a discrete interest rate from 0\u201320 % in 0.5 pp increments.\n",
    "\n",
    "The agent's rate choices are tracked in a rolling buffer and substituted into the\n",
    "`fed_funds` lag features when building the inflation prediction input. This means\n",
    "the agent's decisions propagate through the forecast model with the appropriate\n",
    "delay \u2014 short lags (L3) reflect recent choices, longer lags (L18+) still come\n",
    "from the historical record early in an episode.\n",
    "\n",
    "Unemployment and capacity utilisation evolve from the historical record.\n",
    "Only inflation is model-predicted."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class MonetaryPolicyEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": []}\n",
    "\n",
    "    def __init__(self, model, scaler, feature_cols, historical_df, cfg):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.scaler = scaler\n",
    "        self.feature_cols = feature_cols\n",
    "        self.hist = historical_df.reset_index(drop=True)\n",
    "\n",
    "        self.pi_target  = cfg[\"inflation_target\"]\n",
    "        self.u_target   = cfg[\"unemployment_natural\"]\n",
    "        self.w_pi       = cfg[\"omega_pi\"]\n",
    "        self.w_u        = cfg[\"omega_u\"]\n",
    "        self.w_smooth   = cfg[\"omega_smooth\"]\n",
    "        self.max_steps  = cfg[\"max_steps\"]\n",
    "\n",
    "        self.n_actions  = cfg[\"n_actions\"]\n",
    "        self.rate_grid  = np.linspace(cfg[\"min_rate\"], cfg[\"max_rate\"], self.n_actions)\n",
    "        self.action_space = spaces.Discrete(self.n_actions)\n",
    "        self.observation_space = spaces.Box(-np.inf, np.inf, (4,), dtype=np.float32)\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        if seed is not None:\n",
    "            super().reset(seed=seed)\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        min_start = 30\n",
    "        max_start = len(self.hist) - self.max_steps - 12 - 1\n",
    "        self.start_idx = (min_start if max_start <= min_start\n",
    "                          else np.random.randint(min_start, max_start))\n",
    "        self.idx = self.start_idx\n",
    "        self.step_count = 0\n",
    "        self._done = False\n",
    "\n",
    "        row = self.hist.iloc[self.idx]\n",
    "        self.state = np.array([row[\"inflation\"], row[\"unemployment\"],\n",
    "                               row[\"capacity_util\"], row[\"fed_funds\"]], dtype=np.float32)\n",
    "        self.prev_rate = row[\"fed_funds\"]\n",
    "\n",
    "        # Rolling buffer for agent's rate history (lag propagation)\n",
    "        self._rate_buffer = deque(\n",
    "            [self.hist.iloc[max(0, self.idx - i)][\"fed_funds\"] for i in range(31)],\n",
    "            maxlen=31)\n",
    "\n",
    "        self.episode_history = []\n",
    "        self.cumulative_reward = 0.0\n",
    "        return self.state, {}\n",
    "\n",
    "    def step(self, action):\n",
    "        if self._done:\n",
    "            raise RuntimeError(\"Episode finished\")\n",
    "\n",
    "        rate = float(self.rate_grid[int(action)])\n",
    "        self.step_count += 1\n",
    "        self._rate_buffer.appendleft(rate)\n",
    "\n",
    "        # Build feature vector \u2014 override fed_funds lags with agent's buffer\n",
    "        row = self.hist.iloc[self.idx]\n",
    "        feat_dict = {}\n",
    "        for col in self.feature_cols:\n",
    "            if col in row.index:\n",
    "                if \"fed_funds\" in col:\n",
    "                    lag = int(col.split(\"_\")[0][1:])\n",
    "                    feat_dict[col] = [self._rate_buffer[lag] if lag < len(self._rate_buffer)\n",
    "                                      else row[col]]\n",
    "                else:\n",
    "                    feat_dict[col] = [row[col]]\n",
    "            else:\n",
    "                feat_dict[col] = [0.0]\n",
    "\n",
    "        features_scaled = self.scaler.transform(pd.DataFrame(feat_dict))\n",
    "        next_pi = np.clip(float(self.model.predict(features_scaled)[0]), -2.0, 15.0)\n",
    "\n",
    "        # Other variables from historical record\n",
    "        next_idx = min(self.idx + 1, len(self.hist) - 1)\n",
    "        next_u   = self.hist.iloc[next_idx][\"unemployment\"]\n",
    "        next_cap = self.hist.iloc[next_idx][\"capacity_util\"]\n",
    "\n",
    "        reward = -(self.w_pi * (next_pi - self.pi_target) ** 2\n",
    "                   + self.w_u * (next_u - self.u_target) ** 2\n",
    "                   + self.w_smooth * (rate - self.prev_rate) ** 2)\n",
    "\n",
    "        self.episode_history.append({\n",
    "            \"inflation\": next_pi, \"unemployment\": next_u,\n",
    "            \"capacity\": next_cap, \"rate\": rate, \"reward\": reward})\n",
    "        self.cumulative_reward += reward\n",
    "\n",
    "        self.state = np.array([next_pi, next_u, next_cap, rate], dtype=np.float32)\n",
    "        self.prev_rate = rate\n",
    "        self.idx = next_idx\n",
    "        self._done = self.step_count >= self.max_steps\n",
    "        return self.state, reward, self._done, False, {}\n",
    "\n",
    "env = MonetaryPolicyEnv(final_model, final_scaler, feats, historical, CFG)\n",
    "print(f\"Environment created  |  Actions: {env.n_actions}  |  Episode: {env.max_steps} months\")\n",
    "\n",
    "# Smoke test\n",
    "state, _ = env.reset(seed=42)\n",
    "next_state, reward, done, _, _ = env.step(env.action_space.sample())\n",
    "print(f\"Test step: reward = {reward:.2f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. DQN Agent\n",
    "\n",
    "Standard Deep Q-Network with experience replay, target network, and\n",
    "epsilon-greedy exploration. The Q-network is a 3-layer MLP (128-128-41)\n",
    "trained with Huber loss."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "Transition = namedtuple(\"Transition\", (\"state\", \"action\", \"reward\", \"next_state\", \"done\"))\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buf = deque(maxlen=capacity)\n",
    "    def push(self, *args):\n",
    "        self.buf.append(Transition(*args))\n",
    "    def sample(self, n):\n",
    "        return random.sample(self.buf, n)\n",
    "    def __len__(self):\n",
    "        return len(self.buf)\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, hidden=128):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(state_dim, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, hidden)\n",
    "        self.fc3 = nn.Linear(hidden, action_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, env, cfg):\n",
    "        self.env = env\n",
    "        sd = env.observation_space.shape[0]\n",
    "        ad = env.action_space.n\n",
    "        self.buffer = ReplayBuffer(cfg[\"buffer_capacity\"])\n",
    "        self.batch_size = cfg[\"batch_size\"]\n",
    "        self.gamma = cfg[\"gamma\"]\n",
    "        self.epsilon = cfg[\"epsilon_start\"]\n",
    "        self.eps_min = cfg[\"epsilon_end\"]\n",
    "        self.eps_decay = (cfg[\"epsilon_end\"] / cfg[\"epsilon_start\"]) ** (1.0 / cfg[\"epsilon_decay_steps\"])\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.policy_net = QNetwork(sd, ad, cfg[\"hidden_dim\"]).to(self.device)\n",
    "        self.target_net = QNetwork(sd, ad, cfg[\"hidden_dim\"]).to(self.device)\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "        self.target_net.eval()\n",
    "        self.optimiser = optim.Adam(self.policy_net.parameters(), lr=cfg[\"lr\"])\n",
    "        self.loss_fn = nn.SmoothL1Loss()\n",
    "        self._steps = 0\n",
    "        self._target_freq = cfg[\"target_update_freq\"]\n",
    "\n",
    "    def choose_action(self, state, greedy=False):\n",
    "        if not greedy and np.random.random() < self.epsilon:\n",
    "            return self.env.action_space.sample()\n",
    "        with torch.no_grad():\n",
    "            t = torch.FloatTensor(state).unsqueeze(0).to(self.device)\n",
    "            return self.policy_net(t).argmax().item()\n",
    "\n",
    "    def store(self, s, a, r, s2, done):\n",
    "        self.buffer.push(s, a, r, s2, done)\n",
    "\n",
    "    def update(self):\n",
    "        if len(self.buffer) < self.batch_size:\n",
    "            return None\n",
    "        batch = Transition(*zip(*self.buffer.sample(self.batch_size)))\n",
    "        s  = torch.FloatTensor(np.array(batch.state)).to(self.device)\n",
    "        a  = torch.LongTensor(batch.action).unsqueeze(1).to(self.device)\n",
    "        r  = torch.FloatTensor(batch.reward).unsqueeze(1).to(self.device)\n",
    "        s2 = torch.FloatTensor(np.array(batch.next_state)).to(self.device)\n",
    "        d  = torch.BoolTensor(batch.done).unsqueeze(1).to(self.device)\n",
    "        q = self.policy_net(s).gather(1, a)\n",
    "        with torch.no_grad():\n",
    "            q2 = self.target_net(s2).max(1)[0].unsqueeze(1)\n",
    "            target = r + self.gamma * q2 * (~d)\n",
    "        loss = self.loss_fn(q, target)\n",
    "        self.optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(self.policy_net.parameters(), 10.0)\n",
    "        self.optimiser.step()\n",
    "        self._steps += 1\n",
    "        if self._steps % self._target_freq == 0:\n",
    "            self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "        return loss.item()\n",
    "\n",
    "    def decay_epsilon(self):\n",
    "        self.epsilon = max(self.eps_min, self.epsilon * self.eps_decay)\n",
    "\n",
    "agent = DQNAgent(env, CFG)\n",
    "print(f\"DQN agent on {agent.device}  |  epsilon: {CFG['epsilon_start']} -> {CFG['epsilon_end']}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "episode_rewards, episode_losses = [], []\n",
    "total_steps = 0\n",
    "warmup = CFG[\"train_start_step\"]\n",
    "\n",
    "for ep in range(CFG[\"n_episodes\"]):\n",
    "    s, _ = env.reset()\n",
    "    ep_r, ep_l, n_upd = 0.0, 0.0, 0\n",
    "\n",
    "    for _ in range(env.max_steps):\n",
    "        a = agent.choose_action(s)\n",
    "        s2, r, done, _, _ = env.step(a)\n",
    "        agent.store(s, a, r, s2, done)\n",
    "\n",
    "        if total_steps > warmup:\n",
    "            loss = agent.update()\n",
    "            if loss is not None:\n",
    "                ep_l += loss\n",
    "                n_upd += 1\n",
    "\n",
    "        s = s2\n",
    "        ep_r += r\n",
    "        total_steps += 1\n",
    "        agent.decay_epsilon()\n",
    "        if done:\n",
    "            break\n",
    "    episode_rewards.append(ep_r)\n",
    "    episode_losses.append(ep_l / max(n_upd, 1))\n",
    "\n",
    "    if (ep + 1) % 100 == 0:\n",
    "        avg = np.mean(episode_rewards[-100:])\n",
    "        print(f\"  ep {ep+1:4d}  |  avg reward {avg:8.2f}  |  eps {agent.epsilon:.4f}\")\n",
    "\n",
    "print(f\"\\nFinal 50-episode avg reward: {np.mean(episode_rewards[-50:]):.2f}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 7.5))\n",
    "w = 30\n",
    "\n",
    "ax1.plot(episode_rewards, alpha=0.2, color=C1, lw=0.8)\n",
    "if len(episode_rewards) >= w:\n",
    "    sm = np.convolve(episode_rewards, np.ones(w)/w, mode=\"valid\")\n",
    "    ax1.plot(range(w-1, len(episode_rewards)), sm, color=C1, lw=2.5, label=f\"{w}-episode avg\")\n",
    "ax1.set_ylabel(\"Episode reward\")\n",
    "ax1.set_title(\"Training: cumulative reward per episode\", fontweight=\"bold\")\n",
    "ax1.legend(frameon=False)\n",
    "\n",
    "valid = [(i, l) for i, l in enumerate(episode_losses) if l and l > 0]\n",
    "if valid and len(valid) >= w:\n",
    "    ix, vals = zip(*valid)\n",
    "    sm = np.convolve(vals, np.ones(w)/w, mode=\"valid\")\n",
    "    ax2.plot(range(ix[0]+w-1, ix[0]+w-1+len(sm)), sm, color=C2, lw=2.5)\n",
    "ax2.set_ylabel(\"TD loss\")\n",
    "ax2.set_xlabel(\"Episode\")\n",
    "ax2.set_title(\"Training: Huber loss\", fontweight=\"bold\")\n",
    "\n",
    "fig.tight_layout(h_pad=2.5)\n",
    "fig.savefig(f\"{OUTPUT_PATH}/training_curves.png\", dpi=CFG[\"fig_dpi\"], bbox_inches=\"tight\")\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Policy Comparison\n",
    "\n",
    "Generate rate recommendations for the full historical record under each policy:\n",
    "- **Federal Reserve** (actual decisions)\n",
    "- **Taylor Rule**: $i_t = r^* + \\pi_t + 1.5(\\pi_t - \\pi^*) + 0.5(u_t - u^*)$\n",
    "- **DQN agent** (greedy policy)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def taylor_rule(pi, u, r_star=2.0, pi_star=2.0, u_star=5.0, a_pi=1.5, a_u=0.5):\n",
    "    return np.clip(r_star + pi + a_pi * (pi - pi_star) + a_u * (u - u_star), 0, 20)\n",
    "\n",
    "df = historical.copy()\n",
    "df[\"taylor_rate\"] = df.apply(lambda r: taylor_rule(r[\"inflation\"], r[\"unemployment\"]), axis=1)\n",
    "df[\"dqn_rate\"] = np.nan\n",
    "\n",
    "agent.epsilon = 0.0  # greedy\n",
    "for i in range(len(df)):\n",
    "    if i < 30:\n",
    "        continue\n",
    "    row = df.iloc[i]\n",
    "    state = np.array([row[\"inflation\"], row[\"unemployment\"],\n",
    "                      row[\"capacity_util\"], row[\"fed_funds\"]], dtype=np.float32)\n",
    "    action = agent.choose_action(state, greedy=True)\n",
    "    df.iloc[i, df.columns.get_loc(\"dqn_rate\")] = env.rate_grid[action]\n",
    "\n",
    "print(f\"Generated policy recommendations for {df['dqn_rate'].notna().sum()} months\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Historical Rate Comparison"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(16, 9), sharex=True)\n",
    "fig.suptitle(\"Monetary policy comparison: DQN vs Taylor Rule vs Federal Reserve (1975-2025)\",\n",
    "             fontweight=\"bold\", fontsize=13, y=0.995)\n",
    "\n",
    "axes[0].plot(df.index, df[\"fed_funds\"], lw=2, color=C1, label=\"Federal Reserve (actual)\", alpha=0.9)\n",
    "axes[0].plot(df.index, df[\"taylor_rate\"], lw=1.8, color=C2, ls=\"--\", label=\"Taylor Rule\", alpha=0.8)\n",
    "axes[0].plot(df.index, df[\"dqn_rate\"], lw=2, color=C3, ls=\":\", label=\"DQN agent\", alpha=0.85)\n",
    "for s, e in RECESSIONS:\n",
    "    axes[0].axvspan(s, e, alpha=0.12, color=\"#fca5a5\", zorder=0)\n",
    "axes[0].set_ylabel(\"Nominal interest rate (%)\")\n",
    "axes[0].set_ylim(-1, 22)\n",
    "axes[0].legend(loc=\"upper right\", frameon=True, fontsize=10)\n",
    "axes[0].set_title(\"Interest-rate policies\", fontweight=\"bold\")\n",
    "\n",
    "t_dev = df[\"taylor_rate\"] - df[\"fed_funds\"]\n",
    "d_dev = df[\"dqn_rate\"] - df[\"fed_funds\"]\n",
    "axes[1].fill_between(df.index, t_dev, 0, alpha=0.15, color=C2)\n",
    "axes[1].fill_between(df.index, d_dev, 0, alpha=0.15, color=C3)\n",
    "axes[1].plot(df.index, t_dev, lw=1.5, color=C2, label=\"Taylor deviation\", alpha=0.8)\n",
    "axes[1].plot(df.index, d_dev, lw=1.5, color=C3, label=\"DQN deviation\", alpha=0.8)\n",
    "axes[1].axhline(0, color=C1, lw=1, alpha=0.4)\n",
    "axes[1].set_ylabel(\"Deviation from Fed rate (pp)\")\n",
    "axes[1].set_xlabel(\"Year\")\n",
    "axes[1].legend(loc=\"upper right\", frameon=True, fontsize=10)\n",
    "axes[1].set_title(\"Policy deviations from actual Federal Reserve decisions\", fontweight=\"bold\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{OUTPUT_PATH}/policy_comparison.png\", dpi=CFG[\"fig_dpi\"], bbox_inches=\"tight\")\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"Deviation from actual Federal Reserve decisions:\\n\")\n",
    "for name, col in [(\"Taylor Rule\", \"taylor_rate\"), (\"DQN Agent\", \"dqn_rate\")]:\n",
    "    dev = (df[col] - df[\"fed_funds\"]).dropna()\n",
    "    mad  = np.abs(dev).mean()\n",
    "    rmse = np.sqrt((dev ** 2).mean())\n",
    "    print(f\"  {name:15s}  MAD = {mad:.3f} pp  |  RMSE = {rmse:.3f} pp\")\n",
    "\n",
    "# Improvement\n",
    "t_mad = np.abs(df[\"taylor_rate\"] - df[\"fed_funds\"]).dropna().mean()\n",
    "d_mad = np.abs(df[\"dqn_rate\"] - df[\"fed_funds\"]).dropna().mean()\n",
    "if d_mad < t_mad:\n",
    "    print(f\"\\n  DQN reduces MAD by {((t_mad - d_mad) / t_mad * 100):.1f}% relative to Taylor Rule\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Discussion\n",
    "\n",
    "**What the model does:** A neural network forecasts inflation 12 months ahead\n",
    "using lagged macroeconomic indicators. A DQN agent then uses that forecast,\n",
    "together with current unemployment and capacity data, to learn a rate-setting\n",
    "policy over 3-year simulated episodes. The agent is evaluated by comparing\n",
    "its recommendations against the Taylor Rule and actual Fed decisions across\n",
    "50 years of history.\n",
    "\n",
    "**Information-lag tradeoff:** The cross-validation results quantify the cost\n",
    "of realistic information constraints. Specifications restricted to 18\u201330 month\n",
    "lags perform substantially worse on the Early 1990s fold, where the model\n",
    "must extrapolate from the volatile 1970s\u201380s into a structurally different\n",
    "disinflation period. Adding intermediate lags (3\u201312 months) reduces forecast\n",
    "error, particularly for more stable post-2000 regimes.\n",
    "\n",
    "**Limitations:**\n",
    "- The inflation forecast model has limited out-of-sample accuracy, especially\n",
    "  across regime changes. The agent's policy quality is bounded by model quality.\n",
    "- Unemployment and capacity evolve from historical data rather than responding\n",
    "  to the agent's rate choices. A full general-equilibrium model would capture\n",
    "  these feedback effects but introduces the compounding-error problem.\n",
    "- The agent's tendency to anchor near the current fed funds rate partly reflects\n",
    "  the rate-smoothing penalty rather than learned macro intuition.\n",
    "\n",
    "**References:**\n",
    "1. Taylor, J. B. (1993). Discretion versus policy rules in practice. *Carnegie-Rochester Conference Series on Public Policy.*\n",
    "2. Hinterlang, N. & Tanzer, P. M. (2021). Monetary policy using reinforcement learning. *arXiv:2108.01195.*\n",
    "3. Mnih, V. et al. (2015). Human-level control through deep reinforcement learning. *Nature.*\n",
    "\n",
    "**Data:** Monthly FRED series, 1971\u20132025. Retrieved February 2026."
   ]
  }
 ]
}