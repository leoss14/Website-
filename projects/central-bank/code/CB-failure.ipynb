{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffd887b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged: 857 obs (1954-07 to 2025-12)\n",
      "  Saved: /Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/data_overview.png\n",
      "\n",
      "  Model selection by BIC:\n",
      "    k=2: LL= -1483.3  AIC=  2986.6  BIC=  3033.8\n",
      "    k=3: LL= -1184.3  AIC=  2404.5  BIC=  2489.6\n",
      "    k=4: LL= -1002.0  AIC=  2060.0  BIC=  2192.3\n",
      "    -> Selected: k=4\n",
      "\n",
      "======================================================================\n",
      "[Full sample] MARKOV-SWITCHING REGIME MODEL (4 regimes, n=833)\n",
      "======================================================================\n",
      "\n",
      "  Log-likelihood: -1002.0  |  AIC: 2060.0  |  BIC: 2192.3\n",
      "\n",
      "  Transition matrix (columns = from, rows = to):\n",
      "                From R0  From R1  From R2  From R3\n",
      "  To R0:        0.9404   0.0353   0.0335   0.0000\n",
      "  To R1:        0.0325   0.9647   0.0096   0.0000\n",
      "  To R2:        0.0272   0.0000   0.9410   0.0361\n",
      "  To R3:       -0.0000   0.0000   0.0159   0.9639\n",
      "\n",
      "  Expected durations:\n",
      "    Regime 0: 16.8 months (1.4 years)\n",
      "    Regime 1: 28.3 months (2.4 years)\n",
      "    Regime 2: 17.0 months (1.4 years)\n",
      "    Regime 3: 27.7 months (2.3 years)\n",
      "\n",
      "  Regime                              N       pi        u       ff   spread    E[dur]\n",
      "  --------------------------------------------------------------------------------\n",
      "  Regime 0 inflation (1.4%)         291     1.43     5.84     2.25     1.36     28.3m\n",
      "  Regime 1 inflation (3.1%)         275     3.06     5.72     4.38     1.31     16.8m\n",
      "  Regime 2 inflation (5.1%)         181     5.15     5.87     6.72     0.82     17.0m\n",
      "  Regime 3 inflation (10.1%)         86    10.14     6.14     9.63    -1.02     27.7m\n",
      "\n",
      "                        Markov Switching Model Results                        \n",
      "==============================================================================\n",
      "Dep. Variable:              inflation   No. Observations:                  833\n",
      "Model:               MarkovRegression   Log Likelihood               -1001.999\n",
      "Date:                Fri, 13 Feb 2026   AIC                           2059.998\n",
      "Time:                        13:35:33   BIC                           2192.299\n",
      "Sample:                             0   HQIC                          2110.725\n",
      "                                - 833                                         \n",
      "Covariance Type:               approx                                         \n",
      "                             Regime 0 parameters                              \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.4977      0.062     24.250      0.000       1.377       1.619\n",
      "x1             1.4977      0.062     24.250      0.000       1.377       1.619\n",
      "x2             0.0104      0.019      0.535      0.592      -0.028       0.049\n",
      "sigma2         0.1916      0.021      9.188      0.000       0.151       0.232\n",
      "                             Regime 1 parameters                              \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.2729      0.082     15.583      0.000       1.113       1.433\n",
      "x1             1.2729      0.082     15.583      0.000       1.113       1.433\n",
      "x2            -0.1903      0.027     -7.134      0.000      -0.243      -0.138\n",
      "sigma2         0.4105      0.036     11.461      0.000       0.340       0.481\n",
      "                             Regime 2 parameters                              \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.9918      0.171     11.648      0.000       1.657       2.327\n",
      "x1             1.9918      0.171     11.648      0.000       1.657       2.327\n",
      "x2             0.1945      0.055      3.542      0.000       0.087       0.302\n",
      "sigma2         0.8134      0.101      8.078      0.000       0.616       1.011\n",
      "                             Regime 3 parameters                              \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          3.2909      0.475      6.922      0.000       2.359       4.223\n",
      "x1             3.2909      0.475      6.922      0.000       2.359       4.223\n",
      "x2             0.5757      0.154      3.747      0.000       0.275       0.877\n",
      "sigma2         3.5261      0.593      5.943      0.000       2.363       4.689\n",
      "                         Regime transition parameters                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "p[0->0]        0.9404      0.003    318.302      0.000       0.935       0.946\n",
      "p[1->0]        0.0353        nan        nan        nan         nan         nan\n",
      "p[2->0]        0.0335      0.015      2.260      0.024       0.004       0.063\n",
      "p[3->0]     1.573e-16        nan        nan        nan         nan         nan\n",
      "p[0->1]        0.0325      0.008      4.230      0.000       0.017       0.048\n",
      "p[1->1]        0.9647        nan        nan        nan         nan         nan\n",
      "p[2->1]        0.0096      0.008      1.139      0.255      -0.007       0.026\n",
      "p[3->1]     2.109e-15        nan        nan        nan         nan         nan\n",
      "p[0->2]        0.0272      0.008      3.535      0.000       0.012       0.042\n",
      "p[1->2]     1.987e-07        nan        nan        nan         nan         nan\n",
      "p[2->2]        0.9410      0.018     52.238      0.000       0.906       0.976\n",
      "p[3->2]        0.0361      0.020      1.821      0.069      -0.003       0.075\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using numerical (complex-step) differentiation.\n",
      "[2] Covariance matrix is singular or near-singular, with condition number 2.55e+18. Standard errors may be unstable.\n",
      "  Saved: /Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/ms_regime_probabilities_k4.png\n",
      "  Saved: /Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/ms_regime_context_k4.png\n",
      "  Saved: /Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/ms_regime_distributions_k4.png\n",
      "\n",
      "\n",
      "--- 2-regime baseline for comparison ---\n",
      "\n",
      "======================================================================\n",
      "[2-regime baseline] MARKOV-SWITCHING REGIME MODEL (2 regimes, n=833)\n",
      "======================================================================\n",
      "\n",
      "  Log-likelihood: -1483.3  |  AIC: 2986.6  |  BIC: 3033.8\n",
      "\n",
      "  Transition matrix (columns = from, rows = to):\n",
      "                From R0  From R1\n",
      "  To R0:        0.9928   0.0232\n",
      "  To R1:        0.0072   0.9768\n",
      "\n",
      "  Expected durations:\n",
      "    Regime 0: 138.4 months (11.5 years)\n",
      "    Regime 1: 43.0 months (3.6 years)\n",
      "\n",
      "  Regime                              N       pi        u       ff   spread    E[dur]\n",
      "  --------------------------------------------------------------------------------\n",
      "  Low inflation (2.4%)              622     2.40     5.79     3.57     1.33    138.4m\n",
      "  High inflation (7.4%)             211     7.43     5.99     7.96    -0.05     43.0m\n",
      "\n",
      "                        Markov Switching Model Results                        \n",
      "==============================================================================\n",
      "Dep. Variable:              inflation   No. Observations:                  833\n",
      "Model:               MarkovRegression   Log Likelihood               -1483.285\n",
      "Date:                Fri, 13 Feb 2026   AIC                           2986.571\n",
      "Time:                        13:35:41   BIC                           3033.821\n",
      "Sample:                             0   HQIC                          3004.688\n",
      "                                - 833                                         \n",
      "Covariance Type:               approx                                         \n",
      "                             Regime 0 parameters                              \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.4564        nan        nan        nan         nan         nan\n",
      "x1             1.4564        nan        nan        nan         nan         nan\n",
      "x2            -0.0884      0.029     -3.081      0.002      -0.145      -0.032\n",
      "sigma2         1.2332      0.084     14.765      0.000       1.069       1.397\n",
      "                             Regime 1 parameters                              \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.3361        nan        nan        nan         nan         nan\n",
      "x1             2.3361        nan        nan        nan         nan         nan\n",
      "x2             0.4540      0.120      3.797      0.000       0.220       0.688\n",
      "sigma2         6.7237      0.665     10.117      0.000       5.421       8.026\n",
      "                         Regime transition parameters                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "p[0->0]        0.9928      0.004    281.321      0.000       0.986       1.000\n",
      "p[1->0]        0.0232      0.010      2.214      0.027       0.003       0.044\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using numerical (complex-step) differentiation.\n",
      "  Saved: /Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/ms_regime_probabilities_k2.png\n",
      "  Saved: /Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/ms_regime_context_k2.png\n",
      "  Saved: /Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/ms_regime_distributions_k2.png\n",
      "\n",
      "======================================================================\n",
      "ROBUSTNESS: PRE-2020 SAMPLE (excluding COVID-era)\n",
      "======================================================================\n",
      "  Pre-2020 sample: 762 obs (1956-07 to 2019-12)\n",
      "\n",
      "======================================================================\n",
      "[Pre-2020] MARKOV-SWITCHING REGIME MODEL (2 regimes, n=762)\n",
      "======================================================================\n",
      "\n",
      "  Log-likelihood: -1373.4  |  AIC: 2766.8  |  BIC: 2813.2\n",
      "\n",
      "  Transition matrix (columns = from, rows = to):\n",
      "                From R0  From R1\n",
      "  To R0:        0.9907   0.0222\n",
      "  To R1:        0.0093   0.9778\n",
      "\n",
      "  Expected durations:\n",
      "    Regime 0: 107.9 months (9.0 years)\n",
      "    Regime 1: 45.1 months (3.8 years)\n",
      "\n",
      "  Regime                              N       pi        u       ff   spread    E[dur]\n",
      "  --------------------------------------------------------------------------------\n",
      "  Low inflation (2.3%)              519     2.31     5.74     3.39     1.42    107.9m\n",
      "  High inflation (6.5%)             243     6.51     6.33     8.02     0.28     45.1m\n",
      "\n",
      "                        Markov Switching Model Results                        \n",
      "==============================================================================\n",
      "Dep. Variable:              inflation   No. Observations:                  762\n",
      "Model:               MarkovRegression   Log Likelihood               -1373.400\n",
      "Date:                Fri, 13 Feb 2026   AIC                           2766.799\n",
      "Time:                        13:35:48   BIC                           2813.159\n",
      "Sample:                    07-01-1956   HQIC                          2784.649\n",
      "                         - 12-01-2019                                         \n",
      "Covariance Type:               approx                                         \n",
      "                             Regime 0 parameters                              \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.1115        nan        nan        nan         nan         nan\n",
      "x1             1.1115        nan        nan        nan         nan         nan\n",
      "x2             0.0146      0.031      0.467      0.640      -0.047       0.076\n",
      "sigma2         0.9049      0.064     14.078      0.000       0.779       1.031\n",
      "                             Regime 1 parameters                              \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          3.0104        nan        nan        nan         nan         nan\n",
      "x1             3.0104        nan        nan        nan         nan         nan\n",
      "x2             0.0773      0.137      0.562      0.574      -0.192       0.347\n",
      "sigma2        10.2315      0.945     10.824      0.000       8.379      12.084\n",
      "                         Regime transition parameters                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "p[0->0]        0.9907      0.004    236.458      0.000       0.983       0.999\n",
      "p[1->0]        0.0222      0.009      2.357      0.018       0.004       0.041\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using numerical (complex-step) differentiation.\n",
      "\n",
      "  --- Comparison: Pre-2020 vs Full sample ---\n",
      "  Saved: /Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/ms_regime_probabilities_pre2020.png\n",
      "  Saved: /Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/ms_regime_context_pre2020.png\n",
      "  Saved: /Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/ms_regime_distributions_pre2020.png\n",
      "\n",
      "All outputs: ['/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/ms_regime_probabilities_k4.png', '/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/ms_regime_context_k4.png', '/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/ms_regime_distributions_k4.png', '/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/ms_regime_probabilities_k2.png', '/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/ms_regime_context_k2.png', '/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/ms_regime_distributions_k2.png', '/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/ms_regime_probabilities_pre2020.png', '/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/ms_regime_context_pre2020.png', '/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/ms_regime_distributions_pre2020.png']\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Component 1: Markov-Switching Regime Detection\n",
    "===============================================\n",
    "Uses Hamilton (1989) Markov-switching regression via statsmodels.\n",
    "Now includes pre-2020 robustness check to assess COVID-era distortion.\n",
    "\"\"\"\n",
    "\n",
    "import os, warnings, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import statsmodels.api as sm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SEED = 42; random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "DATA_PATH = '/Users/leoss/Desktop/Portfolio/Website-/Central bank/data'\n",
    "OUTPUT_PATH = '/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs'\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "C1, C2, C3, C4, C5 = \"#2563eb\", \"#dc2626\", \"#7c3aed\", \"#f59e0b\", \"#10b981\"\n",
    "C_BG = \"#fafafa\"\n",
    "plt.rcParams.update({\n",
    "    \"figure.facecolor\": C_BG, \"axes.facecolor\": C_BG,\n",
    "    \"axes.grid\": True, \"grid.color\": \"#e5e7eb\", \"grid.linewidth\": 0.5,\n",
    "    \"font.size\": 11, \"axes.spines.top\": False, \"axes.spines.right\": False,\n",
    "})\n",
    "\n",
    "RECESSIONS = [\n",
    "    (\"1973-11\",\"1975-03\"),(\"1980-01\",\"1980-07\"),(\"1981-07\",\"1982-11\"),\n",
    "    (\"1990-07\",\"1991-03\"),(\"2001-03\",\"2001-11\"),(\"2007-12\",\"2009-06\"),(\"2020-02\",\"2020-04\"),\n",
    "]\n",
    "FED_CHAIRS = [\n",
    "    (\"Burns\",\"1970-02\",\"1978-01\"),(\"Miller\",\"1978-03\",\"1979-08\"),\n",
    "    (\"Volcker\",\"1979-08\",\"1987-08\"),(\"Greenspan\",\"1987-08\",\"2006-01\"),\n",
    "    (\"Bernanke\",\"2006-02\",\"2014-01\"),(\"Yellen\",\"2014-02\",\"2018-02\"),\n",
    "    (\"Powell\",\"2018-02\",\"2024-12\"),\n",
    "]\n",
    "\n",
    "def shade_recessions(ax):\n",
    "    for s, e in RECESSIONS:\n",
    "        ax.axvspan(pd.Timestamp(s), pd.Timestamp(e), alpha=0.10, color=\"#fca5a5\", zorder=0)\n",
    "\n",
    "\n",
    "def load_data(path=DATA_PATH):\n",
    "    def _read(names):\n",
    "        for n in names:\n",
    "            p = os.path.join(path, n)\n",
    "            if os.path.exists(p):\n",
    "                return pd.read_csv(p, parse_dates=[\"observation_date\"],\n",
    "                                   index_col=\"observation_date\")\n",
    "        raise FileNotFoundError(f\"None of {names} found in {path}\")\n",
    "\n",
    "    cpi = _read([\"CPIAUCSL.csv\"])\n",
    "    unrate = _read([\"UNRATE.csv\"])\n",
    "    ff = _read([\"FEDFUNDS.csv\", \"FEDFUNDS-1.csv\"])\n",
    "    tcu = _read([\"TCU.csv\"])\n",
    "    gs10 = _read([\"GS10.csv\"])\n",
    "    nfci_w = _read([\"NFCI.csv\"]); nfci = nfci_w.resample(\"MS\").last()\n",
    "\n",
    "    # CBO NAIRU (quarterly -> monthly)\n",
    "    nrou_q = _read([\"NROU.csv\", \"NROUST.csv\"])\n",
    "    nrou_q.index = pd.DatetimeIndex(nrou_q.index)\n",
    "    nrou_m = nrou_q.resample(\"MS\").interpolate(method=\"linear\")\n",
    "\n",
    "    # Michigan Survey expected inflation\n",
    "    try:\n",
    "        mich = _read([\"MICH.csv\"])\n",
    "    except FileNotFoundError:\n",
    "        mich = None\n",
    "\n",
    "    merged = pd.concat([\n",
    "        cpi.rename(columns={cpi.columns[0]: \"cpi\"}),\n",
    "        unrate.rename(columns={unrate.columns[0]: \"unemployment\"}),\n",
    "        ff.rename(columns={ff.columns[0]: \"fed_funds\"}),\n",
    "        tcu.rename(columns={tcu.columns[0]: \"capacity_util\"}),\n",
    "        gs10.rename(columns={gs10.columns[0]: \"treasury_10y\"}),\n",
    "        nfci.rename(columns={nfci.columns[0]: \"fin_conditions\"}),\n",
    "        nrou_m.rename(columns={nrou_m.columns[0]: \"nrou\"}),\n",
    "    ], axis=1).dropna(subset=[\"cpi\", \"unemployment\", \"fed_funds\", \"nrou\"])\n",
    "\n",
    "    if mich is not None:\n",
    "        merged = merged.join(\n",
    "            mich.rename(columns={mich.columns[0]: \"expected_inflation\"}),\n",
    "            how=\"left\")\n",
    "    else:\n",
    "        merged[\"expected_inflation\"] = np.nan\n",
    "\n",
    "    print(f\"Merged: {len(merged)} obs ({merged.index.min():%Y-%m} to {merged.index.max():%Y-%m})\")\n",
    "    return merged\n",
    "\n",
    "\n",
    "def engineer_features(data):\n",
    "    df = data.copy()\n",
    "    df[\"inflation\"] = df[\"cpi\"].pct_change(12) * 100\n",
    "    df[\"unemp_gap\"] = df[\"unemployment\"] - df[\"nrou\"]\n",
    "    df[\"capacity_gap\"] = df[\"capacity_util\"] - 100.0\n",
    "    df[\"term_spread\"] = df[\"treasury_10y\"] - df[\"fed_funds\"]\n",
    "    df[\"real_rate\"] = df[\"fed_funds\"] - df[\"inflation\"]\n",
    "    df[\"delta_ff\"] = df[\"fed_funds\"].diff()\n",
    "    df[\"delta_pi\"] = df[\"inflation\"].diff()\n",
    "    df[\"delta_u\"] = df[\"unemployment\"].diff()\n",
    "    df[\"ff_lag1\"] = df[\"fed_funds\"].shift(1)\n",
    "    df[\"adaptive_pi_e\"] = df[\"inflation\"].rolling(12).mean()\n",
    "    df[\"pi_expected\"] = df[\"expected_inflation\"].fillna(df[\"adaptive_pi_e\"])\n",
    "    for var in [\"inflation\",\"unemp_gap\",\"capacity_gap\",\"fed_funds\",\"term_spread\",\"fin_conditions\"]:\n",
    "        for lag in [1,3,6,12]:\n",
    "            df[f\"L{lag}_{var}\"] = df[var].shift(lag)\n",
    "    for h in [1,3,6,12]:\n",
    "        df[f\"inflation_{h}m_ahead\"] = df[\"inflation\"].shift(-h)\n",
    "    df[\"recession\"] = 0\n",
    "    for start, end in RECESSIONS:\n",
    "        df.loc[(df.index >= start) & (df.index <= end), \"recession\"] = 1\n",
    "    df = df.dropna(subset=[\"inflation\",\"L12_inflation\"])\n",
    "    df.index = pd.DatetimeIndex(df.index)\n",
    "    return df\n",
    "\n",
    "\n",
    "# ── Markov-Switching Model ─────────────────────────────────────────\n",
    "def fit_markov_switching(df, n_regimes=2, label=\"\"):\n",
    "    prefix = f\"[{label}] \" if label else \"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"{prefix}MARKOV-SWITCHING REGIME MODEL ({n_regimes} regimes, n={len(df)})\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    endog = df[\"inflation\"].copy()\n",
    "    exog = sm.add_constant(df[[\"unemployment\"]].copy())\n",
    "\n",
    "    mod = sm.tsa.MarkovRegression(\n",
    "        endog, k_regimes=n_regimes, exog=exog,\n",
    "        switching_variance=True, switching_exog=True,\n",
    "    )\n",
    "\n",
    "    best_res, best_llf = None, -np.inf\n",
    "    for attempt in range(8):\n",
    "        try:\n",
    "            res = mod.fit(search_reps=30, random_state=SEED+attempt, disp=False, maxiter=500)\n",
    "            if res.llf > best_llf:\n",
    "                best_llf = res.llf; best_res = res\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    if best_res is None:\n",
    "        print(\"  Model failed to converge.\")\n",
    "        return None\n",
    "\n",
    "    res = best_res\n",
    "    print(f\"\\n  Log-likelihood: {res.llf:.1f}  |  AIC: {res.aic:.1f}  |  BIC: {res.bic:.1f}\")\n",
    "\n",
    "    tm = res.regime_transition\n",
    "    tm_avg = tm.mean(axis=2) if tm.ndim == 3 else tm\n",
    "    print(f\"\\n  Transition matrix (columns = from, rows = to):\")\n",
    "    header = \"  \" + \" \"*12 + \"\".join([f\"  From R{j}\" for j in range(n_regimes)])\n",
    "    print(header)\n",
    "    for i in range(n_regimes):\n",
    "        row = f\"  To R{i}:     \"\n",
    "        for j in range(n_regimes):\n",
    "            row += f\"  {tm_avg[i,j]:7.4f}\"\n",
    "        print(row)\n",
    "\n",
    "    durations = res.expected_durations\n",
    "    print(f\"\\n  Expected durations:\")\n",
    "    for r in range(n_regimes):\n",
    "        print(f\"    Regime {r}: {durations[r]:.1f} months ({durations[r]/12:.1f} years)\")\n",
    "\n",
    "    smoothed = res.smoothed_marginal_probabilities\n",
    "    regime_df = df.copy()\n",
    "\n",
    "    regime_means = {}\n",
    "    for r in range(n_regimes):\n",
    "        mask = smoothed[r] > 0.5\n",
    "        regime_means[r] = df.loc[mask, \"inflation\"].mean() if mask.sum() > 0 else 0.0\n",
    "\n",
    "    sorted_regimes = sorted(regime_means, key=regime_means.get)\n",
    "    for new_r in range(n_regimes):\n",
    "        old_r = sorted_regimes[new_r]\n",
    "        regime_df[f\"p_regime_{new_r}\"] = smoothed[old_r].values\n",
    "\n",
    "    regime_df[\"regime\"] = np.argmax(\n",
    "        np.column_stack([regime_df[f\"p_regime_{r}\"].values for r in range(n_regimes)]),\n",
    "        axis=1)\n",
    "\n",
    "    sorted_means = [regime_means[sorted_regimes[r]] for r in range(n_regimes)]\n",
    "    if n_regimes == 2:\n",
    "        labels = [\"Low\", \"High\"]\n",
    "    elif n_regimes == 3:\n",
    "        labels = [\"Low\", \"Medium\", \"High\"]\n",
    "    else:\n",
    "        labels = [f\"Regime {r}\" for r in range(n_regimes)]\n",
    "    regime_names = {r: f\"{labels[r]} inflation ({sorted_means[r]:.1f}%)\" for r in range(n_regimes)}\n",
    "\n",
    "    print(f\"\\n  {'Regime':<30s}  {'N':>5s}  {'pi':>7s}  {'u':>7s}  {'ff':>7s}  {'spread':>7s}  {'E[dur]':>8s}\")\n",
    "    print(f\"  {'-'*80}\")\n",
    "    for r in range(n_regimes):\n",
    "        sub = regime_df[regime_df[\"regime\"] == r]\n",
    "        dur = durations[sorted_regimes[r]]\n",
    "        print(f\"  {regime_names[r]:<30s}  {len(sub):>5d}  {sub['inflation'].mean():>7.2f}  \"\n",
    "              f\"{sub['unemployment'].mean():>7.2f}  {sub['fed_funds'].mean():>7.2f}  \"\n",
    "              f\"{sub['term_spread'].mean():>7.2f}  {dur:>7.1f}m\")\n",
    "\n",
    "    print(f\"\\n{res.summary()}\")\n",
    "    return res, regime_df, regime_names, n_regimes, sorted_regimes, durations\n",
    "\n",
    "\n",
    "def select_n_regimes(df, max_k=4):\n",
    "    print(f\"\\n  Model selection by BIC:\")\n",
    "    results = {}\n",
    "    for k in range(2, max_k + 1):\n",
    "        endog = df[\"inflation\"].copy()\n",
    "        exog = sm.add_constant(df[[\"unemployment\"]].copy())\n",
    "        mod = sm.tsa.MarkovRegression(endog, k_regimes=k, exog=exog,\n",
    "            switching_variance=True, switching_exog=True)\n",
    "        best_res, best_llf = None, -np.inf\n",
    "        for attempt in range(5):\n",
    "            try:\n",
    "                res = mod.fit(search_reps=20, random_state=SEED+attempt, disp=False, maxiter=500)\n",
    "                if res.llf > best_llf:\n",
    "                    best_llf = res.llf; best_res = res\n",
    "            except:\n",
    "                continue\n",
    "        if best_res:\n",
    "            results[k] = best_res\n",
    "            print(f\"    k={k}: LL={best_res.llf:>8.1f}  AIC={best_res.aic:>8.1f}  BIC={best_res.bic:>8.1f}\")\n",
    "    if not results:\n",
    "        return 2\n",
    "    best_k = min(results, key=lambda k: results[k].bic)\n",
    "    print(f\"    -> Selected: k={best_k}\")\n",
    "    return best_k\n",
    "\n",
    "\n",
    "# ── Pre-2020 robustness check ──────────────────────────────────────\n",
    "def robustness_pre2020(df):\n",
    "    \"\"\"Re-estimate MS model ending sample at 2019:12 to check COVID distortion.\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"ROBUSTNESS: PRE-2020 SAMPLE (excluding COVID-era)\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    df_pre = df.loc[:\"2019-12\"].copy()\n",
    "    print(f\"  Pre-2020 sample: {len(df_pre)} obs ({df_pre.index.min():%Y-%m} to {df_pre.index.max():%Y-%m})\")\n",
    "\n",
    "    result_pre = fit_markov_switching(df_pre, n_regimes=2, label=\"Pre-2020\")\n",
    "    if result_pre is None:\n",
    "        print(\"  Pre-2020 model failed.\")\n",
    "        return None\n",
    "\n",
    "    _, rdf_pre, rn_pre, _, _, dur_pre = result_pre\n",
    "\n",
    "    # Compare to full sample\n",
    "    print(f\"\\n  --- Comparison: Pre-2020 vs Full sample ---\")\n",
    "    return result_pre\n",
    "\n",
    "\n",
    "# ── Visualization ──────────────────────────────────────────────────\n",
    "def plot_regimes(df, regime_df, regime_names, n_regimes, sorted_regimes, durations,\n",
    "                 output_path, suffix=\"\"):\n",
    "    regime_colors = [C5, C1, C4, C2, \"#94a3b8\"][:n_regimes]\n",
    "    sfx = f\"_{suffix}\" if suffix else \"\"\n",
    "\n",
    "    # Fig 1: Smoothed probabilities\n",
    "    n_panels = n_regimes + 1\n",
    "    fig, axes = plt.subplots(n_panels, 1, figsize=(16, 2.5 + 2.2*n_regimes), sharex=True)\n",
    "    if n_panels == 1: axes = [axes]\n",
    "    fig.suptitle(f\"Markov-Switching Inflation Regimes ({n_regimes} states): Smoothed Probabilities\",\n",
    "                 fontweight=\"bold\", fontsize=14, y=0.995)\n",
    "\n",
    "    ax = axes[0]; shade_recessions(ax)\n",
    "    for r in range(n_regimes):\n",
    "        mask = regime_df[\"regime\"] == r\n",
    "        ax.scatter(regime_df.index[mask], regime_df[\"inflation\"][mask],\n",
    "                   c=regime_colors[r], s=6, alpha=0.7, label=regime_names[r], zorder=2)\n",
    "    ax.axhline(2, color=\"grey\", ls=\"--\", lw=1, alpha=0.5)\n",
    "    ax.set_ylabel(\"Inflation (%)\"); ax.set_title(\"Inflation by most likely regime\", fontweight=\"bold\")\n",
    "    ax.legend(frameon=True, fontsize=7, markerscale=2, loc=\"upper right\")\n",
    "\n",
    "    for r in range(n_regimes):\n",
    "        ax = axes[r + 1]; shade_recessions(ax)\n",
    "        ax.fill_between(regime_df.index, regime_df[f\"p_regime_{r}\"], 0,\n",
    "                        alpha=0.4, color=regime_colors[r])\n",
    "        ax.plot(regime_df.index, regime_df[f\"p_regime_{r}\"], lw=1, color=regime_colors[r])\n",
    "        ax.axhline(0.5, color=\"grey\", ls=\"--\", lw=0.8, alpha=0.5)\n",
    "        ax.set_ylabel(\"P(regime)\")\n",
    "        dur = durations[sorted_regimes[r]]\n",
    "        ax.set_title(f\"P({regime_names[r]}) | E[duration]: {dur:.0f} months\",\n",
    "                     fontweight=\"bold\", fontsize=10)\n",
    "        ax.set_ylim(-0.05, 1.05)\n",
    "\n",
    "    axes[-1].set_xlabel(\"Year\")\n",
    "    fig.tight_layout()\n",
    "    path1 = f\"{output_path}/ms_regime_probabilities{sfx}.png\"\n",
    "    fig.savefig(path1, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "    print(f\"  Saved: {path1}\")\n",
    "\n",
    "    # Fig 2: Regime timeline + macro context\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(16, 12), sharex=True,\n",
    "                              gridspec_kw={\"height_ratios\": [1, 2, 2, 2]})\n",
    "    fig.suptitle(\"Inflation Regimes in Macroeconomic Context\",\n",
    "                 fontweight=\"bold\", fontsize=14, y=0.995)\n",
    "\n",
    "    ax = axes[0]\n",
    "    for r in range(n_regimes):\n",
    "        mask = regime_df[\"regime\"] == r\n",
    "        for d in regime_df.index[mask]:\n",
    "            ax.axvspan(d, d + pd.DateOffset(months=1), color=regime_colors[r], alpha=0.8)\n",
    "    for i, (ch, s, e) in enumerate(FED_CHAIRS):\n",
    "        mid = pd.Timestamp(s) + (pd.Timestamp(e)-pd.Timestamp(s))/2\n",
    "        if regime_df.index[0] <= mid <= regime_df.index[-1]:\n",
    "            ax.text(mid, 0.5, ch, ha=\"center\", va=\"center\", fontsize=8,\n",
    "                    fontstyle=\"italic\", alpha=0.7)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(\"Regime assignment with Fed chairs\", fontweight=\"bold\")\n",
    "    legend_elements = [Patch(facecolor=regime_colors[r], alpha=0.8, label=regime_names[r])\n",
    "                       for r in range(n_regimes)]\n",
    "    ax.legend(handles=legend_elements, frameon=True, fontsize=7, loc=\"upper left\",\n",
    "              ncol=min(n_regimes,3))\n",
    "\n",
    "    ax = axes[1]; shade_recessions(ax)\n",
    "    ax.plot(regime_df.index, regime_df[\"inflation\"], lw=1.5, color=\"#374151\")\n",
    "    ax.axhline(2, color=C2, ls=\"--\", lw=1, alpha=0.5, label=\"2% target\")\n",
    "    ax.set_ylabel(\"Inflation (%)\"); ax.set_title(\"YoY Inflation\", fontweight=\"bold\")\n",
    "    ax.legend(frameon=False, fontsize=8)\n",
    "\n",
    "    ax = axes[2]; shade_recessions(ax)\n",
    "    ax.plot(regime_df.index, regime_df[\"fed_funds\"], lw=1.5, color=C1, label=\"Fed funds\")\n",
    "    ax.plot(regime_df.index, regime_df[\"treasury_10y\"], lw=1.2, color=C2, alpha=0.6, label=\"10Y Treasury\")\n",
    "    ax.set_ylabel(\"Rate (%)\"); ax.set_title(\"Interest rates\", fontweight=\"bold\")\n",
    "    ax.legend(frameon=False, fontsize=8)\n",
    "\n",
    "    ax = axes[3]; shade_recessions(ax)\n",
    "    ax.plot(regime_df.index, regime_df[\"unemployment\"], lw=1.5, color=C3, label=\"Unemployment\")\n",
    "    ax.plot(regime_df.index, regime_df[\"nrou\"], lw=1.2, color=C4, ls=\"--\",\n",
    "            alpha=0.7, label=\"CBO NAIRU\")\n",
    "    ax.set_ylabel(\"Rate (%)\"); ax.set_xlabel(\"Year\")\n",
    "    ax.set_title(\"Unemployment rate vs CBO natural rate\", fontweight=\"bold\")\n",
    "    ax.legend(frameon=False, fontsize=8)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    path2 = f\"{output_path}/ms_regime_context{sfx}.png\"\n",
    "    fig.savefig(path2, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "    print(f\"  Saved: {path2}\")\n",
    "\n",
    "    # Fig 3: Distributions by regime\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(16, 8))\n",
    "    fig.suptitle(\"Regime Characteristics\", fontweight=\"bold\", fontsize=14, y=1.01)\n",
    "\n",
    "    for ax, (var, label) in zip(axes.flat, [\n",
    "        (\"inflation\",\"Inflation (%)\"), (\"unemployment\",\"Unemployment (%)\"),\n",
    "        (\"fed_funds\",\"Fed funds (%)\"), (\"real_rate\",\"Real rate (%)\"),\n",
    "        (\"term_spread\",\"Term spread (pp)\"), (\"unemp_gap\",\"Unemployment gap (pp, CBO NAIRU)\")]):\n",
    "\n",
    "        data_list = [regime_df.loc[regime_df[\"regime\"]==r, var].dropna().values\n",
    "                     for r in range(n_regimes)]\n",
    "        bp = ax.boxplot(data_list, patch_artist=True, widths=0.6,\n",
    "                        labels=[f\"R{r}\" for r in range(n_regimes)],\n",
    "                        medianprops=dict(color=\"black\", lw=1.5))\n",
    "        for r, patch in enumerate(bp[\"boxes\"]):\n",
    "            patch.set_facecolor(regime_colors[r]); patch.set_alpha(0.6)\n",
    "        ax.set_title(label, fontweight=\"bold\", fontsize=10)\n",
    "        ax.axhline(0, color=\"grey\", lw=0.5, alpha=0.3)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    path3 = f\"{output_path}/ms_regime_distributions{sfx}.png\"\n",
    "    fig.savefig(path3, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "    print(f\"  Saved: {path3}\")\n",
    "\n",
    "    return [path1, path2, path3]\n",
    "\n",
    "\n",
    "# ── Data overview plot ─────────────────────────────────────────────\n",
    "def plot_data_overview(df, output_path):\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(16, 10), sharex=True)\n",
    "    fig.suptitle(\"US Economic Indicators, 1971-2024\", fontweight=\"bold\", fontsize=14, y=1.0)\n",
    "\n",
    "    panels = [\n",
    "        (\"inflation\", \"CPI Inflation (%)\", C1),\n",
    "        (\"unemployment\", \"Unemployment (%)\", C3),\n",
    "        (\"fed_funds\", \"Fed Funds Rate (%)\", C2),\n",
    "        (\"capacity_util\", \"Capacity Utilisation (%)\", C4),\n",
    "        (\"treasury_10y\", \"10-Year Treasury (%)\", C5),\n",
    "        (\"fin_conditions\", \"Financial Conditions (NFCI)\", \"#6b7280\"),\n",
    "    ]\n",
    "    for ax, (var, title, color) in zip(axes.flat, panels):\n",
    "        shade_recessions(ax)\n",
    "        ax.plot(df.index, df[var], lw=1.2, color=color)\n",
    "        ax.set_title(title, fontweight=\"bold\", fontsize=10)\n",
    "\n",
    "    # Add NAIRU to unemployment panel\n",
    "    axes[0, 1].plot(df.index, df[\"nrou\"], lw=1, color=C4, ls=\"--\", alpha=0.6, label=\"CBO NAIRU\")\n",
    "    axes[0, 1].legend(frameon=False, fontsize=7)\n",
    "\n",
    "    axes[-1, 0].set_xlabel(\"Year\"); axes[-1, 1].set_xlabel(\"Year\")\n",
    "    fig.tight_layout()\n",
    "    path = f\"{output_path}/data_overview.png\"\n",
    "    fig.savefig(path, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "    print(f\"  Saved: {path}\")\n",
    "    return path\n",
    "\n",
    "\n",
    "# ── Main ───────────────────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    data = load_data(DATA_PATH)\n",
    "    df = engineer_features(data)\n",
    "\n",
    "    # Data overview\n",
    "    plot_data_overview(df, OUTPUT_PATH)\n",
    "\n",
    "    # Model selection\n",
    "    best_k = select_n_regimes(df, max_k=4)\n",
    "\n",
    "    # Main model\n",
    "    result = fit_markov_switching(df, n_regimes=best_k, label=\"Full sample\")\n",
    "    all_paths = []\n",
    "    if result is not None:\n",
    "        res, regime_df, regime_names, n_regimes, sorted_regimes, durations = result\n",
    "        paths = plot_regimes(df, regime_df, regime_names, n_regimes,\n",
    "                            sorted_regimes, durations, OUTPUT_PATH, suffix=f\"k{best_k}\")\n",
    "        all_paths.extend(paths)\n",
    "\n",
    "    # Always show 2-regime for comparison\n",
    "    if best_k != 2:\n",
    "        print(\"\\n\\n--- 2-regime baseline for comparison ---\")\n",
    "        result2 = fit_markov_switching(df, n_regimes=2, label=\"2-regime baseline\")\n",
    "        if result2 is not None:\n",
    "            res2, rdf2, rn2, n2, sr2, dur2 = result2\n",
    "            paths2 = plot_regimes(df, rdf2, rn2, n2, sr2, dur2, OUTPUT_PATH, suffix=\"k2\")\n",
    "            all_paths.extend(paths2)\n",
    "\n",
    "    # Pre-2020 robustness\n",
    "    result_pre = robustness_pre2020(df)\n",
    "    if result_pre is not None:\n",
    "        res_pre, rdf_pre, rn_pre, n_pre, sr_pre, dur_pre = result_pre\n",
    "        paths_pre = plot_regimes(df.loc[:\"2019-12\"], rdf_pre, rn_pre, n_pre,\n",
    "                                 sr_pre, dur_pre, OUTPUT_PATH, suffix=\"pre2020\")\n",
    "        all_paths.extend(paths_pre)\n",
    "\n",
    "    print(f\"\\nAll outputs: {all_paths}\")\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4283c860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Merged: 857 obs (1954-07 to 2025-12)\n",
      "Fitting Markov-switching regimes...\n",
      "  2 regimes: {0: 'Low inflation (2.4%)', 1: 'High inflation (7.4%)'}\n",
      "======================================================================\n",
      "REGIME-CONDITIONAL TAYLOR RULES\n",
      "  Using CBO NAIRU for unemployment gap\n",
      "======================================================================\n",
      "\n",
      "--- A. Full-sample structural Taylor rule (realized inflation, CBO NAIRU) ---\n",
      "\n",
      "  Parameter               Estimate    OLS SE\n",
      "  ------------------------------------------\n",
      "  rho (smoothing)            0.974     0.007\n",
      "  r* (neutral)               1.901     0.805\n",
      "  a_pi (inflation)          -0.075     0.237\n",
      "  a_u (unemp gap)           -1.594     0.534\n",
      "  Taylor principle: 1 + a_pi = 0.92\n",
      "\n",
      "  Computing block bootstrap HAC standard errors (500 reps)...\n",
      "  Parameter               Estimate    OLS SE    HAC SE\n",
      "  ----------------------------------------------------\n",
      "  rho                        0.974     0.007     0.010\n",
      "  r*                         1.901     0.805     1.126\n",
      "  a_pi                      -0.075     0.237     0.669\n",
      "  a_u                       -1.594     0.534     0.732\n",
      "\n",
      "--- A2. Full-sample Taylor rule (expected inflation, CBO NAIRU) ---\n",
      "\n",
      "  Parameter               Estimate        SE\n",
      "  ------------------------------------------\n",
      "  rho                        0.979     0.006\n",
      "  r*                         1.765     1.067\n",
      "  a_pi                       0.180     0.403\n",
      "  a_u                       -2.158     0.687\n",
      "  Taylor principle (expected pi): 1 + a_pi = 1.18\n",
      "\n",
      "  HAC SE: ['0.010', '1.741', '1.209', '1.020']\n",
      "\n",
      "--- B. Regime-conditional Taylor rules ---\n",
      "\n",
      "  === Realized inflation specification ===\n",
      "  Regime                             rho      r*    a_pi     a_u   1+a_pi     N\n",
      "  ----------------------------------------------------------------------\n",
      "  Low inflation (2.4%)             0.991   1.923  -0.366  -1.968     0.63   622\n",
      "  High inflation (7.4%)            0.964   0.448   0.195  -3.163     1.20   211\n",
      "\n",
      "  HAC standard errors (block bootstrap, 12-month blocks):\n",
      "  Regime                           se(rho)    se(r*)  se(a_pi)   se(a_u)\n",
      "  ----------------------------------------------------------------------\n",
      "  Low inflation (2.4%)               0.007     2.590     1.701     1.493\n",
      "  High inflation (7.4%)              0.020     3.922     0.890     1.225\n",
      "\n",
      "  === Expected inflation specification ===\n",
      "  Regime                             rho      r*    a_pi     a_u   1+a_pi     N\n",
      "  ----------------------------------------------------------------------\n",
      "  Low inflation (2.4%) (exp pi)    0.992   1.827  -0.389  -2.300     0.61   622\n",
      "  High inflation (7.4%) (exp pi)   0.973   1.260   0.422  -4.340     1.42   211\n",
      "\n",
      "--- C. Chow tests at regime transition dates ---\n",
      "\n",
      "  Date          Transition                                  F-stat   p-value\n",
      "  ------------------------------------------------------------------------\n",
      "  1968-07      Low inflation (2.4 -> High inflation (7.      0.25   0.8607 \n",
      "  1971-06      High inflation (7. -> Low inflation (2.4      1.38   0.2467 \n",
      "  1973-03      Low inflation (2.4 -> High inflation (7.      0.69   0.5581 \n",
      "  1982-11      High inflation (7. -> Low inflation (2.4      2.94   0.0324 **\n",
      "  1988-11      Low inflation (2.4 -> High inflation (7.      2.27   0.0787 *\n",
      "  1991-07      High inflation (7. -> Low inflation (2.4      2.77   0.0405 **\n",
      "  2008-06      Low inflation (2.4 -> High inflation (7.      2.74   0.0421 **\n",
      "  2021-05      Low inflation (2.4 -> High inflation (7.      1.78   0.1495 \n",
      "  2023-05      High inflation (7. -> Low inflation (2.4      0.29   0.8305 \n",
      "\n",
      "--- D. Expanding-window Taylor rule prescription ---\n",
      "  Computed 773 real-time prescriptions\n",
      "  Mean discretionary gap: +0.31 pp\n",
      "  Low inflation (2.4%): mean gap = -0.07\n",
      "  High inflation (7.4%): mean gap = +1.34\n",
      "  Saved: /Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/taylor_by_regime.png\n",
      "  Saved: /Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/taylor_prescription_vs_actual.png\n",
      "  Saved: /Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/taylor_principle_by_regime.png\n",
      "\n",
      "Outputs: ['/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/taylor_by_regime.png', '/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/taylor_prescription_vs_actual.png', '/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/taylor_principle_by_regime.png']\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Component 2: Regime-Conditional Taylor Rules\n",
    "=============================================\n",
    "Key changes from original:\n",
    "- CBO NAIRU replaces hardcoded 5% unemployment gap\n",
    "- Expected inflation (MICH / adaptive proxy) specification alongside realized\n",
    "- HAC standard errors via block bootstrap\n",
    "- Pre-2020 robustness check\n",
    "\"\"\"\n",
    "\n",
    "import os, warnings, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "import statsmodels.api as sm\n",
    "from scipy.optimize import least_squares\n",
    "from scipy import stats\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SEED = 42; random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "DATA_PATH = '/Users/leoss/Desktop/Portfolio/Website-/Central bank/data'\n",
    "OUTPUT_PATH = '/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs'\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "C1, C2, C3, C4, C5 = \"#2563eb\", \"#dc2626\", \"#7c3aed\", \"#f59e0b\", \"#10b981\"\n",
    "C_BG = \"#fafafa\"\n",
    "plt.rcParams.update({\n",
    "    \"figure.facecolor\": C_BG, \"axes.facecolor\": C_BG,\n",
    "    \"axes.grid\": True, \"grid.color\": \"#e5e7eb\", \"grid.linewidth\": 0.5,\n",
    "    \"font.size\": 11, \"axes.spines.top\": False, \"axes.spines.right\": False,\n",
    "})\n",
    "\n",
    "RECESSIONS = [\n",
    "    (\"1973-11\",\"1975-03\"),(\"1980-01\",\"1980-07\"),(\"1981-07\",\"1982-11\"),\n",
    "    (\"1990-07\",\"1991-03\"),(\"2001-03\",\"2001-11\"),(\"2007-12\",\"2009-06\"),(\"2020-02\",\"2020-04\"),\n",
    "]\n",
    "FED_CHAIRS = [\n",
    "    (\"Burns\",\"1970-02\",\"1978-01\"),(\"Miller\",\"1978-03\",\"1979-08\"),\n",
    "    (\"Volcker\",\"1979-08\",\"1987-08\"),(\"Greenspan\",\"1987-08\",\"2006-01\"),\n",
    "    (\"Bernanke\",\"2006-02\",\"2014-01\"),(\"Yellen\",\"2014-02\",\"2018-02\"),\n",
    "    (\"Powell\",\"2018-02\",\"2024-12\"),\n",
    "]\n",
    "\n",
    "def shade_recessions(ax):\n",
    "    for s, e in RECESSIONS:\n",
    "        ax.axvspan(pd.Timestamp(s), pd.Timestamp(e), alpha=0.10, color=\"#fca5a5\", zorder=0)\n",
    "\n",
    "\n",
    "def load_data(path=DATA_PATH):\n",
    "    def _read(names):\n",
    "        for n in names:\n",
    "            p = os.path.join(path, n)\n",
    "            if os.path.exists(p):\n",
    "                return pd.read_csv(p, parse_dates=[\"observation_date\"],\n",
    "                                   index_col=\"observation_date\")\n",
    "        raise FileNotFoundError(f\"None of {names} found in {path}\")\n",
    "\n",
    "    cpi = _read([\"CPIAUCSL.csv\"])\n",
    "    unrate = _read([\"UNRATE.csv\"])\n",
    "    ff = _read([\"FEDFUNDS.csv\", \"FEDFUNDS-1.csv\"])\n",
    "    tcu = _read([\"TCU.csv\"])\n",
    "    gs10 = _read([\"GS10.csv\"])\n",
    "    nfci_w = _read([\"NFCI.csv\"]); nfci = nfci_w.resample(\"MS\").last()\n",
    "    nrou_q = _read([\"NROU.csv\", \"NROUST.csv\"])\n",
    "    nrou_q.index = pd.DatetimeIndex(nrou_q.index)\n",
    "    nrou_m = nrou_q.resample(\"MS\").interpolate(method=\"linear\")\n",
    "    try:\n",
    "        mich = _read([\"MICH.csv\"])\n",
    "    except FileNotFoundError:\n",
    "        mich = None\n",
    "\n",
    "    merged = pd.concat([\n",
    "        cpi.rename(columns={cpi.columns[0]: \"cpi\"}),\n",
    "        unrate.rename(columns={unrate.columns[0]: \"unemployment\"}),\n",
    "        ff.rename(columns={ff.columns[0]: \"fed_funds\"}),\n",
    "        tcu.rename(columns={tcu.columns[0]: \"capacity_util\"}),\n",
    "        gs10.rename(columns={gs10.columns[0]: \"treasury_10y\"}),\n",
    "        nfci.rename(columns={nfci.columns[0]: \"fin_conditions\"}),\n",
    "        nrou_m.rename(columns={nrou_m.columns[0]: \"nrou\"}),\n",
    "    ], axis=1).dropna(subset=[\"cpi\", \"unemployment\", \"fed_funds\", \"nrou\"])\n",
    "\n",
    "    if mich is not None:\n",
    "        merged = merged.join(\n",
    "            mich.rename(columns={mich.columns[0]: \"expected_inflation\"}), how=\"left\")\n",
    "    else:\n",
    "        merged[\"expected_inflation\"] = np.nan\n",
    "    print(f\"Merged: {len(merged)} obs ({merged.index.min():%Y-%m} to {merged.index.max():%Y-%m})\")\n",
    "    return merged\n",
    "\n",
    "\n",
    "def engineer_features(data):\n",
    "    df = data.copy()\n",
    "    df[\"inflation\"] = df[\"cpi\"].pct_change(12) * 100\n",
    "    df[\"unemp_gap\"] = df[\"unemployment\"] - df[\"nrou\"]\n",
    "    df[\"capacity_gap\"] = df[\"capacity_util\"] - 100.0\n",
    "    df[\"term_spread\"] = df[\"treasury_10y\"] - df[\"fed_funds\"]\n",
    "    df[\"real_rate\"] = df[\"fed_funds\"] - df[\"inflation\"]\n",
    "    df[\"delta_ff\"] = df[\"fed_funds\"].diff()\n",
    "    df[\"delta_pi\"] = df[\"inflation\"].diff()\n",
    "    df[\"delta_u\"] = df[\"unemployment\"].diff()\n",
    "    df[\"ff_lag1\"] = df[\"fed_funds\"].shift(1)\n",
    "    df[\"adaptive_pi_e\"] = df[\"inflation\"].rolling(12).mean()\n",
    "    df[\"pi_expected\"] = df[\"expected_inflation\"].fillna(df[\"adaptive_pi_e\"])\n",
    "    for var in [\"inflation\",\"unemp_gap\",\"capacity_gap\",\"fed_funds\",\"term_spread\",\"fin_conditions\"]:\n",
    "        for lag in [1,3,6,12]:\n",
    "            df[f\"L{lag}_{var}\"] = df[var].shift(lag)\n",
    "    for h in [1,3,6,12]:\n",
    "        df[f\"inflation_{h}m_ahead\"] = df[\"inflation\"].shift(-h)\n",
    "    df[\"recession\"] = 0\n",
    "    for start, end in RECESSIONS:\n",
    "        df.loc[(df.index >= start) & (df.index <= end), \"recession\"] = 1\n",
    "    df = df.dropna(subset=[\"inflation\",\"L12_inflation\"])\n",
    "    df.index = pd.DatetimeIndex(df.index)\n",
    "    return df\n",
    "\n",
    "\n",
    "# ── Get regimes from Markov-switching ──────────────────────────────\n",
    "def get_regimes(df, n_regimes=2):\n",
    "    endog = df[\"inflation\"].copy()\n",
    "    exog = sm.add_constant(df[[\"unemployment\"]].copy())\n",
    "    mod = sm.tsa.MarkovRegression(endog, k_regimes=n_regimes, exog=exog,\n",
    "        switching_variance=True, switching_exog=True)\n",
    "    best_res, best_llf = None, -np.inf\n",
    "    for attempt in range(8):\n",
    "        try:\n",
    "            res = mod.fit(search_reps=30, random_state=SEED+attempt, disp=False, maxiter=500)\n",
    "            if res.llf > best_llf: best_llf = res.llf; best_res = res\n",
    "        except: continue\n",
    "    if best_res is None:\n",
    "        return df, {0: \"Full sample\"}, 1\n",
    "    smoothed = best_res.smoothed_marginal_probabilities\n",
    "    regime_means = {}\n",
    "    for r in range(n_regimes):\n",
    "        mask = smoothed[r] > 0.5\n",
    "        regime_means[r] = df.loc[mask, \"inflation\"].mean() if mask.sum() > 0 else 0.0\n",
    "    sorted_regimes = sorted(regime_means, key=regime_means.get)\n",
    "    rdf = df.copy()\n",
    "    for new_r in range(n_regimes):\n",
    "        rdf[f\"p_regime_{new_r}\"] = smoothed[sorted_regimes[new_r]].values\n",
    "    rdf[\"regime\"] = np.argmax(\n",
    "        np.column_stack([rdf[f\"p_regime_{r}\"].values for r in range(n_regimes)]), axis=1)\n",
    "    sorted_means = [regime_means[sorted_regimes[r]] for r in range(n_regimes)]\n",
    "    labels = [\"Low\",\"High\"] if n_regimes==2 else [f\"R{r}\" for r in range(n_regimes)]\n",
    "    regime_names = {r: f\"{labels[r]} inflation ({sorted_means[r]:.1f}%)\" for r in range(n_regimes)}\n",
    "    return rdf, regime_names, n_regimes\n",
    "\n",
    "\n",
    "# ── Taylor Rule NLS (CBO NAIRU) ───────────────────────────────────\n",
    "def taylor_resid(params, y, pi, u_gap, ff_lag):\n",
    "    \"\"\"Residuals for structural Taylor rule using unemployment gap directly.\"\"\"\n",
    "    rho, r_star, a_pi, a_u = params\n",
    "    target = r_star + pi + a_pi * (pi - 2.0) + a_u * u_gap\n",
    "    return y - (rho * ff_lag + (1 - rho) * target)\n",
    "\n",
    "\n",
    "def taylor_resid_expected(params, y, pi_e, u_gap, ff_lag):\n",
    "    \"\"\"Residuals using expected inflation instead of realized.\"\"\"\n",
    "    rho, r_star, a_pi, a_u = params\n",
    "    target = r_star + pi_e + a_pi * (pi_e - 2.0) + a_u * u_gap\n",
    "    return y - (rho * ff_lag + (1 - rho) * target)\n",
    "\n",
    "\n",
    "def fit_taylor_nls(sub, label=\"\", use_expected=False):\n",
    "    \"\"\"Fit structural Taylor rule via NLS. Uses CBO NAIRU for unemployment gap.\"\"\"\n",
    "    y = sub[\"fed_funds\"].values\n",
    "    u_gap = sub[\"unemp_gap\"].values  # already unemployment - NAIRU\n",
    "    ff_lag = sub[\"ff_lag1\"].values\n",
    "\n",
    "    if use_expected:\n",
    "        pi = sub[\"pi_expected\"].values\n",
    "        valid = ~np.isnan(pi)\n",
    "        if valid.sum() < 30:\n",
    "            return None\n",
    "        y, pi, u_gap, ff_lag = y[valid], pi[valid], u_gap[valid], ff_lag[valid]\n",
    "        resid_fn = taylor_resid_expected\n",
    "    else:\n",
    "        pi = sub[\"inflation\"].values\n",
    "        resid_fn = taylor_resid\n",
    "\n",
    "    res = least_squares(resid_fn, [0.85, 2.0, 0.5, 0.5],\n",
    "        args=(y, pi, u_gap, ff_lag),\n",
    "        bounds=([0, -5, -2, -5], [0.999, 10, 5, 5]))\n",
    "\n",
    "    rho, rstar, a_pi, a_u = res.x\n",
    "    n = len(y)\n",
    "    sigma2 = np.sum(res.fun**2) / (n - 4)\n",
    "    J = res.jac\n",
    "    try:\n",
    "        cov = sigma2 * np.linalg.inv(J.T @ J)\n",
    "        se = np.sqrt(np.diag(cov))\n",
    "    except:\n",
    "        se = [np.nan]*4\n",
    "\n",
    "    target = rstar + pi + a_pi * (pi - 2.0) + a_u * u_gap\n",
    "    prescribed = np.maximum(target, 0.0)\n",
    "    ssr = np.sum(res.fun**2)\n",
    "\n",
    "    return {\n",
    "        \"label\": label, \"n\": n, \"use_expected\": use_expected,\n",
    "        \"rho\": rho, \"rstar\": rstar, \"a_pi\": a_pi, \"a_u\": a_u,\n",
    "        \"se\": se, \"ssr\": ssr, \"sigma2\": sigma2,\n",
    "        \"prescribed\": prescribed, \"actual\": y,\n",
    "        \"taylor_principle\": 1 + a_pi,\n",
    "    }\n",
    "\n",
    "\n",
    "# ── HAC standard errors via block bootstrap ───────────────────────\n",
    "def bootstrap_taylor_se(sub, n_boot=500, block_size=12, use_expected=False):\n",
    "    \"\"\"Block bootstrap for HAC-robust standard errors on NLS Taylor rule.\"\"\"\n",
    "    n = len(sub)\n",
    "    boot_params = []\n",
    "\n",
    "    for b in range(n_boot):\n",
    "        # Block bootstrap indices\n",
    "        n_blocks = int(np.ceil(n / block_size))\n",
    "        block_starts = np.random.randint(0, n - block_size + 1, size=n_blocks)\n",
    "        indices = np.concatenate([np.arange(s, s + block_size) for s in block_starts])[:n]\n",
    "\n",
    "        boot_sub = sub.iloc[indices].copy()\n",
    "        y = boot_sub[\"fed_funds\"].values\n",
    "        u_gap = boot_sub[\"unemp_gap\"].values\n",
    "        ff_lag = boot_sub[\"ff_lag1\"].values\n",
    "\n",
    "        if use_expected:\n",
    "            pi = boot_sub[\"pi_expected\"].values\n",
    "            valid = ~np.isnan(pi)\n",
    "            if valid.sum() < 30:\n",
    "                continue\n",
    "            y, pi, u_gap, ff_lag = y[valid], pi[valid], u_gap[valid], ff_lag[valid]\n",
    "            resid_fn = taylor_resid_expected\n",
    "        else:\n",
    "            pi = boot_sub[\"inflation\"].values\n",
    "            resid_fn = taylor_resid\n",
    "\n",
    "        try:\n",
    "            res = least_squares(resid_fn, [0.85, 2.0, 0.5, 0.5],\n",
    "                args=(y, pi, u_gap, ff_lag),\n",
    "                bounds=([0, -5, -2, -5], [0.999, 10, 5, 5]),\n",
    "                max_nfev=300)\n",
    "            boot_params.append(res.x)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    if len(boot_params) < 50:\n",
    "        return [np.nan]*4\n",
    "\n",
    "    boot_params = np.array(boot_params)\n",
    "    return np.std(boot_params, axis=0)\n",
    "\n",
    "\n",
    "# ── Chow test ─────────────────────────────────────────────────────\n",
    "def chow_test(df, break_date, dep=\"delta_ff\", regressors=[\"inflation\",\"unemp_gap\"]):\n",
    "    sub = df[[dep] + regressors].dropna()\n",
    "    before = sub.loc[:break_date]\n",
    "    after = sub.loc[break_date:]\n",
    "    if len(before) < 10 or len(after) < 10:\n",
    "        return np.nan, np.nan\n",
    "    k = len(regressors) + 1\n",
    "    X_pool = sm.add_constant(sub[regressors].values); y_pool = sub[dep].values\n",
    "    res_pool = sm.OLS(y_pool, X_pool).fit()\n",
    "    X1 = sm.add_constant(before[regressors].values); y1 = before[dep].values\n",
    "    res1 = sm.OLS(y1, X1).fit()\n",
    "    X2 = sm.add_constant(after[regressors].values); y2 = after[dep].values\n",
    "    res2 = sm.OLS(y2, X2).fit()\n",
    "    n = len(sub)\n",
    "    F = ((res_pool.ssr - res1.ssr - res2.ssr) / k) / ((res1.ssr + res2.ssr) / (n - 2*k))\n",
    "    p_val = 1 - stats.f.cdf(F, k, n - 2*k)\n",
    "    return F, p_val\n",
    "\n",
    "\n",
    "# ── Expanding-window Taylor prescription ───────────────────────────\n",
    "def expanding_taylor(df, min_window=60):\n",
    "    dates_out, prescribed_out, actual_out = [], [], []\n",
    "    for end in range(min_window, len(df)):\n",
    "        window = df.iloc[:end+1]\n",
    "        current = df.iloc[end]\n",
    "        try:\n",
    "            y = window[\"fed_funds\"].values\n",
    "            pi = window[\"inflation\"].values\n",
    "            u_gap = window[\"unemp_gap\"].values\n",
    "            ff_lag = window[\"ff_lag1\"].values\n",
    "            res = least_squares(taylor_resid, [0.85, 2.0, 0.5, 0.5],\n",
    "                args=(y, pi, u_gap, ff_lag),\n",
    "                bounds=([0, -5, -2, -5], [0.999, 10, 5, 5]),\n",
    "                max_nfev=500)\n",
    "            rho, rstar, a_pi, a_u = res.x\n",
    "            target = rstar + current[\"inflation\"] + a_pi*(current[\"inflation\"]-2.0) + a_u*current[\"unemp_gap\"]\n",
    "            prescribed_out.append(max(0, target))\n",
    "        except:\n",
    "            prescribed_out.append(np.nan)\n",
    "        dates_out.append(df.index[end])\n",
    "        actual_out.append(current[\"fed_funds\"])\n",
    "    return pd.DataFrame({\"date\": dates_out, \"prescribed\": prescribed_out,\n",
    "                          \"actual\": actual_out}).set_index(\"date\")\n",
    "\n",
    "\n",
    "# ── Main analysis ──────────────────────────────────────────────────\n",
    "def run_analysis(df, regime_df, regime_names, n_regimes):\n",
    "    print(\"=\"*70)\n",
    "    print(\"REGIME-CONDITIONAL TAYLOR RULES\")\n",
    "    print(\"  Using CBO NAIRU for unemployment gap\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    sub = regime_df[[\"fed_funds\",\"ff_lag1\",\"inflation\",\"unemployment\",\n",
    "                     \"unemp_gap\",\"pi_expected\",\"regime\"]].dropna(\n",
    "                         subset=[\"fed_funds\",\"ff_lag1\",\"inflation\",\"unemp_gap\"])\n",
    "\n",
    "    # ── A. Full-sample Taylor rule (realized inflation) ──\n",
    "    print(\"\\n--- A. Full-sample structural Taylor rule (realized inflation, CBO NAIRU) ---\")\n",
    "    full = fit_taylor_nls(sub, \"Full sample (realized pi)\")\n",
    "    print(f\"\\n  {'Parameter':<20s}  {'Estimate':>10s}  {'OLS SE':>8s}\")\n",
    "    print(f\"  {'-'*42}\")\n",
    "    for nm, v, se in zip([\"rho (smoothing)\",\"r* (neutral)\",\"a_pi (inflation)\",\"a_u (unemp gap)\"],\n",
    "                          [full[\"rho\"],full[\"rstar\"],full[\"a_pi\"],full[\"a_u\"]], full[\"se\"]):\n",
    "        print(f\"  {nm:<20s}  {v:>10.3f}  {se:>8.3f}\")\n",
    "    print(f\"  Taylor principle: 1 + a_pi = {full['taylor_principle']:.2f}\")\n",
    "\n",
    "    # HAC standard errors\n",
    "    print(\"\\n  Computing block bootstrap HAC standard errors (500 reps)...\")\n",
    "    hac_se = bootstrap_taylor_se(sub, n_boot=500, block_size=12, use_expected=False)\n",
    "    full[\"hac_se\"] = hac_se\n",
    "    print(f\"  {'Parameter':<20s}  {'Estimate':>10s}  {'OLS SE':>8s}  {'HAC SE':>8s}\")\n",
    "    print(f\"  {'-'*52}\")\n",
    "    for nm, v, se, hse in zip([\"rho\",\"r*\",\"a_pi\",\"a_u\"],\n",
    "                               [full[\"rho\"],full[\"rstar\"],full[\"a_pi\"],full[\"a_u\"]],\n",
    "                               full[\"se\"], hac_se):\n",
    "        print(f\"  {nm:<20s}  {v:>10.3f}  {se:>8.3f}  {hse:>8.3f}\")\n",
    "\n",
    "    # ── A2. Expected inflation specification ──\n",
    "    print(\"\\n--- A2. Full-sample Taylor rule (expected inflation, CBO NAIRU) ---\")\n",
    "    full_exp = fit_taylor_nls(sub, \"Full sample (expected pi)\", use_expected=True)\n",
    "    if full_exp is not None:\n",
    "        print(f\"\\n  {'Parameter':<20s}  {'Estimate':>10s}  {'SE':>8s}\")\n",
    "        print(f\"  {'-'*42}\")\n",
    "        for nm, v, se in zip([\"rho\",\"r*\",\"a_pi\",\"a_u\"],\n",
    "                              [full_exp[\"rho\"],full_exp[\"rstar\"],full_exp[\"a_pi\"],full_exp[\"a_u\"]],\n",
    "                              full_exp[\"se\"]):\n",
    "            print(f\"  {nm:<20s}  {v:>10.3f}  {se:>8.3f}\")\n",
    "        print(f\"  Taylor principle (expected pi): 1 + a_pi = {full_exp['taylor_principle']:.2f}\")\n",
    "\n",
    "        hac_se_exp = bootstrap_taylor_se(sub, n_boot=500, block_size=12, use_expected=True)\n",
    "        full_exp[\"hac_se\"] = hac_se_exp\n",
    "        print(f\"\\n  HAC SE: {['%.3f' % s for s in hac_se_exp]}\")\n",
    "    else:\n",
    "        print(\"  Not enough expected inflation data.\")\n",
    "\n",
    "    # ── B. Regime-conditional Taylor rules ──\n",
    "    print(f\"\\n--- B. Regime-conditional Taylor rules ---\")\n",
    "    regime_results = {}\n",
    "    regime_results_exp = {}\n",
    "    for r in range(n_regimes):\n",
    "        rsub = sub[sub[\"regime\"] == r]\n",
    "        if len(rsub) < 30:\n",
    "            print(f\"  {regime_names[r]}: too few obs ({len(rsub)}), skipping\")\n",
    "            continue\n",
    "\n",
    "        # Realized inflation\n",
    "        result = fit_taylor_nls(rsub, regime_names[r])\n",
    "        regime_results[r] = result\n",
    "        hac = bootstrap_taylor_se(rsub, n_boot=500, block_size=12)\n",
    "        result[\"hac_se\"] = hac\n",
    "\n",
    "        # Expected inflation\n",
    "        result_exp = fit_taylor_nls(rsub, f\"{regime_names[r]} (exp pi)\", use_expected=True)\n",
    "        if result_exp is not None:\n",
    "            regime_results_exp[r] = result_exp\n",
    "            hac_exp = bootstrap_taylor_se(rsub, n_boot=500, block_size=12, use_expected=True)\n",
    "            result_exp[\"hac_se\"] = hac_exp\n",
    "\n",
    "    if regime_results:\n",
    "        print(f\"\\n  === Realized inflation specification ===\")\n",
    "        print(f\"  {'Regime':<30s}  {'rho':>6s}  {'r*':>6s}  {'a_pi':>6s}  {'a_u':>6s}  {'1+a_pi':>7s}  {'N':>4s}\")\n",
    "        print(f\"  {'-'*70}\")\n",
    "        for r, res in regime_results.items():\n",
    "            tp = res[\"taylor_principle\"]\n",
    "            print(f\"  {res['label']:<30s}  {res['rho']:>6.3f}  {res['rstar']:>6.3f}  \"\n",
    "                  f\"{res['a_pi']:>6.3f}  {res['a_u']:>6.3f}  {tp:>7.2f}  {res['n']:>4d}\")\n",
    "\n",
    "        print(f\"\\n  HAC standard errors (block bootstrap, 12-month blocks):\")\n",
    "        print(f\"  {'Regime':<30s}  {'se(rho)':>8s}  {'se(r*)':>8s}  {'se(a_pi)':>8s}  {'se(a_u)':>8s}\")\n",
    "        print(f\"  {'-'*70}\")\n",
    "        for r, res in regime_results.items():\n",
    "            hse = res[\"hac_se\"]\n",
    "            print(f\"  {res['label']:<30s}  {hse[0]:>8.3f}  {hse[1]:>8.3f}  {hse[2]:>8.3f}  {hse[3]:>8.3f}\")\n",
    "\n",
    "    if regime_results_exp:\n",
    "        print(f\"\\n  === Expected inflation specification ===\")\n",
    "        print(f\"  {'Regime':<30s}  {'rho':>6s}  {'r*':>6s}  {'a_pi':>6s}  {'a_u':>6s}  {'1+a_pi':>7s}  {'N':>4s}\")\n",
    "        print(f\"  {'-'*70}\")\n",
    "        for r, res in regime_results_exp.items():\n",
    "            tp = res[\"taylor_principle\"]\n",
    "            print(f\"  {res['label']:<30s}  {res['rho']:>6.3f}  {res['rstar']:>6.3f}  \"\n",
    "                  f\"{res['a_pi']:>6.3f}  {res['a_u']:>6.3f}  {tp:>7.2f}  {res['n']:>4d}\")\n",
    "\n",
    "    # ── C. Structural break tests (using CBO NAIRU gap) ──\n",
    "    print(f\"\\n--- C. Chow tests at regime transition dates ---\")\n",
    "    transitions = []\n",
    "    prev_regime = regime_df[\"regime\"].iloc[0]\n",
    "    for i in range(1, len(regime_df)):\n",
    "        curr = regime_df[\"regime\"].iloc[i]\n",
    "        if curr != prev_regime:\n",
    "            transitions.append({\n",
    "                \"date\": regime_df.index[i],\n",
    "                \"from\": regime_names.get(prev_regime, f\"R{prev_regime}\"),\n",
    "                \"to\": regime_names.get(curr, f\"R{curr}\"),\n",
    "            })\n",
    "        prev_regime = curr\n",
    "\n",
    "    if transitions:\n",
    "        tested_dates = set()\n",
    "        print(f\"\\n  {'Date':<12s}  {'Transition':<40s}  {'F-stat':>8s}  {'p-value':>8s}\")\n",
    "        print(f\"  {'-'*72}\")\n",
    "        for tr in transitions:\n",
    "            d = tr[\"date\"]\n",
    "            if any(abs((d - td).days) < 365 for td in tested_dates):\n",
    "                continue\n",
    "            tested_dates.add(d)\n",
    "            test_df = regime_df[[\"delta_ff\",\"inflation\",\"unemp_gap\"]].dropna()\n",
    "            F, p = chow_test(test_df, d.strftime(\"%Y-%m-%d\"),\n",
    "                             regressors=[\"inflation\",\"unemp_gap\"])\n",
    "            sig = \"***\" if p < 0.01 else \"**\" if p < 0.05 else \"*\" if p < 0.10 else \"\"\n",
    "            print(f\"  {d:%Y-%m}      {tr['from'][:18]:>18s} -> {tr['to'][:18]:<18s}  {F:>8.2f}  {p:>7.4f} {sig}\")\n",
    "\n",
    "    # ── D. Expanding-window Taylor prescription ──\n",
    "    print(f\"\\n--- D. Expanding-window Taylor rule prescription ---\")\n",
    "    expand_df = expanding_taylor(regime_df, min_window=60)\n",
    "    expand_df[\"gap\"] = expand_df[\"actual\"] - expand_df[\"prescribed\"]\n",
    "    expand_df[\"regime\"] = regime_df.loc[expand_df.index, \"regime\"]\n",
    "\n",
    "    print(f\"  Computed {len(expand_df)} real-time prescriptions\")\n",
    "    print(f\"  Mean discretionary gap: {expand_df['gap'].mean():+.2f} pp\")\n",
    "    for r in range(n_regimes):\n",
    "        rsub = expand_df[expand_df[\"regime\"] == r]\n",
    "        if len(rsub) > 0:\n",
    "            print(f\"  {regime_names[r]}: mean gap = {rsub['gap'].mean():+.2f}\")\n",
    "\n",
    "    return full, full_exp, regime_results, regime_results_exp, expand_df, transitions\n",
    "\n",
    "\n",
    "# ── Visualization ──────────────────────────────────────────────────\n",
    "def plot_results(regime_df, regime_names, n_regimes, full, full_exp,\n",
    "                 regime_results, regime_results_exp, expand_df, output_path):\n",
    "    regime_colors = [C5, C1, C4, C2, \"#94a3b8\"][:n_regimes]\n",
    "\n",
    "    # ── Fig 1: Regime-conditional Taylor parameters (with HAC SE) ──\n",
    "    if len(regime_results) >= 2:\n",
    "        fig, axes = plt.subplots(1, 4, figsize=(16, 5))\n",
    "        fig.suptitle(\"Taylor Rule Parameters by Inflation Regime (CBO NAIRU, HAC SE)\",\n",
    "                     fontweight=\"bold\", fontsize=14, y=1.02)\n",
    "\n",
    "        params = [\"rho\", \"rstar\", \"a_pi\", \"a_u\"]\n",
    "        titles = [\"Smoothing (rho)\", \"Neutral rate (r*)\",\n",
    "                  \"Inflation response (a_pi)\", \"Unemp gap response (a_u)\"]\n",
    "\n",
    "        for ax, param, title in zip(axes, params, titles):\n",
    "            labels_list = []; vals = []; colors = []; errors = []\n",
    "            idx = params.index(param)\n",
    "\n",
    "            # Full sample\n",
    "            labels_list.append(\"Full sample\"); vals.append(full[param])\n",
    "            colors.append(\"#6b7280\")\n",
    "            hse = full.get(\"hac_se\", full[\"se\"])\n",
    "            errors.append(1.96 * hse[idx] if not np.isnan(hse[idx]) else 0)\n",
    "\n",
    "            for r in sorted(regime_results.keys()):\n",
    "                res = regime_results[r]\n",
    "                labels_list.append(regime_names[r][:20]); vals.append(res[param])\n",
    "                colors.append(regime_colors[r])\n",
    "                hse_r = res.get(\"hac_se\", res[\"se\"])\n",
    "                errors.append(1.96 * hse_r[idx] if not np.isnan(hse_r[idx]) else 0)\n",
    "\n",
    "            y_pos = np.arange(len(labels_list))\n",
    "            ax.barh(y_pos, vals, xerr=errors, color=colors, alpha=0.75,\n",
    "                    edgecolor=\"white\", lw=1, capsize=4, height=0.6)\n",
    "            ax.set_yticks(y_pos); ax.set_yticklabels(labels_list, fontsize=8)\n",
    "            ax.axvline(0, color=\"grey\", lw=0.5)\n",
    "            ax.set_title(title, fontweight=\"bold\", fontsize=10)\n",
    "            ax.invert_yaxis()\n",
    "            if param == \"a_pi\":\n",
    "                ax.axvline(0, color=C2, ls=\"--\", lw=1, alpha=0.5)\n",
    "\n",
    "        fig.tight_layout()\n",
    "        path1 = f\"{output_path}/taylor_by_regime.png\"\n",
    "        fig.savefig(path1, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "        print(f\"  Saved: {path1}\")\n",
    "    else:\n",
    "        path1 = None\n",
    "\n",
    "    # ── Fig 2: Taylor prescription vs actual ──\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(16, 12), sharex=True,\n",
    "                              gridspec_kw={\"height_ratios\": [1, 3, 2]})\n",
    "    fig.suptitle(\"Taylor Rule Prescription vs Actual Fed Funds Rate (CBO NAIRU)\",\n",
    "                 fontweight=\"bold\", fontsize=14, y=0.995)\n",
    "\n",
    "    ax = axes[0]\n",
    "    for r in range(n_regimes):\n",
    "        mask = regime_df.loc[expand_df.index, \"regime\"] == r\n",
    "        for d in expand_df.index[mask]:\n",
    "            ax.axvspan(d, d + pd.DateOffset(months=1), color=regime_colors[r], alpha=0.8)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(\"Inflation regime\", fontweight=\"bold\", fontsize=10)\n",
    "    legend_elements = [Patch(facecolor=regime_colors[r], alpha=0.8, label=regime_names[r])\n",
    "                       for r in range(n_regimes)]\n",
    "    ax.legend(handles=legend_elements, frameon=True, fontsize=7, loc=\"upper left\",\n",
    "              ncol=min(n_regimes,3))\n",
    "\n",
    "    ax = axes[1]; shade_recessions(ax)\n",
    "    ax.plot(expand_df.index, expand_df[\"actual\"], lw=2, color=C1, label=\"Actual fed funds\", zorder=3)\n",
    "    ax.plot(expand_df.index, expand_df[\"prescribed\"], lw=1.5, color=C2, alpha=0.8,\n",
    "            label=\"Taylor rule prescription\", zorder=2)\n",
    "    ax.fill_between(expand_df.index, expand_df[\"actual\"], expand_df[\"prescribed\"],\n",
    "                    where=expand_df[\"actual\"] > expand_df[\"prescribed\"],\n",
    "                    alpha=0.15, color=C2, label=\"Too tight\")\n",
    "    ax.fill_between(expand_df.index, expand_df[\"actual\"], expand_df[\"prescribed\"],\n",
    "                    where=expand_df[\"actual\"] < expand_df[\"prescribed\"],\n",
    "                    alpha=0.15, color=C1, label=\"Too loose\")\n",
    "    ax.set_ylabel(\"Rate (%)\")\n",
    "    ax.set_title(\"Fed funds: actual vs Taylor rule prescription\", fontweight=\"bold\")\n",
    "    ax.legend(frameon=True, fontsize=8, loc=\"upper right\")\n",
    "    ax.set_ylim(bottom=-1)\n",
    "\n",
    "    ax = axes[2]; shade_recessions(ax)\n",
    "    gap = expand_df[\"gap\"]\n",
    "    ax.fill_between(expand_df.index, gap, 0, where=gap > 0, alpha=0.4, color=C2, label=\"Tighter than rule\")\n",
    "    ax.fill_between(expand_df.index, gap, 0, where=gap < 0, alpha=0.4, color=C1, label=\"Looser than rule\")\n",
    "    ax.axhline(0, color=\"grey\", lw=1)\n",
    "    ax.set_ylabel(\"Gap (pp)\"); ax.set_xlabel(\"Year\")\n",
    "    ax.set_title(\"Discretionary gap (actual minus prescribed)\", fontweight=\"bold\")\n",
    "    ax.legend(frameon=True, fontsize=8)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    path2 = f\"{output_path}/taylor_prescription_vs_actual.png\"\n",
    "    fig.savefig(path2, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "    print(f\"  Saved: {path2}\")\n",
    "\n",
    "    # ── Fig 3: Taylor principle by regime (realized vs expected) ──\n",
    "    if len(regime_results) >= 2:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        fig.suptitle(\"Taylor Principle: Realized vs Expected Inflation\",\n",
    "                     fontweight=\"bold\", fontsize=14, y=1.02)\n",
    "\n",
    "        for ax, (results_dict, title_suffix) in zip(axes, [\n",
    "            (regime_results, \"Realized inflation\"),\n",
    "            (regime_results_exp, \"Expected inflation (MICH/adaptive)\")]):\n",
    "\n",
    "            if not results_dict:\n",
    "                ax.text(0.5, 0.5, \"Not enough data\", ha=\"center\", va=\"center\",\n",
    "                        transform=ax.transAxes)\n",
    "                ax.set_title(title_suffix, fontweight=\"bold\")\n",
    "                continue\n",
    "\n",
    "            labels_list = [\"Full sample\"] + [regime_names[r][:25] for r in sorted(results_dict.keys())]\n",
    "            ref = full if \"Realized\" in title_suffix else full_exp\n",
    "            if ref is None:\n",
    "                continue\n",
    "            tp_vals = [ref[\"taylor_principle\"]] + \\\n",
    "                      [results_dict[r][\"taylor_principle\"] for r in sorted(results_dict.keys())]\n",
    "            colors_bar = [\"#6b7280\"] + [regime_colors[r] for r in sorted(results_dict.keys())]\n",
    "\n",
    "            # HAC-based error bars\n",
    "            errs = []\n",
    "            hse = ref.get(\"hac_se\", ref[\"se\"])\n",
    "            errs.append(1.96 * hse[2] if not np.isnan(hse[2]) else 0)\n",
    "            for r in sorted(results_dict.keys()):\n",
    "                hse_r = results_dict[r].get(\"hac_se\", results_dict[r][\"se\"])\n",
    "                errs.append(1.96 * hse_r[2] if not np.isnan(hse_r[2]) else 0)\n",
    "\n",
    "            bars = ax.bar(labels_list, tp_vals, yerr=errs, color=colors_bar,\n",
    "                          alpha=0.75, edgecolor=\"white\", lw=1, width=0.6, capsize=5)\n",
    "            ax.axhline(1.0, color=C2, ls=\"--\", lw=2, alpha=0.7, label=\"Taylor principle = 1\")\n",
    "            ax.set_ylabel(\"1 + a_pi\")\n",
    "            ax.set_title(title_suffix, fontweight=\"bold\")\n",
    "            ax.legend(frameon=False, fontsize=9)\n",
    "            for bar, val in zip(bars, tp_vals):\n",
    "                ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(errs)*0.1 + 0.02,\n",
    "                        f\"{val:.2f}\", ha=\"center\", va=\"bottom\", fontsize=10, fontweight=\"bold\")\n",
    "\n",
    "        fig.tight_layout()\n",
    "        path3 = f\"{output_path}/taylor_principle_by_regime.png\"\n",
    "        fig.savefig(path3, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "        print(f\"  Saved: {path3}\")\n",
    "    else:\n",
    "        path3 = None\n",
    "\n",
    "    return [p for p in [path1, path2, path3] if p]\n",
    "\n",
    "\n",
    "# ── Main ───────────────────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Loading data...\")\n",
    "    data = load_data(DATA_PATH)\n",
    "    df = engineer_features(data)\n",
    "\n",
    "    print(\"Fitting Markov-switching regimes...\")\n",
    "    regime_df, regime_names, n_regimes = get_regimes(df, n_regimes=2)\n",
    "    print(f\"  {n_regimes} regimes: {regime_names}\")\n",
    "\n",
    "    full, full_exp, regime_results, regime_results_exp, expand_df, transitions = \\\n",
    "        run_analysis(df, regime_df, regime_names, n_regimes)\n",
    "\n",
    "    paths = plot_results(regime_df, regime_names, n_regimes, full, full_exp,\n",
    "                         regime_results, regime_results_exp, expand_df, OUTPUT_PATH)\n",
    "\n",
    "    print(f\"\\nOutputs: {paths}\")\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e74e85fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Merged: 857 obs (1954-07 to 2025-12)\n",
      "Fitting regimes...\n",
      "  2 regimes: {0: 'Low inflation (2.4%)', 1: 'High inflation (7.4%)'}\n",
      "\n",
      "======================================================================\n",
      "STRUCTURAL BREAK DETECTION (Sequential sup-Wald)\n",
      "  Using CBO NAIRU-based unemployment gap\n",
      "======================================================================\n",
      "  DV: delta_ff  |  Regressors: ['inflation', 'unemp_gap']\n",
      "\n",
      "  Break 1: no further significant breaks found.\n",
      "\n",
      "  Detected breaks vs chair transitions:\n",
      "  Break date      Nearest chair transition          Distance\n",
      "  ----------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "YIELD CURVE AND REGIME TRANSITIONS\n",
      "======================================================================\n",
      "\n",
      "  Major regime transitions: 9\n",
      "\n",
      "  Date          Direction   Spread at t    Spread t-6   Spread t-12\n",
      "  ------------------------------------------------------------\n",
      "  1968-07      up               -0.53          0.29          0.85\n",
      "  1971-06      down              1.61          1.90          1.35\n",
      "  1973-03      up               -0.38          0.99          1.39\n",
      "  1982-11      down              1.35          1.14          0.62\n",
      "  1988-11      up                0.61          1.21          1.56\n",
      "  1991-07      down              2.45          1.93          1.26\n",
      "  2008-06      up                2.10          0.77          0.24\n",
      "  2021-05      up                1.56          1.15          0.88\n",
      "  2023-05      down             -1.49         -0.72          0.28\n",
      "\n",
      "  Logit: P(regime change in 12m) ~ term_spread\n",
      "  Spread coefficient: -0.0093 (p=0.8852)\n",
      "  -> Term spread does NOT significantly predict regime transitions\n",
      "\n",
      "======================================================================\n",
      "RECESSION MODEL: LEAVE-ONE-RECESSION-OUT CV\n",
      "======================================================================\n",
      "\n",
      "  --- 6-month horizon ---\n",
      "  Left out                 Train N    Test N  AUC (full)  AUC (spread)\n",
      "  ------------------------------------------------------------------\n",
      "  Time-split ref               540       113       0.779\n",
      "\n",
      "  1973-74 Oil                  618        35       0.986         0.972\n",
      "  1980 Volcker I               628        25       0.974         0.885\n",
      "  1981-82 Volcker II           618        35       0.719         0.589\n",
      "  1990-91                      626        27       0.165         0.077\n",
      "  2001 Dot-com                 626        27       0.665         0.549\n",
      "  2007-09 GFC                  616        37       0.702         0.127\n",
      "  2020 COVID                   632        21       0.952         0.755\n",
      "\n",
      "  Average LORO                                     0.738         0.565\n",
      "\n",
      "  --- 12-month horizon ---\n",
      "  Left out                 Train N    Test N  AUC (full)  AUC (spread)\n",
      "  ------------------------------------------------------------------\n",
      "  Time-split ref               540       107       0.703\n",
      "\n",
      "  1973-74 Oil                  612        35       0.939         1.000\n",
      "  1980 Volcker I               622        25       0.746         0.842\n",
      "  1981-82 Volcker II           612        35       1.000         0.838\n",
      "  1990-91                      620        27       0.279         0.314\n",
      "  2001 Dot-com                 620        27       0.750         0.750\n",
      "  2007-09 GFC                  610        37       0.490         0.350\n",
      "  2020 COVID                   626        21       1.000         0.995\n",
      "\n",
      "  Average LORO                                     0.743         0.727\n",
      "  Saved: /Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/yield_curve_regimes.png\n",
      "\n",
      "Outputs: ['/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/yield_curve_regimes.png']\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Component 3: Structural Break Detection & Yield Curve Analysis\n",
    "==============================================================\n",
    "Updated: uses CBO NAIRU-based unemployment gap in break detection.\n",
    "\"\"\"\n",
    "\n",
    "import os, warnings, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy import stats\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SEED = 42; random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "DATA_PATH = '/Users/leoss/Desktop/Portfolio/Website-/Central bank/data'\n",
    "OUTPUT_PATH = '/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs'\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "C1, C2, C3, C4, C5 = \"#2563eb\", \"#dc2626\", \"#7c3aed\", \"#f59e0b\", \"#10b981\"\n",
    "C_BG = \"#fafafa\"\n",
    "plt.rcParams.update({\n",
    "    \"figure.facecolor\": C_BG, \"axes.facecolor\": C_BG,\n",
    "    \"axes.grid\": True, \"grid.color\": \"#e5e7eb\", \"grid.linewidth\": 0.5,\n",
    "    \"font.size\": 11, \"axes.spines.top\": False, \"axes.spines.right\": False,\n",
    "})\n",
    "\n",
    "RECESSIONS = [\n",
    "    (\"1973-11\",\"1975-03\"),(\"1980-01\",\"1980-07\"),(\"1981-07\",\"1982-11\"),\n",
    "    (\"1990-07\",\"1991-03\"),(\"2001-03\",\"2001-11\"),(\"2007-12\",\"2009-06\"),(\"2020-02\",\"2020-04\"),\n",
    "]\n",
    "FED_CHAIRS = [\n",
    "    (\"Burns\",\"1970-02\",\"1978-01\"),(\"Miller\",\"1978-03\",\"1979-08\"),\n",
    "    (\"Volcker\",\"1979-08\",\"1987-08\"),(\"Greenspan\",\"1987-08\",\"2006-01\"),\n",
    "    (\"Bernanke\",\"2006-02\",\"2014-01\"),(\"Yellen\",\"2014-02\",\"2018-02\"),\n",
    "    (\"Powell\",\"2018-02\",\"2024-12\"),\n",
    "]\n",
    "CHAIR_DATES = [(ch, pd.Timestamp(s), pd.Timestamp(e)) for ch,s,e in FED_CHAIRS]\n",
    "\n",
    "def shade_recessions(ax):\n",
    "    for s, e in RECESSIONS:\n",
    "        ax.axvspan(pd.Timestamp(s), pd.Timestamp(e), alpha=0.10, color=\"#fca5a5\", zorder=0)\n",
    "\n",
    "\n",
    "def load_data(path=DATA_PATH):\n",
    "    def _read(names):\n",
    "        for n in names:\n",
    "            p = os.path.join(path, n)\n",
    "            if os.path.exists(p):\n",
    "                return pd.read_csv(p, parse_dates=[\"observation_date\"],\n",
    "                                   index_col=\"observation_date\")\n",
    "        raise FileNotFoundError(f\"None of {names} found in {path}\")\n",
    "\n",
    "    cpi = _read([\"CPIAUCSL.csv\"])\n",
    "    unrate = _read([\"UNRATE.csv\"])\n",
    "    ff = _read([\"FEDFUNDS.csv\", \"FEDFUNDS-1.csv\"])\n",
    "    tcu = _read([\"TCU.csv\"])\n",
    "    gs10 = _read([\"GS10.csv\"])\n",
    "    nfci_w = _read([\"NFCI.csv\"]); nfci = nfci_w.resample(\"MS\").last()\n",
    "    nrou_q = _read([\"NROU.csv\", \"NROUST.csv\"])\n",
    "    nrou_q.index = pd.DatetimeIndex(nrou_q.index)\n",
    "    nrou_m = nrou_q.resample(\"MS\").interpolate(method=\"linear\")\n",
    "    try:\n",
    "        mich = _read([\"MICH.csv\"])\n",
    "    except FileNotFoundError:\n",
    "        mich = None\n",
    "\n",
    "    merged = pd.concat([\n",
    "        cpi.rename(columns={cpi.columns[0]: \"cpi\"}),\n",
    "        unrate.rename(columns={unrate.columns[0]: \"unemployment\"}),\n",
    "        ff.rename(columns={ff.columns[0]: \"fed_funds\"}),\n",
    "        tcu.rename(columns={tcu.columns[0]: \"capacity_util\"}),\n",
    "        gs10.rename(columns={gs10.columns[0]: \"treasury_10y\"}),\n",
    "        nfci.rename(columns={nfci.columns[0]: \"fin_conditions\"}),\n",
    "        nrou_m.rename(columns={nrou_m.columns[0]: \"nrou\"}),\n",
    "    ], axis=1).dropna(subset=[\"cpi\", \"unemployment\", \"fed_funds\", \"nrou\"])\n",
    "\n",
    "    if mich is not None:\n",
    "        merged = merged.join(\n",
    "            mich.rename(columns={mich.columns[0]: \"expected_inflation\"}), how=\"left\")\n",
    "    else:\n",
    "        merged[\"expected_inflation\"] = np.nan\n",
    "    print(f\"Merged: {len(merged)} obs ({merged.index.min():%Y-%m} to {merged.index.max():%Y-%m})\")\n",
    "    return merged\n",
    "\n",
    "\n",
    "def engineer_features(data):\n",
    "    df = data.copy()\n",
    "    df[\"inflation\"] = df[\"cpi\"].pct_change(12) * 100\n",
    "    df[\"unemp_gap\"] = df[\"unemployment\"] - df[\"nrou\"]\n",
    "    df[\"capacity_gap\"] = df[\"capacity_util\"] - 100.0\n",
    "    df[\"term_spread\"] = df[\"treasury_10y\"] - df[\"fed_funds\"]\n",
    "    df[\"real_rate\"] = df[\"fed_funds\"] - df[\"inflation\"]\n",
    "    df[\"delta_ff\"] = df[\"fed_funds\"].diff()\n",
    "    df[\"delta_pi\"] = df[\"inflation\"].diff()\n",
    "    df[\"delta_u\"] = df[\"unemployment\"].diff()\n",
    "    df[\"ff_lag1\"] = df[\"fed_funds\"].shift(1)\n",
    "    df[\"adaptive_pi_e\"] = df[\"inflation\"].rolling(12).mean()\n",
    "    df[\"pi_expected\"] = df[\"expected_inflation\"].fillna(df[\"adaptive_pi_e\"])\n",
    "    for var in [\"inflation\",\"unemp_gap\",\"capacity_gap\",\"fed_funds\",\"term_spread\",\"fin_conditions\"]:\n",
    "        for lag in [1,3,6,12]:\n",
    "            df[f\"L{lag}_{var}\"] = df[var].shift(lag)\n",
    "    for h in [1,3,6,12]:\n",
    "        df[f\"inflation_{h}m_ahead\"] = df[\"inflation\"].shift(-h)\n",
    "    df[\"recession\"] = 0\n",
    "    for start, end in RECESSIONS:\n",
    "        df.loc[(df.index >= start) & (df.index <= end), \"recession\"] = 1\n",
    "    df = df.dropna(subset=[\"inflation\",\"L12_inflation\"])\n",
    "    df.index = pd.DatetimeIndex(df.index)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_regimes(df, n_regimes=2):\n",
    "    endog = df[\"inflation\"].copy()\n",
    "    exog = sm.add_constant(df[[\"unemployment\"]].copy())\n",
    "    mod = sm.tsa.MarkovRegression(endog, k_regimes=n_regimes, exog=exog,\n",
    "        switching_variance=True, switching_exog=True)\n",
    "    best_res, best_llf = None, -np.inf\n",
    "    for attempt in range(8):\n",
    "        try:\n",
    "            res = mod.fit(search_reps=30, random_state=SEED+attempt, disp=False, maxiter=500)\n",
    "            if res.llf > best_llf: best_llf = res.llf; best_res = res\n",
    "        except: continue\n",
    "    smoothed = best_res.smoothed_marginal_probabilities\n",
    "    regime_means = {}\n",
    "    for r in range(n_regimes):\n",
    "        mask = smoothed[r] > 0.5\n",
    "        regime_means[r] = df.loc[mask, \"inflation\"].mean() if mask.sum() > 0 else 0.0\n",
    "    sorted_regimes = sorted(regime_means, key=regime_means.get)\n",
    "    rdf = df.copy()\n",
    "    for new_r in range(n_regimes):\n",
    "        rdf[f\"p_regime_{new_r}\"] = smoothed[sorted_regimes[new_r]].values\n",
    "    rdf[\"regime\"] = np.argmax(\n",
    "        np.column_stack([rdf[f\"p_regime_{r}\"].values for r in range(n_regimes)]), axis=1)\n",
    "    sorted_means = [regime_means[sorted_regimes[r]] for r in range(n_regimes)]\n",
    "    labels = [\"Low\",\"High\"] if n_regimes==2 else [f\"R{r}\" for r in range(n_regimes)]\n",
    "    regime_names = {r: f\"{labels[r]} inflation ({sorted_means[r]:.1f}%)\" for r in range(n_regimes)}\n",
    "    return rdf, regime_names, n_regimes\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# PART A: STRUCTURAL BREAK DETECTION (now uses CBO NAIRU gap)\n",
    "# ================================================================\n",
    "def sup_wald_break_test(df, dep=\"delta_ff\", regressors=[\"inflation\",\"unemp_gap\"],\n",
    "                        min_frac=0.15):\n",
    "    sub = df[[dep] + regressors].dropna()\n",
    "    n = len(sub); trim = int(n * min_frac); k = len(regressors) + 1\n",
    "    X_pool = sm.add_constant(sub[regressors].values)\n",
    "    y_pool = sub[dep].values\n",
    "    res_pool = sm.OLS(y_pool, X_pool).fit()\n",
    "    ssr_pool = res_pool.ssr\n",
    "\n",
    "    dates_test, f_stats = [], []\n",
    "    for t in range(trim, n - trim):\n",
    "        X1 = sm.add_constant(sub[regressors].values[:t])\n",
    "        y1 = sub[dep].values[:t]\n",
    "        X2 = sm.add_constant(sub[regressors].values[t:])\n",
    "        y2 = sub[dep].values[t:]\n",
    "        try:\n",
    "            res1 = sm.OLS(y1, X1).fit(); res2 = sm.OLS(y2, X2).fit()\n",
    "            F = ((ssr_pool - res1.ssr - res2.ssr) / k) / ((res1.ssr + res2.ssr) / (n - 2*k))\n",
    "            f_stats.append(F)\n",
    "        except:\n",
    "            f_stats.append(0)\n",
    "        dates_test.append(sub.index[t])\n",
    "\n",
    "    f_stats = np.array(f_stats)\n",
    "    dates_test = pd.DatetimeIndex(dates_test)\n",
    "    best_idx = np.argmax(f_stats)\n",
    "\n",
    "    # Andrews (1993) critical values for sup-Wald, k=3, 15% trimming\n",
    "    cv_10 = 7.12; cv_05 = 8.68; cv_01 = 12.16\n",
    "    best_F = f_stats[best_idx]\n",
    "    sig = \"***\" if best_F > cv_01 else \"**\" if best_F > cv_05 else \"*\" if best_F > cv_10 else \"\"\n",
    "\n",
    "    return {\n",
    "        \"best_date\": dates_test[best_idx], \"best_F\": best_F, \"sig\": sig,\n",
    "        \"cv\": {\"1%\": cv_01, \"5%\": cv_05, \"10%\": cv_10},\n",
    "        \"dates\": dates_test, \"f_stats\": f_stats,\n",
    "    }\n",
    "\n",
    "\n",
    "def sequential_breaks(df, dep=\"delta_ff\", regressors=[\"inflation\",\"unemp_gap\"],\n",
    "                      max_breaks=4, min_frac=0.15):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"STRUCTURAL BREAK DETECTION (Sequential sup-Wald)\")\n",
    "    print(f\"  Using CBO NAIRU-based unemployment gap\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"  DV: {dep}  |  Regressors: {regressors}\")\n",
    "\n",
    "    sub = df[[dep] + regressors].dropna()\n",
    "    breaks = []\n",
    "    segments = [(sub.index[0], sub.index[-1])]\n",
    "\n",
    "    for b in range(max_breaks):\n",
    "        best_overall = None\n",
    "        for seg_start, seg_end in segments:\n",
    "            seg = sub.loc[seg_start:seg_end]\n",
    "            if len(seg) < int(len(sub) * min_frac * 2):\n",
    "                continue\n",
    "            result = sup_wald_break_test(seg, dep, regressors, min_frac)\n",
    "            if result[\"best_F\"] > result[\"cv\"][\"5%\"]:\n",
    "                if best_overall is None or result[\"best_F\"] > best_overall[\"best_F\"]:\n",
    "                    best_overall = result\n",
    "                    best_overall[\"segment\"] = (seg_start, seg_end)\n",
    "\n",
    "        if best_overall is None:\n",
    "            print(f\"\\n  Break {b+1}: no further significant breaks found.\")\n",
    "            break\n",
    "\n",
    "        breaks.append(best_overall)\n",
    "        bd = best_overall[\"best_date\"]\n",
    "        print(f\"\\n  Break {b+1}: {bd:%Y-%m}  (F = {best_overall['best_F']:.2f}{best_overall['sig']})\")\n",
    "\n",
    "        seg_s, seg_e = best_overall[\"segment\"]\n",
    "        new_segments = []\n",
    "        for s, e in segments:\n",
    "            if s == seg_s and e == seg_e:\n",
    "                new_segments.append((s, bd)); new_segments.append((bd, e))\n",
    "            else:\n",
    "                new_segments.append((s, e))\n",
    "        segments = new_segments\n",
    "\n",
    "    print(f\"\\n  Detected breaks vs chair transitions:\")\n",
    "    print(f\"  {'Break date':<14s}  {'Nearest chair transition':<30s}  {'Distance':>10s}\")\n",
    "    print(f\"  {'-'*58}\")\n",
    "    for brk in breaks:\n",
    "        bd = brk[\"best_date\"]\n",
    "        nearest = min(CHAIR_DATES, key=lambda x: min(abs((bd-x[1]).days), abs((bd-x[2]).days)))\n",
    "        d1 = abs((bd - nearest[1]).days); d2 = abs((bd - nearest[2]).days)\n",
    "        if d1 < d2:\n",
    "            chair_event = f\"{nearest[0]} start ({nearest[1]:%Y-%m})\"; dist_months = d1/30\n",
    "        else:\n",
    "            chair_event = f\"{nearest[0]} end ({nearest[2]:%Y-%m})\"; dist_months = d2/30\n",
    "        print(f\"  {bd:%Y-%m}        {chair_event:<30s}  {dist_months:>8.1f}m\")\n",
    "\n",
    "    return breaks, segments\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# PART B: YIELD CURVE AND REGIME TRANSITIONS\n",
    "# ================================================================\n",
    "def yield_curve_regime_analysis(regime_df, regime_names, n_regimes):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"YIELD CURVE AND REGIME TRANSITIONS\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    transitions = []\n",
    "    prev = regime_df[\"regime\"].iloc[0]\n",
    "    for i in range(1, len(regime_df)):\n",
    "        curr = regime_df[\"regime\"].iloc[i]\n",
    "        if curr != prev:\n",
    "            transitions.append({\"date\": regime_df.index[i], \"from_regime\": prev,\n",
    "                                \"to_regime\": curr,\n",
    "                                \"direction\": \"up\" if curr > prev else \"down\"})\n",
    "        prev = curr\n",
    "\n",
    "    filtered = []\n",
    "    for tr in transitions:\n",
    "        if not filtered or (tr[\"date\"] - filtered[-1][\"date\"]).days > 365:\n",
    "            filtered.append(tr)\n",
    "    transitions = filtered\n",
    "\n",
    "    print(f\"\\n  Major regime transitions: {len(transitions)}\")\n",
    "    print(f\"\\n  {'Date':<12s}  {'Direction':<8s}  {'Spread at t':>12s}  {'Spread t-6':>12s}  {'Spread t-12':>12s}\")\n",
    "    print(f\"  {'-'*60}\")\n",
    "\n",
    "    for tr in transitions:\n",
    "        d = tr[\"date\"]\n",
    "        spread_at = regime_df.loc[:d, \"term_spread\"].iloc[-1]\n",
    "        d_6 = d - pd.DateOffset(months=6)\n",
    "        mask_6 = (regime_df.index >= d_6) & (regime_df.index < d)\n",
    "        spread_6 = regime_df.loc[mask_6, \"term_spread\"].mean() if mask_6.sum() > 0 else np.nan\n",
    "        d_12 = d - pd.DateOffset(months=12)\n",
    "        mask_12 = (regime_df.index >= d_12) & (regime_df.index < d)\n",
    "        spread_12 = regime_df.loc[mask_12, \"term_spread\"].mean() if mask_12.sum() > 0 else np.nan\n",
    "        tr[\"spread_at\"] = spread_at; tr[\"spread_6m\"] = spread_6; tr[\"spread_12m\"] = spread_12\n",
    "        print(f\"  {d:%Y-%m}      {tr['direction']:<8s}  {spread_at:>12.2f}  {spread_6:>12.2f}  {spread_12:>12.2f}\")\n",
    "\n",
    "    # Logit test\n",
    "    rdf = regime_df.copy()\n",
    "    rdf[\"regime_change\"] = (rdf[\"regime\"].diff() != 0).astype(int)\n",
    "    rdf[\"regime_change_12m\"] = rdf[\"regime_change\"].rolling(12).max().shift(-12)\n",
    "    test_df = rdf[[\"term_spread\",\"regime_change_12m\"]].dropna()\n",
    "    if len(test_df) > 50:\n",
    "        X = sm.add_constant(test_df[\"term_spread\"].values)\n",
    "        y = test_df[\"regime_change_12m\"].values\n",
    "        try:\n",
    "            logit = sm.Logit(y, X).fit(disp=False)\n",
    "            print(f\"\\n  Logit: P(regime change in 12m) ~ term_spread\")\n",
    "            print(f\"  Spread coefficient: {logit.params[1]:.4f} (p={logit.pvalues[1]:.4f})\")\n",
    "            if logit.pvalues[1] < 0.05:\n",
    "                print(f\"  -> Term spread significantly predicts regime transitions\")\n",
    "            else:\n",
    "                print(f\"  -> Term spread does NOT significantly predict regime transitions\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return transitions\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# PART C: RECESSION MODEL ROBUSTNESS\n",
    "# ================================================================\n",
    "def leave_one_recession_out(df):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"RECESSION MODEL: LEAVE-ONE-RECESSION-OUT CV\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    rec_features = [\"term_spread\",\"inflation\",\"unemp_gap\",\"fed_funds\",\n",
    "                    \"capacity_gap\",\"fin_conditions\",\"real_rate\"]\n",
    "\n",
    "    df = df.copy()\n",
    "    for h in [6,12,18]:\n",
    "        col = f\"recession_{h}m_ahead\"\n",
    "        if col not in df.columns:\n",
    "            df[col] = df[\"recession\"].rolling(h).max().shift(-h)\n",
    "\n",
    "    recession_episodes = [\n",
    "        (\"1973-74 Oil\", \"1973-11\", \"1975-03\"),\n",
    "        (\"1980 Volcker I\", \"1980-01\", \"1980-07\"),\n",
    "        (\"1981-82 Volcker II\", \"1981-07\", \"1982-11\"),\n",
    "        (\"1990-91\", \"1990-07\", \"1991-03\"),\n",
    "        (\"2001 Dot-com\", \"2001-03\", \"2001-11\"),\n",
    "        (\"2007-09 GFC\", \"2007-12\", \"2009-06\"),\n",
    "        (\"2020 COVID\", \"2020-02\", \"2020-04\"),\n",
    "    ]\n",
    "\n",
    "    for h in [6, 12]:\n",
    "        target = f\"recession_{h}m_ahead\"\n",
    "        rec_df = df[rec_features + [target]].dropna()\n",
    "        y_full = rec_df[target].astype(int).values\n",
    "        X_full = rec_df[rec_features].values\n",
    "\n",
    "        print(f\"\\n  --- {h}-month horizon ---\")\n",
    "        print(f\"  {'Left out':<22s}  {'Train N':>8s}  {'Test N':>8s}  {'AUC (full)':>10s}  {'AUC (spread)':>12s}\")\n",
    "        print(f\"  {'-'*66}\")\n",
    "\n",
    "        tr_mask = rec_df.index <= \"2015-12\"; te_mask = ~tr_mask\n",
    "        if te_mask.sum() > 0 and len(np.unique(y_full[te_mask])) > 1:\n",
    "            sc = StandardScaler(); X_tr = sc.fit_transform(X_full[tr_mask]); X_te = sc.transform(X_full[te_mask])\n",
    "            clf = LogisticRegression(C=1.0, max_iter=1000, random_state=SEED)\n",
    "            clf.fit(X_tr, y_full[tr_mask])\n",
    "            ref_auc = roc_auc_score(y_full[te_mask], clf.predict_proba(X_te)[:,1])\n",
    "            print(f\"  {'Time-split ref':<22s}  {tr_mask.sum():>8d}  {te_mask.sum():>8d}  {ref_auc:>10.3f}\")\n",
    "        print()\n",
    "\n",
    "        results_loro = []\n",
    "        for name, rs, re in recession_episodes:\n",
    "            pre_start = pd.Timestamp(rs) - pd.DateOffset(months=18)\n",
    "            test_mask = (rec_df.index >= pre_start) & (rec_df.index <= re)\n",
    "            train_mask = ~test_mask\n",
    "            y_tr = y_full[train_mask]; X_tr_raw = X_full[train_mask]\n",
    "            y_te = y_full[test_mask]; X_te_raw = X_full[test_mask]\n",
    "            if len(y_te) < 5 or len(np.unique(y_te)) < 2:\n",
    "                print(f\"  {name:<22s}  {train_mask.sum():>8d}  {test_mask.sum():>8d}  {'skip':>10s}\")\n",
    "                continue\n",
    "            sc = StandardScaler()\n",
    "            X_tr = sc.fit_transform(X_tr_raw); X_te = sc.transform(X_te_raw)\n",
    "            clf_full = LogisticRegression(C=1.0, max_iter=1000, random_state=SEED)\n",
    "            clf_full.fit(X_tr, y_tr)\n",
    "            auc_full = roc_auc_score(y_te, clf_full.predict_proba(X_te)[:,1])\n",
    "            si = rec_features.index(\"term_spread\")\n",
    "            clf_sp = LogisticRegression(C=1.0, max_iter=1000, random_state=SEED)\n",
    "            clf_sp.fit(X_tr[:,si:si+1], y_tr)\n",
    "            auc_sp = roc_auc_score(y_te, clf_sp.predict_proba(X_te[:,si:si+1])[:,1])\n",
    "            results_loro.append({\"name\": name, \"auc_full\": auc_full, \"auc_spread\": auc_sp})\n",
    "            print(f\"  {name:<22s}  {train_mask.sum():>8d}  {test_mask.sum():>8d}  {auc_full:>10.3f}  {auc_sp:>12.3f}\")\n",
    "\n",
    "        if results_loro:\n",
    "            avg_full = np.mean([r[\"auc_full\"] for r in results_loro])\n",
    "            avg_sp = np.mean([r[\"auc_spread\"] for r in results_loro])\n",
    "            print(f\"\\n  {'Average LORO':<22s}  {'':>8s}  {'':>8s}  {avg_full:>10.3f}  {avg_sp:>12.3f}\")\n",
    "\n",
    "    return results_loro\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# VISUALIZATION\n",
    "# ================================================================\n",
    "def plot_results(df, regime_df, regime_names, n_regimes, breaks, transitions, output_path):\n",
    "    regime_colors = [C5, C1, C4, C2][:n_regimes]\n",
    "    chair_colors_map = {\"Burns\":\"#dbeafe\",\"Miller\":\"#fee2e2\",\"Volcker\":\"#ede9fe\",\n",
    "                        \"Greenspan\":\"#fef3c7\",\"Bernanke\":\"#d1fae5\",\"Yellen\":\"#fce7f3\",\"Powell\":\"#e0e7ff\"}\n",
    "\n",
    "    # ── Fig 1: Sup-Wald F-statistic ──\n",
    "    if breaks:\n",
    "        first_break = breaks[0]\n",
    "        fig, axes = plt.subplots(3, 1, figsize=(16, 10), sharex=True,\n",
    "                                  gridspec_kw={\"height_ratios\": [1, 2, 2]})\n",
    "        fig.suptitle(\"Structural Break Detection in Fed Reaction Function (CBO NAIRU gap)\",\n",
    "                     fontweight=\"bold\", fontsize=14, y=0.995)\n",
    "\n",
    "        ax = axes[0]\n",
    "        for ch, cs, ce in CHAIR_DATES:\n",
    "            color = chair_colors_map.get(ch, \"#e5e7eb\")\n",
    "            ax.axvspan(cs, ce, color=color, alpha=0.5)\n",
    "            mid = cs + (ce - cs)/2\n",
    "            if df.index[0] <= mid <= df.index[-1]:\n",
    "                ax.text(mid, 0.5, ch, ha=\"center\", va=\"center\", fontsize=8, fontstyle=\"italic\")\n",
    "        ax.set_yticks([]); ax.set_title(\"Fed chair tenures\", fontweight=\"bold\", fontsize=10)\n",
    "\n",
    "        ax = axes[1]\n",
    "        ax.plot(first_break[\"dates\"], first_break[\"f_stats\"], lw=2, color=C1)\n",
    "        ax.axhline(first_break[\"cv\"][\"5%\"], color=C2, ls=\"--\", lw=1.5,\n",
    "                    label=f'5% critical value ({first_break[\"cv\"][\"5%\"]:.1f})')\n",
    "        ax.axhline(first_break[\"cv\"][\"1%\"], color=C2, ls=\":\", lw=1,\n",
    "                    label=f'1% critical value ({first_break[\"cv\"][\"1%\"]:.1f})')\n",
    "        for brk in breaks:\n",
    "            ax.axvline(brk[\"best_date\"], color=C3, ls=\"-\", lw=2, alpha=0.7)\n",
    "            ax.text(brk[\"best_date\"], ax.get_ylim()[1]*0.9,\n",
    "                    f' {brk[\"best_date\"]:%Y-%m}', fontsize=9, color=C3, fontweight=\"bold\")\n",
    "        for ch, cs, ce in CHAIR_DATES:\n",
    "            if first_break[\"dates\"][0] <= cs <= first_break[\"dates\"][-1]:\n",
    "                ax.axvline(cs, color=\"#9ca3af\", ls=\"--\", lw=1, alpha=0.5)\n",
    "        ax.set_ylabel(\"F-statistic\")\n",
    "        ax.set_title(\"Sup-Wald F-statistic (testing every possible break date)\", fontweight=\"bold\")\n",
    "        ax.legend(frameon=True, fontsize=8)\n",
    "\n",
    "        ax = axes[2]; shade_recessions(ax)\n",
    "        test_df = df[[\"delta_ff\"]].dropna()\n",
    "        ax.plot(test_df.index, test_df[\"delta_ff\"], lw=1, color=\"#374151\", alpha=0.7)\n",
    "        for brk in breaks:\n",
    "            ax.axvline(brk[\"best_date\"], color=C3, ls=\"-\", lw=2, alpha=0.7)\n",
    "        ax.axhline(0, color=\"grey\", lw=0.8)\n",
    "        ax.set_ylabel(\"Monthly change (pp)\")\n",
    "        ax.set_title(\"Fed funds rate changes (dependent variable)\", fontweight=\"bold\")\n",
    "        ax.set_xlabel(\"Year\")\n",
    "\n",
    "        fig.tight_layout()\n",
    "        path1 = f\"{output_path}/structural_breaks.png\"\n",
    "        fig.savefig(path1, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "        print(f\"  Saved: {path1}\")\n",
    "    else:\n",
    "        path1 = None\n",
    "\n",
    "    # ── Fig 2: Term spread around regime transitions ──\n",
    "    if transitions:\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(16, 8), sharex=True)\n",
    "        fig.suptitle(\"Yield Curve Behaviour Around Inflation Regime Transitions\",\n",
    "                     fontweight=\"bold\", fontsize=14, y=0.995)\n",
    "\n",
    "        ax = axes[0]; shade_recessions(ax)\n",
    "        ax.plot(regime_df.index, regime_df[\"term_spread\"], lw=1.5, color=C1)\n",
    "        ax.axhline(0, color=C2, ls=\"--\", lw=1.5, alpha=0.7, label=\"Inversion threshold\")\n",
    "        for tr in transitions:\n",
    "            color = C2 if tr[\"direction\"] == \"up\" else C5\n",
    "            ax.axvline(tr[\"date\"], color=color, ls=\"-\", lw=2, alpha=0.7)\n",
    "        ax.set_ylabel(\"Term spread (pp)\")\n",
    "        ax.set_title(\"10Y-FFR spread with regime transition dates\", fontweight=\"bold\")\n",
    "        legend_elements = [\n",
    "            Line2D([0],[0], color=C2, ls=\"-\", lw=2, label=\"Transition to high inflation\"),\n",
    "            Line2D([0],[0], color=C5, ls=\"-\", lw=2, label=\"Transition to low inflation\"),\n",
    "            Line2D([0],[0], color=C2, ls=\"--\", lw=1.5, label=\"Inversion threshold\"),\n",
    "        ]\n",
    "        ax.legend(handles=legend_elements, frameon=True, fontsize=8)\n",
    "\n",
    "        ax = axes[1]\n",
    "        for r in range(n_regimes):\n",
    "            mask = regime_df[\"regime\"] == r\n",
    "            for d in regime_df.index[mask]:\n",
    "                ax.axvspan(d, d + pd.DateOffset(months=1), color=regime_colors[r], alpha=0.8)\n",
    "        ax.set_yticks([]); ax.set_xlabel(\"Year\")\n",
    "        ax.set_title(\"Inflation regime\", fontweight=\"bold\")\n",
    "        legend_elements = [Patch(facecolor=regime_colors[r], alpha=0.8, label=regime_names[r])\n",
    "                           for r in range(n_regimes)]\n",
    "        ax.legend(handles=legend_elements, frameon=True, fontsize=7, loc=\"upper left\")\n",
    "\n",
    "        fig.tight_layout()\n",
    "        path2 = f\"{output_path}/yield_curve_regimes.png\"\n",
    "        fig.savefig(path2, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "        print(f\"  Saved: {path2}\")\n",
    "    else:\n",
    "        path2 = None\n",
    "\n",
    "    return [p for p in [path1, path2] if p]\n",
    "\n",
    "\n",
    "# ── Main ───────────────────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Loading data...\")\n",
    "    data = load_data(DATA_PATH)\n",
    "    df = engineer_features(data)\n",
    "\n",
    "    print(\"Fitting regimes...\")\n",
    "    regime_df, regime_names, n_regimes = get_regimes(df, n_regimes=2)\n",
    "    print(f\"  {n_regimes} regimes: {regime_names}\")\n",
    "\n",
    "    breaks, segments = sequential_breaks(\n",
    "        regime_df, dep=\"delta_ff\", regressors=[\"inflation\",\"unemp_gap\"],\n",
    "        max_breaks=3, min_frac=0.15)\n",
    "\n",
    "    transitions = yield_curve_regime_analysis(regime_df, regime_names, n_regimes)\n",
    "    loro_results = leave_one_recession_out(df)\n",
    "\n",
    "    paths = plot_results(df, regime_df, regime_names, n_regimes,\n",
    "                         breaks, transitions, OUTPUT_PATH)\n",
    "\n",
    "    print(f\"\\nOutputs: {paths}\")\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f78c107e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Merged: 857 obs (1954-07 to 2025-12)\n",
      "Fitting regimes...\n",
      "  2 regimes: {0: 'Low inflation (2.4%)', 1: 'High inflation (7.4%)'}\n",
      "\n",
      "======================================================================\n",
      "REGIME-AWARE INFLATION FORECASTING (CBO NAIRU gap)\n",
      "======================================================================\n",
      "\n",
      "  === 1-month horizon (652 obs) ===\n",
      "\n",
      "  Model                           MSE       MAE        R2\n",
      "  -----------------------------------------------------\n",
      "  AR (lags only)                0.450     0.459    +0.616\n",
      "  Pooled Ridge                  0.568     0.560    +0.432\n",
      "  Ridge + regime                0.499     0.516    +0.542\n",
      "  Ridge + regime prob           0.490     0.511    +0.551\n",
      "  Regime-conditional            0.518     0.512    +0.609\n",
      "  RF pooled                     0.638     0.557    +0.511\n",
      "\n",
      "  === 3-month horizon (650 obs) ===\n",
      "\n",
      "  Model                           MSE       MAE        R2\n",
      "  -----------------------------------------------------\n",
      "  AR (lags only)                1.075     0.710    +0.041\n",
      "  Pooled Ridge                  1.353     0.885    -0.534\n",
      "  Ridge + regime                1.194     0.806    -0.259\n",
      "  Ridge + regime prob           1.152     0.793    -0.228\n",
      "  Regime-conditional            1.218     0.771    +0.029\n",
      "  RF pooled                     1.546     0.906    -0.428\n",
      "\n",
      "  === 6-month horizon (647 obs) ===\n",
      "\n",
      "  Model                           MSE       MAE        R2\n",
      "  -----------------------------------------------------\n",
      "  AR (lags only)                1.993     1.046    -2.228\n",
      "  Pooled Ridge                  2.668     1.318    -4.980\n",
      "  Ridge + regime                2.374     1.213    -3.987\n",
      "  Ridge + regime prob           2.276     1.190    -3.839\n",
      "  Regime-conditional            2.460     1.138    -2.776\n",
      "  RF pooled                     3.398     1.352    -3.247\n",
      "\n",
      "  === 12-month horizon (641 obs) ===\n",
      "\n",
      "  Model                           MSE       MAE        R2\n",
      "  -----------------------------------------------------\n",
      "  AR (lags only)                4.528     1.688   -13.441\n",
      "  Pooled Ridge                  6.213     2.064   -26.964\n",
      "  Ridge + regime                5.632     1.904   -21.588\n",
      "  Ridge + regime prob           5.441     1.872   -20.733\n",
      "  Regime-conditional            6.235     1.936   -14.299\n",
      "  RF pooled                     8.695     2.357   -25.873\n",
      "\n",
      "======================================================================\n",
      "SUBSAMPLE STABILITY: WHY 12-MONTH FORECASTING FAILS\n",
      "======================================================================\n",
      "\n",
      "  Inflation autocorrelation by regime:\n",
      "  Regime                       AC(1)    AC(3)    AC(6)   AC(12)\n",
      "  ------------------------------------------------------------\n",
      "  R0 (n=622)                   0.950    0.792    0.598    0.283\n",
      "  R1 (n=211)                   0.987    0.934    0.816    0.505\n",
      "  Full sample                  0.990    0.955    0.893    0.731\n",
      "\n",
      "  Period                         N   Var(pi)     AR R2   Ridge R2\n",
      "  ------------------------------------------------------------\n",
      "  Volcker disinflation          84      7.45    -0.485     -6.414\n",
      "  Great Moderation I           156      1.27    -4.002     -8.370\n",
      "  Great Moderation II           96      1.10    -2.219     -2.583\n",
      "  Post-GFC                     144      1.14    -3.538     -2.768\n",
      "  COVID+                        37      4.72    -1.814     -3.386\n",
      "  Saved: /Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/forecast_regime_comparison.png\n",
      "  Saved: /Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/forecast_regime_improvement.png\n",
      "  Saved: /Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/forecast_subsample_stability.png\n",
      "\n",
      "Outputs: ['/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/forecast_regime_comparison.png', '/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/forecast_regime_improvement.png', '/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/forecast_subsample_stability.png']\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Component 4: Regime-Aware Inflation Forecasting\n",
    "================================================\n",
    "Updated: uses CBO NAIRU-based unemployment gap throughout.\n",
    "Removed synthetic data fallback.\n",
    "\"\"\"\n",
    "\n",
    "import os, warnings, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SEED = 42; random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "DATA_PATH = '/Users/leoss/Desktop/Portfolio/Website-/Central bank/data'\n",
    "OUTPUT_PATH = '/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs'\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "C1, C2, C3, C4, C5 = \"#2563eb\", \"#dc2626\", \"#7c3aed\", \"#f59e0b\", \"#10b981\"\n",
    "C_BG = \"#fafafa\"\n",
    "plt.rcParams.update({\n",
    "    \"figure.facecolor\": C_BG, \"axes.facecolor\": C_BG,\n",
    "    \"axes.grid\": True, \"grid.color\": \"#e5e7eb\", \"grid.linewidth\": 0.5,\n",
    "    \"font.size\": 11, \"axes.spines.top\": False, \"axes.spines.right\": False,\n",
    "})\n",
    "\n",
    "RECESSIONS = [\n",
    "    (\"1973-11\",\"1975-03\"),(\"1980-01\",\"1980-07\"),(\"1981-07\",\"1982-11\"),\n",
    "    (\"1990-07\",\"1991-03\"),(\"2001-03\",\"2001-11\"),(\"2007-12\",\"2009-06\"),(\"2020-02\",\"2020-04\"),\n",
    "]\n",
    "\n",
    "def shade_recessions(ax):\n",
    "    for s, e in RECESSIONS:\n",
    "        ax.axvspan(pd.Timestamp(s), pd.Timestamp(e), alpha=0.10, color=\"#fca5a5\", zorder=0)\n",
    "\n",
    "\n",
    "def load_data(path=DATA_PATH):\n",
    "    def _read(names):\n",
    "        for n in names:\n",
    "            p = os.path.join(path, n)\n",
    "            if os.path.exists(p):\n",
    "                return pd.read_csv(p, parse_dates=[\"observation_date\"],\n",
    "                                   index_col=\"observation_date\")\n",
    "        raise FileNotFoundError(f\"None of {names} found in {path}\")\n",
    "\n",
    "    cpi = _read([\"CPIAUCSL.csv\"])\n",
    "    unrate = _read([\"UNRATE.csv\"])\n",
    "    ff = _read([\"FEDFUNDS.csv\", \"FEDFUNDS-1.csv\"])\n",
    "    tcu = _read([\"TCU.csv\"])\n",
    "    gs10 = _read([\"GS10.csv\"])\n",
    "    nfci_w = _read([\"NFCI.csv\"]); nfci = nfci_w.resample(\"MS\").last()\n",
    "    nrou_q = _read([\"NROU.csv\", \"NROUST.csv\"])\n",
    "    nrou_q.index = pd.DatetimeIndex(nrou_q.index)\n",
    "    nrou_m = nrou_q.resample(\"MS\").interpolate(method=\"linear\")\n",
    "    try:\n",
    "        mich = _read([\"MICH.csv\"])\n",
    "    except FileNotFoundError:\n",
    "        mich = None\n",
    "\n",
    "    merged = pd.concat([\n",
    "        cpi.rename(columns={cpi.columns[0]: \"cpi\"}),\n",
    "        unrate.rename(columns={unrate.columns[0]: \"unemployment\"}),\n",
    "        ff.rename(columns={ff.columns[0]: \"fed_funds\"}),\n",
    "        tcu.rename(columns={tcu.columns[0]: \"capacity_util\"}),\n",
    "        gs10.rename(columns={gs10.columns[0]: \"treasury_10y\"}),\n",
    "        nfci.rename(columns={nfci.columns[0]: \"fin_conditions\"}),\n",
    "        nrou_m.rename(columns={nrou_m.columns[0]: \"nrou\"}),\n",
    "    ], axis=1).dropna(subset=[\"cpi\", \"unemployment\", \"fed_funds\", \"nrou\"])\n",
    "\n",
    "    if mich is not None:\n",
    "        merged = merged.join(\n",
    "            mich.rename(columns={mich.columns[0]: \"expected_inflation\"}), how=\"left\")\n",
    "    else:\n",
    "        merged[\"expected_inflation\"] = np.nan\n",
    "    print(f\"Merged: {len(merged)} obs ({merged.index.min():%Y-%m} to {merged.index.max():%Y-%m})\")\n",
    "    return merged\n",
    "\n",
    "\n",
    "def engineer_features(data):\n",
    "    df = data.copy()\n",
    "    df[\"inflation\"] = df[\"cpi\"].pct_change(12) * 100\n",
    "    df[\"unemp_gap\"] = df[\"unemployment\"] - df[\"nrou\"]\n",
    "    df[\"capacity_gap\"] = df[\"capacity_util\"] - 100.0\n",
    "    df[\"term_spread\"] = df[\"treasury_10y\"] - df[\"fed_funds\"]\n",
    "    df[\"real_rate\"] = df[\"fed_funds\"] - df[\"inflation\"]\n",
    "    df[\"delta_ff\"] = df[\"fed_funds\"].diff()\n",
    "    df[\"ff_lag1\"] = df[\"fed_funds\"].shift(1)\n",
    "    df[\"adaptive_pi_e\"] = df[\"inflation\"].rolling(12).mean()\n",
    "    df[\"pi_expected\"] = df[\"expected_inflation\"].fillna(df[\"adaptive_pi_e\"])\n",
    "    for var in [\"inflation\",\"unemp_gap\",\"capacity_gap\",\"fed_funds\",\"term_spread\",\"fin_conditions\"]:\n",
    "        for lag in [1,3,6,12]:\n",
    "            df[f\"L{lag}_{var}\"] = df[var].shift(lag)\n",
    "    for h in [1,3,6,12]:\n",
    "        df[f\"inflation_{h}m_ahead\"] = df[\"inflation\"].shift(-h)\n",
    "    df[\"recession\"] = 0\n",
    "    for start, end in RECESSIONS:\n",
    "        df.loc[(df.index >= start) & (df.index <= end), \"recession\"] = 1\n",
    "    df = df.dropna(subset=[\"inflation\",\"L12_inflation\"])\n",
    "    df.index = pd.DatetimeIndex(df.index)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_regimes(df, n_regimes=2):\n",
    "    endog = df[\"inflation\"].copy()\n",
    "    exog = sm.add_constant(df[[\"unemployment\"]].copy())\n",
    "    mod = sm.tsa.MarkovRegression(endog, k_regimes=n_regimes, exog=exog,\n",
    "        switching_variance=True, switching_exog=True)\n",
    "    best_res, best_llf = None, -np.inf\n",
    "    for attempt in range(8):\n",
    "        try:\n",
    "            res = mod.fit(search_reps=30, random_state=SEED+attempt, disp=False, maxiter=500)\n",
    "            if res.llf > best_llf: best_llf = res.llf; best_res = res\n",
    "        except: continue\n",
    "    smoothed = best_res.smoothed_marginal_probabilities\n",
    "    regime_means = {}\n",
    "    for r in range(n_regimes):\n",
    "        mask = smoothed[r] > 0.5\n",
    "        regime_means[r] = df.loc[mask, \"inflation\"].mean() if mask.sum() > 0 else 0.0\n",
    "    sorted_regimes = sorted(regime_means, key=regime_means.get)\n",
    "    rdf = df.copy()\n",
    "    for new_r in range(n_regimes):\n",
    "        rdf[f\"p_regime_{new_r}\"] = smoothed[sorted_regimes[new_r]].values\n",
    "    rdf[\"regime\"] = np.argmax(\n",
    "        np.column_stack([rdf[f\"p_regime_{r}\"].values for r in range(n_regimes)]), axis=1)\n",
    "    sorted_means = [regime_means[sorted_regimes[r]] for r in range(n_regimes)]\n",
    "    labels = [\"Low\",\"High\"] if n_regimes==2 else [f\"R{r}\" for r in range(n_regimes)]\n",
    "    regime_names = {r: f\"{labels[r]} inflation ({sorted_means[r]:.1f}%)\" for r in range(n_regimes)}\n",
    "    return rdf, regime_names, n_regimes\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# FORECASTING\n",
    "# ================================================================\n",
    "\n",
    "BASE_FEATURES = [\"L1_inflation\",\"L3_inflation\",\"L6_inflation\",\"L12_inflation\"]\n",
    "EXTENDED_FEATURES = BASE_FEATURES + [\n",
    "    \"L1_fed_funds\",\"L3_fed_funds\",\"L6_fed_funds\",\n",
    "    \"L6_unemp_gap\",\"L6_term_spread\",\"L6_fin_conditions\"\n",
    "]\n",
    "\n",
    "CV_FOLDS = [\n",
    "    {\"train_end\":\"1990-12\",\"test_start\":\"1991-01\",\"test_end\":\"1995-12\",\"name\":\"Early 1990s\"},\n",
    "    {\"train_end\":\"1995-12\",\"test_start\":\"1996-01\",\"test_end\":\"2000-12\",\"name\":\"Late 1990s\"},\n",
    "    {\"train_end\":\"2000-12\",\"test_start\":\"2001-01\",\"test_end\":\"2007-12\",\"name\":\"2000s\"},\n",
    "    {\"train_end\":\"2007-12\",\"test_start\":\"2008-01\",\"test_end\":\"2015-12\",\"name\":\"GFC & after\"},\n",
    "    {\"train_end\":\"2015-12\",\"test_start\":\"2016-01\",\"test_end\":\"2023-01\",\"name\":\"Recent\"},\n",
    "]\n",
    "\n",
    "HORIZONS = [1, 3, 6, 12]\n",
    "\n",
    "\n",
    "def run_forecasting(regime_df, regime_names, n_regimes):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"REGIME-AWARE INFLATION FORECASTING (CBO NAIRU gap)\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    base_f = [f for f in BASE_FEATURES if f in regime_df.columns]\n",
    "    ext_f = [f for f in EXTENDED_FEATURES if f in regime_df.columns]\n",
    "\n",
    "    all_results = {}\n",
    "\n",
    "    for h in HORIZONS:\n",
    "        target = f\"inflation_{h}m_ahead\"\n",
    "        if target not in regime_df.columns:\n",
    "            regime_df[target] = regime_df[\"inflation\"].shift(-h)\n",
    "\n",
    "        fc_df = regime_df[ext_f + [target, \"regime\"] +\n",
    "                          [f\"p_regime_{r}\" for r in range(n_regimes)]].dropna()\n",
    "\n",
    "        print(f\"\\n  === {h}-month horizon ({len(fc_df)} obs) ===\")\n",
    "\n",
    "        models = {\n",
    "            \"AR (lags only)\": {\"features\": base_f, \"regime_aware\": False,\n",
    "                \"fn\": lambda: Ridge(alpha=1.0)},\n",
    "            \"Pooled Ridge\": {\"features\": ext_f, \"regime_aware\": False,\n",
    "                \"fn\": lambda: Ridge(alpha=10.0)},\n",
    "            \"Ridge + regime\": {\"features\": ext_f + [\"regime\"], \"regime_aware\": False,\n",
    "                \"fn\": lambda: Ridge(alpha=10.0)},\n",
    "            \"Ridge + regime prob\": {\"features\": ext_f + [f\"p_regime_{r}\" for r in range(n_regimes)],\n",
    "                \"regime_aware\": False, \"fn\": lambda: Ridge(alpha=10.0)},\n",
    "            \"Regime-conditional\": {\"features\": ext_f, \"regime_aware\": True,\n",
    "                \"fn\": lambda: Ridge(alpha=10.0)},\n",
    "            \"RF pooled\": {\"features\": ext_f, \"regime_aware\": False,\n",
    "                \"fn\": lambda: RandomForestRegressor(n_estimators=200, max_depth=6,\n",
    "                    min_samples_leaf=10, random_state=SEED)},\n",
    "        }\n",
    "\n",
    "        horizon_results = {}\n",
    "\n",
    "        for mname, spec in models.items():\n",
    "            fold_results = []\n",
    "\n",
    "            for fold in CV_FOLDS:\n",
    "                tr = fc_df.loc[:fold[\"train_end\"]]\n",
    "                te = fc_df.loc[fold[\"test_start\"]:fold[\"test_end\"]]\n",
    "                if len(te) < 6 or len(tr) < 30:\n",
    "                    continue\n",
    "\n",
    "                feats = [f for f in spec[\"features\"] if f in fc_df.columns]\n",
    "\n",
    "                if spec[\"regime_aware\"]:\n",
    "                    preds = np.full(len(te), np.nan)\n",
    "                    for r in range(n_regimes):\n",
    "                        tr_r = tr[tr[\"regime\"] == r]\n",
    "                        te_r_mask = te[\"regime\"] == r\n",
    "                        if te_r_mask.sum() == 0:\n",
    "                            continue\n",
    "                        if len(tr_r) < 15:\n",
    "                            sc = StandardScaler()\n",
    "                            Xtr = sc.fit_transform(tr[feats])\n",
    "                            Xte = sc.transform(te.loc[te_r_mask, feats])\n",
    "                            m = spec[\"fn\"](); m.fit(Xtr, tr[target].values)\n",
    "                            preds[te_r_mask.values] = m.predict(Xte)\n",
    "                            continue\n",
    "                        sc = StandardScaler()\n",
    "                        Xtr = sc.fit_transform(tr_r[feats])\n",
    "                        Xte = sc.transform(te.loc[te_r_mask, feats])\n",
    "                        m = spec[\"fn\"](); m.fit(Xtr, tr_r[target].values)\n",
    "                        preds[te_r_mask.values] = m.predict(Xte)\n",
    "\n",
    "                    valid = ~np.isnan(preds)\n",
    "                    if valid.sum() < 6: continue\n",
    "                    mse = mean_squared_error(te[target].values[valid], preds[valid])\n",
    "                    r2 = r2_score(te[target].values[valid], preds[valid])\n",
    "                    mae = mean_absolute_error(te[target].values[valid], preds[valid])\n",
    "                else:\n",
    "                    sc = StandardScaler()\n",
    "                    Xtr = sc.fit_transform(tr[feats])\n",
    "                    Xte = sc.transform(te[feats])\n",
    "                    m = spec[\"fn\"](); m.fit(Xtr, tr[target].values)\n",
    "                    preds = m.predict(Xte)\n",
    "                    mse = mean_squared_error(te[target].values, preds)\n",
    "                    r2 = r2_score(te[target].values, preds)\n",
    "                    mae = mean_absolute_error(te[target].values, preds)\n",
    "\n",
    "                fold_results.append({\"mse\": mse, \"r2\": r2, \"mae\": mae, \"fold\": fold[\"name\"]})\n",
    "\n",
    "            if fold_results:\n",
    "                horizon_results[mname] = {\n",
    "                    \"avg_mse\": np.mean([f[\"mse\"] for f in fold_results]),\n",
    "                    \"avg_r2\": np.mean([f[\"r2\"] for f in fold_results]),\n",
    "                    \"avg_mae\": np.mean([f[\"mae\"] for f in fold_results]),\n",
    "                    \"folds\": fold_results\n",
    "                }\n",
    "\n",
    "        print(f\"\\n  {'Model':<25s}  {'MSE':>8s}  {'MAE':>8s}  {'R2':>8s}\")\n",
    "        print(f\"  {'-'*53}\")\n",
    "        for mname in models:\n",
    "            if mname in horizon_results:\n",
    "                r = horizon_results[mname]\n",
    "                print(f\"  {mname:<25s}  {r['avg_mse']:>8.3f}  {r['avg_mae']:>8.3f}  {r['avg_r2']:>+8.3f}\")\n",
    "\n",
    "        all_results[h] = horizon_results\n",
    "\n",
    "    return all_results\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# SUBSAMPLE STABILITY\n",
    "# ================================================================\n",
    "def subsample_stability(regime_df):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"SUBSAMPLE STABILITY: WHY 12-MONTH FORECASTING FAILS\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    print(f\"\\n  Inflation autocorrelation by regime:\")\n",
    "    print(f\"  {'Regime':<25s}\", end=\"\")\n",
    "    for lag in [1, 3, 6, 12]:\n",
    "        print(f\"  {'AC('+str(lag)+')':>7s}\", end=\"\")\n",
    "    print()\n",
    "    print(f\"  {'-'*60}\")\n",
    "\n",
    "    for r in sorted(regime_df[\"regime\"].unique()):\n",
    "        sub = regime_df[regime_df[\"regime\"] == r][\"inflation\"]\n",
    "        print(f\"  {'R'+str(r)+' (n='+str(len(sub))+')' :<25s}\", end=\"\")\n",
    "        for lag in [1, 3, 6, 12]:\n",
    "            ac = sub.autocorr(lag=lag)\n",
    "            print(f\"  {ac:>7.3f}\", end=\"\")\n",
    "        print()\n",
    "\n",
    "    full = regime_df[\"inflation\"]\n",
    "    print(f\"  {'Full sample':<25s}\", end=\"\")\n",
    "    for lag in [1, 3, 6, 12]:\n",
    "        print(f\"  {full.autocorr(lag=lag):>7.3f}\", end=\"\")\n",
    "    print()\n",
    "\n",
    "    ext_f = [f for f in EXTENDED_FEATURES if f in regime_df.columns]\n",
    "    target = \"inflation_12m_ahead\"\n",
    "    if target not in regime_df.columns:\n",
    "        regime_df[target] = regime_df[\"inflation\"].shift(-12)\n",
    "    fc_df = regime_df[ext_f + [target]].dropna()\n",
    "\n",
    "    periods = [\n",
    "        (\"Pre-Volcker\", \"1973-01\", \"1979-12\"),\n",
    "        (\"Volcker disinflation\", \"1980-01\", \"1986-12\"),\n",
    "        (\"Great Moderation I\", \"1987-01\", \"1999-12\"),\n",
    "        (\"Great Moderation II\", \"2000-01\", \"2007-12\"),\n",
    "        (\"Post-GFC\", \"2008-01\", \"2019-12\"),\n",
    "        (\"COVID+\", \"2020-01\", \"2023-01\"),\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n  {'Period':<25s}  {'N':>5s}  {'Var(pi)':>8s}  {'AR R2':>8s}  {'Ridge R2':>9s}\")\n",
    "    print(f\"  {'-'*60}\")\n",
    "\n",
    "    period_results = []\n",
    "    for pname, ps, pe in periods:\n",
    "        tr = fc_df.loc[:ps]; te = fc_df.loc[ps:pe]\n",
    "        if len(tr) < 30 or len(te) < 6: continue\n",
    "        var_pi = te[target].var()\n",
    "\n",
    "        base_f = [f for f in BASE_FEATURES if f in fc_df.columns]\n",
    "        sc = StandardScaler()\n",
    "        Xtr = sc.fit_transform(tr[base_f]); Xte = sc.transform(te[base_f])\n",
    "        m_ar = Ridge(alpha=1.0); m_ar.fit(Xtr, tr[target].values)\n",
    "        r2_ar = r2_score(te[target].values, m_ar.predict(Xte))\n",
    "\n",
    "        sc2 = StandardScaler()\n",
    "        Xtr2 = sc2.fit_transform(tr[ext_f]); Xte2 = sc2.transform(te[ext_f])\n",
    "        m_ridge = Ridge(alpha=10.0); m_ridge.fit(Xtr2, tr[target].values)\n",
    "        r2_ridge = r2_score(te[target].values, m_ridge.predict(Xte2))\n",
    "\n",
    "        period_results.append({\"period\": pname, \"n\": len(te), \"var_pi\": var_pi,\n",
    "                               \"r2_ar\": r2_ar, \"r2_ridge\": r2_ridge})\n",
    "        print(f\"  {pname:<25s}  {len(te):>5d}  {var_pi:>8.2f}  {r2_ar:>+8.3f}  {r2_ridge:>+9.3f}\")\n",
    "\n",
    "    return period_results\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# VISUALIZATION\n",
    "# ================================================================\n",
    "def plot_results(all_results, period_results, output_path):\n",
    "    model_colors = {\"AR (lags only)\": \"#6b7280\", \"Pooled Ridge\": C1,\n",
    "                    \"Ridge + regime\": C3, \"Ridge + regime prob\": C4,\n",
    "                    \"Regime-conditional\": C2, \"RF pooled\": C5}\n",
    "\n",
    "    # ── Fig 1: MSE and R2 by horizon ──\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    fig.suptitle(\"Inflation Forecasting: Does Regime Awareness Help?\",\n",
    "                 fontweight=\"bold\", fontsize=14, y=1.02)\n",
    "\n",
    "    model_names = list(all_results[HORIZONS[0]].keys())\n",
    "    x = np.arange(len(HORIZONS)); w = 0.8 / len(model_names)\n",
    "\n",
    "    for i, mname in enumerate(model_names):\n",
    "        mses = [all_results[h].get(mname, {}).get(\"avg_mse\", np.nan) for h in HORIZONS]\n",
    "        color = model_colors.get(mname, f\"C{i}\")\n",
    "        axes[0].bar(x + i*w, mses, w, label=mname, color=color, alpha=0.75,\n",
    "                    edgecolor=\"white\", lw=1)\n",
    "    axes[0].set_xticks(x + w*(len(model_names)-1)/2)\n",
    "    axes[0].set_xticklabels([f\"{h}m\" for h in HORIZONS])\n",
    "    axes[0].set_ylabel(\"Test MSE (lower = better)\")\n",
    "    axes[0].set_title(\"Forecast MSE by horizon\", fontweight=\"bold\")\n",
    "    axes[0].legend(frameon=True, fontsize=7)\n",
    "\n",
    "    for i, mname in enumerate(model_names):\n",
    "        r2s = [all_results[h].get(mname, {}).get(\"avg_r2\", np.nan) for h in HORIZONS]\n",
    "        color = model_colors.get(mname, f\"C{i}\")\n",
    "        axes[1].bar(x + i*w, r2s, w, label=mname, color=color, alpha=0.75,\n",
    "                    edgecolor=\"white\", lw=1)\n",
    "    axes[1].set_xticks(x + w*(len(model_names)-1)/2)\n",
    "    axes[1].set_xticklabels([f\"{h}m\" for h in HORIZONS])\n",
    "    axes[1].set_ylabel(\"Test R2\"); axes[1].axhline(0, color=\"grey\", lw=1, alpha=0.5)\n",
    "    axes[1].set_title(\"Forecast R2 by horizon\", fontweight=\"bold\")\n",
    "    axes[1].legend(frameon=True, fontsize=7)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    path1 = f\"{output_path}/forecast_regime_comparison.png\"\n",
    "    fig.savefig(path1, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "    print(f\"  Saved: {path1}\")\n",
    "\n",
    "    # ── Fig 2: Regime improvement ──\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    fig.suptitle(\"Regime Awareness: Improvement Over Pooled Ridge\",\n",
    "                 fontweight=\"bold\", fontsize=14, y=1.02)\n",
    "\n",
    "    regime_models = [\"Ridge + regime\", \"Ridge + regime prob\", \"Regime-conditional\"]\n",
    "    x = np.arange(len(HORIZONS)); w = 0.8 / len(regime_models)\n",
    "    for i, mname in enumerate(regime_models):\n",
    "        deltas = []\n",
    "        for h in HORIZONS:\n",
    "            pooled = all_results[h].get(\"Pooled Ridge\", {}).get(\"avg_mse\", np.nan)\n",
    "            regime = all_results[h].get(mname, {}).get(\"avg_mse\", np.nan)\n",
    "            delta_pct = (regime - pooled) / pooled * 100 if pooled > 0 else np.nan\n",
    "            deltas.append(delta_pct)\n",
    "        color = model_colors.get(mname, f\"C{i}\")\n",
    "        ax.bar(x + i*w, deltas, w, label=mname, color=color, alpha=0.75,\n",
    "               edgecolor=\"white\", lw=1)\n",
    "    ax.set_xticks(x + w*(len(regime_models)-1)/2)\n",
    "    ax.set_xticklabels([f\"{h}m\" for h in HORIZONS])\n",
    "    ax.axhline(0, color=\"grey\", lw=1.5)\n",
    "    ax.set_ylabel(\"% change in MSE vs Pooled Ridge (negative = better)\")\n",
    "    ax.set_title(\"Does conditioning on regimes reduce forecast error?\", fontweight=\"bold\")\n",
    "    ax.legend(frameon=True, fontsize=9)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    path2 = f\"{output_path}/forecast_regime_improvement.png\"\n",
    "    fig.savefig(path2, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "    print(f\"  Saved: {path2}\")\n",
    "\n",
    "    # ── Fig 3: Subsample stability ──\n",
    "    if period_results:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        fig.suptitle(\"Why 12-Month Inflation Forecasting Fails: Subsample Analysis\",\n",
    "                     fontweight=\"bold\", fontsize=14, y=1.02)\n",
    "\n",
    "        pnames = [p[\"period\"] for p in period_results]\n",
    "        r2_ars = [p[\"r2_ar\"] for p in period_results]\n",
    "        r2_ridges = [p[\"r2_ridge\"] for p in period_results]\n",
    "        var_pis = [p[\"var_pi\"] for p in period_results]\n",
    "\n",
    "        ax = axes[0]\n",
    "        ax.scatter(var_pis, r2_ridges, s=80, color=C1, zorder=3, edgecolors=\"white\", lw=1)\n",
    "        for p, vp, r2 in zip(pnames, var_pis, r2_ridges):\n",
    "            ax.annotate(p, (vp, r2), fontsize=8, textcoords=\"offset points\", xytext=(5, 5))\n",
    "        ax.axhline(0, color=\"grey\", ls=\"--\", lw=1)\n",
    "        ax.set_xlabel(\"Inflation variance in test period\")\n",
    "        ax.set_ylabel(\"12-month forecast R2\")\n",
    "        ax.set_title(\"Forecast quality vs inflation variability\", fontweight=\"bold\")\n",
    "\n",
    "        ax = axes[1]\n",
    "        x_p = np.arange(len(pnames))\n",
    "        ax.bar(x_p - 0.2, r2_ars, 0.35, label=\"AR\", color=\"#6b7280\", alpha=0.75, edgecolor=\"white\")\n",
    "        ax.bar(x_p + 0.2, r2_ridges, 0.35, label=\"Ridge\", color=C1, alpha=0.75, edgecolor=\"white\")\n",
    "        ax.set_xticks(x_p); ax.set_xticklabels(pnames, rotation=30, ha=\"right\", fontsize=9)\n",
    "        ax.axhline(0, color=\"grey\", ls=\"--\", lw=1)\n",
    "        ax.set_ylabel(\"12-month forecast R2\")\n",
    "        ax.set_title(\"R2 by test period\", fontweight=\"bold\")\n",
    "        ax.legend(frameon=True, fontsize=9)\n",
    "\n",
    "        fig.tight_layout()\n",
    "        path3 = f\"{output_path}/forecast_subsample_stability.png\"\n",
    "        fig.savefig(path3, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "        print(f\"  Saved: {path3}\")\n",
    "    else:\n",
    "        path3 = None\n",
    "\n",
    "    return [p for p in [path1, path2, path3] if p]\n",
    "\n",
    "\n",
    "# ── Main ───────────────────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Loading data...\")\n",
    "    data = load_data(DATA_PATH)\n",
    "    df = engineer_features(data)\n",
    "\n",
    "    print(\"Fitting regimes...\")\n",
    "    regime_df, regime_names, n_regimes = get_regimes(df, n_regimes=2)\n",
    "    print(f\"  {n_regimes} regimes: {regime_names}\")\n",
    "\n",
    "    all_results = run_forecasting(regime_df, regime_names, n_regimes)\n",
    "    period_results = subsample_stability(regime_df)\n",
    "    paths = plot_results(all_results, period_results, OUTPUT_PATH)\n",
    "\n",
    "    print(f\"\\nOutputs: {paths}\")\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05b54261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "  No commodity price series found (PPIACO.csv etc), proceeding without\n",
      "Merged: 857 obs (1954-07 to 2025-12)\n",
      "Fitting regimes...\n",
      "  2 regimes: {0: 'Low inflation (2.4%)', 1: 'High inflation (7.4%)'}\n",
      "Identifying monetary policy shocks...\n",
      "\n",
      "======================================================================\n",
      "IDENTIFYING MONETARY POLICY SHOCKS\n",
      "  Rich conditioning set (6 lags, commodity prices)\n",
      "======================================================================\n",
      "  No commodity prices available, using macro variables only\n",
      "\n",
      "  N = 701, R2 = 0.340, adj-R2 = 0.310\n",
      "  Number of regressors: 30 + constant\n",
      "\n",
      "  Key coefficients (first lag only):\n",
      "  Variable                       Coef        SE         t\n",
      "  -----------------------------------------------------\n",
      "  L1_inflation                -0.0074    0.0440     -0.17\n",
      "  L1_unemp_gap                 0.0511    0.0753      0.68\n",
      "  L1_fed_funds                 0.7957    0.1338      5.95\n",
      "  L1_term_spread               0.5078    0.1995      2.55\n",
      "  L1_capacity_gap              0.0999    0.0584      1.71\n",
      "\n",
      "  Shock stats: mean=0.0000, sd=0.4199\n",
      "  Correlation with delta_ff: 0.813\n",
      "  Correlation with inflation: 0.007\n",
      "  Correlation with unemp_gap: -0.014\n",
      "Running state-dependent local projections...\n",
      "\n",
      "======================================================================\n",
      "STATE-DEPENDENT LOCAL PROJECTIONS\n",
      "  Shock variable: mp_shock\n",
      "  Max horizon: 48 months, 6 control lags\n",
      "======================================================================\n",
      "\n",
      "  --- Response: Inflation (pp) ---\n",
      "   Horizon   IRF(High)     SE(H)    IRF(Low)     SE(L)      Diff      N\n",
      "  -----------------------------------------------------------------\n",
      "         1      0.1051    0.0527      0.3402    0.1613   -0.2351    700\n",
      "         3      0.2805    0.0909      0.2968    0.1696   -0.0163    698\n",
      "         6      0.3051    0.1219      0.3708    0.2128   -0.0657    695\n",
      "        12      0.4137    0.1645      1.2788    0.4047   -0.8651    689\n",
      "        24     -0.0374    0.1777      0.7449    0.5587   -0.7823    677\n",
      "        36     -0.4429    0.1281     -0.1585    0.5665   -0.2843    665\n",
      "        48     -0.5469    0.2268      0.2383    0.4080   -0.7852    653\n",
      "\n",
      "  --- Response: Unemployment (pp) ---\n",
      "   Horizon   IRF(High)     SE(H)    IRF(Low)     SE(L)      Diff      N\n",
      "  -----------------------------------------------------------------\n",
      "         1     -0.0370    0.0235     -0.8144    0.6255   +0.7774    700\n",
      "         3     -0.0584    0.0464     -0.5842    0.3519   +0.5258    698\n",
      "         6      0.0170    0.0643     -0.8085    0.3259   +0.8255    695\n",
      "        12      0.1448    0.0886     -0.6589    0.3390   +0.8038    689\n",
      "        24      0.3034    0.1172     -0.2508    0.4048   +0.5542    677\n",
      "        36      0.2163    0.0841      0.4276    0.2776   -0.2113    665\n",
      "        48      0.0639    0.0769      0.8085    0.4316   -0.7446    653\n",
      "\n",
      "  --- Response: Fed funds rate (pp) ---\n",
      "   Horizon   IRF(High)     SE(H)    IRF(Low)     SE(L)      Diff      N\n",
      "  -----------------------------------------------------------------\n",
      "         1      1.3327    0.1002      1.4660    0.0645   -0.1333    700\n",
      "         3      1.0093    0.1539      1.7530    0.1802   -0.7436    698\n",
      "         6      0.4639    0.2142      2.0076    0.3064   -1.5437    695\n",
      "        12      0.2956    0.2970      1.8178    0.4932   -1.5222    689\n",
      "        24     -0.2508    0.2906      0.7040    0.6349   -0.9548    677\n",
      "        36     -0.7106    0.2251     -0.3332    0.3954   -0.3774    665\n",
      "        48     -0.9057    0.1683     -0.4982    0.3853   -0.4075    653\n",
      "\n",
      "  --- Response: Capacity utilisation (pp) ---\n",
      "   Horizon   IRF(High)     SE(H)    IRF(Low)     SE(L)      Diff      N\n",
      "  -----------------------------------------------------------------\n",
      "         1      0.2058    0.0712      0.9203    0.7073   -0.7145    700\n",
      "         3      0.1952    0.1626      0.7132    0.4507   -0.5180    698\n",
      "         6     -0.2065    0.2217      1.1111    0.5558   -1.3176    695\n",
      "        12     -0.5015    0.2392      1.1217    1.0058   -1.6232    689\n",
      "        24     -1.0288    0.3683     -0.1990    1.1020   -0.8298    677\n",
      "        36     -0.4421    0.2699     -1.2176    0.6202   +0.7755    665\n",
      "        48      0.0692    0.2471     -1.5036    0.9157   +1.5728    653\n",
      "Running linear local projections (baseline)...\n",
      "\n",
      "======================================================================\n",
      "LINEAR LOCAL PROJECTIONS (no regime interaction)\n",
      "======================================================================\n",
      "Plotting...\n",
      "  Saved: /Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/lp_irfs_by_regime.png\n",
      "  Saved: /Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/lp_irfs_regime_difference.png\n",
      "  Saved: /Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/lp_irfs_linear_vs_regime.png\n",
      "\n",
      "Outputs: ['/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/lp_irfs_by_regime.png', '/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/lp_irfs_regime_difference.png', '/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/lp_irfs_linear_vs_regime.png']\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Component 5: State-Dependent Local Projections\n",
    "================================================\n",
    "Jordà (2005) local projections with smooth regime interaction\n",
    "following Auerbach & Gorodnichenko (2012).\n",
    "\n",
    "Revision notes:\n",
    "- Shock identification uses rich conditioning set (6 lags of inflation,\n",
    "  unemp_gap, fed_funds, term_spread, capacity_gap, plus commodity price\n",
    "  inflation if available) to purge predictable policy movements.\n",
    "- Commodity price inflation partially addresses the price puzzle.\n",
    "- LP controls match the shock conditioning set (Plagborg-Møller & Wolf 2021).\n",
    "\"\"\"\n",
    "\n",
    "import os, warnings, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "import statsmodels.api as sm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SEED = 42; random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "DATA_PATH = '/Users/leoss/Desktop/Portfolio/Website-/Central bank/data'\n",
    "OUTPUT_PATH = '/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs'\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "C1, C2, C3, C4, C5 = \"#2563eb\", \"#dc2626\", \"#7c3aed\", \"#f59e0b\", \"#10b981\"\n",
    "C_BG = \"#fafafa\"\n",
    "plt.rcParams.update({\n",
    "    \"figure.facecolor\": C_BG, \"axes.facecolor\": C_BG,\n",
    "    \"axes.grid\": True, \"grid.color\": \"#e5e7eb\", \"grid.linewidth\": 0.5,\n",
    "    \"font.size\": 11, \"axes.spines.top\": False, \"axes.spines.right\": False,\n",
    "})\n",
    "\n",
    "RECESSIONS = [\n",
    "    (\"1973-11\",\"1975-03\"),(\"1980-01\",\"1980-07\"),(\"1981-07\",\"1982-11\"),\n",
    "    (\"1990-07\",\"1991-03\"),(\"2001-03\",\"2001-11\"),(\"2007-12\",\"2009-06\"),(\"2020-02\",\"2020-04\"),\n",
    "]\n",
    "\n",
    "\n",
    "def shade_recessions(ax):\n",
    "    for s, e in RECESSIONS:\n",
    "        ax.axvspan(pd.Timestamp(s), pd.Timestamp(e), alpha=0.10, color=\"#fca5a5\", zorder=0)\n",
    "\n",
    "\n",
    "def load_data(path=DATA_PATH):\n",
    "    def _read(names):\n",
    "        for n in names:\n",
    "            p = os.path.join(path, n)\n",
    "            if os.path.exists(p):\n",
    "                return pd.read_csv(p, parse_dates=[\"observation_date\"],\n",
    "                                   index_col=\"observation_date\")\n",
    "        raise FileNotFoundError(f\"None of {names} found in {path}\")\n",
    "\n",
    "    cpi = _read([\"CPIAUCSL.csv\"])\n",
    "    unrate = _read([\"UNRATE.csv\"])\n",
    "    ff = _read([\"FEDFUNDS.csv\", \"FEDFUNDS-1.csv\"])\n",
    "    tcu = _read([\"TCU.csv\"])\n",
    "    gs10 = _read([\"GS10.csv\"])\n",
    "    nfci_w = _read([\"NFCI.csv\"]); nfci = nfci_w.resample(\"MS\").last()\n",
    "    nrou_q = _read([\"NROU.csv\", \"NROUST.csv\"])\n",
    "    nrou_q.index = pd.DatetimeIndex(nrou_q.index)\n",
    "    nrou_m = nrou_q.resample(\"MS\").interpolate(method=\"linear\")\n",
    "    try:\n",
    "        mich = _read([\"MICH.csv\"])\n",
    "    except FileNotFoundError:\n",
    "        mich = None\n",
    "\n",
    "    # Commodity prices (PPI all commodities or similar)\n",
    "    ppi = None\n",
    "    for name in [\"PPIACO.csv\", \"PPIFGS.csv\", \"PPIITM.csv\"]:\n",
    "        p = os.path.join(path, name)\n",
    "        if os.path.exists(p):\n",
    "            ppi = pd.read_csv(p, parse_dates=[\"observation_date\"],\n",
    "                              index_col=\"observation_date\")\n",
    "            print(f\"  Loaded commodity prices from {name}\")\n",
    "            break\n",
    "    if ppi is None:\n",
    "        print(\"  No commodity price series found (PPIACO.csv etc), proceeding without\")\n",
    "\n",
    "    merged = pd.concat([\n",
    "        cpi.rename(columns={cpi.columns[0]: \"cpi\"}),\n",
    "        unrate.rename(columns={unrate.columns[0]: \"unemployment\"}),\n",
    "        ff.rename(columns={ff.columns[0]: \"fed_funds\"}),\n",
    "        tcu.rename(columns={tcu.columns[0]: \"capacity_util\"}),\n",
    "        gs10.rename(columns={gs10.columns[0]: \"treasury_10y\"}),\n",
    "        nfci.rename(columns={nfci.columns[0]: \"fin_conditions\"}),\n",
    "        nrou_m.rename(columns={nrou_m.columns[0]: \"nrou\"}),\n",
    "    ], axis=1).dropna(subset=[\"cpi\", \"unemployment\", \"fed_funds\", \"nrou\"])\n",
    "\n",
    "    if mich is not None:\n",
    "        merged = merged.join(\n",
    "            mich.rename(columns={mich.columns[0]: \"expected_inflation\"}), how=\"left\")\n",
    "    else:\n",
    "        merged[\"expected_inflation\"] = np.nan\n",
    "\n",
    "    if ppi is not None:\n",
    "        merged = merged.join(\n",
    "            ppi.rename(columns={ppi.columns[0]: \"ppi_commodities\"}), how=\"left\")\n",
    "    else:\n",
    "        merged[\"ppi_commodities\"] = np.nan\n",
    "\n",
    "    print(f\"Merged: {len(merged)} obs ({merged.index.min():%Y-%m} to {merged.index.max():%Y-%m})\")\n",
    "    return merged\n",
    "\n",
    "\n",
    "def engineer_features(data):\n",
    "    df = data.copy()\n",
    "    df[\"inflation\"] = df[\"cpi\"].pct_change(12) * 100\n",
    "    df[\"unemp_gap\"] = df[\"unemployment\"] - df[\"nrou\"]\n",
    "    df[\"capacity_gap\"] = df[\"capacity_util\"] - 100.0\n",
    "    df[\"term_spread\"] = df[\"treasury_10y\"] - df[\"fed_funds\"]\n",
    "    df[\"real_rate\"] = df[\"fed_funds\"] - df[\"inflation\"]\n",
    "    df[\"delta_ff\"] = df[\"fed_funds\"].diff()\n",
    "    df[\"delta_pi\"] = df[\"inflation\"].diff()\n",
    "    df[\"delta_u\"] = df[\"unemployment\"].diff()\n",
    "    df[\"ff_lag1\"] = df[\"fed_funds\"].shift(1)\n",
    "    df[\"adaptive_pi_e\"] = df[\"inflation\"].rolling(12).mean()\n",
    "    df[\"pi_expected\"] = df[\"expected_inflation\"].fillna(df[\"adaptive_pi_e\"])\n",
    "\n",
    "    # Commodity price inflation (12-month)\n",
    "    if \"ppi_commodities\" in df.columns and df[\"ppi_commodities\"].notna().sum() > 24:\n",
    "        df[\"commodity_inflation\"] = df[\"ppi_commodities\"].pct_change(12) * 100\n",
    "    else:\n",
    "        df[\"commodity_inflation\"] = np.nan\n",
    "\n",
    "    for var in [\"inflation\", \"unemp_gap\", \"capacity_gap\", \"fed_funds\",\n",
    "                \"term_spread\", \"fin_conditions\", \"commodity_inflation\"]:\n",
    "        for lag in [1, 2, 3, 4, 5, 6, 12]:\n",
    "            df[f\"L{lag}_{var}\"] = df[var].shift(lag)\n",
    "    for h in [1, 3, 6, 12]:\n",
    "        df[f\"inflation_{h}m_ahead\"] = df[\"inflation\"].shift(-h)\n",
    "    df[\"recession\"] = 0\n",
    "    for start, end in RECESSIONS:\n",
    "        df.loc[(df.index >= start) & (df.index <= end), \"recession\"] = 1\n",
    "    df = df.dropna(subset=[\"inflation\", \"L12_inflation\"])\n",
    "    df.index = pd.DatetimeIndex(df.index)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_regimes(df, n_regimes=2):\n",
    "    endog = df[\"inflation\"].copy()\n",
    "    exog = sm.add_constant(df[[\"unemployment\"]].copy())\n",
    "    mod = sm.tsa.MarkovRegression(endog, k_regimes=n_regimes, exog=exog,\n",
    "        switching_variance=True, switching_exog=True)\n",
    "    best_res, best_llf = None, -np.inf\n",
    "    for attempt in range(8):\n",
    "        try:\n",
    "            res = mod.fit(search_reps=30, random_state=SEED+attempt, disp=False, maxiter=500)\n",
    "            if res.llf > best_llf:\n",
    "                best_llf = res.llf; best_res = res\n",
    "        except:\n",
    "            continue\n",
    "    smoothed = best_res.smoothed_marginal_probabilities\n",
    "    regime_means = {}\n",
    "    for r in range(n_regimes):\n",
    "        mask = smoothed[r] > 0.5\n",
    "        regime_means[r] = df.loc[mask, \"inflation\"].mean() if mask.sum() > 0 else 0.0\n",
    "    sorted_regimes = sorted(regime_means, key=regime_means.get)\n",
    "    rdf = df.copy()\n",
    "    for new_r in range(n_regimes):\n",
    "        rdf[f\"p_regime_{new_r}\"] = smoothed[sorted_regimes[new_r]].values\n",
    "    rdf[\"regime\"] = np.argmax(\n",
    "        np.column_stack([rdf[f\"p_regime_{r}\"].values for r in range(n_regimes)]), axis=1)\n",
    "    sorted_means = [regime_means[sorted_regimes[r]] for r in range(n_regimes)]\n",
    "    labels = [\"Low\", \"High\"] if n_regimes == 2 else [f\"R{r}\" for r in range(n_regimes)]\n",
    "    regime_names = {r: f\"{labels[r]} inflation ({sorted_means[r]:.1f}%)\" for r in range(n_regimes)}\n",
    "    return rdf, regime_names, n_regimes\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# MONETARY POLICY SHOCK IDENTIFICATION\n",
    "# ================================================================\n",
    "def identify_mp_shocks(df):\n",
    "    \"\"\"\n",
    "    Identify monetary policy shocks as residuals from a rich\n",
    "    Taylor-type reaction function.\n",
    "\n",
    "    Conditioning set: 6 lags of inflation, unemp_gap, fed_funds,\n",
    "    term_spread, capacity_gap, plus commodity price inflation\n",
    "    (if available). This is closer to the Fed's actual information\n",
    "    set and partially addresses the price puzzle by controlling for\n",
    "    cost-push shocks that both raise inflation and trigger rate hikes.\n",
    "\n",
    "    References: Romer & Romer (2004), Coibion (2012), Ramey (2016)\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"IDENTIFYING MONETARY POLICY SHOCKS\")\n",
    "    print(f\"  Rich conditioning set (6 lags, commodity prices)\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    # Build conditioning set\n",
    "    base_vars = [\"inflation\", \"unemp_gap\", \"fed_funds\", \"term_spread\", \"capacity_gap\"]\n",
    "    has_commodities = df[\"commodity_inflation\"].notna().sum() > 100\n",
    "\n",
    "    control_cols = []\n",
    "    for var in base_vars:\n",
    "        for lag in [1, 2, 3, 4, 5, 6]:\n",
    "            col = f\"L{lag}_{var}\"\n",
    "            if col in df.columns:\n",
    "                control_cols.append(col)\n",
    "\n",
    "    if has_commodities:\n",
    "        for lag in [1, 2, 3, 4, 5, 6]:\n",
    "            col = f\"L{lag}_commodity_inflation\"\n",
    "            if col in df.columns:\n",
    "                control_cols.append(col)\n",
    "        print(f\"  Including commodity price inflation (6 lags)\")\n",
    "    else:\n",
    "        print(f\"  No commodity prices available, using macro variables only\")\n",
    "\n",
    "    dep = df[\"delta_ff\"].copy()\n",
    "    controls = df[control_cols].copy()\n",
    "    valid = dep.notna() & controls.notna().all(axis=1)\n",
    "    dep = dep[valid]; controls = controls[valid]\n",
    "\n",
    "    X = sm.add_constant(controls.values)\n",
    "    model = sm.OLS(dep.values, X).fit(cov_type=\"HAC\", cov_kwds={\"maxlags\": 12})\n",
    "\n",
    "    print(f\"\\n  N = {model.nobs:.0f}, R2 = {model.rsquared:.3f}, adj-R2 = {model.rsquared_adj:.3f}\")\n",
    "    print(f\"  Number of regressors: {len(control_cols)} + constant\")\n",
    "\n",
    "    # Print key coefficients (first lag of each variable)\n",
    "    print(f\"\\n  Key coefficients (first lag only):\")\n",
    "    print(f\"  {'Variable':<25s}  {'Coef':>8s}  {'SE':>8s}  {'t':>8s}\")\n",
    "    print(f\"  {'-'*53}\")\n",
    "    param_names = [\"const\"] + control_cols\n",
    "    for var in base_vars + ([\"commodity_inflation\"] if has_commodities else []):\n",
    "        col = f\"L1_{var}\"\n",
    "        if col in param_names:\n",
    "            idx = param_names.index(col)\n",
    "            print(f\"  {col:<25s}  {model.params[idx]:>8.4f}  {model.bse[idx]:>8.4f}  {model.tvalues[idx]:>8.2f}\")\n",
    "\n",
    "    # Store shocks\n",
    "    shock = pd.Series(np.nan, index=df.index)\n",
    "    shock[valid] = model.resid\n",
    "    df = df.copy()\n",
    "    df[\"mp_shock\"] = shock\n",
    "\n",
    "    # Standardise shock for interpretability (1 SD = 1 unit)\n",
    "    shock_std = shock.std()\n",
    "    df[\"mp_shock_std\"] = shock / shock_std\n",
    "\n",
    "    print(f\"\\n  Shock stats: mean={shock.mean():.4f}, sd={shock.std():.4f}\")\n",
    "    print(f\"  Correlation with delta_ff: {shock.corr(dep):.3f}\")\n",
    "\n",
    "    # Diagnostic: does the shock still have the price puzzle?\n",
    "    shock_valid = df[\"mp_shock\"].dropna()\n",
    "    corr_pi = shock_valid.corr(df.loc[shock_valid.index, \"inflation\"])\n",
    "    corr_u = shock_valid.corr(df.loc[shock_valid.index, \"unemp_gap\"])\n",
    "    print(f\"  Correlation with inflation: {corr_pi:.3f}\")\n",
    "    print(f\"  Correlation with unemp_gap: {corr_u:.3f}\")\n",
    "\n",
    "    return df, model\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# LOCAL PROJECTIONS\n",
    "# ================================================================\n",
    "def local_projections(df, shock_col=\"mp_shock\", max_horizon=48, n_lags=6):\n",
    "    \"\"\"\n",
    "    Jordà (2005) local projections with Auerbach-Gorodnichenko (2012)\n",
    "    smooth regime interaction.\n",
    "\n",
    "    Controls in the LP match the shock conditioning set\n",
    "    (Plagborg-Møller & Wolf 2021).\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"STATE-DEPENDENT LOCAL PROJECTIONS\")\n",
    "    print(f\"  Shock variable: {shock_col}\")\n",
    "    print(f\"  Max horizon: {max_horizon} months, {n_lags} control lags\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    response_vars = [\"inflation\", \"unemployment\", \"fed_funds\", \"capacity_util\"]\n",
    "    response_labels = [\"Inflation (pp)\", \"Unemployment (pp)\",\n",
    "                       \"Fed funds rate (pp)\", \"Capacity utilisation (pp)\"]\n",
    "\n",
    "    F_t = df[\"p_regime_1\"].values\n",
    "    shock = df[shock_col].values\n",
    "\n",
    "    # Control variables matching the shock conditioning set\n",
    "    control_cols = []\n",
    "    for var in [\"inflation\", \"unemployment\", \"fed_funds\", \"term_spread\", \"capacity_gap\"]:\n",
    "        for lag in range(1, n_lags + 1):\n",
    "            col = f\"_lp_L{lag}_{var}\"\n",
    "            df[col] = df[var].shift(lag)\n",
    "            control_cols.append(col)\n",
    "\n",
    "    if df[\"commodity_inflation\"].notna().sum() > 100:\n",
    "        for lag in range(1, n_lags + 1):\n",
    "            col = f\"_lp_L{lag}_commodity_inflation\"\n",
    "            df[col] = df[\"commodity_inflation\"].shift(lag)\n",
    "            control_cols.append(col)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for var, label in zip(response_vars, response_labels):\n",
    "        print(f\"\\n  --- Response: {label} ---\")\n",
    "        irf_high = np.full(max_horizon + 1, np.nan)\n",
    "        irf_low = np.full(max_horizon + 1, np.nan)\n",
    "        se_high = np.full(max_horizon + 1, np.nan)\n",
    "        se_low = np.full(max_horizon + 1, np.nan)\n",
    "        n_obs = np.full(max_horizon + 1, 0)\n",
    "\n",
    "        irf_high[0] = 0.0; irf_low[0] = 0.0\n",
    "        se_high[0] = 0.0; se_low[0] = 0.0\n",
    "\n",
    "        for h in range(1, max_horizon + 1):\n",
    "            y_ahead = df[var].shift(-h)\n",
    "            y_base = df[var].shift(1)\n",
    "            dep = y_ahead - y_base\n",
    "\n",
    "            reg_df = pd.DataFrame({\n",
    "                \"dep\": dep,\n",
    "                \"shock_H\": shock * F_t,\n",
    "                \"shock_L\": shock * (1 - F_t),\n",
    "            }, index=df.index)\n",
    "\n",
    "            for cc in control_cols:\n",
    "                vals = df[cc].values if cc in df.columns else np.full(len(df), np.nan)\n",
    "                reg_df[f\"{cc}_H\"] = vals * F_t\n",
    "                reg_df[f\"{cc}_L\"] = vals * (1 - F_t)\n",
    "\n",
    "            reg_df = reg_df.dropna()\n",
    "            if len(reg_df) < 80:\n",
    "                continue\n",
    "\n",
    "            exog_cols = [\"shock_H\", \"shock_L\"]\n",
    "            exog_cols += [c for c in reg_df.columns if c.startswith(\"_lp_L\") and c.endswith(\"_H\")]\n",
    "            exog_cols += [c for c in reg_df.columns if c.startswith(\"_lp_L\") and c.endswith(\"_L\")]\n",
    "\n",
    "            X = sm.add_constant(reg_df[exog_cols].values)\n",
    "            y = reg_df[\"dep\"].values\n",
    "\n",
    "            try:\n",
    "                model = sm.OLS(y, X).fit(\n",
    "                    cov_type=\"HAC\",\n",
    "                    cov_kwds={\"maxlags\": max(h + 1, 12)}\n",
    "                )\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            irf_high[h] = model.params[1]\n",
    "            irf_low[h] = model.params[2]\n",
    "            se_high[h] = model.bse[1]\n",
    "            se_low[h] = model.bse[2]\n",
    "            n_obs[h] = int(model.nobs)\n",
    "\n",
    "        print(f\"  {'Horizon':>8s}  {'IRF(High)':>10s}  {'SE(H)':>8s}  {'IRF(Low)':>10s}  \"\n",
    "              f\"{'SE(L)':>8s}  {'Diff':>8s}  {'N':>5s}\")\n",
    "        print(f\"  {'-'*65}\")\n",
    "        for h in [1, 3, 6, 12, 24, 36, 48]:\n",
    "            if h <= max_horizon and not np.isnan(irf_high[h]):\n",
    "                diff = irf_high[h] - irf_low[h]\n",
    "                print(f\"  {h:>8d}  {irf_high[h]:>10.4f}  {se_high[h]:>8.4f}  \"\n",
    "                      f\"{irf_low[h]:>10.4f}  {se_low[h]:>8.4f}  {diff:>+8.4f}  {n_obs[h]:>5d}\")\n",
    "\n",
    "        results[var] = {\n",
    "            \"label\": label,\n",
    "            \"irf_high\": irf_high, \"irf_low\": irf_low,\n",
    "            \"se_high\": se_high, \"se_low\": se_low,\n",
    "            \"n_obs\": n_obs,\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# LINEAR LOCAL PROJECTIONS (BASELINE)\n",
    "# ================================================================\n",
    "def linear_local_projections(df, shock_col=\"mp_shock\", max_horizon=48, n_lags=6):\n",
    "    \"\"\"Standard (non-regime-dependent) local projections for comparison.\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"LINEAR LOCAL PROJECTIONS (no regime interaction)\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    response_vars = [\"inflation\", \"unemployment\", \"fed_funds\", \"capacity_util\"]\n",
    "    response_labels = [\"Inflation (pp)\", \"Unemployment (pp)\",\n",
    "                       \"Fed funds rate (pp)\", \"Capacity utilisation (pp)\"]\n",
    "\n",
    "    shock = df[shock_col].values\n",
    "\n",
    "    control_cols = []\n",
    "    for var in [\"inflation\", \"unemployment\", \"fed_funds\", \"term_spread\", \"capacity_gap\"]:\n",
    "        for lag in range(1, n_lags + 1):\n",
    "            col = f\"_lp_L{lag}_{var}\"\n",
    "            if col not in df.columns:\n",
    "                df[col] = df[var].shift(lag)\n",
    "            control_cols.append(col)\n",
    "    if df[\"commodity_inflation\"].notna().sum() > 100:\n",
    "        for lag in range(1, n_lags + 1):\n",
    "            col = f\"_lp_L{lag}_commodity_inflation\"\n",
    "            if col not in df.columns:\n",
    "                df[col] = df[\"commodity_inflation\"].shift(lag)\n",
    "            control_cols.append(col)\n",
    "\n",
    "    results = {}\n",
    "    for var, label in zip(response_vars, response_labels):\n",
    "        irf = np.full(max_horizon + 1, np.nan)\n",
    "        se = np.full(max_horizon + 1, np.nan)\n",
    "        irf[0] = 0.0; se[0] = 0.0\n",
    "\n",
    "        for h in range(1, max_horizon + 1):\n",
    "            y_ahead = df[var].shift(-h)\n",
    "            y_base = df[var].shift(1)\n",
    "            dep = y_ahead - y_base\n",
    "\n",
    "            reg_df = pd.DataFrame({\"dep\": dep, \"shock\": shock}, index=df.index)\n",
    "            for cc in control_cols:\n",
    "                reg_df[cc] = df[cc].values if cc in df.columns else np.nan\n",
    "            reg_df = reg_df.dropna()\n",
    "            if len(reg_df) < 80:\n",
    "                continue\n",
    "\n",
    "            exog_cols = [\"shock\"] + control_cols\n",
    "            X = sm.add_constant(reg_df[exog_cols].values)\n",
    "            y = reg_df[\"dep\"].values\n",
    "\n",
    "            try:\n",
    "                model = sm.OLS(y, X).fit(\n",
    "                    cov_type=\"HAC\", cov_kwds={\"maxlags\": max(h + 1, 12)})\n",
    "                irf[h] = model.params[1]\n",
    "                se[h] = model.bse[1]\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        results[var] = {\"label\": label, \"irf\": irf, \"se\": se}\n",
    "    return results\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# VISUALIZATION\n",
    "# ================================================================\n",
    "def plot_irfs(regime_results, linear_results, output_path):\n",
    "    response_vars = [\"inflation\", \"unemployment\", \"fed_funds\", \"capacity_util\"]\n",
    "\n",
    "    # ── Fig 1: Main IRF comparison (regime-dependent) ──\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    fig.suptitle(\"Impulse Responses to a Monetary Policy Shock by Inflation Regime\\n\"\n",
    "                 \"(Jordà local projections, Newey-West HAC, 90% CI)\",\n",
    "                 fontweight=\"bold\", fontsize=13, y=1.02)\n",
    "\n",
    "    for ax, var in zip(axes.flat, response_vars):\n",
    "        res = regime_results[var]\n",
    "        horizons = np.arange(len(res[\"irf_high\"]))\n",
    "\n",
    "        h_irf = res[\"irf_high\"]; h_se = res[\"se_high\"]\n",
    "        valid_h = ~np.isnan(h_irf)\n",
    "        ax.plot(horizons[valid_h], h_irf[valid_h], lw=2, color=C2,\n",
    "                label=\"High inflation regime\")\n",
    "        ax.fill_between(horizons[valid_h],\n",
    "                        (h_irf - 1.65 * h_se)[valid_h],\n",
    "                        (h_irf + 1.65 * h_se)[valid_h],\n",
    "                        alpha=0.15, color=C2)\n",
    "\n",
    "        l_irf = res[\"irf_low\"]; l_se = res[\"se_low\"]\n",
    "        valid_l = ~np.isnan(l_irf)\n",
    "        ax.plot(horizons[valid_l], l_irf[valid_l], lw=2, color=C1,\n",
    "                label=\"Low inflation regime\")\n",
    "        ax.fill_between(horizons[valid_l],\n",
    "                        (l_irf - 1.65 * l_se)[valid_l],\n",
    "                        (l_irf + 1.65 * l_se)[valid_l],\n",
    "                        alpha=0.15, color=C1)\n",
    "\n",
    "        ax.axhline(0, color=\"grey\", lw=1, ls=\"--\")\n",
    "        ax.set_xlabel(\"Months after shock\")\n",
    "        ax.set_ylabel(res[\"label\"])\n",
    "        ax.set_title(res[\"label\"], fontweight=\"bold\")\n",
    "        ax.legend(frameon=True, fontsize=8)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    path1 = f\"{output_path}/lp_irfs_by_regime.png\"\n",
    "    fig.savefig(path1, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "    print(f\"  Saved: {path1}\")\n",
    "\n",
    "    # ── Fig 2: Regime difference ──\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    fig.suptitle(\"Difference in Impulse Responses: High vs Low Inflation Regime\\n\"\n",
    "                 \"(positive = stronger response in high-inflation regime)\",\n",
    "                 fontweight=\"bold\", fontsize=13, y=1.02)\n",
    "\n",
    "    for ax, var in zip(axes.flat, response_vars):\n",
    "        res = regime_results[var]\n",
    "        horizons = np.arange(len(res[\"irf_high\"]))\n",
    "        diff = res[\"irf_high\"] - res[\"irf_low\"]\n",
    "        se_diff = np.sqrt(res[\"se_high\"]**2 + res[\"se_low\"]**2)\n",
    "\n",
    "        valid = ~np.isnan(diff)\n",
    "        ax.plot(horizons[valid], diff[valid], lw=2, color=C3)\n",
    "        ax.fill_between(horizons[valid],\n",
    "                        (diff - 1.65 * se_diff)[valid],\n",
    "                        (diff + 1.65 * se_diff)[valid],\n",
    "                        alpha=0.2, color=C3)\n",
    "        ax.axhline(0, color=\"grey\", lw=1.5, ls=\"--\")\n",
    "        ax.set_xlabel(\"Months after shock\")\n",
    "        ax.set_ylabel(\"Difference (pp)\")\n",
    "        ax.set_title(res[\"label\"], fontweight=\"bold\")\n",
    "\n",
    "        sig = valid.copy()\n",
    "        sig[valid] = np.abs(diff[valid]) > 1.65 * se_diff[valid]\n",
    "        if sig.any():\n",
    "            for i in range(1, len(horizons)):\n",
    "                if sig[i]:\n",
    "                    ax.axvspan(horizons[i] - 0.5, horizons[i] + 0.5,\n",
    "                               alpha=0.08, color=C4, zorder=0)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    path2 = f\"{output_path}/lp_irfs_regime_difference.png\"\n",
    "    fig.savefig(path2, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "    print(f\"  Saved: {path2}\")\n",
    "\n",
    "    # ── Fig 3: Linear vs regime-dependent ──\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    fig.suptitle(\"Monetary Policy Transmission: Linear vs Regime-Dependent IRFs\",\n",
    "                 fontweight=\"bold\", fontsize=13, y=1.02)\n",
    "\n",
    "    for ax, var in zip(axes.flat, response_vars):\n",
    "        res_r = regime_results[var]\n",
    "        res_l = linear_results[var]\n",
    "        horizons = np.arange(len(res_r[\"irf_high\"]))\n",
    "\n",
    "        valid_lin = ~np.isnan(res_l[\"irf\"])\n",
    "        ax.plot(horizons[valid_lin], res_l[\"irf\"][valid_lin], lw=2, color=\"#6b7280\",\n",
    "                label=\"Linear (pooled)\", ls=\"--\")\n",
    "        ax.fill_between(horizons[valid_lin],\n",
    "                        (res_l[\"irf\"] - 1.65 * res_l[\"se\"])[valid_lin],\n",
    "                        (res_l[\"irf\"] + 1.65 * res_l[\"se\"])[valid_lin],\n",
    "                        alpha=0.1, color=\"#6b7280\")\n",
    "\n",
    "        valid_h = ~np.isnan(res_r[\"irf_high\"])\n",
    "        ax.plot(horizons[valid_h], res_r[\"irf_high\"][valid_h], lw=2, color=C2,\n",
    "                label=\"High inflation\")\n",
    "        valid_l = ~np.isnan(res_r[\"irf_low\"])\n",
    "        ax.plot(horizons[valid_l], res_r[\"irf_low\"][valid_l], lw=2, color=C1,\n",
    "                label=\"Low inflation\")\n",
    "\n",
    "        ax.axhline(0, color=\"grey\", lw=1, ls=\"--\")\n",
    "        ax.set_xlabel(\"Months after shock\")\n",
    "        ax.set_ylabel(res_r[\"label\"])\n",
    "        ax.set_title(res_r[\"label\"], fontweight=\"bold\")\n",
    "        ax.legend(frameon=True, fontsize=8)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    path3 = f\"{output_path}/lp_irfs_linear_vs_regime.png\"\n",
    "    fig.savefig(path3, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "    print(f\"  Saved: {path3}\")\n",
    "\n",
    "    return [path1, path2, path3]\n",
    "\n",
    "\n",
    "# ── Main ──\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Loading data...\")\n",
    "    data = load_data(DATA_PATH)\n",
    "    df = engineer_features(data)\n",
    "\n",
    "    print(\"Fitting regimes...\")\n",
    "    regime_df, regime_names, n_regimes = get_regimes(df, n_regimes=2)\n",
    "    print(f\"  {n_regimes} regimes: {regime_names}\")\n",
    "\n",
    "    print(\"Identifying monetary policy shocks...\")\n",
    "    regime_df, shock_model = identify_mp_shocks(regime_df)\n",
    "\n",
    "    print(\"Running state-dependent local projections...\")\n",
    "    regime_results = local_projections(regime_df, shock_col=\"mp_shock\", max_horizon=48)\n",
    "\n",
    "    print(\"Running linear local projections (baseline)...\")\n",
    "    linear_results = linear_local_projections(regime_df, shock_col=\"mp_shock\", max_horizon=48)\n",
    "\n",
    "    print(\"Plotting...\")\n",
    "    paths = plot_irfs(regime_results, linear_results, OUTPUT_PATH)\n",
    "\n",
    "    print(f\"\\nOutputs: {paths}\")\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a27d3e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Merged: 857 obs (1954-07 to 2025-12)\n",
      "Estimating Taylor rules...\n",
      "\n",
      "======================================================================\n",
      "TAYLOR RULE ESTIMATION FOR COUNTERFACTUALS\n",
      "======================================================================\n",
      "\n",
      "  Specification                 rho      r*    a_pi     a_u   1+a_pi         SSR\n",
      "  ---------------------------------------------------------------------------\n",
      "  Unconstrained NLS           0.974   1.945  -0.086  -1.609     0.91       191.4\n",
      "  Constrained (a_pi>=0.5)     0.982   1.240   0.500  -2.098     1.50       192.4\n",
      "  Textbook Taylor (1993)      0.000   2.000   0.500   0.500     1.50     11959.7\n",
      "\n",
      "  Note: unconstrained a_pi = -0.086 < 0.5, indicating the data\n",
      "  prefers a rule that barely responds to inflation. The constrained\n",
      "  version forces a minimum inflation response consistent with theory.\n",
      "Estimating VAR...\n",
      "\n",
      "======================================================================\n",
      "VAR ESTIMATION: ['inflation', 'unemployment', 'fed_funds'], 6 lags\n",
      "======================================================================\n",
      "\n",
      "  Lag selection:\n",
      "  Criterion    Lags\n",
      "  ------------------\n",
      "  AIC            11\n",
      "  BIC             2\n",
      "  HQIC            2\n",
      "\n",
      "  Using 2 lags\n",
      "  Observations: 843\n",
      "\n",
      "  inflation: R2 = 0.984\n",
      "\n",
      "  unemployment: R2 = 0.940\n",
      "\n",
      "  fed_funds: R2 = 0.985\n",
      "\n",
      "Running full-sample counterfactual (constrained rule)...\n",
      "  Mean actual ff: 4.69\n",
      "  Mean CF ff: 5.02\n",
      "  Mean actual inflation: 3.68\n",
      "  Mean CF inflation: 3.86\n",
      "\n",
      "Running full-sample counterfactual (textbook rule)...\n",
      "  Mean CF ff (textbook): 10.07\n",
      "  Mean CF inflation (textbook): 5.65\n",
      "\n",
      "======================================================================\n",
      "EPISODE COUNTERFACTUALS\n",
      "======================================================================\n",
      "\n",
      "  --- Burns accommodation (1971-78) ---\n",
      "                            Actual  constraine    textbook\n",
      "  -------------------------------------------------------\n",
      "        Fed funds (mean)      6.43        5.99        9.98\n",
      "        Inflation (mean)      6.61        4.57        5.87\n",
      "     Unemployment (mean)      6.45        6.19        6.49\n",
      "\n",
      "  --- Volcker tightening (1979-82) ---\n",
      "                            Actual  constraine    textbook\n",
      "  -------------------------------------------------------\n",
      "        Fed funds (mean)     12.45       10.19       13.88\n",
      "        Inflation (mean)      8.90        7.15        8.26\n",
      "     Unemployment (mean)      7.99        6.91        7.06\n",
      "\n",
      "  --- Greenspan era (1987-2000) ---\n",
      "                            Actual  constraine    textbook\n",
      "  -------------------------------------------------------\n",
      "        Fed funds (mean)      5.79        5.32        7.53\n",
      "        Inflation (mean)      3.28        3.53        4.20\n",
      "     Unemployment (mean)      5.61        5.90        6.00\n",
      "\n",
      "  --- Post-GFC ZLB (2009-15) ---\n",
      "                            Actual  constraine    textbook\n",
      "  -------------------------------------------------------\n",
      "        Fed funds (mean)      0.13        0.57        5.05\n",
      "        Inflation (mean)      1.39        1.19        2.50\n",
      "     Unemployment (mean)      7.81        5.44        5.60\n",
      "\n",
      "  --- COVID and after (2020-23) ---\n",
      "                            Actual  constraine    textbook\n",
      "  -------------------------------------------------------\n",
      "        Fed funds (mean)      1.29        2.51        7.06\n",
      "        Inflation (mean)      4.68        2.93        4.08\n",
      "     Unemployment (mean)      5.39        4.53        4.48\n",
      "\n",
      "Plotting...\n",
      "  Saved: /Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/counterfactual_full_sample.png\n",
      "  Saved: /Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/counterfactual_rule_comparison.png\n",
      "  Saved: /Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/counterfactual_episodes.png\n",
      "\n",
      "Outputs: ['/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/counterfactual_full_sample.png', '/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/counterfactual_rule_comparison.png', '/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/counterfactual_episodes.png']\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Component 6: Counterfactual Policy Simulation\n",
    "===============================================\n",
    "Estimates a reduced-form VAR on [inflation, unemployment, fed_funds],\n",
    "then simulates counterfactual paths under mechanical Taylor rule adherence.\n",
    "\n",
    "Revision notes:\n",
    "- Constrained NLS Taylor rule (a_pi >= 0.5) so the rule actually\n",
    "  responds to inflation, not just unemployment.\n",
    "- Additional \"textbook\" Taylor rule variant (r*=2, a_pi=0.5, a_u=0.5)\n",
    "  for a clean benchmark.\n",
    "- Both counterfactuals shown side by side.\n",
    "\"\"\"\n",
    "\n",
    "import os, warnings, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.api import VAR\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SEED = 42; random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "DATA_PATH = '/Users/leoss/Desktop/Portfolio/Website-/Central bank/data'\n",
    "OUTPUT_PATH = '/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs'\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "C1, C2, C3, C4, C5 = \"#2563eb\", \"#dc2626\", \"#7c3aed\", \"#f59e0b\", \"#10b981\"\n",
    "C_BG = \"#fafafa\"\n",
    "plt.rcParams.update({\n",
    "    \"figure.facecolor\": C_BG, \"axes.facecolor\": C_BG,\n",
    "    \"axes.grid\": True, \"grid.color\": \"#e5e7eb\", \"grid.linewidth\": 0.5,\n",
    "    \"font.size\": 11, \"axes.spines.top\": False, \"axes.spines.right\": False,\n",
    "})\n",
    "\n",
    "RECESSIONS = [\n",
    "    (\"1973-11\",\"1975-03\"),(\"1980-01\",\"1980-07\"),(\"1981-07\",\"1982-11\"),\n",
    "    (\"1990-07\",\"1991-03\"),(\"2001-03\",\"2001-11\"),(\"2007-12\",\"2009-06\"),(\"2020-02\",\"2020-04\"),\n",
    "]\n",
    "\n",
    "\n",
    "def shade_recessions(ax):\n",
    "    for s, e in RECESSIONS:\n",
    "        ax.axvspan(pd.Timestamp(s), pd.Timestamp(e), alpha=0.10, color=\"#fca5a5\", zorder=0)\n",
    "\n",
    "\n",
    "def load_data(path=DATA_PATH):\n",
    "    def _read(names):\n",
    "        for n in names:\n",
    "            p = os.path.join(path, n)\n",
    "            if os.path.exists(p):\n",
    "                return pd.read_csv(p, parse_dates=[\"observation_date\"],\n",
    "                                   index_col=\"observation_date\")\n",
    "        raise FileNotFoundError(f\"None of {names} found in {path}\")\n",
    "\n",
    "    cpi = _read([\"CPIAUCSL.csv\"])\n",
    "    unrate = _read([\"UNRATE.csv\"])\n",
    "    ff = _read([\"FEDFUNDS.csv\", \"FEDFUNDS-1.csv\"])\n",
    "    tcu = _read([\"TCU.csv\"])\n",
    "    gs10 = _read([\"GS10.csv\"])\n",
    "    nfci_w = _read([\"NFCI.csv\"]); nfci = nfci_w.resample(\"MS\").last()\n",
    "    nrou_q = _read([\"NROU.csv\", \"NROUST.csv\"])\n",
    "    nrou_q.index = pd.DatetimeIndex(nrou_q.index)\n",
    "    nrou_m = nrou_q.resample(\"MS\").interpolate(method=\"linear\")\n",
    "    try:\n",
    "        mich = _read([\"MICH.csv\"])\n",
    "    except FileNotFoundError:\n",
    "        mich = None\n",
    "\n",
    "    merged = pd.concat([\n",
    "        cpi.rename(columns={cpi.columns[0]: \"cpi\"}),\n",
    "        unrate.rename(columns={unrate.columns[0]: \"unemployment\"}),\n",
    "        ff.rename(columns={ff.columns[0]: \"fed_funds\"}),\n",
    "        tcu.rename(columns={tcu.columns[0]: \"capacity_util\"}),\n",
    "        gs10.rename(columns={gs10.columns[0]: \"treasury_10y\"}),\n",
    "        nfci.rename(columns={nfci.columns[0]: \"fin_conditions\"}),\n",
    "        nrou_m.rename(columns={nrou_m.columns[0]: \"nrou\"}),\n",
    "    ], axis=1).dropna(subset=[\"cpi\", \"unemployment\", \"fed_funds\", \"nrou\"])\n",
    "\n",
    "    if mich is not None:\n",
    "        merged = merged.join(\n",
    "            mich.rename(columns={mich.columns[0]: \"expected_inflation\"}), how=\"left\")\n",
    "    else:\n",
    "        merged[\"expected_inflation\"] = np.nan\n",
    "    print(f\"Merged: {len(merged)} obs ({merged.index.min():%Y-%m} to {merged.index.max():%Y-%m})\")\n",
    "    return merged\n",
    "\n",
    "\n",
    "def engineer_features(data):\n",
    "    df = data.copy()\n",
    "    df[\"inflation\"] = df[\"cpi\"].pct_change(12) * 100\n",
    "    df[\"unemp_gap\"] = df[\"unemployment\"] - df[\"nrou\"]\n",
    "    df[\"capacity_gap\"] = df[\"capacity_util\"] - 100.0\n",
    "    df[\"term_spread\"] = df[\"treasury_10y\"] - df[\"fed_funds\"]\n",
    "    df[\"real_rate\"] = df[\"fed_funds\"] - df[\"inflation\"]\n",
    "    df[\"delta_ff\"] = df[\"fed_funds\"].diff()\n",
    "    df[\"ff_lag1\"] = df[\"fed_funds\"].shift(1)\n",
    "    df[\"adaptive_pi_e\"] = df[\"inflation\"].rolling(12).mean()\n",
    "    df[\"pi_expected\"] = df[\"expected_inflation\"].fillna(df[\"adaptive_pi_e\"])\n",
    "    for var in [\"inflation\", \"unemp_gap\", \"capacity_gap\", \"fed_funds\", \"term_spread\", \"fin_conditions\"]:\n",
    "        for lag in [1, 3, 6, 12]:\n",
    "            df[f\"L{lag}_{var}\"] = df[var].shift(lag)\n",
    "    df[\"recession\"] = 0\n",
    "    for start, end in RECESSIONS:\n",
    "        df.loc[(df.index >= start) & (df.index <= end), \"recession\"] = 1\n",
    "    df = df.dropna(subset=[\"inflation\"])\n",
    "    df.index = pd.DatetimeIndex(df.index)\n",
    "    return df\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# TAYLOR RULE ESTIMATION\n",
    "# ================================================================\n",
    "def taylor_resid(params, y, pi, u_gap, ff_lag):\n",
    "    rho, r_star, a_pi, a_u = params\n",
    "    target = r_star + pi + a_pi * (pi - 2.0) + a_u * u_gap\n",
    "    return y - (rho * ff_lag + (1 - rho) * target)\n",
    "\n",
    "\n",
    "def estimate_taylor_rules(df):\n",
    "    \"\"\"\n",
    "    Estimate Taylor rules:\n",
    "    1. Constrained NLS (a_pi >= 0.5) so the rule actually responds to inflation\n",
    "    2. Textbook Taylor (1993) with fixed parameters\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"TAYLOR RULE ESTIMATION FOR COUNTERFACTUALS\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    sub = df[[\"fed_funds\", \"ff_lag1\", \"inflation\", \"unemp_gap\"]].dropna()\n",
    "    y = sub[\"fed_funds\"].values\n",
    "    pi = sub[\"inflation\"].values\n",
    "    u_gap = sub[\"unemp_gap\"].values\n",
    "    ff_lag = sub[\"ff_lag1\"].values\n",
    "\n",
    "    # 1. Unconstrained (for reference)\n",
    "    res_unc = least_squares(taylor_resid, [0.85, 2.0, 0.5, 0.5],\n",
    "        args=(y, pi, u_gap, ff_lag),\n",
    "        bounds=([0, -5, -2, -5], [0.999, 10, 5, 5]))\n",
    "    p_unc = res_unc.x\n",
    "\n",
    "    # 2. Constrained: a_pi >= 0.5 (lower bound on inflation response)\n",
    "    res_con = least_squares(taylor_resid, [0.85, 2.0, 0.5, 0.5],\n",
    "        args=(y, pi, u_gap, ff_lag),\n",
    "        bounds=([0, -5, 0.5, -5], [0.999, 10, 5, 5]))\n",
    "    p_con = res_con.x\n",
    "\n",
    "    # 3. Textbook Taylor (1993): r*=2, a_pi=0.5, a_u=0.5, no smoothing\n",
    "    p_text = np.array([0.0, 2.0, 0.5, 0.5])\n",
    "\n",
    "    # Print comparison\n",
    "    print(f\"\\n  {'Specification':<25s}  {'rho':>6s}  {'r*':>6s}  {'a_pi':>6s}  {'a_u':>6s}  {'1+a_pi':>7s}  {'SSR':>10s}\")\n",
    "    print(f\"  {'-'*75}\")\n",
    "\n",
    "    for label, params, res in [\n",
    "        (\"Unconstrained NLS\", p_unc, res_unc),\n",
    "        (\"Constrained (a_pi>=0.5)\", p_con, res_con),\n",
    "    ]:\n",
    "        ssr = np.sum(res.fun**2)\n",
    "        tp = 1 + params[2]\n",
    "        print(f\"  {label:<25s}  {params[0]:>6.3f}  {params[1]:>6.3f}  {params[2]:>6.3f}  \"\n",
    "              f\"{params[3]:>6.3f}  {tp:>7.2f}  {ssr:>10.1f}\")\n",
    "\n",
    "    # Textbook SSR\n",
    "    ssr_text = np.sum(taylor_resid(p_text, y, pi, u_gap, ff_lag)**2)\n",
    "    tp_text = 1 + p_text[2]\n",
    "    print(f\"  {'Textbook Taylor (1993)':<25s}  {p_text[0]:>6.3f}  {p_text[1]:>6.3f}  {p_text[2]:>6.3f}  \"\n",
    "          f\"{p_text[3]:>6.3f}  {tp_text:>7.2f}  {ssr_text:>10.1f}\")\n",
    "\n",
    "    print(f\"\\n  Note: unconstrained a_pi = {p_unc[2]:.3f} < 0.5, indicating the data\")\n",
    "    print(f\"  prefers a rule that barely responds to inflation. The constrained\")\n",
    "    print(f\"  version forces a minimum inflation response consistent with theory.\")\n",
    "\n",
    "    return {\n",
    "        \"unconstrained\": p_unc,\n",
    "        \"constrained\": p_con,\n",
    "        \"textbook\": p_text,\n",
    "    }\n",
    "\n",
    "\n",
    "def taylor_prescribed(pi, u_gap, params, with_smoothing=True, ff_prev=None):\n",
    "    \"\"\"Compute Taylor rule prescription.\"\"\"\n",
    "    rho, rstar, a_pi, a_u = params\n",
    "    target = rstar + pi + a_pi * (pi - 2.0) + a_u * u_gap\n",
    "    target = max(target, 0.0)  # ZLB\n",
    "\n",
    "    if with_smoothing and rho > 0 and ff_prev is not None:\n",
    "        return rho * ff_prev + (1 - rho) * target\n",
    "    return target\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# VAR ESTIMATION\n",
    "# ================================================================\n",
    "def estimate_var(df, var_cols=[\"inflation\", \"unemployment\", \"fed_funds\"], lags=6):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"VAR ESTIMATION: {var_cols}, {lags} lags\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    var_df = df[var_cols].dropna()\n",
    "    model = VAR(var_df)\n",
    "    lag_selection = model.select_order(maxlags=12)\n",
    "\n",
    "    print(f\"\\n  Lag selection:\")\n",
    "    print(f\"  {'Criterion':<10s}  {'Lags':>5s}\")\n",
    "    print(f\"  {'-'*18}\")\n",
    "    for crit in [\"aic\", \"bic\", \"hqic\"]:\n",
    "        val = getattr(lag_selection, crit)\n",
    "        print(f\"  {crit.upper():<10s}  {val:>5d}\")\n",
    "\n",
    "    bic_lags = lag_selection.bic\n",
    "    use_lags = max(2, min(bic_lags if bic_lags is not None else lags, lags))\n",
    "    print(f\"\\n  Using {use_lags} lags\")\n",
    "\n",
    "    result = model.fit(use_lags)\n",
    "    print(f\"  Observations: {result.nobs}\")\n",
    "\n",
    "    try:\n",
    "        for i, col in enumerate(var_cols):\n",
    "            ss_res = np.sum(result.resid.iloc[:, i].values ** 2)\n",
    "            y = var_df[col].values[use_lags:]\n",
    "            ss_tot = np.sum((y - y.mean()) ** 2)\n",
    "            r2 = 1 - ss_res / ss_tot if ss_tot > 0 else np.nan\n",
    "            print(f\"\\n  {col}: R2 = {r2:.3f}\")\n",
    "    except Exception:\n",
    "        print(\"\\n  (R2 diagnostics unavailable)\")\n",
    "\n",
    "    return result, var_df\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# COUNTERFACTUAL SIMULATION\n",
    "# ================================================================\n",
    "def run_counterfactual(var_result, df, taylor_params, rule_label,\n",
    "                        var_cols=[\"inflation\", \"unemployment\", \"fed_funds\"],\n",
    "                        use_smoothing=True):\n",
    "    \"\"\"\n",
    "    Simulate counterfactual path where the Fed follows the given\n",
    "    Taylor rule, using VAR dynamics for inflation and unemployment.\n",
    "    \"\"\"\n",
    "    n_lags = var_result.k_ar\n",
    "    coefs = var_result.coefs\n",
    "    intercept = var_result.coefs_exog[:, 0] if var_result.coefs_exog.shape[1] > 0 else np.zeros(len(var_cols))\n",
    "\n",
    "    pi_idx = var_cols.index(\"inflation\")\n",
    "    u_idx = var_cols.index(\"unemployment\")\n",
    "    ff_idx = var_cols.index(\"fed_funds\")\n",
    "\n",
    "    var_df = df[var_cols].dropna()\n",
    "    nrou_series = df[\"nrou\"].reindex(var_df.index)\n",
    "\n",
    "    cf_data = var_df.values.copy()\n",
    "    start = n_lags + 12\n",
    "\n",
    "    for t in range(start, len(var_df)):\n",
    "        lag_vals = np.zeros((n_lags, len(var_cols)))\n",
    "        for lag in range(n_lags):\n",
    "            lag_vals[lag] = cf_data[t - lag - 1]\n",
    "\n",
    "        pred = intercept.copy()\n",
    "        for lag in range(n_lags):\n",
    "            pred += coefs[lag] @ lag_vals[lag]\n",
    "\n",
    "        cf_pi = cf_data[t - 1, pi_idx]\n",
    "        cf_u = cf_data[t - 1, u_idx]\n",
    "        cf_nrou = nrou_series.iloc[t] if t < len(nrou_series) and not np.isnan(nrou_series.iloc[t]) else 5.0\n",
    "        cf_u_gap = cf_u - cf_nrou\n",
    "        cf_ff_prev = cf_data[t - 1, ff_idx]\n",
    "\n",
    "        taylor_ff = taylor_prescribed(\n",
    "            cf_pi, cf_u_gap, taylor_params,\n",
    "            with_smoothing=use_smoothing, ff_prev=cf_ff_prev)\n",
    "\n",
    "        cf_data[t, pi_idx] = pred[pi_idx]\n",
    "        cf_data[t, u_idx] = pred[u_idx]\n",
    "        cf_data[t, ff_idx] = taylor_ff\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "        \"actual_inflation\": var_df[\"inflation\"].values,\n",
    "        f\"cf_inflation_{rule_label}\": cf_data[:, pi_idx],\n",
    "        \"actual_unemployment\": var_df[\"unemployment\"].values,\n",
    "        f\"cf_unemployment_{rule_label}\": cf_data[:, u_idx],\n",
    "        \"actual_ff\": var_df[\"fed_funds\"].values,\n",
    "        f\"cf_ff_{rule_label}\": cf_data[:, ff_idx],\n",
    "    }, index=var_df.index)\n",
    "\n",
    "    return result_df.iloc[start:]\n",
    "\n",
    "\n",
    "def episode_counterfactuals(var_result, df, taylor_rules, episodes,\n",
    "                             var_cols=[\"inflation\", \"unemployment\", \"fed_funds\"]):\n",
    "    \"\"\"Run counterfactuals for specific episodes, comparing rule specifications.\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"EPISODE COUNTERFACTUALS\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    n_lags = var_result.k_ar\n",
    "    coefs = var_result.coefs\n",
    "    intercept = var_result.coefs_exog[:, 0] if var_result.coefs_exog.shape[1] > 0 else np.zeros(len(var_cols))\n",
    "\n",
    "    pi_idx = var_cols.index(\"inflation\")\n",
    "    u_idx = var_cols.index(\"unemployment\")\n",
    "    ff_idx = var_cols.index(\"fed_funds\")\n",
    "\n",
    "    all_episodes = {}\n",
    "\n",
    "    for ep_name, ep_start, ep_end in episodes:\n",
    "        print(f\"\\n  --- {ep_name} ---\")\n",
    "        var_df = df[var_cols].dropna()\n",
    "        nrou_series = df[\"nrou\"].reindex(var_df.index)\n",
    "\n",
    "        start_dt = pd.Timestamp(ep_start)\n",
    "        end_dt = pd.Timestamp(ep_end)\n",
    "        valid_dates = var_df.index[(var_df.index >= start_dt) & (var_df.index <= end_dt)]\n",
    "        if len(valid_dates) == 0:\n",
    "            print(f\"    No data, skipping\")\n",
    "            continue\n",
    "        start_idx = var_df.index.get_loc(valid_dates[0])\n",
    "        end_idx = var_df.index.get_loc(valid_dates[-1])\n",
    "        if start_idx < n_lags or end_idx - start_idx < 6:\n",
    "            print(f\"    Too few observations, skipping\")\n",
    "            continue\n",
    "\n",
    "        ep_data = {\"dates\": var_df.index[start_idx:end_idx + 1],\n",
    "                   \"actual\": var_df.values[start_idx:end_idx + 1]}\n",
    "\n",
    "        print(f\"  {'':>22s}  {'Actual':>8s}\", end=\"\")\n",
    "        for rl in taylor_rules:\n",
    "            print(f\"  {rl[:10]:>10s}\", end=\"\")\n",
    "        print()\n",
    "        print(f\"  {'-'*55}\")\n",
    "\n",
    "        for rule_label, rule_params in taylor_rules.items():\n",
    "            cf_data = var_df.values.copy()\n",
    "            use_smoothing = rule_label != \"textbook\"  # textbook has rho=0\n",
    "\n",
    "            for t in range(start_idx, end_idx + 1):\n",
    "                lag_vals = np.zeros((n_lags, len(var_cols)))\n",
    "                for lag in range(n_lags):\n",
    "                    lag_vals[lag] = cf_data[t - lag - 1]\n",
    "\n",
    "                pred = intercept.copy()\n",
    "                for lag in range(n_lags):\n",
    "                    pred += coefs[lag] @ lag_vals[lag]\n",
    "\n",
    "                cf_pi = cf_data[t - 1, pi_idx]\n",
    "                cf_u = cf_data[t - 1, u_idx]\n",
    "                cf_nrou = nrou_series.iloc[t] if not np.isnan(nrou_series.iloc[t]) else 5.0\n",
    "                cf_u_gap = cf_u - cf_nrou\n",
    "                cf_ff_prev = cf_data[t - 1, ff_idx]\n",
    "\n",
    "                taylor_ff = taylor_prescribed(\n",
    "                    cf_pi, cf_u_gap, rule_params,\n",
    "                    with_smoothing=use_smoothing, ff_prev=cf_ff_prev)\n",
    "\n",
    "                cf_data[t, pi_idx] = pred[pi_idx]\n",
    "                cf_data[t, u_idx] = pred[u_idx]\n",
    "                cf_data[t, ff_idx] = taylor_ff\n",
    "\n",
    "            ep_data[rule_label] = cf_data[start_idx:end_idx + 1]\n",
    "\n",
    "        # Print summary\n",
    "        actual = ep_data[\"actual\"]\n",
    "        for var_name, idx, label in [(\"Fed funds\", ff_idx, \"ff\"),\n",
    "                                      (\"Inflation\", pi_idx, \"pi\"),\n",
    "                                      (\"Unemployment\", u_idx, \"u\")]:\n",
    "            line = f\"  {var_name + ' (mean)':>22s}  {actual[:, idx].mean():>8.2f}\"\n",
    "            for rl in taylor_rules:\n",
    "                cf = ep_data[rl]\n",
    "                line += f\"  {cf[:, idx].mean():>10.2f}\"\n",
    "            print(line)\n",
    "\n",
    "        all_episodes[ep_name] = ep_data\n",
    "\n",
    "    return all_episodes\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# VISUALIZATION\n",
    "# ================================================================\n",
    "def plot_results(full_cf_constrained, full_cf_textbook, all_episodes,\n",
    "                 taylor_rules, output_path):\n",
    "\n",
    "    # ── Fig 1: Full-sample counterfactual (constrained rule) ──\n",
    "    cf = full_cf_constrained\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(16, 12), sharex=True)\n",
    "    fig.suptitle(\"Counterfactual: What If the Fed Had Followed a Taylor Rule?\\n\"\n",
    "                 \"(Constrained NLS: a_pi >= 0.5, with interest rate smoothing)\",\n",
    "                 fontweight=\"bold\", fontsize=13, y=0.995)\n",
    "\n",
    "    panels = [\n",
    "        (\"actual_ff\", \"cf_ff_constrained\", \"Fed funds rate (%)\", C1),\n",
    "        (\"actual_inflation\", \"cf_inflation_constrained\", \"Inflation (%)\", C2),\n",
    "        (\"actual_unemployment\", \"cf_unemployment_constrained\", \"Unemployment (%)\", C3),\n",
    "    ]\n",
    "\n",
    "    for ax, (act_col, cf_col, ylabel, color) in zip(axes, panels):\n",
    "        shade_recessions(ax)\n",
    "        ax.plot(cf.index, cf[act_col], lw=1.8, color=color,\n",
    "                label=\"Actual\", zorder=3)\n",
    "        ax.plot(cf.index, cf[cf_col], lw=1.5, color=color,\n",
    "                alpha=0.5, ls=\"--\", label=\"Counterfactual\", zorder=2)\n",
    "        ax.set_ylabel(ylabel)\n",
    "        ax.set_title(ylabel, fontweight=\"bold\")\n",
    "        ax.legend(frameon=True, fontsize=8, loc=\"upper right\")\n",
    "        if \"inflation\" in act_col and \"ff\" not in act_col:\n",
    "            ax.axhline(2, color=\"grey\", ls=\":\", lw=1, alpha=0.5)\n",
    "\n",
    "    axes[-1].set_xlabel(\"Year\")\n",
    "    fig.tight_layout()\n",
    "    path1 = f\"{output_path}/counterfactual_full_sample.png\"\n",
    "    fig.savefig(path1, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "    print(f\"  Saved: {path1}\")\n",
    "\n",
    "    # ── Fig 2: Constrained vs textbook comparison (gap) ──\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(16, 12), sharex=True)\n",
    "    fig.suptitle(\"Counterfactual Comparison: Constrained NLS vs Textbook Taylor Rule\",\n",
    "                 fontweight=\"bold\", fontsize=13, y=0.995)\n",
    "\n",
    "    cf_t = full_cf_textbook\n",
    "    # Align indices\n",
    "    common_idx = cf.index.intersection(cf_t.index)\n",
    "\n",
    "    ax = axes[0]; shade_recessions(ax)\n",
    "    ax.plot(common_idx, cf.loc[common_idx, \"actual_ff\"], lw=1.8, color=\"#374151\",\n",
    "            label=\"Actual\")\n",
    "    ax.plot(common_idx, cf.loc[common_idx, \"cf_ff_constrained\"], lw=1.5, color=C1,\n",
    "            ls=\"--\", label=\"Constrained NLS\")\n",
    "    ax.plot(common_idx, cf_t.loc[common_idx, \"cf_ff_textbook\"], lw=1.5, color=C4,\n",
    "            ls=\"--\", label=\"Textbook (r*=2, a_pi=0.5, a_u=0.5)\")\n",
    "    ax.set_ylabel(\"Fed funds rate (%)\"); ax.set_title(\"Fed funds rate\", fontweight=\"bold\")\n",
    "    ax.legend(frameon=True, fontsize=8)\n",
    "\n",
    "    ax = axes[1]; shade_recessions(ax)\n",
    "    ax.plot(common_idx, cf.loc[common_idx, \"actual_inflation\"], lw=1.8, color=\"#374151\",\n",
    "            label=\"Actual\")\n",
    "    ax.plot(common_idx, cf.loc[common_idx, \"cf_inflation_constrained\"], lw=1.5, color=C1,\n",
    "            ls=\"--\", label=\"Constrained NLS\")\n",
    "    ax.plot(common_idx, cf_t.loc[common_idx, \"cf_inflation_textbook\"], lw=1.5, color=C4,\n",
    "            ls=\"--\", label=\"Textbook\")\n",
    "    ax.axhline(2, color=\"grey\", ls=\":\", lw=1, alpha=0.5)\n",
    "    ax.set_ylabel(\"Inflation (%)\"); ax.set_title(\"Inflation\", fontweight=\"bold\")\n",
    "    ax.legend(frameon=True, fontsize=8)\n",
    "\n",
    "    ax = axes[2]; shade_recessions(ax)\n",
    "    ax.plot(common_idx, cf.loc[common_idx, \"actual_unemployment\"], lw=1.8, color=\"#374151\",\n",
    "            label=\"Actual\")\n",
    "    ax.plot(common_idx, cf.loc[common_idx, \"cf_unemployment_constrained\"], lw=1.5, color=C1,\n",
    "            ls=\"--\", label=\"Constrained NLS\")\n",
    "    ax.plot(common_idx, cf_t.loc[common_idx, \"cf_unemployment_textbook\"], lw=1.5, color=C4,\n",
    "            ls=\"--\", label=\"Textbook\")\n",
    "    ax.set_ylabel(\"Unemployment (%)\"); ax.set_xlabel(\"Year\")\n",
    "    ax.set_title(\"Unemployment\", fontweight=\"bold\")\n",
    "    ax.legend(frameon=True, fontsize=8)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    path2 = f\"{output_path}/counterfactual_rule_comparison.png\"\n",
    "    fig.savefig(path2, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "    print(f\"  Saved: {path2}\")\n",
    "\n",
    "    # ── Fig 3: Episode panels ──\n",
    "    n_eps = len(all_episodes)\n",
    "    if n_eps == 0:\n",
    "        return [path1, path2]\n",
    "\n",
    "    fig, axes = plt.subplots(n_eps, 2, figsize=(16, 4 * n_eps))\n",
    "    if n_eps == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    fig.suptitle(\"Counterfactual Paths by Historical Episode\",\n",
    "                 fontweight=\"bold\", fontsize=14, y=1.01)\n",
    "\n",
    "    rule_colors = {\"constrained\": C1, \"textbook\": C4}\n",
    "\n",
    "    for row, (ep_name, ep_data) in enumerate(all_episodes.items()):\n",
    "        dates = ep_data[\"dates\"]\n",
    "        actual = ep_data[\"actual\"]\n",
    "        pi_idx, ff_idx = 0, 2  # inflation=0, fed_funds=2\n",
    "\n",
    "        # Left: fed funds\n",
    "        ax = axes[row, 0]\n",
    "        ax.plot(dates, actual[:, ff_idx], lw=2, color=\"#374151\", label=\"Actual\")\n",
    "        for rl in taylor_rules:\n",
    "            if rl in ep_data:\n",
    "                color = rule_colors.get(rl, C5)\n",
    "                ax.plot(dates, ep_data[rl][:, ff_idx], lw=1.5, color=color,\n",
    "                        ls=\"--\", label=f\"{rl}\")\n",
    "        ax.set_ylabel(\"Fed funds (%)\")\n",
    "        ax.set_title(f\"{ep_name}: Fed funds\", fontweight=\"bold\", fontsize=10)\n",
    "        ax.legend(frameon=True, fontsize=7, loc=\"best\")\n",
    "\n",
    "        # Right: inflation\n",
    "        ax = axes[row, 1]\n",
    "        ax.plot(dates, actual[:, pi_idx], lw=2, color=\"#374151\", label=\"Actual\")\n",
    "        for rl in taylor_rules:\n",
    "            if rl in ep_data:\n",
    "                color = rule_colors.get(rl, C5)\n",
    "                ax.plot(dates, ep_data[rl][:, pi_idx], lw=1.5, color=color,\n",
    "                        ls=\"--\", label=f\"{rl}\")\n",
    "        ax.axhline(2, color=\"grey\", ls=\":\", lw=1, alpha=0.5)\n",
    "        ax.set_ylabel(\"Inflation (%)\")\n",
    "        ax.set_title(f\"{ep_name}: Inflation\", fontweight=\"bold\", fontsize=10)\n",
    "        ax.legend(frameon=True, fontsize=7, loc=\"best\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    path3 = f\"{output_path}/counterfactual_episodes.png\"\n",
    "    fig.savefig(path3, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "    print(f\"  Saved: {path3}\")\n",
    "\n",
    "    return [path1, path2, path3]\n",
    "\n",
    "\n",
    "# ── Main ──\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Loading data...\")\n",
    "    data = load_data(DATA_PATH)\n",
    "    df = engineer_features(data)\n",
    "\n",
    "    print(\"Estimating Taylor rules...\")\n",
    "    taylor_rules = estimate_taylor_rules(df)\n",
    "\n",
    "    print(\"Estimating VAR...\")\n",
    "    var_result, var_df = estimate_var(df, lags=6)\n",
    "\n",
    "    # Full-sample counterfactuals\n",
    "    print(\"\\nRunning full-sample counterfactual (constrained rule)...\")\n",
    "    full_cf_con = run_counterfactual(var_result, df, taylor_rules[\"constrained\"],\n",
    "                                      \"constrained\", use_smoothing=True)\n",
    "    print(f\"  Mean actual ff: {full_cf_con['actual_ff'].mean():.2f}\")\n",
    "    print(f\"  Mean CF ff: {full_cf_con['cf_ff_constrained'].mean():.2f}\")\n",
    "    print(f\"  Mean actual inflation: {full_cf_con['actual_inflation'].mean():.2f}\")\n",
    "    print(f\"  Mean CF inflation: {full_cf_con['cf_inflation_constrained'].mean():.2f}\")\n",
    "\n",
    "    print(\"\\nRunning full-sample counterfactual (textbook rule)...\")\n",
    "    full_cf_text = run_counterfactual(var_result, df, taylor_rules[\"textbook\"],\n",
    "                                       \"textbook\", use_smoothing=False)\n",
    "    print(f\"  Mean CF ff (textbook): {full_cf_text['cf_ff_textbook'].mean():.2f}\")\n",
    "    print(f\"  Mean CF inflation (textbook): {full_cf_text['cf_inflation_textbook'].mean():.2f}\")\n",
    "\n",
    "    # Episode counterfactuals\n",
    "    EPISODES = [\n",
    "        (\"Burns accommodation (1971-78)\",     \"1971-01\", \"1978-06\"),\n",
    "        (\"Volcker tightening (1979-82)\",       \"1979-01\", \"1983-12\"),\n",
    "        (\"Greenspan era (1987-2000)\",          \"1987-01\", \"2000-12\"),\n",
    "        (\"Post-GFC ZLB (2009-15)\",             \"2009-01\", \"2015-12\"),\n",
    "        (\"COVID and after (2020-23)\",          \"2020-01\", \"2023-06\"),\n",
    "    ]\n",
    "\n",
    "    all_episodes = episode_counterfactuals(\n",
    "        var_result, df,\n",
    "        {\"constrained\": taylor_rules[\"constrained\"],\n",
    "         \"textbook\": taylor_rules[\"textbook\"]},\n",
    "        EPISODES)\n",
    "\n",
    "    print(\"\\nPlotting...\")\n",
    "    paths = plot_results(full_cf_con, full_cf_text, all_episodes,\n",
    "                         {\"constrained\": taylor_rules[\"constrained\"],\n",
    "                          \"textbook\": taylor_rules[\"textbook\"]},\n",
    "                         OUTPUT_PATH)\n",
    "\n",
    "    print(f\"\\nOutputs: {paths}\")\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04ca9639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Merged: 857 obs (1954-07 to 2025-12)\n",
      "Fitting regimes...\n",
      "  2 regimes: {0: 'Low inflation (2.4%)', 1: 'High inflation (7.4%)'}\n",
      "Running regime-dependent SVAR analysis...\n",
      "\n",
      "======================================================================\n",
      "REGIME-DEPENDENT STRUCTURAL VAR\n",
      "  Ordering: inflation -> unemp_gap -> fed_funds (Cholesky)\n",
      "======================================================================\n",
      "\n",
      "  --- Full sample ---\n",
      "  [Full sample] N=839, lags=6, AIC=-5.5, BIC=-5.2\n",
      "    Computing bootstrap confidence intervals...\n",
      "    Bootstrap: 500/500 successful replications\n",
      "\n",
      "  --- Low inflation (2.4%) ---\n",
      "  [Low inflation (2.4%)] N=628, lags=6, AIC=-5.6, BIC=-5.2\n",
      "    Computing bootstrap confidence intervals...\n",
      "    Bootstrap: 500/500 successful replications\n",
      "\n",
      "  --- High inflation (7.4%) ---\n",
      "  [High inflation (7.4%)] N=205, lags=6, AIC=-4.0, BIC=-3.0\n",
      "    Computing bootstrap confidence intervals...\n",
      "    Bootstrap: 500/500 successful replications\n",
      "\n",
      "  === Monetary policy shock -> Inflation (cumulative) ===\n",
      "   Horizon        Full  Low inflation (  High inflation \n",
      "  --------------------------------------------------\n",
      "         1      0.0795           0.0004           0.0161\n",
      "         3      0.2687           0.1315           0.1676\n",
      "         6      0.3149           0.2910           0.0944\n",
      "        12      0.3328           0.3206           0.0908\n",
      "        24      0.2929           0.2245          -0.0005\n",
      "        36      0.2403           0.1644          -0.0256\n",
      "        48      0.1885           0.1248          -0.0154\n",
      "\n",
      "  === Monetary policy shock -> Unemployment gap ===\n",
      "   Horizon        Full  Low inflation (  High inflation \n",
      "  --------------------------------------------------\n",
      "         1     -0.1181          -0.1351          -0.0016\n",
      "         3     -0.1977          -0.1203          -0.0466\n",
      "         6     -0.2209          -0.2433           0.0216\n",
      "        12     -0.1285          -0.2285           0.0753\n",
      "        24     -0.0225          -0.1427           0.0857\n",
      "        36      0.0367          -0.0956           0.0405\n",
      "        48      0.0654          -0.0679           0.0088\n",
      "\n",
      "  === Forecast Error Variance Decomposition (inflation) ===\n",
      "   Horizon    pi shock   u_gap shock    ff shock\n",
      "  --------------------------------------------\n",
      "         1       1.000         0.000       0.000\n",
      "         3       0.987         0.000       0.013\n",
      "         6       0.959         0.003       0.039\n",
      "        12       0.930         0.012       0.058\n",
      "        24       0.893         0.028       0.079\n",
      "        48       0.849         0.054       0.098\n",
      "Plotting...\n",
      "  Saved: /Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/svar_irfs_full_sample.png\n",
      "  Saved: /Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/svar_irfs_by_regime.png\n",
      "  Saved: /Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/svar_fevd_comparison.png\n",
      "\n",
      "Outputs: ['/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/svar_irfs_full_sample.png', '/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/svar_irfs_by_regime.png', '/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs/svar_fevd_comparison.png']\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Component 7: Regime-Dependent Structural VAR\n",
    "=============================================\n",
    "Estimates a 3-variable SVAR [inflation, unemployment_gap, fed_funds]\n",
    "with Cholesky identification, separately for each inflation regime.\n",
    "\n",
    "Cholesky ordering: inflation -> unemp_gap -> fed_funds\n",
    "(monetary policy responds contemporaneously to both, but neither\n",
    "responds within the month to a policy shock)\n",
    "\n",
    "Produces regime-specific impulse response functions with\n",
    "bootstrapped confidence bands.\n",
    "\"\"\"\n",
    "\n",
    "import os, warnings, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SEED = 42; random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "DATA_PATH = '/Users/leoss/Desktop/Portfolio/Website-/Central bank/data'\n",
    "OUTPUT_PATH = '/Users/leoss/Desktop/Portfolio/Website-/Central bank/Outputs'\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "C1, C2, C3, C4, C5 = \"#2563eb\", \"#dc2626\", \"#7c3aed\", \"#f59e0b\", \"#10b981\"\n",
    "C_BG = \"#fafafa\"\n",
    "plt.rcParams.update({\n",
    "    \"figure.facecolor\": C_BG, \"axes.facecolor\": C_BG,\n",
    "    \"axes.grid\": True, \"grid.color\": \"#e5e7eb\", \"grid.linewidth\": 0.5,\n",
    "    \"font.size\": 11, \"axes.spines.top\": False, \"axes.spines.right\": False,\n",
    "})\n",
    "\n",
    "\n",
    "def load_data(path=DATA_PATH):\n",
    "    def _read(names):\n",
    "        for n in names:\n",
    "            p = os.path.join(path, n)\n",
    "            if os.path.exists(p):\n",
    "                return pd.read_csv(p, parse_dates=[\"observation_date\"],\n",
    "                                   index_col=\"observation_date\")\n",
    "        raise FileNotFoundError(f\"None of {names} found in {path}\")\n",
    "\n",
    "    cpi = _read([\"CPIAUCSL.csv\"])\n",
    "    unrate = _read([\"UNRATE.csv\"])\n",
    "    ff = _read([\"FEDFUNDS.csv\", \"FEDFUNDS-1.csv\"])\n",
    "    tcu = _read([\"TCU.csv\"])\n",
    "    gs10 = _read([\"GS10.csv\"])\n",
    "    nfci_w = _read([\"NFCI.csv\"]); nfci = nfci_w.resample(\"MS\").last()\n",
    "    nrou_q = _read([\"NROU.csv\", \"NROUST.csv\"])\n",
    "    nrou_q.index = pd.DatetimeIndex(nrou_q.index)\n",
    "    nrou_m = nrou_q.resample(\"MS\").interpolate(method=\"linear\")\n",
    "    try:\n",
    "        mich = _read([\"MICH.csv\"])\n",
    "    except FileNotFoundError:\n",
    "        mich = None\n",
    "\n",
    "    merged = pd.concat([\n",
    "        cpi.rename(columns={cpi.columns[0]: \"cpi\"}),\n",
    "        unrate.rename(columns={unrate.columns[0]: \"unemployment\"}),\n",
    "        ff.rename(columns={ff.columns[0]: \"fed_funds\"}),\n",
    "        tcu.rename(columns={tcu.columns[0]: \"capacity_util\"}),\n",
    "        gs10.rename(columns={gs10.columns[0]: \"treasury_10y\"}),\n",
    "        nfci.rename(columns={nfci.columns[0]: \"fin_conditions\"}),\n",
    "        nrou_m.rename(columns={nrou_m.columns[0]: \"nrou\"}),\n",
    "    ], axis=1).dropna(subset=[\"cpi\", \"unemployment\", \"fed_funds\", \"nrou\"])\n",
    "\n",
    "    if mich is not None:\n",
    "        merged = merged.join(\n",
    "            mich.rename(columns={mich.columns[0]: \"expected_inflation\"}), how=\"left\")\n",
    "    else:\n",
    "        merged[\"expected_inflation\"] = np.nan\n",
    "    print(f\"Merged: {len(merged)} obs ({merged.index.min():%Y-%m} to {merged.index.max():%Y-%m})\")\n",
    "    return merged\n",
    "\n",
    "\n",
    "def engineer_features(data):\n",
    "    df = data.copy()\n",
    "    df[\"inflation\"] = df[\"cpi\"].pct_change(12) * 100\n",
    "    df[\"unemp_gap\"] = df[\"unemployment\"] - df[\"nrou\"]\n",
    "    df[\"capacity_gap\"] = df[\"capacity_util\"] - 100.0\n",
    "    df[\"term_spread\"] = df[\"treasury_10y\"] - df[\"fed_funds\"]\n",
    "    df[\"real_rate\"] = df[\"fed_funds\"] - df[\"inflation\"]\n",
    "    df[\"delta_ff\"] = df[\"fed_funds\"].diff()\n",
    "    df[\"ff_lag1\"] = df[\"fed_funds\"].shift(1)\n",
    "    df[\"adaptive_pi_e\"] = df[\"inflation\"].rolling(12).mean()\n",
    "    df[\"pi_expected\"] = df[\"expected_inflation\"].fillna(df[\"adaptive_pi_e\"])\n",
    "    for var in [\"inflation\", \"unemp_gap\", \"capacity_gap\", \"fed_funds\", \"term_spread\", \"fin_conditions\"]:\n",
    "        for lag in [1, 3, 6, 12]:\n",
    "            df[f\"L{lag}_{var}\"] = df[var].shift(lag)\n",
    "    df[\"recession\"] = 0\n",
    "    for start, end in RECESSIONS:\n",
    "        df.loc[(df.index >= start) & (df.index <= end), \"recession\"] = 1\n",
    "    df = df.dropna(subset=[\"inflation\"])\n",
    "    df.index = pd.DatetimeIndex(df.index)\n",
    "    return df\n",
    "\n",
    "\n",
    "RECESSIONS = [\n",
    "    (\"1973-11\",\"1975-03\"),(\"1980-01\",\"1980-07\"),(\"1981-07\",\"1982-11\"),\n",
    "    (\"1990-07\",\"1991-03\"),(\"2001-03\",\"2001-11\"),(\"2007-12\",\"2009-06\"),(\"2020-02\",\"2020-04\"),\n",
    "]\n",
    "\n",
    "\n",
    "def get_regimes(df, n_regimes=2):\n",
    "    endog = df[\"inflation\"].copy()\n",
    "    exog = sm.add_constant(df[[\"unemployment\"]].copy())\n",
    "    mod = sm.tsa.MarkovRegression(endog, k_regimes=n_regimes, exog=exog,\n",
    "        switching_variance=True, switching_exog=True)\n",
    "    best_res, best_llf = None, -np.inf\n",
    "    for attempt in range(8):\n",
    "        try:\n",
    "            res = mod.fit(search_reps=30, random_state=SEED+attempt, disp=False, maxiter=500)\n",
    "            if res.llf > best_llf:\n",
    "                best_llf = res.llf; best_res = res\n",
    "        except:\n",
    "            continue\n",
    "    smoothed = best_res.smoothed_marginal_probabilities\n",
    "    regime_means = {}\n",
    "    for r in range(n_regimes):\n",
    "        mask = smoothed[r] > 0.5\n",
    "        regime_means[r] = df.loc[mask, \"inflation\"].mean() if mask.sum() > 0 else 0.0\n",
    "    sorted_regimes = sorted(regime_means, key=regime_means.get)\n",
    "    rdf = df.copy()\n",
    "    for new_r in range(n_regimes):\n",
    "        rdf[f\"p_regime_{new_r}\"] = smoothed[sorted_regimes[new_r]].values\n",
    "    rdf[\"regime\"] = np.argmax(\n",
    "        np.column_stack([rdf[f\"p_regime_{r}\"].values for r in range(n_regimes)]), axis=1)\n",
    "    sorted_means = [regime_means[sorted_regimes[r]] for r in range(n_regimes)]\n",
    "    labels = [\"Low\", \"High\"] if n_regimes == 2 else [f\"R{r}\" for r in range(n_regimes)]\n",
    "    regime_names = {r: f\"{labels[r]} inflation ({sorted_means[r]:.1f}%)\" for r in range(n_regimes)}\n",
    "    return rdf, regime_names, n_regimes\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# SVAR ESTIMATION\n",
    "# ================================================================\n",
    "def estimate_svar(df_sub, var_cols, n_lags, label=\"\"):\n",
    "    \"\"\"\n",
    "    Estimate VAR and compute Cholesky-identified IRFs.\n",
    "    Returns VAR result and IRFs.\n",
    "    \"\"\"\n",
    "    sub = df_sub[var_cols].dropna()\n",
    "    if len(sub) < n_lags * len(var_cols) + 30:\n",
    "        print(f\"  [{label}] Too few observations ({len(sub)}), skipping\")\n",
    "        return None, None\n",
    "\n",
    "    model = VAR(sub)\n",
    "    result = model.fit(n_lags)\n",
    "\n",
    "    # Compute IRFs with Cholesky decomposition (default in statsmodels)\n",
    "    irf = result.irf(periods=48)\n",
    "\n",
    "    print(f\"  [{label}] N={result.nobs}, lags={n_lags}, \"\n",
    "          f\"AIC={result.aic:.1f}, BIC={result.bic:.1f}\")\n",
    "\n",
    "    return result, irf\n",
    "\n",
    "\n",
    "def bootstrap_irf_ci(df_sub, var_cols, n_lags, n_boot=500, periods=48,\n",
    "                      ci_level=0.90):\n",
    "    \"\"\"\n",
    "    Bootstrap confidence intervals for Cholesky IRFs.\n",
    "    Uses residual resampling (standard VAR bootstrap).\n",
    "    \"\"\"\n",
    "    sub = df_sub[var_cols].dropna()\n",
    "    n_vars = len(var_cols)\n",
    "\n",
    "    # Estimate base model\n",
    "    model = VAR(sub)\n",
    "    result = model.fit(n_lags)\n",
    "    base_irf = result.irf(periods=periods).irfs  # (periods+1, n_vars, n_vars)\n",
    "\n",
    "    residuals = result.resid  # (T-p, n_vars)\n",
    "    fitted = result.fittedvalues\n",
    "    T = len(residuals)\n",
    "\n",
    "    boot_irfs = np.zeros((n_boot, periods + 1, n_vars, n_vars))\n",
    "    successful = 0\n",
    "\n",
    "    for b in range(n_boot):\n",
    "        # Resample residuals\n",
    "        boot_idx = np.random.randint(0, T, size=T)\n",
    "        boot_resid = residuals.values[boot_idx]\n",
    "\n",
    "        # Reconstruct data\n",
    "        boot_y = fitted.values + boot_resid\n",
    "        boot_df = pd.DataFrame(boot_y, columns=var_cols,\n",
    "                                index=fitted.index)\n",
    "\n",
    "        try:\n",
    "            boot_model = VAR(boot_df)\n",
    "            boot_result = boot_model.fit(n_lags)\n",
    "            boot_irf_obj = boot_result.irf(periods=periods)\n",
    "            boot_irfs[successful] = boot_irf_obj.irfs\n",
    "            successful += 1\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    if successful < 50:\n",
    "        print(f\"    Bootstrap: only {successful}/{n_boot} successful, CI may be unreliable\")\n",
    "        return None\n",
    "\n",
    "    boot_irfs = boot_irfs[:successful]\n",
    "    alpha = (1 - ci_level) / 2\n",
    "    ci_lower = np.quantile(boot_irfs, alpha, axis=0)\n",
    "    ci_upper = np.quantile(boot_irfs, 1 - alpha, axis=0)\n",
    "\n",
    "    print(f\"    Bootstrap: {successful}/{n_boot} successful replications\")\n",
    "\n",
    "    return {\"lower\": ci_lower, \"upper\": ci_upper, \"median\": np.median(boot_irfs, axis=0)}\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# REGIME-DEPENDENT ANALYSIS\n",
    "# ================================================================\n",
    "def regime_svar_analysis(regime_df, regime_names, n_regimes):\n",
    "    \"\"\"\n",
    "    Estimate SVAR separately for each regime and compare IRFs.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"REGIME-DEPENDENT STRUCTURAL VAR\")\n",
    "    print(f\"  Ordering: inflation -> unemp_gap -> fed_funds (Cholesky)\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    var_cols = [\"inflation\", \"unemp_gap\", \"fed_funds\"]\n",
    "    n_lags = 6\n",
    "\n",
    "    # Full-sample SVAR\n",
    "    print(f\"\\n  --- Full sample ---\")\n",
    "    full_result, full_irf = estimate_svar(regime_df, var_cols, n_lags, \"Full sample\")\n",
    "\n",
    "    # Full-sample bootstrap CI\n",
    "    print(f\"    Computing bootstrap confidence intervals...\")\n",
    "    full_ci = bootstrap_irf_ci(regime_df, var_cols, n_lags, n_boot=500, periods=48)\n",
    "\n",
    "    # Regime-specific SVARs\n",
    "    regime_results = {}\n",
    "    regime_irfs = {}\n",
    "    regime_cis = {}\n",
    "\n",
    "    for r in range(n_regimes):\n",
    "        label = regime_names[r]\n",
    "        print(f\"\\n  --- {label} ---\")\n",
    "        rsub = regime_df[regime_df[\"regime\"] == r].copy()\n",
    "\n",
    "        result, irf = estimate_svar(rsub, var_cols, n_lags, label)\n",
    "        if result is None:\n",
    "            continue\n",
    "\n",
    "        regime_results[r] = result\n",
    "        regime_irfs[r] = irf\n",
    "\n",
    "        print(f\"    Computing bootstrap confidence intervals...\")\n",
    "        ci = bootstrap_irf_ci(rsub, var_cols, n_lags, n_boot=500, periods=48)\n",
    "        regime_cis[r] = ci\n",
    "\n",
    "    # Print key IRF comparisons\n",
    "    print(f\"\\n  === Monetary policy shock -> Inflation (cumulative) ===\")\n",
    "    print(f\"  {'Horizon':>8s}\", end=\"\")\n",
    "    print(f\"  {'Full':>10s}\", end=\"\")\n",
    "    for r in sorted(regime_results.keys()):\n",
    "        print(f\"  {regime_names[r][:15]:>15s}\", end=\"\")\n",
    "    print()\n",
    "    print(f\"  {'-'*50}\")\n",
    "\n",
    "    shock_idx = var_cols.index(\"fed_funds\")\n",
    "    resp_idx = var_cols.index(\"inflation\")\n",
    "\n",
    "    for h in [1, 3, 6, 12, 24, 36, 48]:\n",
    "        print(f\"  {h:>8d}\", end=\"\")\n",
    "        if full_irf is not None:\n",
    "            print(f\"  {full_irf.irfs[h, resp_idx, shock_idx]:>10.4f}\", end=\"\")\n",
    "        else:\n",
    "            print(f\"  {'N/A':>10s}\", end=\"\")\n",
    "        for r in sorted(regime_results.keys()):\n",
    "            irf_val = regime_irfs[r].irfs[h, resp_idx, shock_idx]\n",
    "            print(f\"  {irf_val:>15.4f}\", end=\"\")\n",
    "        print()\n",
    "\n",
    "    print(f\"\\n  === Monetary policy shock -> Unemployment gap ===\")\n",
    "    resp_idx_u = var_cols.index(\"unemp_gap\")\n",
    "    print(f\"  {'Horizon':>8s}\", end=\"\")\n",
    "    print(f\"  {'Full':>10s}\", end=\"\")\n",
    "    for r in sorted(regime_results.keys()):\n",
    "        print(f\"  {regime_names[r][:15]:>15s}\", end=\"\")\n",
    "    print()\n",
    "    print(f\"  {'-'*50}\")\n",
    "\n",
    "    for h in [1, 3, 6, 12, 24, 36, 48]:\n",
    "        print(f\"  {h:>8d}\", end=\"\")\n",
    "        if full_irf is not None:\n",
    "            print(f\"  {full_irf.irfs[h, resp_idx_u, shock_idx]:>10.4f}\", end=\"\")\n",
    "        else:\n",
    "            print(f\"  {'N/A':>10s}\", end=\"\")\n",
    "        for r in sorted(regime_results.keys()):\n",
    "            irf_val = regime_irfs[r].irfs[h, resp_idx_u, shock_idx]\n",
    "            print(f\"  {irf_val:>15.4f}\", end=\"\")\n",
    "        print()\n",
    "\n",
    "    # Forecast error variance decomposition\n",
    "    print(f\"\\n  === Forecast Error Variance Decomposition (inflation) ===\")\n",
    "    if full_result is not None:\n",
    "        fevd_obj = full_result.fevd(48)\n",
    "        fevd = fevd_obj.decomp  # shape: (n_vars, periods, n_vars)\n",
    "        # fevd[i, h, j] = fraction of variance of variable i at horizon h from shock j\n",
    "        print(f\"  {'Horizon':>8s}  {'pi shock':>10s}  {'u_gap shock':>12s}  {'ff shock':>10s}\")\n",
    "        print(f\"  {'-'*44}\")\n",
    "        for h in [0, 2, 5, 11, 23, 47]:\n",
    "            pi_pi = fevd[resp_idx, h, 0]\n",
    "            pi_u = fevd[resp_idx, h, 1]\n",
    "            pi_ff = fevd[resp_idx, h, 2]\n",
    "            print(f\"  {h+1:>8d}  {pi_pi:>10.3f}  {pi_u:>12.3f}  {pi_ff:>10.3f}\")\n",
    "\n",
    "    return {\n",
    "        \"full\": {\"result\": full_result, \"irf\": full_irf, \"ci\": full_ci},\n",
    "        \"regimes\": {r: {\"result\": regime_results[r], \"irf\": regime_irfs[r],\n",
    "                        \"ci\": regime_cis.get(r)} for r in regime_results},\n",
    "        \"var_cols\": var_cols,\n",
    "        \"regime_names\": regime_names,\n",
    "    }\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# VISUALIZATION\n",
    "# ================================================================\n",
    "def plot_svar_results(svar_results, output_path):\n",
    "    \"\"\"Plot SVAR impulse response functions.\"\"\"\n",
    "    var_cols = svar_results[\"var_cols\"]\n",
    "    regime_names = svar_results[\"regime_names\"]\n",
    "    regime_colors = [C5, C2, C4]  # low, high\n",
    "\n",
    "    shock_idx = var_cols.index(\"fed_funds\")\n",
    "    response_labels = {\n",
    "        \"inflation\": \"Inflation (pp)\",\n",
    "        \"unemp_gap\": \"Unemployment gap (pp)\",\n",
    "        \"fed_funds\": \"Fed funds (pp)\",\n",
    "    }\n",
    "\n",
    "    # ── Fig 1: Full-sample IRFs to monetary policy shock ──\n",
    "    full_irf = svar_results[\"full\"][\"irf\"]\n",
    "    full_ci = svar_results[\"full\"][\"ci\"]\n",
    "\n",
    "    if full_irf is not None:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "        fig.suptitle(\"Structural IRFs to a Monetary Policy Shock (Cholesky identification)\\n\"\n",
    "                     \"Full sample, 90% bootstrap confidence bands\",\n",
    "                     fontweight=\"bold\", fontsize=13, y=1.05)\n",
    "\n",
    "        horizons = np.arange(full_irf.irfs.shape[0])\n",
    "\n",
    "        for ax, (resp_idx, var_name) in zip(axes, enumerate(var_cols)):\n",
    "            resp_idx_val = resp_idx\n",
    "            irf_vals = full_irf.irfs[:, resp_idx_val, shock_idx]\n",
    "            ax.plot(horizons, irf_vals, lw=2, color=C1)\n",
    "\n",
    "            if full_ci is not None:\n",
    "                ax.fill_between(horizons,\n",
    "                                full_ci[\"lower\"][:, resp_idx_val, shock_idx],\n",
    "                                full_ci[\"upper\"][:, resp_idx_val, shock_idx],\n",
    "                                alpha=0.2, color=C1)\n",
    "\n",
    "            ax.axhline(0, color=\"grey\", lw=1, ls=\"--\")\n",
    "            ax.set_xlabel(\"Months\")\n",
    "            ax.set_ylabel(response_labels[var_name])\n",
    "            ax.set_title(f\"Response of {response_labels[var_name]}\", fontweight=\"bold\", fontsize=10)\n",
    "\n",
    "        fig.tight_layout()\n",
    "        path1 = f\"{output_path}/svar_irfs_full_sample.png\"\n",
    "        fig.savefig(path1, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "        print(f\"  Saved: {path1}\")\n",
    "    else:\n",
    "        path1 = None\n",
    "\n",
    "    # ── Fig 2: Regime-dependent IRFs (main result) ──\n",
    "    regime_data = svar_results[\"regimes\"]\n",
    "    if len(regime_data) >= 2:\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "        fig.suptitle(\"Monetary Policy Transmission by Inflation Regime\\n\"\n",
    "                     \"(Cholesky SVAR, 90% bootstrap CI)\",\n",
    "                     fontweight=\"bold\", fontsize=13, y=1.02)\n",
    "\n",
    "        # Top row: IRFs by regime\n",
    "        for col, (resp_idx_val, var_name) in enumerate(zip(range(len(var_cols)), var_cols)):\n",
    "            ax = axes[0, col]\n",
    "\n",
    "            for r in sorted(regime_data.keys()):\n",
    "                irf_obj = regime_data[r][\"irf\"]\n",
    "                ci = regime_data[r].get(\"ci\")\n",
    "                color = regime_colors[r]\n",
    "                label = regime_names[r]\n",
    "\n",
    "                horizons = np.arange(irf_obj.irfs.shape[0])\n",
    "                irf_vals = irf_obj.irfs[:, resp_idx_val, shock_idx]\n",
    "                ax.plot(horizons, irf_vals, lw=2, color=color, label=label)\n",
    "\n",
    "                if ci is not None:\n",
    "                    ax.fill_between(horizons,\n",
    "                                    ci[\"lower\"][:, resp_idx_val, shock_idx],\n",
    "                                    ci[\"upper\"][:, resp_idx_val, shock_idx],\n",
    "                                    alpha=0.12, color=color)\n",
    "\n",
    "            ax.axhline(0, color=\"grey\", lw=1, ls=\"--\")\n",
    "            ax.set_xlabel(\"Months\")\n",
    "            ax.set_ylabel(response_labels[var_name])\n",
    "            ax.set_title(f\"Response of {response_labels[var_name]}\", fontweight=\"bold\", fontsize=10)\n",
    "            ax.legend(frameon=True, fontsize=7)\n",
    "\n",
    "        # Bottom row: difference (high minus low)\n",
    "        r_keys = sorted(regime_data.keys())\n",
    "        if len(r_keys) >= 2:\n",
    "            r_low, r_high = r_keys[0], r_keys[1]\n",
    "            for col, (resp_idx_val, var_name) in enumerate(zip(range(len(var_cols)), var_cols)):\n",
    "                ax = axes[1, col]\n",
    "\n",
    "                irf_low = regime_data[r_low][\"irf\"].irfs[:, resp_idx_val, shock_idx]\n",
    "                irf_high = regime_data[r_high][\"irf\"].irfs[:, resp_idx_val, shock_idx]\n",
    "                diff = irf_high - irf_low\n",
    "                horizons = np.arange(len(diff))\n",
    "\n",
    "                ax.plot(horizons, diff, lw=2, color=C3)\n",
    "                ax.axhline(0, color=\"grey\", lw=1.5, ls=\"--\")\n",
    "                ax.set_xlabel(\"Months\")\n",
    "                ax.set_ylabel(\"Difference (pp)\")\n",
    "                ax.set_title(f\"Difference: high minus low regime\", fontweight=\"bold\", fontsize=10)\n",
    "\n",
    "                # Approximate CI on difference using bootstrap\n",
    "                ci_low = regime_data[r_low].get(\"ci\")\n",
    "                ci_high = regime_data[r_high].get(\"ci\")\n",
    "                if ci_low is not None and ci_high is not None:\n",
    "                    # Conservative: sum of variances\n",
    "                    se_low = (ci_low[\"upper\"][:, resp_idx_val, shock_idx] -\n",
    "                              ci_low[\"lower\"][:, resp_idx_val, shock_idx]) / (2 * 1.645)\n",
    "                    se_high = (ci_high[\"upper\"][:, resp_idx_val, shock_idx] -\n",
    "                               ci_high[\"lower\"][:, resp_idx_val, shock_idx]) / (2 * 1.645)\n",
    "                    se_diff = np.sqrt(se_low**2 + se_high**2)\n",
    "                    ax.fill_between(horizons, diff - 1.645 * se_diff,\n",
    "                                    diff + 1.645 * se_diff, alpha=0.2, color=C3)\n",
    "\n",
    "        fig.tight_layout()\n",
    "        path2 = f\"{output_path}/svar_irfs_by_regime.png\"\n",
    "        fig.savefig(path2, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "        print(f\"  Saved: {path2}\")\n",
    "    else:\n",
    "        path2 = None\n",
    "\n",
    "    # ── Fig 3: FEVD comparison ──\n",
    "    if full_irf is not None and len(regime_data) >= 2:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "        fig.suptitle(\"Forecast Error Variance Decomposition of Inflation\\n\"\n",
    "                     \"(share explained by monetary policy shock)\",\n",
    "                     fontweight=\"bold\", fontsize=13, y=1.05)\n",
    "\n",
    "        # Full sample FEVD\n",
    "        full_result = svar_results[\"full\"][\"result\"]\n",
    "        full_fevd = full_result.fevd(48).decomp  # shape: (n_vars, periods, n_vars)\n",
    "\n",
    "        ax = axes[0]\n",
    "        pi_idx = var_cols.index(\"inflation\")\n",
    "        n_periods = full_fevd.shape[1]\n",
    "        horizons = np.arange(n_periods)\n",
    "        for j, var_name in enumerate(var_cols):\n",
    "            ax.plot(horizons, full_fevd[pi_idx, :, j], lw=2,\n",
    "                    label=f\"{var_name} shock\")\n",
    "        ax.set_xlabel(\"Months\"); ax.set_ylabel(\"Share of variance\")\n",
    "        ax.set_title(\"Full sample\", fontweight=\"bold\")\n",
    "        ax.legend(frameon=True, fontsize=8)\n",
    "        ax.set_ylim(0, 1)\n",
    "\n",
    "        for ax_idx, r in enumerate(sorted(regime_data.keys())):\n",
    "            ax = axes[ax_idx + 1]\n",
    "            r_result = regime_data[r][\"result\"]\n",
    "            r_fevd = r_result.fevd(48).decomp\n",
    "            n_periods_r = r_fevd.shape[1]\n",
    "            horizons = np.arange(n_periods_r)\n",
    "            for j, var_name in enumerate(var_cols):\n",
    "                ax.plot(horizons, r_fevd[pi_idx, :, j], lw=2,\n",
    "                        label=f\"{var_name} shock\")\n",
    "            ax.set_xlabel(\"Months\"); ax.set_ylabel(\"Share of variance\")\n",
    "            ax.set_title(regime_names[r], fontweight=\"bold\")\n",
    "            ax.legend(frameon=True, fontsize=8)\n",
    "            ax.set_ylim(0, 1)\n",
    "\n",
    "        fig.tight_layout()\n",
    "        path3 = f\"{output_path}/svar_fevd_comparison.png\"\n",
    "        fig.savefig(path3, dpi=200, bbox_inches=\"tight\"); plt.close(fig)\n",
    "        print(f\"  Saved: {path3}\")\n",
    "    else:\n",
    "        path3 = None\n",
    "\n",
    "    return [p for p in [path1, path2, path3] if p]\n",
    "\n",
    "\n",
    "# ── Main ──\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Loading data...\")\n",
    "    data = load_data(DATA_PATH)\n",
    "    df = engineer_features(data)\n",
    "\n",
    "    print(\"Fitting regimes...\")\n",
    "    regime_df, regime_names, n_regimes = get_regimes(df, n_regimes=2)\n",
    "    print(f\"  {n_regimes} regimes: {regime_names}\")\n",
    "\n",
    "    print(\"Running regime-dependent SVAR analysis...\")\n",
    "    svar_results = regime_svar_analysis(regime_df, regime_names, n_regimes)\n",
    "\n",
    "    print(\"Plotting...\")\n",
    "    paths = plot_svar_results(svar_results, OUTPUT_PATH)\n",
    "\n",
    "    print(f\"\\nOutputs: {paths}\")\n",
    "    print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
