{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4c5398c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 263 zone centroids to /Users/leoss/Desktop/Portfolio/Website-/uber_visualizations/data/zone_centroids.csv\n",
      "\n",
      "Sample:\n",
      " zone_id               zone_name       borough  latitude  longitude\n",
      "       1          Newark Airport           EWR 40.691831 -74.174000\n",
      "       2             Jamaica Bay        Queens 40.616745 -73.831299\n",
      "       3 Allerton/Pelham Gardens         Bronx 40.864474 -73.847422\n",
      "       4           Alphabet City     Manhattan 40.723752 -73.976968\n",
      "       5           Arden Heights Staten Island 40.552659 -74.188484\n",
      "       6 Arrochar/Fort Wadsworth Staten Island 40.600324 -74.071771\n",
      "       7                 Astoria        Queens 40.761493 -73.919694\n",
      "       8            Astoria Park        Queens 40.778559 -73.923086\n",
      "       9              Auburndale        Queens 40.751035 -73.787949\n",
      "      10            Baisley Park        Queens 40.678953 -73.790986\n",
      "\n",
      "EWR check (zone_id=1):\n",
      " zone_id      zone_name borough  latitude  longitude\n",
      "       1 Newark Airport     EWR 40.691831    -74.174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lk/thldsylx4nx779cggs7gnk900000gn/T/ipykernel_28546/1471430234.py:13: UserWarning:\n",
      "\n",
      "Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generate zone_centroids.csv from the TLC taxi zones shapefile.\n",
    "Computes the centroid of each zone polygon in WGS84 coordinates.\n",
    "\"\"\"\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "PATH_SHAPEFILE = '/Users/leoss/Desktop/Portfolio/Website-/uber_visualizations/data/taxi_zones/taxi_zones.shp'\n",
    "OUTPUT_PATH = '/Users/leoss/Desktop/Portfolio/Website-/uber_visualizations/data/zone_centroids.csv'\n",
    "\n",
    "gdf = gpd.read_file(PATH_SHAPEFILE)\n",
    "gdf = gdf.to_crs(epsg=4326)\n",
    "centroids_proj = gdf.geometry.centroid\n",
    "centroids_wgs84 = gpd.GeoSeries(centroids_proj, crs=gdf.crs).to_crs(epsg=4326)\n",
    "\n",
    "gdf['latitude'] = centroids_wgs84.y\n",
    "gdf['longitude'] = centroids_wgs84.x\n",
    "\n",
    "\n",
    "centroids = gdf[['LocationID', 'zone', 'borough', 'latitude', 'longitude']].copy()\n",
    "centroids.columns = ['zone_id', 'zone_name', 'borough', 'latitude', 'longitude']\n",
    "centroids['zone_id'] = centroids['zone_id'].astype(int)\n",
    "centroids = centroids.sort_values('zone_id').reset_index(drop=True)\n",
    "\n",
    "centroids.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "print(f\"Saved {len(centroids)} zone centroids to {OUTPUT_PATH}\")\n",
    "print(f\"\\nSample:\")\n",
    "print(centroids.head(10).to_string(index=False))\n",
    "print(f\"\\nEWR check (zone_id=1):\")\n",
    "print(centroids[centroids['zone_id'] == 1].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4539b00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "UBER COMPREHENSIVE ANALYSIS: 2018 → 2025\n",
      "======================================================================\n",
      "\n",
      "Configuration:\n",
      "  Sample size: 20,000,000 trips per year\n",
      "  Clusters: 6\n",
      "\n",
      "======================================================================\n",
      "LOADING ZONE CENTROIDS & SHAPEFILE\n",
      "======================================================================\n",
      "  Loaded 263 zone centroids\n",
      "  Loaded 263 taxi zone geometries\n",
      "\n",
      "======================================================================\n",
      "PART 1: 2018 UBER ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "[1.1] Loading 2018 data...\n",
      "  Total rows: 19,808,094\n",
      "  Uber trips: 4,502,999 (22.7%)\n",
      "\n",
      "[1.2] Processing temporal and geographic features...\n",
      "\n",
      "[1.3] Clustering on geographic coordinates...\n",
      "  Cluster distribution:\n",
      "    Cluster 0 - Manhattan: Yorkville East: 765,644 ( 17.0%)\n",
      "    Cluster 1 - Brooklyn: Borough Park: 388,895 (  8.6%)\n",
      "    Cluster 2 - Queens: Jamaica: 369,831 (  8.2%)\n",
      "    Cluster 3 - Manhattan: Gramercy: 1,882,965 ( 41.7%)\n",
      "    Cluster 4 - Bronx: East Tremont: 477,419 ( 10.6%)\n",
      "    Cluster 5 - Brooklyn: Ocean Hill: 626,327 ( 13.9%)\n",
      "\n",
      "======================================================================\n",
      "PART 2: 2025 UBER ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "[2.1] Loading 2025 data...\n",
      "  Total rows: 20,405,666\n",
      "  Uber trips: 15,356,455 (75.3%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "UBER GEOGRAPHIC EVOLUTION: COMPREHENSIVE ANALYSIS\n",
    "- Clusters matched by geographic proximity (not index)\n",
    "- Consistent naming based on nearest major zone\n",
    "- Methodologically sound comparisons\n",
    "\"\"\"\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import gc\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"UBER COMPREHENSIVE ANALYSIS: 2018 → 2025\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "SAMPLE_SIZE = 20_000_000\n",
    "N_CLUSTERS = 6\n",
    "\n",
    "OUTPUT_DIR = '/Users/leoss/Desktop/Portfolio/Website-/uber_visualizations/outputs/'\n",
    "PATH_2018 = '/Users/leoss/Desktop/Portfolio/Website-/uber_visualizations/data/fhv_tripdata_2018-01.parquet'\n",
    "PATH_2025 = '/Users/leoss/Desktop/Portfolio/Website-/uber_visualizations/data/fhvhv_tripdata_2025-01.parquet'\n",
    "PATH_CENTROIDS = '/Users/leoss/Desktop/Portfolio/Website-/uber_visualizations/data/zone_centroids.csv'\n",
    "PATH_SHAPEFILE = '/Users/leoss/Desktop/Portfolio/Website-/uber_visualizations/data/taxi_zones/taxi_zones.shp'\n",
    "\n",
    "UBER_2018_BASES = ['B02512', 'B02598', 'B02617', 'B02682', 'B02764', 'B02765', 'B02835', 'B02836']\n",
    "UBER_2025_LICENSE = 'HV0003'\n",
    "\n",
    "# Cluster color palette (shared across all cluster visualizations)\n",
    "\n",
    "CLUSTER_COLORS = ['#e6194b', '#3cb44b', '#4363d8', '#f58231', '#911eb4', '#42d4f4']\n",
    "\n",
    "\n",
    "# Airport zone IDs (TLC)\n",
    "AIRPORT_ZONE_IDS = {132, 138, 1}\n",
    "AIRPORT_LABELS = {132: 'JFK', 138: 'LaGuardia', 1: 'Newark (EWR)'}\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Sample size: {SAMPLE_SIZE:,} trips per year\")\n",
    "print(f\"  Clusters: {N_CLUSTERS}\")\n",
    "\n",
    "# ============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def haversine_km(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Great-circle distance between two points in km.\"\"\"\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    return 2 * 6371 * asin(sqrt(a))\n",
    "\n",
    "\n",
    "def name_cluster_by_location(center_lat, center_lon, zone_centroids):\n",
    "    \"\"\"Name cluster based on nearest major zone.\"\"\"\n",
    "    zone_distances = np.sqrt(\n",
    "        (zone_centroids['latitude'] - center_lat) ** 2 +\n",
    "        (zone_centroids['longitude'] - center_lon) ** 2\n",
    "    )\n",
    "    nearest_idx = zone_distances.idxmin()\n",
    "    nearest_zone = zone_centroids.iloc[nearest_idx]\n",
    "    return f\"{nearest_zone['borough']}: {nearest_zone['zone_name']}\"\n",
    "\n",
    "\n",
    "def match_clusters_by_proximity(centers_2018, centers_2025):\n",
    "    \"\"\"Match 2018 to 2025 clusters by geographic proximity (greedy).\"\"\"\n",
    "    distances = cdist(centers_2018, centers_2025, metric='cityblock')\n",
    "    matches = {}\n",
    "    used_2025 = set()\n",
    "\n",
    "    pairs = []\n",
    "    for i in range(len(centers_2018)):\n",
    "        for j in range(len(centers_2025)):\n",
    "            pairs.append((i, j, distances[i, j]))\n",
    "\n",
    "    pairs.sort(key=lambda x: x[2])\n",
    "\n",
    "    for i, j, dist in pairs:\n",
    "        if i not in matches and j not in used_2025:\n",
    "            matches[i] = j\n",
    "            used_2025.add(j)\n",
    "\n",
    "    return matches\n",
    "\n",
    "\n",
    "def lorenz_data(df, zone_col='zone_id'):\n",
    "    \"\"\"Return (cumulative share of zones, cumulative share of trips).\"\"\"\n",
    "    zone_counts = df.groupby(zone_col).size().sort_values().values\n",
    "    cum_zones = np.arange(1, len(zone_counts) + 1) / len(zone_counts)\n",
    "    cum_trips = np.cumsum(zone_counts) / zone_counts.sum()\n",
    "    return cum_zones, cum_trips\n",
    "\n",
    "\n",
    "def gini_from_lorenz(cum_zones, cum_trips):\n",
    "    \"\"\"Gini coefficient via trapezoidal integration under the Lorenz curve.\"\"\"\n",
    "    area_under = np.trapz(cum_trips, cum_zones)\n",
    "    return 1 - 2 * area_under\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD ZONE CENTROIDS & SHAPEFILE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"LOADING ZONE CENTROIDS & SHAPEFILE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "zone_centroids = pd.read_csv(PATH_CENTROIDS)\n",
    "print(f\"  Loaded {len(zone_centroids)} zone centroids\")\n",
    "\n",
    "gdf_raw = gpd.read_file(PATH_SHAPEFILE)\n",
    "gdf_raw = gdf_raw.to_crs(epsg=4326)\n",
    "taxi_zones_geo_4326 = json.loads(gdf_raw.to_json())\n",
    "\n",
    "for f in taxi_zones_geo_4326['features']:\n",
    "    f['properties']['LocationID'] = str(int(f['properties']['LocationID']))\n",
    "\n",
    "all_zone_ids = [f['properties']['LocationID'] for f in taxi_zones_geo_4326['features']]\n",
    "print(f\"  Loaded {len(all_zone_ids)} taxi zone geometries\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 1: 2018 UBER DATA\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 1: 2018 UBER ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n[1.1] Loading 2018 data...\")\n",
    "table_2018 = pq.read_table(PATH_2018, columns=[])\n",
    "total_2018 = table_2018.num_rows\n",
    "print(f\"  Total rows: {total_2018:,}\")\n",
    "\n",
    "columns_2018 = ['pickup_datetime', 'PUlocationID', 'dispatching_base_num']\n",
    "table_2018 = pq.read_table(PATH_2018, columns=columns_2018)\n",
    "\n",
    "df_2018_full = table_2018.to_pandas()\n",
    "df_2018_full = df_2018_full[df_2018_full['dispatching_base_num'].isin(UBER_2018_BASES)].copy()\n",
    "\n",
    "uber_count_2018 = len(df_2018_full)\n",
    "print(f\"  Uber trips: {uber_count_2018:,} ({100 * uber_count_2018 / total_2018:.1f}%)\")\n",
    "\n",
    "df_2018 = df_2018_full.sample(n=min(SAMPLE_SIZE, uber_count_2018), random_state=42)\n",
    "del df_2018_full, table_2018\n",
    "gc.collect()\n",
    "\n",
    "print(\"\\n[1.2] Processing temporal and geographic features...\")\n",
    "df_2018['pickup_datetime'] = pd.to_datetime(df_2018['pickup_datetime'])\n",
    "df_2018['hour'] = df_2018['pickup_datetime'].dt.hour\n",
    "df_2018['day_of_week'] = df_2018['pickup_datetime'].dt.dayofweek\n",
    "df_2018['day_name'] = df_2018['pickup_datetime'].dt.day_name()\n",
    "\n",
    "df_2018 = df_2018.dropna(subset=['PUlocationID'])\n",
    "df_2018['PUlocationID'] = df_2018['PUlocationID'].astype(int)\n",
    "df_2018 = df_2018.merge(\n",
    "    zone_centroids[['zone_id', 'zone_name', 'borough', 'latitude', 'longitude']],\n",
    "    left_on='PUlocationID',\n",
    "    right_on='zone_id',\n",
    "    how='left'\n",
    ")\n",
    "df_2018 = df_2018.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "print(\"\\n[1.3] Clustering on geographic coordinates...\")\n",
    "coords_2018 = df_2018[['latitude', 'longitude']].values\n",
    "kmeans_2018 = KMeans(n_clusters=N_CLUSTERS, random_state=42, n_init=10)\n",
    "df_2018['cluster'] = kmeans_2018.fit_predict(coords_2018)\n",
    "\n",
    "cluster_names_2018 = {}\n",
    "for i in range(N_CLUSTERS):\n",
    "    lat, lon = kmeans_2018.cluster_centers_[i]\n",
    "    cluster_names_2018[i] = name_cluster_by_location(lat, lon, zone_centroids)\n",
    "\n",
    "df_2018['cluster_name'] = df_2018['cluster'].map(cluster_names_2018)\n",
    "\n",
    "cluster_counts_2018 = df_2018['cluster'].value_counts().sort_index()\n",
    "print(\"  Cluster distribution:\")\n",
    "for i, count in enumerate(cluster_counts_2018):\n",
    "    pct = 100 * count / len(df_2018)\n",
    "    print(f\"    Cluster {i} - {cluster_names_2018[i]}: {count:>7,} ({pct:>5.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 2: 2025 UBER DATA\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 2: 2025 UBER ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n[2.1] Loading 2025 data...\")\n",
    "table_2025 = pq.read_table(PATH_2025, columns=[])\n",
    "total_2025 = table_2025.num_rows\n",
    "print(f\"  Total rows: {total_2025:,}\")\n",
    "\n",
    "columns_2025 = ['pickup_datetime', 'PULocationID', 'hvfhs_license_num']\n",
    "table_2025 = pq.read_table(PATH_2025, columns=columns_2025)\n",
    "\n",
    "df_2025_full = table_2025.to_pandas()\n",
    "df_2025_full = df_2025_full[df_2025_full['hvfhs_license_num'] == UBER_2025_LICENSE].copy()\n",
    "\n",
    "uber_count_2025 = len(df_2025_full)\n",
    "print(f\"  Uber trips: {uber_count_2025:,} ({100 * uber_count_2025 / total_2025:.1f}%)\")\n",
    "\n",
    "df_2025 = df_2025_full.sample(n=min(SAMPLE_SIZE, uber_count_2025), random_state=42)\n",
    "del df_2025_full, table_2025\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8e2718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2.2] Processing temporal and geographic features...\n",
      "\n",
      "[2.3] Clustering on geographic coordinates...\n",
      "  Cluster distribution:\n",
      "    Cluster 0 - Manhattan: Murray Hill: 5,996,328 ( 38.9%)\n",
      "    Cluster 1 - Bronx: Claremont/Bathgate: 2,713,198 ( 17.6%)\n",
      "    Cluster 2 - Brooklyn: Prospect-Lefferts Gardens: 3,180,936 ( 20.7%)\n",
      "    Cluster 3 - Queens: Baisley Park: 1,353,333 (  8.8%)\n",
      "    Cluster 4 - Queens: Elmhurst: 1,824,961 ( 11.8%)\n",
      "    Cluster 5 - Staten Island: Grymes Hill/Clifton: 332,575 (  2.2%)\n",
      "\n",
      "======================================================================\n",
      "MATCHING CLUSTERS BY GEOGRAPHIC PROXIMITY\n",
      "======================================================================\n",
      "\n",
      "  2018 Cluster                                            → 2025 Cluster                                            Shift (km)\n",
      "  -----------------------------------------------------------------------------------------------------------------------------\n",
      "  Manhattan: Yorkville East                               → Queens: Elmhurst                                              6.15\n",
      "  Brooklyn: Borough Park                                  → Staten Island: Grymes Hill/Clifton                            9.25\n",
      "  Queens: Jamaica                                         → Queens: Baisley Park                                          2.55\n",
      "  Manhattan: Gramercy                                     → Manhattan: Murray Hill                                        1.22\n",
      "  Bronx: East Tremont                                     → Bronx: Claremont/Bathgate                                     0.72\n",
      "  Brooklyn: Ocean Hill                                    → Brooklyn: Prospect-Lefferts Gardens                           2.83\n",
      "\n",
      "======================================================================\n",
      "PART 3: CREATING VISUALIZATIONS\n",
      "======================================================================\n",
      "\n",
      "[3.1a] 2018 cluster choropleth map...\n",
      "  Filtered to 258 zones with data\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[2.2] Processing temporal and geographic features...\")\n",
    "df_2025['pickup_datetime'] = pd.to_datetime(df_2025['pickup_datetime'])\n",
    "df_2025['hour'] = df_2025['pickup_datetime'].dt.hour\n",
    "df_2025['day_of_week'] = df_2025['pickup_datetime'].dt.dayofweek\n",
    "df_2025['day_name'] = df_2025['pickup_datetime'].dt.day_name()\n",
    "\n",
    "df_2025 = df_2025.dropna(subset=['PULocationID'])\n",
    "df_2025['PULocationID'] = df_2025['PULocationID'].astype(int)\n",
    "df_2025 = df_2025.merge(\n",
    "    zone_centroids[['zone_id', 'zone_name', 'borough', 'latitude', 'longitude']],\n",
    "    left_on='PULocationID',\n",
    "    right_on='zone_id',\n",
    "    how='left'\n",
    ")\n",
    "df_2025 = df_2025.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "print(\"\\n[2.3] Clustering on geographic coordinates...\")\n",
    "coords_2025 = df_2025[['latitude', 'longitude']].values\n",
    "kmeans_2025 = KMeans(n_clusters=N_CLUSTERS, random_state=42, n_init=10)\n",
    "df_2025['cluster'] = kmeans_2025.fit_predict(coords_2025)\n",
    "\n",
    "cluster_names_2025 = {}\n",
    "for i in range(N_CLUSTERS):\n",
    "    lat, lon = kmeans_2025.cluster_centers_[i]\n",
    "    cluster_names_2025[i] = name_cluster_by_location(lat, lon, zone_centroids)\n",
    "\n",
    "df_2025['cluster_name'] = df_2025['cluster'].map(cluster_names_2025)\n",
    "\n",
    "cluster_counts_2025 = df_2025['cluster'].value_counts().sort_index()\n",
    "print(\"  Cluster distribution:\")\n",
    "for i, count in enumerate(cluster_counts_2025):\n",
    "    pct = 100 * count / len(df_2025)\n",
    "    print(f\"    Cluster {i} - {cluster_names_2025[i]}: {count:>7,} ({pct:>5.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# MATCH CLUSTERS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MATCHING CLUSTERS BY GEOGRAPHIC PROXIMITY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "centers_2018 = kmeans_2018.cluster_centers_\n",
    "centers_2025 = kmeans_2025.cluster_centers_\n",
    "\n",
    "cluster_matches = match_clusters_by_proximity(centers_2018, centers_2025)\n",
    "\n",
    "print(f\"\\n  {'2018 Cluster':<55} → {'2025 Cluster':<55} {'Shift (km)':>10}\")\n",
    "print(\"  \" + \"-\" * 125)\n",
    "\n",
    "for idx_2018, idx_2025 in sorted(cluster_matches.items()):\n",
    "    lat1, lon1 = centers_2018[idx_2018]\n",
    "    lat2, lon2 = centers_2025[idx_2025]\n",
    "    dist = haversine_km(lat1, lon1, lat2, lon2)\n",
    "    print(f\"  {cluster_names_2018[idx_2018]:<55} → {cluster_names_2025[idx_2025]:<55} {dist:>10.2f}\")\n",
    "\n",
    "\n",
    "cluster_color_map_2018 = {\n",
    "    cluster_names_2018[i]: CLUSTER_COLORS[i % len(CLUSTER_COLORS)]\n",
    "    for i in range(N_CLUSTERS)\n",
    "}\n",
    "\n",
    "cluster_color_map_2025 = {\n",
    "    cluster_names_2025[idx_25]: CLUSTER_COLORS[idx_18 % len(CLUSTER_COLORS)]\n",
    "    for idx_18, idx_25 in cluster_matches.items()\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# PART 3: VISUALIZATIONS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 3: CREATING VISUALIZATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# --- 3.1a: 2018 Cluster Choropleth Map ---\n",
    "print(\"\\n[3.1a] 2018 cluster choropleth map...\")\n",
    "\n",
    "zone_clusters = df_2018.groupby('zone_id').agg({\n",
    "    'cluster': lambda x: x.mode()[0],\n",
    "    'cluster_name': lambda x: x.mode()[0],\n",
    "    'zone_name': 'first',\n",
    "    'borough': 'first'\n",
    "}).reset_index()\n",
    "zone_clusters['zone_id'] = zone_clusters['zone_id'].astype(float).astype(int).astype(str)\n",
    "\n",
    "zone_ids_with_data = set(zone_clusters['zone_id'].values)\n",
    "filtered_geojson = {\n",
    "    'type': 'FeatureCollection',\n",
    "    'features': [f for f in taxi_zones_geo_4326['features']\n",
    "                 if f['properties']['LocationID'] in zone_ids_with_data]\n",
    "}\n",
    "print(f\"  Filtered to {len(filtered_geojson['features'])} zones with data\")\n",
    "\n",
    "# Build figure: grey background FIRST, then choropleth on top\n",
    "fig = go.Figure()\n",
    "\n",
    "# Grey background — all taxi zones\n",
    "fig.add_trace(go.Choroplethmap(\n",
    "    geojson=taxi_zones_geo_4326,\n",
    "    locations=all_zone_ids,\n",
    "    featureidkey='properties.LocationID',\n",
    "    z=[1] * len(all_zone_ids),\n",
    "    colorscale=[[0, '#e8e8e8'], [1, '#e8e8e8']],\n",
    "    marker_opacity=0.4,\n",
    "    marker_line_width=0.3,\n",
    "    marker_line_color='#ccc',\n",
    "    showscale=False,\n",
    "    hoverinfo='skip',\n",
    "))\n",
    "# 2018 map\n",
    "fig_tmp = px.choropleth_map(\n",
    "    zone_clusters,\n",
    "    geojson=filtered_geojson,\n",
    "    locations='zone_id',\n",
    "    featureidkey='properties.LocationID',\n",
    "    color='cluster_name',\n",
    "    color_discrete_map=cluster_color_map_2018,  # ← replaces color_discrete_sequence\n",
    "    map_style='carto-positron-nolabels',\n",
    "    zoom=9.5,\n",
    "    center={'lat': 40.7128, 'lon': -73.9352},\n",
    "    opacity=0.95,\n",
    "    hover_data={'zone_id': False, 'zone_name': True, 'borough': True, 'cluster_name': True},\n",
    "    labels={'cluster_name': 'Cluster'}\n",
    ")\n",
    "\n",
    "\n",
    "fig_tmp.update_traces(marker=dict(line=dict(width=0.8, color='rgba(255,255,255,0.8)')))\n",
    "for trace in fig_tmp.data:\n",
    "    fig.add_trace(trace)\n",
    "\n",
    "# Centroid markers\n",
    "for i, (lat, lon) in enumerate(centers_2018):\n",
    "    name = cluster_names_2018[i]\n",
    "    fig.add_trace(go.Scattermap(\n",
    "        lat=[lat], lon=[lon],\n",
    "        mode='markers+text',\n",
    "        marker=dict(size=20, color='black', opacity=0.85),\n",
    "        text=str(i),\n",
    "        textfont=dict(size=11, color='white', family='Arial Black'),\n",
    "        textposition='middle center',\n",
    "        name=name,\n",
    "        showlegend=False,\n",
    "        hovertemplate=f'<b>Cluster {i}</b><br>{name}<extra></extra>',\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='2018 Uber: Geographic Demand Clusters',\n",
    "    legend=dict(\n",
    "        title=\"Demand Clusters\",\n",
    "        yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01,\n",
    "        bgcolor=\"rgba(255,255,255,0.95)\",\n",
    "        bordercolor=\"#dde1e7\", borderwidth=1, font=dict(size=12),\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, t=50, b=0),\n",
    "    map=dict(\n",
    "        style='carto-positron-nolabels',\n",
    "        center={'lat': 40.7128, 'lon': -73.9352},\n",
    "        zoom=9.5,\n",
    "    ),\n",
    "    height=700, width=1200,\n",
    ")\n",
    "\n",
    "fig.write_html(OUTPUT_DIR + '1_uber_2018_clusters.html')\n",
    "fig.show()\n",
    "print(\"  ✓ Saved: 1_uber_2018_clusters.html\")\n",
    "\n",
    "# --- 3.1b: 2025 Cluster Choropleth Map ---\n",
    "print(\"\\n[3.1b] 2025 cluster choropleth map...\")\n",
    "\n",
    "zone_clusters_2025 = df_2025.groupby('zone_id').agg({\n",
    "    'cluster': lambda x: x.mode()[0],\n",
    "    'cluster_name': lambda x: x.mode()[0],\n",
    "    'zone_name': 'first',\n",
    "    'borough': 'first'\n",
    "}).reset_index()\n",
    "zone_clusters_2025['zone_id'] = zone_clusters_2025['zone_id'].astype(float).astype(int).astype(str)\n",
    "\n",
    "zone_ids_2025 = set(zone_clusters_2025['zone_id'].values)\n",
    "filtered_geojson_2025 = {\n",
    "    'type': 'FeatureCollection',\n",
    "    'features': [f for f in taxi_zones_geo_4326['features']\n",
    "                 if f['properties']['LocationID'] in zone_ids_2025]\n",
    "}\n",
    "print(f\"  Filtered to {len(filtered_geojson_2025['features'])} zones with data\")\n",
    "\n",
    "fig_2025 = go.Figure()\n",
    "\n",
    "# Grey background\n",
    "fig_tmp_2025 = px.choropleth_map(\n",
    "    zone_clusters_2025,\n",
    "    geojson=filtered_geojson_2025,\n",
    "    locations='zone_id',\n",
    "    featureidkey='properties.LocationID',\n",
    "    color='cluster_name',\n",
    "    color_discrete_map=cluster_color_map_2025,  # ← same color for matched clusters\n",
    "    map_style='carto-positron-nolabels',\n",
    "    zoom=9.5,\n",
    "    center={'lat': 40.7128, 'lon': -73.9352},\n",
    "    opacity=0.95,\n",
    "    hover_data={'zone_id': False, 'zone_name': True, 'borough': True, 'cluster_name': True},\n",
    "    labels={'cluster_name': 'Cluster'}\n",
    ")\n",
    "\n",
    "\n",
    "fig_tmp_2025.update_traces(marker=dict(line=dict(width=0.8, color='rgba(255,255,255,0.8)')))\n",
    "for trace in fig_tmp_2025.data:\n",
    "    fig_2025.add_trace(trace)\n",
    "\n",
    "for i, (lat, lon) in enumerate(centers_2025):\n",
    "    name = cluster_names_2025[i]\n",
    "    fig_2025.add_trace(go.Scattermap(\n",
    "        lat=[lat], lon=[lon],\n",
    "        mode='markers+text',\n",
    "        marker=dict(size=0, color='black', opacity=0.85),\n",
    "        text=str(i),\n",
    "        textfont=dict(size=11, color='white', family='Arial Black'),\n",
    "        textposition='middle center',\n",
    "        name=name,\n",
    "        showlegend=False,\n",
    "        hovertemplate=f'<b>Cluster {i}</b><br>{name}<extra></extra>',\n",
    "    ))\n",
    "\n",
    "fig_2025.update_layout(\n",
    "    title='2025 Uber: Geographic Demand Clusters',\n",
    "    legend=dict(\n",
    "        title=\"Demand Clusters\",\n",
    "        yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01,\n",
    "        bgcolor=\"rgba(255,255,255,0.95)\",\n",
    "        bordercolor=\"#dde1e7\", borderwidth=1, font=dict(size=12),\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, t=50, b=0),\n",
    "    map=dict(\n",
    "        style='carto-positron-nolabels',\n",
    "        center={'lat': 40.7128, 'lon': -73.9352},\n",
    "        zoom=9.5,\n",
    "    ),\n",
    "    height=700, width=1200,\n",
    ")\n",
    "\n",
    "fig_2025.write_html(OUTPUT_DIR + '2_uber_2025_clusters.html')\n",
    "fig_2025.show()\n",
    "print(\"  ✓ Saved: 2_uber_2025_clusters.html\")\n",
    "\n",
    "# --- 3.2: Top zones comparison ---\n",
    "print(\"\\n[3.2] Creating top zones comparison...\")\n",
    "\n",
    "zone_counts_2018 = df_2018.groupby(['zone_id', 'zone_name', 'borough']).size().reset_index(name='count_2018')\n",
    "zone_counts_2025 = df_2025.groupby(['zone_id', 'zone_name', 'borough']).size().reset_index(name='count_2025')\n",
    "\n",
    "zone_comparison = zone_counts_2018.merge(\n",
    "    zone_counts_2025, on=['zone_id', 'zone_name', 'borough'], how='outer'\n",
    ").fillna(0)\n",
    "zone_comparison['share_2018'] = 100 * zone_comparison['count_2018'] / zone_comparison['count_2018'].sum()\n",
    "zone_comparison['share_2025'] = 100 * zone_comparison['count_2025'] / zone_comparison['count_2025'].sum()\n",
    "zone_comparison['share_change'] = zone_comparison['share_2025'] - zone_comparison['share_2018']\n",
    "\n",
    "top_zones = zone_comparison.nlargest(20, 'share_2025')\n",
    "\n",
    "fig_top_zones = go.Figure()\n",
    "fig_top_zones.add_trace(go.Bar(\n",
    "    name='2018',\n",
    "    y=top_zones['zone_name'] + ' (' + top_zones['borough'] + ')',\n",
    "    x=top_zones['share_2018'],\n",
    "    orientation='h',\n",
    "    marker_color='#ff6b6b',\n",
    "    text=[f'{x:.1f}%' for x in top_zones['share_2018']],\n",
    "    textposition='outside'\n",
    "))\n",
    "fig_top_zones.add_trace(go.Bar(\n",
    "    name='2025',\n",
    "    y=top_zones['zone_name'] + ' (' + top_zones['borough'] + ')',\n",
    "    x=top_zones['share_2025'],\n",
    "    orientation='h',\n",
    "    marker_color='#4ecdc4',\n",
    "    text=[f'{x:.1f}%' for x in top_zones['share_2025']],\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "fig_top_zones.update_layout(\n",
    "    title='Top 20 Pickup Zones: 2018 vs 2025 (% of Total Trips)',\n",
    "    xaxis_title='Share of Total Trips (%)',\n",
    "    barmode='group',\n",
    "    height=800, width=1200,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig_top_zones.write_html(OUTPUT_DIR + '3_top_zones_comparison.html')\n",
    "print(f\"  ✓ Saved: 3_top_zones_comparison.html\")\n",
    "\n",
    "# --- 3.3: Hourly patterns (normalized) ---\n",
    "print(\"\\n[3.3] Creating temporal analysis (normalized)...\")\n",
    "\n",
    "hourly_2018 = df_2018.groupby('hour').size()\n",
    "hourly_2025 = df_2025.groupby('hour').size()\n",
    "hourly_2018_pct = 100 * hourly_2018 / hourly_2018.sum()\n",
    "hourly_2025_pct = 100 * hourly_2025 / hourly_2025.sum()\n",
    "\n",
    "fig_hourly = go.Figure()\n",
    "fig_hourly.add_trace(go.Scatter(\n",
    "    x=hourly_2018_pct.index, y=hourly_2018_pct.values, name='2018',\n",
    "    mode='lines+markers', line=dict(color='#ff6b6b', width=3),\n",
    "    hovertemplate='<b>Hour %{x}</b><br>Share: %{y:.2f}%<extra></extra>'\n",
    "))\n",
    "fig_hourly.add_trace(go.Scatter(\n",
    "    x=hourly_2025_pct.index, y=hourly_2025_pct.values, name='2025',\n",
    "    mode='lines+markers', line=dict(color='#4ecdc4', width=3),\n",
    "    hovertemplate='<b>Hour %{x}</b><br>Share: %{y:.2f}%<extra></extra>'\n",
    "))\n",
    "\n",
    "fig_hourly.update_layout(\n",
    "    title='Hourly Demand Pattern: 2018 vs 2025 (% of Daily Trips)',\n",
    "    xaxis_title='Hour of Day',\n",
    "    yaxis_title='Share of Total Trips (%)',\n",
    "    template='plotly_white',\n",
    "    height=500, width=1200,\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig_hourly.write_html(OUTPUT_DIR + '4_hourly_patterns.html')\n",
    "print(f\"  ✓ Saved: 4_hourly_patterns.html\")\n",
    "\n",
    "# --- 3.4: Daily patterns (normalized) ---\n",
    "print(\"\\n[3.4] Creating day-of-week analysis (normalized)...\")\n",
    "\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "daily_2018 = df_2018.groupby('day_name').size().reindex(day_order)\n",
    "daily_2025 = df_2025.groupby('day_name').size().reindex(day_order)\n",
    "daily_2018_pct = 100 * daily_2018 / daily_2018.sum()\n",
    "daily_2025_pct = 100 * daily_2025 / daily_2025.sum()\n",
    "\n",
    "fig_daily = go.Figure()\n",
    "fig_daily.add_trace(go.Bar(\n",
    "    name='2018', x=day_order, y=daily_2018_pct.values, marker_color='#ff6b6b',\n",
    "    text=[f'{x:.1f}%' for x in daily_2018_pct.values], textposition='outside'\n",
    "))\n",
    "fig_daily.add_trace(go.Bar(\n",
    "    name='2025', x=day_order, y=daily_2025_pct.values, marker_color='#4ecdc4',\n",
    "    text=[f'{x:.1f}%' for x in daily_2025_pct.values], textposition='outside'\n",
    "))\n",
    "\n",
    "fig_daily.update_layout(\n",
    "    title='Weekly Demand Pattern: 2018 vs 2025 (% of Weekly Trips)',\n",
    "    xaxis_title='Day of Week',\n",
    "    yaxis_title='Share of Total Trips (%)',\n",
    "    barmode='group',\n",
    "    template='plotly_white',\n",
    "    height=500, width=1200\n",
    ")\n",
    "\n",
    "fig_daily.write_html(OUTPUT_DIR + '5_daily_patterns.html')\n",
    "print(f\"  ✓ Saved: 5_daily_patterns.html\")\n",
    "\n",
    "# --- 3.5: Heatmaps (normalized) ---\n",
    "print(\"\\n[3.5] Creating demand heatmaps (normalized)...\")\n",
    "\n",
    "fig_heat = make_subplots(rows=2, cols=1, subplot_titles=('2018', '2025'), vertical_spacing=0.12)\n",
    "\n",
    "for df, row in [(df_2018, 1), (df_2025, 2)]:\n",
    "    pivot = df.groupby(['day_name', 'hour']).size().reset_index(name='trips')\n",
    "    pivot_table = pivot.pivot(index='day_name', columns='hour', values='trips').reindex(day_order)\n",
    "    pivot_table_pct = 100 * pivot_table / pivot_table.sum().sum()\n",
    "\n",
    "    fig_heat.add_trace(go.Heatmap(\n",
    "        z=pivot_table_pct.values,\n",
    "        x=pivot_table_pct.columns,\n",
    "        y=pivot_table_pct.index,\n",
    "        colorscale='Viridis',\n",
    "        showscale=(row == 2),\n",
    "        colorbar=dict(title='% of Total<br>Trips') if row == 2 else None,\n",
    "        hovertemplate='<b>%{y}, Hour %{x}</b><br>Share: %{z:.2f}%<extra></extra>'\n",
    "    ), row=row, col=1)\n",
    "\n",
    "fig_heat.update_layout(title='Demand Heatmaps: Hour × Day (% of Total Trips)', height=700, width=1200)\n",
    "fig_heat.write_html(OUTPUT_DIR + '6_demand_heatmaps.html')\n",
    "print(f\"  ✓ Saved: 6_demand_heatmaps.html\")\n",
    "\n",
    "# --- 3.6: Borough analysis (normalized) ---\n",
    "print(\"\\n[3.6] Creating borough analysis (normalized)...\")\n",
    "\n",
    "borough_2018 = df_2018.groupby('borough').size()\n",
    "borough_2025 = df_2025.groupby('borough').size()\n",
    "borough_2018_pct = 100 * borough_2018 / borough_2018.sum()\n",
    "borough_2025_pct = 100 * borough_2025 / borough_2025.sum()\n",
    "\n",
    "fig_borough = go.Figure()\n",
    "fig_borough.add_trace(go.Bar(\n",
    "    name='2018', x=borough_2018_pct.index, y=borough_2018_pct.values, marker_color='#ff6b6b',\n",
    "    text=[f'{x:.1f}%' for x in borough_2018_pct.values], textposition='outside'\n",
    "))\n",
    "fig_borough.add_trace(go.Bar(\n",
    "    name='2025', x=borough_2025_pct.index, y=borough_2025_pct.values, marker_color='#4ecdc4',\n",
    "    text=[f'{x:.1f}%' for x in borough_2025_pct.values], textposition='outside'\n",
    "))\n",
    "\n",
    "fig_borough.update_layout(\n",
    "    title='Demand by Borough: 2018 vs 2025 (% of Total Trips)',\n",
    "    xaxis_title='Borough',\n",
    "    yaxis_title='Share of Total Trips (%)',\n",
    "    barmode='group',\n",
    "    template='plotly_white',\n",
    "    height=500, width=1000\n",
    ")\n",
    "\n",
    "fig_borough.write_html(OUTPUT_DIR + '7_borough_analysis.html')\n",
    "print(f\"  ✓ Saved: 7_borough_analysis.html\")\n",
    "\n",
    "# --- 3.7: Cluster shift map (matched, Haversine) ---\n",
    "print(\"\\n[3.7] Creating cluster shift map...\")\n",
    "\n",
    "fig_shifts = go.Figure()\n",
    "\n",
    "for i in range(len(centers_2018)):\n",
    "    fig_shifts.add_trace(go.Scattermap(\n",
    "        lat=[centers_2018[i, 0]], lon=[centers_2018[i, 1]],\n",
    "        mode='markers+text',\n",
    "        marker=dict(size=25, color='#ff6b6b', opacity=0.8),\n",
    "        text=f\"18-{i}\",\n",
    "        textfont=dict(size=10, color='white', family='Arial Black'),\n",
    "        textposition='middle center',\n",
    "        name=f'2018: {cluster_names_2018[i]}',\n",
    "        hovertemplate=f'<b>2018 Cluster {i}</b><br>{cluster_names_2018[i]}<extra></extra>'\n",
    "    ))\n",
    "\n",
    "for i in range(len(centers_2025)):\n",
    "    fig_shifts.add_trace(go.Scattermap(\n",
    "        lat=[centers_2025[i, 0]], lon=[centers_2025[i, 1]],\n",
    "        mode='markers+text',\n",
    "        marker=dict(size=25, color='#4ecdc4', opacity=0.8),\n",
    "        text=f\"25-{i}\",\n",
    "        textfont=dict(size=10, color='white', family='Arial Black'),\n",
    "        textposition='middle center',\n",
    "        name=f'2025: {cluster_names_2025[i]}',\n",
    "        hovertemplate=f'<b>2025 Cluster {i}</b><br>{cluster_names_2025[i]}<extra></extra>'\n",
    "    ))\n",
    "\n",
    "for idx_2018, idx_2025 in cluster_matches.items():\n",
    "    lat1, lon1 = centers_2018[idx_2018]\n",
    "    lat2, lon2 = centers_2025[idx_2025]\n",
    "    dist = haversine_km(lat1, lon1, lat2, lon2)\n",
    "\n",
    "    fig_shifts.add_trace(go.Scattermap(\n",
    "        lat=[lat1, lat2], lon=[lon1, lon2],\n",
    "        mode='lines',\n",
    "        line=dict(width=3, color='black'),\n",
    "        showlegend=False,\n",
    "        hovertemplate=(\n",
    "            f'<b>Shift: {dist:.2f} km</b><br>'\n",
    "            f'From: {cluster_names_2018[idx_2018]}<br>'\n",
    "            f'To: {cluster_names_2025[idx_2025]}<extra></extra>'\n",
    "        )\n",
    "    ))\n",
    "\n",
    "fig_shifts.update_layout(\n",
    "    title='Cluster Center Shifts: 2018 → 2025 (Matched by Geographic Proximity)',\n",
    "    map_style='carto-positron',\n",
    "    map_zoom=10,\n",
    "    map_center=dict(lat=40.75, lon=-73.95),\n",
    "    height=800, width=1400,\n",
    "    legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01, bgcolor=\"rgba(255,255,255,0.9)\")\n",
    ")\n",
    "\n",
    "fig_shifts.write_html(OUTPUT_DIR + '8_cluster_shifts.html')\n",
    "print(f\"  ✓ Saved: 8_cluster_shifts.html\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 4: ADDITIONAL VISUALIZATIONS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 4: ADDITIONAL VISUALIZATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# --- 4.1: Lorenz Curve ---\n",
    "print(\"\\n[4.1] Creating Lorenz curve...\")\n",
    "\n",
    "cz_18, ct_18 = lorenz_data(df_2018)\n",
    "cz_25, ct_25 = lorenz_data(df_2025)\n",
    "gini_18 = gini_from_lorenz(cz_18, ct_18)\n",
    "gini_25 = gini_from_lorenz(cz_25, ct_25)\n",
    "\n",
    "fig_lorenz = go.Figure()\n",
    "\n",
    "fig_lorenz.add_trace(go.Scatter(\n",
    "    x=[0, 1], y=[0, 1],\n",
    "    mode='lines', line=dict(color='#888', width=1.5, dash='dash'),\n",
    "    name='Perfect equality', hoverinfo='skip'\n",
    "))\n",
    "fig_lorenz.add_trace(go.Scatter(\n",
    "    x=np.concatenate([[0], cz_18]), y=np.concatenate([[0], ct_18]),\n",
    "    mode='lines', line=dict(color='#ff6b6b', width=2.5),\n",
    "    name=f'2018 (Gini = {gini_18:.3f})',\n",
    "    hovertemplate='%{x:.0%} of zones → %{y:.0%} of trips<extra>2018</extra>'\n",
    "))\n",
    "fig_lorenz.add_trace(go.Scatter(\n",
    "    x=np.concatenate([[0], cz_25]), y=np.concatenate([[0], ct_25]),\n",
    "    mode='lines', line=dict(color='#4ecdc4', width=2.5),\n",
    "    name=f'2025 (Gini = {gini_25:.3f})',\n",
    "    hovertemplate='%{x:.0%} of zones → %{y:.0%} of trips<extra>2025</extra>'\n",
    "))\n",
    "\n",
    "fig_lorenz.update_layout(\n",
    "    title='Lorenz Curve: Spatial Concentration of Uber Pickups by Zone',\n",
    "    xaxis_title='Cumulative Share of Zones (ranked by trip count)',\n",
    "    yaxis_title='Cumulative Share of Trips',\n",
    "    xaxis=dict(range=[0, 1], tickformat='.0%'),\n",
    "    yaxis=dict(range=[0, 1], tickformat='.0%'),\n",
    "    template='plotly_white',\n",
    "    height=600, width=800,\n",
    "    legend=dict(x=0.05, y=0.95),\n",
    "    annotations=[dict(\n",
    "        x=0.65, y=0.25,\n",
    "        text=f'Gini 2018: {gini_18:.3f}<br>Gini 2025: {gini_25:.3f}',\n",
    "        showarrow=False, font=dict(size=13),\n",
    "        bgcolor='rgba(255,255,255,0.85)',\n",
    "        bordercolor='#ddd', borderwidth=1\n",
    "    )]\n",
    ")\n",
    "\n",
    "fig_lorenz.write_html(OUTPUT_DIR + '9_lorenz_curve.html')\n",
    "print(f\"  ✓ Saved: 9_lorenz_curve.html\")\n",
    "\n",
    "# --- 4.2: Manhattan vs Airports ---\n",
    "print(\"\\n[4.2] Creating Manhattan vs Airports comparison...\")\n",
    "\n",
    "\n",
    "def manhattan_airport_shares(df, zone_col='zone_id', borough_col='borough'):\n",
    "    total = len(df)\n",
    "    result = {}\n",
    "    result['Manhattan'] = len(df[df[borough_col] == 'Manhattan']) / total * 100\n",
    "\n",
    "    for zid, label in AIRPORT_LABELS.items():\n",
    "        result[label] = len(df[df[zone_col] == zid]) / total * 100\n",
    "\n",
    "    result['All Airports'] = len(df[df[zone_col].isin(AIRPORT_ZONE_IDS)]) / total * 100\n",
    "    result['Other'] = 100 - result['Manhattan'] - result['All Airports']\n",
    "    return result\n",
    "\n",
    "\n",
    "shares_18 = manhattan_airport_shares(df_2018)\n",
    "shares_25 = manhattan_airport_shares(df_2025)\n",
    "\n",
    "categories = ['Manhattan', 'JFK', 'LaGuardia', 'Newark (EWR)', 'All Airports', 'Other']\n",
    "vals_18 = [shares_18[c] for c in categories]\n",
    "vals_25 = [shares_25[c] for c in categories]\n",
    "changes = [v25 - v18 for v18, v25 in zip(vals_18, vals_25)]\n",
    "\n",
    "fig_ma = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    row_heights=[0.65, 0.35],\n",
    "    shared_xaxes=True,\n",
    "    vertical_spacing=0.08,\n",
    "    subplot_titles=('Trip Share by Area: 2018 vs 2025', 'Percentage-Point Change (2025 − 2018)')\n",
    ")\n",
    "\n",
    "fig_ma.add_trace(go.Bar(\n",
    "    x=categories, y=vals_18, name='2018', marker_color='#ff6b6b',\n",
    "    text=[f'{v:.1f}%' for v in vals_18], textposition='outside'\n",
    "), row=1, col=1)\n",
    "fig_ma.add_trace(go.Bar(\n",
    "    x=categories, y=vals_25, name='2025', marker_color='#4ecdc4',\n",
    "    text=[f'{v:.1f}%' for v in vals_25], textposition='outside'\n",
    "), row=1, col=1)\n",
    "\n",
    "bar_colors = ['#2ecc71' if c > 0 else '#e74c3c' for c in changes]\n",
    "fig_ma.add_trace(go.Bar(\n",
    "    x=categories, y=changes, marker_color=bar_colors,\n",
    "    text=[f'{c:+.1f} pp' for c in changes], textposition='outside',\n",
    "    showlegend=False\n",
    "), row=2, col=1)\n",
    "fig_ma.add_hline(y=0, line_dash='dot', line_color='#888', row=2, col=1)\n",
    "\n",
    "fig_ma.update_layout(\n",
    "    barmode='group', template='plotly_white',\n",
    "    height=750, width=1000,\n",
    "    legend=dict(x=0.85, y=0.98),\n",
    ")\n",
    "fig_ma.update_yaxes(title_text='Share of Total Trips (%)', row=1, col=1)\n",
    "fig_ma.update_yaxes(title_text='Change (pp)', row=2, col=1)\n",
    "\n",
    "fig_ma.write_html(OUTPUT_DIR + '10_manhattan_vs_airports.html')\n",
    "print(f\"  ✓ Saved: 10_manhattan_vs_airports.html\")\n",
    "\n",
    "# --- 4.3: Improved Cluster Centroid Shift Map ---\n",
    "print(\"\\n[4.3] Creating improved cluster centroid shift map...\")\n",
    "\n",
    "shift_data = []\n",
    "for idx_18, idx_25 in cluster_matches.items():\n",
    "    lat1, lon1 = centers_2018[idx_18]\n",
    "    lat2, lon2 = centers_2025[idx_25]\n",
    "    shift_data.append({\n",
    "        'idx_18': idx_18, 'idx_25': idx_25,\n",
    "        'name_18': cluster_names_2018[idx_18],\n",
    "        'name_25': cluster_names_2025[idx_25],\n",
    "        'dist_km': haversine_km(lat1, lon1, lat2, lon2)\n",
    "    })\n",
    "\n",
    "fig_shift2 = go.Figure()\n",
    "\n",
    "# Grey background\n",
    "fig_shift2.add_trace(go.Choroplethmap(\n",
    "    geojson=taxi_zones_geo_4326,\n",
    "    locations=all_zone_ids,\n",
    "    featureidkey='properties.LocationID',\n",
    "    z=[1] * len(all_zone_ids),\n",
    "    colorscale=[[0, '#e8e8e8'], [1, '#e8e8e8']],\n",
    "    marker_opacity=0.35,\n",
    "    marker_line_width=0.3,\n",
    "    marker_line_color='#ccc',\n",
    "    showscale=False,\n",
    "    hoverinfo='skip',\n",
    "))\n",
    "\n",
    "# Shift lines\n",
    "for sa in shift_data:\n",
    "    lat1, lon1 = centers_2018[sa['idx_18']]\n",
    "    lat2, lon2 = centers_2025[sa['idx_25']]\n",
    "    fig_shift2.add_trace(go.Scattermap(\n",
    "        lat=[lat1, lat2], lon=[lon1, lon2],\n",
    "        mode='lines', line=dict(width=2.5, color='#333'),\n",
    "        showlegend=False,\n",
    "        hovertemplate=(\n",
    "            f\"<b>{sa['name_18']}</b> → <b>{sa['name_25']}</b>\"\n",
    "            f\"<br>Shift: {sa['dist_km']:.2f} km<extra></extra>\"\n",
    "        )\n",
    "    ))\n",
    "\n",
    "# 2018 centroids — circles\n",
    "for i in range(len(centers_2018)):\n",
    "    fig_shift2.add_trace(go.Scattermap(\n",
    "        lat=[centers_2018[i, 0]], lon=[centers_2018[i, 1]],\n",
    "        mode='markers',\n",
    "        marker=dict(size=16, color=CLUSTER_COLORS[i % len(CLUSTER_COLORS)], opacity=0.9),\n",
    "        name=f'2018: {cluster_names_2018[i]}',\n",
    "        legendgroup='2018', legendgrouptitle_text='2018 Centroids',\n",
    "        hovertemplate=f'<b>2018 — Cluster {i}</b><br>{cluster_names_2018[i]}<extra></extra>',\n",
    "    ))\n",
    "\n",
    "# 2025 centroids — squares, same color as matched 2018 cluster\n",
    "for i in range(len(centers_2025)):\n",
    "    matched_18 = [k for k, v in cluster_matches.items() if v == i]\n",
    "    color_idx = matched_18[0] if matched_18 else i\n",
    "    fig_shift2.add_trace(go.Scattermap(\n",
    "        lat=[centers_2025[i, 0]], lon=[centers_2025[i, 1]],\n",
    "        mode='markers',\n",
    "        marker=dict(size=16, color=CLUSTER_COLORS[color_idx % len(CLUSTER_COLORS)],\n",
    "                    opacity=0.9, symbol='square'),\n",
    "        name=f'2025: {cluster_names_2025[i]}',\n",
    "        legendgroup='2025', legendgrouptitle_text='2025 Centroids',\n",
    "        hovertemplate=f'<b>2025 — Cluster {i}</b><br>{cluster_names_2025[i]}<extra></extra>',\n",
    "    ))\n",
    "\n",
    "fig_shift2.update_layout(\n",
    "    title='Cluster Centroid Shifts: 2018 → 2025 (Haversine distances, matched by proximity)',\n",
    "    map_style='carto-positron-nolabels',\n",
    "    map_zoom=9.8,\n",
    "    map_center=dict(lat=40.72, lon=-73.94),\n",
    "    height=750, width=1200,\n",
    "    legend=dict(\n",
    "        yanchor='top', y=0.99, xanchor='left', x=0.01,\n",
    "        bgcolor='rgba(255,255,255,0.92)',\n",
    "        bordercolor='#dde1e7', borderwidth=1, font=dict(size=11),\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, t=50, b=0),\n",
    ")\n",
    "\n",
    "fig_shift2.write_html(OUTPUT_DIR + '11_cluster_shifts_improved.html')\n",
    "print(f\"  ✓ Saved: 11_cluster_shifts_improved.html\")\n",
    "\n",
    "# --- 4.4: Borough Share Treemaps ---\n",
    "print(\"\\n[4.4] Creating borough share treemaps...\")\n",
    "\n",
    "BOROUGH_COLORS = {\n",
    "    'Manhattan': '#4363d8', 'Brooklyn': '#3cb44b', 'Queens': '#f58231',\n",
    "    'Bronx': '#e6194b', 'Staten Island': '#911eb4', 'EWR': '#42d4f4',\n",
    "}\n",
    "\n",
    "borough_df_2018 = df_2018.groupby('borough').size().reset_index(name='trips')\n",
    "borough_df_2018['share'] = borough_df_2018['trips'] / borough_df_2018['trips'].sum()\n",
    "borough_df_2018['label'] = borough_df_2018.apply(\n",
    "    lambda r: f\"{r['borough']}<br>{r['share']:.1%}\", axis=1\n",
    ")\n",
    "\n",
    "borough_df_2025 = df_2025.groupby('borough').size().reset_index(name='trips')\n",
    "borough_df_2025['share'] = borough_df_2025['trips'] / borough_df_2025['trips'].sum()\n",
    "borough_df_2025['label'] = borough_df_2025.apply(\n",
    "    lambda r: f\"{r['borough']}<br>{r['share']:.1%}\", axis=1\n",
    ")\n",
    "\n",
    "fig_tree = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    specs=[[{'type': 'treemap'}, {'type': 'treemap'}]],\n",
    "    subplot_titles=('January 2018', 'January 2025'),\n",
    "    horizontal_spacing=0.03,\n",
    ")\n",
    "\n",
    "fig_tree.add_trace(go.Treemap(\n",
    "    labels=borough_df_2018['label'],\n",
    "    parents=['' for _ in range(len(borough_df_2018))],\n",
    "    values=borough_df_2018['trips'],\n",
    "    marker=dict(\n",
    "        colors=[BOROUGH_COLORS.get(b, '#999') for b in borough_df_2018['borough']],\n",
    "        line_width=1.5\n",
    "    ),\n",
    "    textinfo='label', textfont=dict(size=15),\n",
    "    hovertemplate='<b>%{label}</b><br>Trips: %{value:,.0f}<extra></extra>',\n",
    "), row=1, col=1)\n",
    "\n",
    "fig_tree.add_trace(go.Treemap(\n",
    "    labels=borough_df_2025['label'],\n",
    "    parents=['' for _ in range(len(borough_df_2025))],\n",
    "    values=borough_df_2025['trips'],\n",
    "    marker=dict(\n",
    "        colors=[BOROUGH_COLORS.get(b, '#999') for b in borough_df_2025['borough']],\n",
    "        line_width=1.5\n",
    "    ),\n",
    "    textinfo='label', textfont=dict(size=15),\n",
    "    hovertemplate='<b>%{label}</b><br>Trips: %{value:,.0f}<extra></extra>',\n",
    "), row=1, col=2)\n",
    "\n",
    "fig_tree.update_layout(\n",
    "    height=550, width=1100,\n",
    "    template='plotly_white',\n",
    "    margin=dict(t=80, b=20, l=10, r=10),\n",
    ")\n",
    "\n",
    "fig_tree.write_html(OUTPUT_DIR + '12_borough_treemaps.html')\n",
    "print(f\"  ✓ Saved: 12_borough_treemaps.html\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 5: METRICS & SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PART 5: METRICS & SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "peak_hour_2018 = df_2018.groupby('hour').size().idxmax()\n",
    "peak_hour_2025 = df_2025.groupby('hour').size().idxmax()\n",
    "\n",
    "top_zone_2018 = df_2018.groupby('zone_name').size().idxmax()\n",
    "top_zone_2025 = df_2025.groupby('zone_name').size().idxmax()\n",
    "\n",
    "matched_shifts = [\n",
    "    haversine_km(\n",
    "        centers_2018[i18, 0], centers_2018[i18, 1],\n",
    "        centers_2025[i25, 0], centers_2025[i25, 1]\n",
    "    )\n",
    "    for i18, i25 in cluster_matches.items()\n",
    "]\n",
    "avg_shift = np.mean(matched_shifts)\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    'Metric': [\n",
    "        'Total Trips (All Companies)',\n",
    "        'Uber Trips',\n",
    "        'Uber Market Share (%)',\n",
    "        'Sample Size',\n",
    "        'Unique Zones',\n",
    "        'Top Pickup Zone',\n",
    "        'Peak Hour',\n",
    "        'Most Active Day',\n",
    "        'Gini Coefficient (zone-level)',\n",
    "        'Avg Cluster Shift (km)'\n",
    "    ],\n",
    "    '2018': [\n",
    "        f'{total_2018:,}',\n",
    "        f'{uber_count_2018:,}',\n",
    "        f'{100 * uber_count_2018 / total_2018:.1f}',\n",
    "        f'{len(df_2018):,}',\n",
    "        df_2018['zone_id'].nunique(),\n",
    "        top_zone_2018,\n",
    "        f'{peak_hour_2018}:00',\n",
    "        df_2018.groupby('day_name').size().idxmax(),\n",
    "        f'{gini_18:.4f}',\n",
    "        '-'\n",
    "    ],\n",
    "    '2025': [\n",
    "        f'{total_2025:,}',\n",
    "        f'{uber_count_2025:,}',\n",
    "        f'{100 * uber_count_2025 / total_2025:.1f}',\n",
    "        f'{len(df_2025):,}',\n",
    "        df_2025['zone_id'].nunique(),\n",
    "        top_zone_2025,\n",
    "        f'{peak_hour_2025}:00',\n",
    "        df_2025.groupby('day_name').size().idxmax(),\n",
    "        f'{gini_25:.4f}',\n",
    "        f'{avg_shift:.2f}'\n",
    "    ]\n",
    "})\n",
    "\n",
    "summary.to_csv(OUTPUT_DIR + '13_comprehensive_summary.csv', index=False)\n",
    "print(f\"\\n  ✓ Saved: 13_comprehensive_summary.csv\")\n",
    "\n",
    "zone_comparison.sort_values('count_2025', ascending=False).head(50).to_csv(\n",
    "    OUTPUT_DIR + '14_top_50_zones.csv', index=False\n",
    ")\n",
    "print(f\"  ✓ Saved: 14_top_50_zones.csv\")\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nGenerated 14 files in {OUTPUT_DIR}\")\n",
    "print(f\"  1.  2018 cluster choropleth map\")\n",
    "print(f\"  2.  2025 cluster choropleth map\")\n",
    "print(f\"  3.  Top 20 zones comparison\")\n",
    "print(f\"  4.  Hourly demand patterns\")\n",
    "print(f\"  5.  Daily demand patterns\")\n",
    "print(f\"  6.  Hour × Day heatmaps\")\n",
    "print(f\"  7.  Borough bar chart\")\n",
    "print(f\"  8.  Cluster shift map (basic)\")\n",
    "print(f\"  9.  Lorenz curve\")\n",
    "print(f\"  10. Manhattan vs Airports\")\n",
    "print(f\"  11. Cluster shifts (improved)\")\n",
    "print(f\"  12. Borough treemaps\")\n",
    "print(f\"  13. Summary metrics CSV\")\n",
    "print(f\"  14. Top 50 zones CSV\")\n",
    "\n",
    "print(f\"\\nKey numbers:\")\n",
    "print(f\"  Market share: {100 * uber_count_2018 / total_2018:.1f}% → {100 * uber_count_2025 / total_2025:.1f}%\")\n",
    "print(f\"  Gini (zone-level): {gini_18:.3f} → {gini_25:.3f}\")\n",
    "print(f\"  Avg cluster shift: {avg_shift:.2f} km\")\n",
    "print(f\"  Peak hour: {peak_hour_2018}:00 → {peak_hour_2025}:00\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
