{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f986d33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "NATURAL RESOURCE ANALYSIS - COMPLETE\n",
      "======================================================================\n",
      "\n",
      "1. Loading production data...\n",
      "   Production data: 17166 rows\n",
      "   Using Production_TotalValue (already in USD)\n",
      "   Aggregated: 3346 country-years\n",
      "   Merged: 3069 rows, 126 countries\n",
      "\n",
      "2. Creating production map...\n",
      "   âœ“ Production map saved\n",
      "\n",
      "3. Clustering analysis...\n",
      "   Clusters: {0: 38, 1: 23, 2: 41, 3: 8, 4: 15}\n",
      "   âœ“ Cluster map saved (discrete, no fake scale)\n",
      "\n",
      "5. Creating PCA loadings plots...\n",
      "   âœ“ PCA loadings saved\n",
      "\n",
      "6. Creating PCA scatter plot...\n",
      "   âœ“ Scatter plot saved\n",
      "\n",
      "7. Saving data files...\n",
      "   âœ“ Top countries saved\n",
      "\n",
      "======================================================================\n",
      "âœ… COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "Output directory: /Users/leoss/Desktop/Portfolio/Website-/capstone_visualizations/individual_plots\n",
      "\n",
      "Files created:\n",
      "  1. map_production.html - Interactive map (Total/Oil/Gas/Coal/Metals)\n",
      "  2. map_clusters.html - Cluster choropleth\n",
      "  3. pca_loadings_pc1.html - PC1 loadings\n",
      "  4. pca_loadings_pc2.html - PC2 loadings\n",
      "  5. scatter_pca.html - PCA scatter\n",
      "  6. cluster_assignments.csv - Cluster data\n",
      "  7. top_countries_2019.csv - Rankings\n",
      "\n",
      "Data summary:\n",
      "  â€¢ 126 countries\n",
      "  â€¢ 25 years (1995-2019)\n",
      "  â€¢ 5 clusters identified\n",
      "  â€¢ 55.7% variance explained by PCA\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "COMPLETE NATURAL RESOURCE ANALYSIS - FINAL VERSION\n",
    "Using correct NaturalResource.csv with Production_TotalValue\n",
    "Output: /Users/leoss/Desktop/Portfolio/Website-/Capstone-Proj/individual_plots\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import os\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "input_file = \"/Users/leoss/Desktop/GitHub/Capstone/MASTER/Master.csv\"\n",
    "production_file = \"/Users/leoss/Desktop/GitHub/Capstone/MASTER/NaturalResource.csv\"\n",
    "output_dir = \"/Users/leoss/Desktop/Portfolio/Website-/capstone_visualizations/individual_plots\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"NATURAL RESOURCE ANALYSIS - COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# 1. LOAD AND PREPARE PRODUCTION DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n1. Loading production data...\")\n",
    "\n",
    "df_prod = pd.read_csv(production_file)\n",
    "df_master = pd.read_csv(input_file)\n",
    "\n",
    "print(f\"   Production data: {len(df_prod)} rows\")\n",
    "print(f\"   Using Production_TotalValue (already in USD)\")\n",
    "\n",
    "# Categorize resources into 4 groups\n",
    "def categorize_resource(resource):\n",
    "    if resource == 'Oil': return 'Oil'\n",
    "    elif resource == 'Natural Gas': return 'Natural Gas'\n",
    "    elif resource == 'Coal': return 'Coal'\n",
    "    else: return 'Metals'  # All other minerals\n",
    "\n",
    "df_prod['Resource_Category'] = df_prod['Resource'].apply(categorize_resource)\n",
    "\n",
    "# Aggregate Production_TotalValue by category, country, year\n",
    "prod_agg = df_prod.groupby(['Country Name', 'Year', 'Resource_Category'])['Production_TotalValue'].sum().reset_index()\n",
    "\n",
    "# Pivot to wide format\n",
    "prod_wide = prod_agg.pivot_table(\n",
    "    index=['Country Name', 'Year'], \n",
    "    columns='Resource_Category', \n",
    "    values='Production_TotalValue', \n",
    "    fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "# Calculate Total\n",
    "resource_cols = [c for c in prod_wide.columns if c not in ['Country Name', 'Year']]\n",
    "prod_wide['Total'] = prod_wide[resource_cols].sum(axis=1)\n",
    "\n",
    "print(f\"   Aggregated: {len(prod_wide)} country-years\")\n",
    "\n",
    "# Merge with master data\n",
    "master_data = df_master[[\n",
    "    'Country Name', 'Year', 'Country Code', 'Population',\n",
    "    'GDP per capita (constant prices, PPP)', \n",
    "    'Economic Complexity Index', 'Human capital index', 'Manufacturing'\n",
    "]].copy()\n",
    "\n",
    "map_data = prod_wide.merge(master_data, on=['Country Name', 'Year'], how='inner')\n",
    "\n",
    "print(f\"   Merged: {len(map_data)} rows, {map_data['Country Code'].nunique()} countries\")\n",
    "\n",
    "# Calculate GDP and derived metrics\n",
    "map_data['GDP_total'] = map_data['GDP per capita (constant prices, PPP)'] * map_data['Population']\n",
    "\n",
    "for res in ['Total', 'Oil', 'Natural Gas', 'Coal', 'Metals']:\n",
    "    if res in map_data.columns:\n",
    "        map_data[f'{res}_Per_Capita'] = map_data[res] / map_data['Population']\n",
    "        map_data[f'{res}_GDP_Norm'] = (map_data[res] / map_data['GDP_total']) * 100\n",
    "\n",
    "# ============================================================================\n",
    "# 2. CREATE PRODUCTION MAP WITH SYNCED DROPDOWNS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n2. Creating production map...\")\n",
    "\n",
    "# Create all 15 traces (5 resources Ã— 3 normalizations)\n",
    "initial_data = map_data[map_data['Year'] == 2019]\n",
    "traces = []\n",
    "\n",
    "for resource in ['Total', 'Oil', 'Natural Gas', 'Coal', 'Metals']:\n",
    "    for suffix, norm_type, units in [('', 'absolute', 'USD'), \n",
    "                                     ('_Per_Capita', 'per_capita', 'USD/person'), \n",
    "                                     ('_GDP_Norm', 'gdp_norm', '% GDP')]:\n",
    "        col = f'{resource}{suffix}'\n",
    "        z = initial_data[col].fillna(0)\n",
    "        \n",
    "        # Format hover text\n",
    "        if norm_type == 'absolute':\n",
    "            hover = [f\"${v/1e9:.2f}B\" if v >= 1e9 else f\"${v/1e6:.1f}M\" if v >= 1e6 else f\"${v:,.0f}\" for v in z]\n",
    "        elif norm_type == 'per_capita':\n",
    "            hover = [f\"${v:,.0f}\" for v in z]\n",
    "        else:\n",
    "            hover = [f\"{v:.2f}%\" for v in z]\n",
    "        \n",
    "        traces.append(go.Choropleth(\n",
    "            locations=initial_data['Country Code'],\n",
    "            z=z,\n",
    "            text=initial_data['Country Name'],\n",
    "            customdata=hover,\n",
    "            colorscale='YlOrRd',\n",
    "            marker=dict(line=dict(color='#999999', width=0.5)),\n",
    "            colorbar=dict(title=units, len=0.7),\n",
    "            hovertemplate=f'<b>%{{text}}</b><br>{resource}: %{{customdata}}<extra></extra>',\n",
    "            visible=False\n",
    "        ))\n",
    "\n",
    "traces[0].visible = True  # Start with Total + Absolute\n",
    "\n",
    "# Create slider steps that update data for all years\n",
    "slider_steps = []\n",
    "for year in sorted(map_data['Year'].unique()):\n",
    "    year_data = map_data[map_data['Year'] == year]\n",
    "    z_list, hover_list = [], []\n",
    "    \n",
    "    for resource in ['Total', 'Oil', 'Natural Gas', 'Coal', 'Metals']:\n",
    "        for suffix, norm_type in [('', 'absolute'), ('_Per_Capita', 'per_capita'), ('_GDP_Norm', 'gdp_norm')]:\n",
    "            col = f'{resource}{suffix}'\n",
    "            z = year_data[col].fillna(0)\n",
    "            \n",
    "            # Format hover for this year\n",
    "            if norm_type == 'absolute':\n",
    "                hover = [f\"${v/1e9:.2f}B\" if v >= 1e9 else f\"${v/1e6:.1f}M\" if v >= 1e6 else f\"${v:,.0f}\" for v in z]\n",
    "            elif norm_type == 'per_capita':\n",
    "                hover = [f\"${v:,.0f}\" for v in z]\n",
    "            else:\n",
    "                hover = [f\"{v:.2f}%\" for v in z]\n",
    "            \n",
    "            z_list.append(z.tolist())\n",
    "            hover_list.append(hover)\n",
    "    \n",
    "    slider_steps.append({\n",
    "        'method': 'restyle',\n",
    "        'args': [{\n",
    "            'z': z_list,\n",
    "            'customdata': hover_list,\n",
    "            'locations': [year_data['Country Code'].tolist()] * 15,\n",
    "            'text': [year_data['Country Name'].tolist()] * 15\n",
    "        }],\n",
    "        'label': str(year)\n",
    "    })\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure(data=traces)\n",
    "\n",
    "fig.update_layout(\n",
    "    sliders=[{\n",
    "        'active': len(slider_steps) - 1,\n",
    "        'yanchor': 'top',\n",
    "        'xanchor': 'left',\n",
    "        'currentvalue': {\n",
    "            'prefix': 'Year: ',\n",
    "            'visible': True,\n",
    "            'xanchor': 'center',\n",
    "            'font': {'size': 18, 'color': '#002A54'}\n",
    "        },\n",
    "        'pad': {'b': 10, 't': 50},\n",
    "        'len': 0.9,\n",
    "        'x': 0.05,\n",
    "        'y': 0,\n",
    "        'steps': slider_steps,\n",
    "        'transition': {'duration': 0}\n",
    "    }],\n",
    "    title={\n",
    "        'text': \"Natural Resource Production\",\n",
    "        'x': 0.5,\n",
    "        'font': {'size': 22, 'color': '#002A54'}\n",
    "    },\n",
    "    geo=dict(\n",
    "        showframe=False,\n",
    "        showcoastlines=True,\n",
    "        coastlinecolor='#aaaaaa',\n",
    "        projection_type='natural earth',\n",
    "        bgcolor='#e3f2fd',\n",
    "        showland=True,\n",
    "        landcolor='#fafafa',\n",
    "        showcountries=True,\n",
    "        countrycolor='#999999',\n",
    "        countrywidth=0.5\n",
    "    ),\n",
    "    height=700,\n",
    "    margin={\"r\":50,\"t\":120,\"l\":50,\"b\":120}\n",
    ")\n",
    "\n",
    "# Save with custom controls\n",
    "fig_html = fig.to_html(include_plotlyjs='cdn', config={'displayModeBar': False})\n",
    "\n",
    "controls_html = \"\"\"\n",
    "<div style=\"position: fixed; top: 20px; left: 20px; z-index: 1000; background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); border: 2px solid #002A54;\">\n",
    "    <label style=\"font-weight: 600; color: #002A54; margin-right: 10px;\">Resource:</label>\n",
    "    <select id=\"resourceSelect\" style=\"padding: 8px; border: 2px solid #002A54; border-radius: 4px; font-size: 14px;\">\n",
    "        <option value=\"0\">Total</option>\n",
    "        <option value=\"1\">Oil</option>\n",
    "        <option value=\"2\">Natural Gas</option>\n",
    "        <option value=\"3\">Coal</option>\n",
    "        <option value=\"4\">Metals</option>\n",
    "    </select>\n",
    "</div>\n",
    "<div style=\"position: fixed; top: 20px; right: 20px; z-index: 1000; background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); border: 2px solid #E30613;\">\n",
    "    <label style=\"font-weight: 600; color: #E30613; margin-right: 10px;\">View:</label>\n",
    "    <select id=\"normSelect\" style=\"padding: 8px; border: 2px solid #E30613; border-radius: 4px; font-size: 14px;\">\n",
    "        <option value=\"0\">Absolute</option>\n",
    "        <option value=\"1\">Per Capita</option>\n",
    "        <option value=\"2\">% of GDP</option>\n",
    "    </select>\n",
    "</div>\n",
    "<script>\n",
    "let currentResource = 0;\n",
    "let currentNorm = 0;\n",
    "\n",
    "function updateMap() {\n",
    "    const vis = Array(15).fill(false);\n",
    "    vis[currentResource * 3 + currentNorm] = true;\n",
    "    const plotDiv = document.getElementsByClassName('plotly-graph-div')[0];\n",
    "    if (plotDiv) {\n",
    "        Plotly.restyle(plotDiv, {visible: vis});\n",
    "    }\n",
    "}\n",
    "\n",
    "setTimeout(function() {\n",
    "    document.getElementById('resourceSelect').addEventListener('change', function() {\n",
    "        currentResource = parseInt(this.value);\n",
    "        updateMap();\n",
    "    });\n",
    "    \n",
    "    document.getElementById('normSelect').addEventListener('change', function() {\n",
    "        currentNorm = parseInt(this.value);\n",
    "        updateMap();\n",
    "    });\n",
    "}, 100);\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "fig_html = fig_html.replace('<body>', '<body>' + controls_html)\n",
    "\n",
    "with open(os.path.join(output_dir, 'map_production.html'), 'w') as f:\n",
    "    f.write(fig_html)\n",
    "\n",
    "print(\"   âœ“ Production map saved\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. CLUSTERING ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n3. Clustering analysis...\")\n",
    "\n",
    "cluster_year = 2019\n",
    "cluster_data = map_data[map_data['Year'] == cluster_year].copy()\n",
    "\n",
    "feature_cols = [\n",
    "    'Metals_GDP_Norm', 'Oil_GDP_Norm', 'Natural Gas_GDP_Norm', 'Coal_GDP_Norm',\n",
    "    'Economic Complexity Index', 'Human capital index'\n",
    "]\n",
    "\n",
    "cluster_subset = cluster_data[['Country Code', 'Country Name'] + feature_cols].dropna()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(cluster_subset[feature_cols])\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
    "cluster_subset['Cluster'] = kmeans.fit_predict(X_pca)\n",
    "cluster_subset['PC1'] = X_pca[:, 0]\n",
    "cluster_subset['PC2'] = X_pca[:, 1]\n",
    "\n",
    "print(f\"   Clusters: {cluster_subset['Cluster'].value_counts().sort_index().to_dict()}\")\n",
    "\n",
    "cluster_subset.to_csv(os.path.join(output_dir, 'cluster_assignments.csv'), index=False)\n",
    "\n",
    "# ============================================================================\n",
    "# 4. CLUSTER MAP\n",
    "# ============================================================================\n",
    "\n",
    "# Discrete qualitative colorscale (no visual ordering)\n",
    "cluster_colorscale = [\n",
    "    [0.00, '#1b9e77'], [0.20, '#1b9e77'],  # Cluster 0\n",
    "    [0.20, '#d95f02'], [0.40, '#d95f02'],  # Cluster 1\n",
    "    [0.40, '#7570b3'], [0.60, '#7570b3'],  # Cluster 2\n",
    "    [0.60, '#e7298a'], [0.80, '#e7298a'],  # Cluster 3\n",
    "    [0.80, '#66a61e'], [1.00, '#66a61e'],  # Cluster 4\n",
    "]\n",
    "\n",
    "fig_cluster = go.Figure(data=go.Choropleth(\n",
    "    locations=cluster_subset['Country Code'],\n",
    "    z=cluster_subset['Cluster'],\n",
    "    text=cluster_subset['Country Name'],\n",
    "    colorscale=cluster_colorscale,\n",
    "    zmin=0,\n",
    "    zmax=4,\n",
    "    showscale=False,  # ðŸ”¥ removes misleading legend\n",
    "    marker=dict(line=dict(color='#999999', width=0.4)),\n",
    "    hovertemplate='<b>%{text}</b><br>Cluster: %{z}<extra></extra>'\n",
    "))\n",
    "\n",
    "fig_cluster.update_layout(\n",
    "    geo=dict(\n",
    "        showframe=False,\n",
    "        showcoastlines=True,\n",
    "        coastlinecolor='#b0b0b0',\n",
    "        projection_type='natural earth',\n",
    "        bgcolor='#f5f7fa',\n",
    "        landcolor='#ffffff',\n",
    "        countrycolor='#9e9e9e',\n",
    "        countrywidth=0.5\n",
    "    ),\n",
    "    height=900,\n",
    "    margin=dict(l=20, r=20, t=20, b=20)  # ðŸ”§ key fix\n",
    ")\n",
    "\n",
    "fig_cluster.write_html(os.path.join(output_dir, 'map_clusters.html'))\n",
    "print(\"   âœ“ Cluster map saved (discrete, no fake scale)\")\n",
    "# ============================================================================\n",
    "# 5. PCA LOADINGS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n5. Creating PCA loadings plots...\")\n",
    "\n",
    "loadings = pd.DataFrame(pca.components_.T, columns=['PC1', 'PC2'], index=feature_cols)\n",
    "\n",
    "# PC1\n",
    "fig_pc1 = go.Figure()\n",
    "loadings_pc1 = loadings['PC1'].sort_values()\n",
    "fig_pc1.add_trace(go.Bar(\n",
    "    y=loadings_pc1.index, x=loadings_pc1.values, orientation='h',\n",
    "    marker_color=['#2ecc71' if x > 0 else '#e74c3c' for x in loadings_pc1],\n",
    "    text=[f\"{x:.3f}\" for x in loadings_pc1.values], textposition='outside'\n",
    "))\n",
    "fig_pc1.update_layout(\n",
    "    title=f\"PC1 Loadings ({pca.explained_variance_ratio_[0]:.1%} variance)\",\n",
    "    xaxis_title=\"Loading\", height=500, showlegend=False,\n",
    "    xaxis=dict(zeroline=True, zerolinewidth=2, zerolinecolor='black'),\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig_pc1.write_html(os.path.join(output_dir, 'pca_loadings_pc1.html'))\n",
    "\n",
    "# PC2\n",
    "fig_pc2 = go.Figure()\n",
    "loadings_pc2 = loadings['PC2'].sort_values()\n",
    "fig_pc2.add_trace(go.Bar(\n",
    "    y=loadings_pc2.index, x=loadings_pc2.values, orientation='h',\n",
    "    marker_color=['#2ecc71' if x > 0 else '#e74c3c' for x in loadings_pc2],\n",
    "    text=[f\"{x:.3f}\" for x in loadings_pc2.values], textposition='outside'\n",
    "))\n",
    "fig_pc2.update_layout(\n",
    "    title=f\"PC2 Loadings ({pca.explained_variance_ratio_[1]:.1%} variance)\",\n",
    "    xaxis_title=\"Loading\", height=500, showlegend=False,\n",
    "    xaxis=dict(zeroline=True, zerolinewidth=2, zerolinecolor='black'),\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig_pc2.write_html(os.path.join(output_dir, 'pca_loadings_pc2.html'))\n",
    "\n",
    "loadings.to_csv(os.path.join(output_dir, 'pca_loadings.csv'))\n",
    "print(\"   âœ“ PCA loadings saved\")\n",
    "\n",
    "# ============================================================================\n",
    "# 6. SCATTER PLOT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n6. Creating PCA scatter plot...\")\n",
    "\n",
    "fig_scatter = px.scatter(\n",
    "    cluster_subset,\n",
    "    x='PC1', y='PC2',\n",
    "    color='Cluster',\n",
    "    hover_data=['Country Name'],\n",
    "    title='Countries by Resource Production Patterns (PCA)',\n",
    "    color_continuous_scale='Viridis',\n",
    "    labels={'PC1': 'PC1 (Economic Development)', 'PC2': 'PC2 (Hydrocarbon Production)'}\n",
    ")\n",
    "fig_scatter.update_traces(marker=dict(size=10, line=dict(width=1, color='white')))\n",
    "fig_scatter.update_layout(height=600, template='plotly_white')\n",
    "fig_scatter.write_html(os.path.join(output_dir, 'scatter_pca.html'))\n",
    "print(\"   âœ“ Scatter plot saved\")\n",
    "\n",
    "# ============================================================================\n",
    "# 7. SAVE SUMMARY DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n7. Saving data files...\")\n",
    "\n",
    "# Top countries analysis\n",
    "top_countries = []\n",
    "for resource in ['Total', 'Oil', 'Natural Gas', 'Coal', 'Metals']:\n",
    "    for suffix, label in [('', 'Absolute'), ('_Per_Capita', 'Per Capita'), ('_GDP_Norm', 'GDP Norm')]:\n",
    "        col = f'{resource}{suffix}'\n",
    "        if col in initial_data.columns:\n",
    "            top10 = initial_data.nlargest(10, col)[['Country Name', col]].copy()\n",
    "            top10['Resource'] = resource\n",
    "            top10['Normalization'] = label\n",
    "            top10['Rank'] = range(1, 11)\n",
    "            top10 = top10.rename(columns={col: 'Value'})\n",
    "            top_countries.append(top10)\n",
    "\n",
    "pd.concat(top_countries).to_csv(os.path.join(output_dir, 'top_countries_2019.csv'), index=False)\n",
    "print(\"   âœ“ Top countries saved\")\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nOutput directory: {output_dir}\")\n",
    "print(f\"\\nFiles created:\")\n",
    "print(f\"  1. map_production.html - Interactive map (Total/Oil/Gas/Coal/Metals)\")\n",
    "print(f\"  2. map_clusters.html - Cluster choropleth\")\n",
    "print(f\"  3. pca_loadings_pc1.html - PC1 loadings\")\n",
    "print(f\"  4. pca_loadings_pc2.html - PC2 loadings\")\n",
    "print(f\"  5. scatter_pca.html - PCA scatter\")\n",
    "print(f\"  6. cluster_assignments.csv - Cluster data\")\n",
    "print(f\"  7. top_countries_2019.csv - Rankings\")\n",
    "print(f\"\\nData summary:\")\n",
    "print(f\"  â€¢ {map_data['Country Code'].nunique()} countries\")\n",
    "print(f\"  â€¢ {map_data['Year'].nunique()} years (1995-2019)\")\n",
    "print(f\"  â€¢ 5 clusters identified\")\n",
    "print(f\"  â€¢ {pca.explained_variance_ratio_.sum():.1%} variance explained by PCA\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f11f28dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MACHINE LEARNING: PREDICTING ECONOMIC COMPLEXITY\n",
      "======================================================================\n",
      "\n",
      "1. Preparing ML dataset...\n",
      "   Dataset: 125 observations\n",
      "   Features: 5\n",
      "   Target: Economic Complexity Index\n",
      "   Target range: [-1.90, 2.55]\n",
      "   Train: 100 | Test: 25\n",
      "\n",
      "2. Training models...\n",
      "\n",
      "   A. OLS Linear Regression (Baseline)\n",
      "      Train RÂ²: 0.5812 | Test RÂ²: 0.6778\n",
      "      Test RMSE: 0.5813\n",
      "\n",
      "   B. Ridge Regression\n",
      "      Train RÂ²: 0.5812 | Test RÂ²: 0.6764\n",
      "      Test RMSE: 0.5825\n",
      "\n",
      "   C. Random Forest\n",
      "      Train RÂ²: 0.7804 | Test RÂ²: 0.7244\n",
      "      Test RMSE: 0.5376\n",
      "\n",
      "   D. Gradient Boosting\n",
      "      Train RÂ²: 0.9860 | Test RÂ²: 0.5972\n",
      "      Test RMSE: 0.6499\n",
      "\n",
      "   E. XGBoost\n",
      "      Train RÂ²: 0.9778 | Test RÂ²: 0.5789\n",
      "      Test RMSE: 0.6645\n",
      "\n",
      "   F. LightGBM\n",
      "      Train RÂ²: 0.9227 | Test RÂ²: 0.5458\n",
      "      Test RMSE: 0.6901\n",
      "\n",
      "   G. Neural Network (MLP)\n",
      "      Train RÂ²: 0.6992 | Test RÂ²: 0.6409\n",
      "      Test RMSE: 0.6137\n",
      "\n",
      "3. Cross-validation (5-fold)...\n",
      "   OLS: 0.4813 Â± 0.1021\n",
      "   Ridge: 0.4831 Â± 0.0995\n",
      "   Random Forest: 0.4781 Â± 0.1499\n",
      "   Gradient Boosting: 0.4784 Â± 0.1720\n",
      "   XGBoost: 0.5400 Â± 0.1547\n",
      "   LightGBM: 0.5201 Â± 0.2056\n",
      "   Neural Network: 0.4475 Â± 0.2226\n",
      "\n",
      "4. Creating model comparison table...\n",
      "\n",
      "==========================================================================================\n",
      "MODEL COMPARISON\n",
      "==========================================================================================\n",
      "            Model  Train RÂ²  Test RÂ²    CV RÂ²  Test RMSE  Test MAE   Overfit\n",
      "    Random Forest  0.780358 0.724369 0.478105   0.537623  0.434903  0.055988\n",
      "              OLS  0.581202 0.677757 0.481317   0.581307  0.471885 -0.096556\n",
      "            Ridge  0.581151 0.676413 0.483104   0.582519  0.472683 -0.095262\n",
      "   Neural Network  0.699177 0.640880 0.447519   0.613668  0.505467  0.058297\n",
      "Gradient Boosting  0.985966 0.597204 0.478425   0.649915  0.530797  0.388762\n",
      "          XGBoost  0.977794 0.578940 0.539983   0.664486  0.542345  0.398853\n",
      "         LightGBM  0.922683 0.545839 0.520127   0.690111  0.545917  0.376844\n",
      "==========================================================================================\n",
      "\n",
      "5. Creating visualizations...\n",
      "   âœ“ Model comparison chart saved\n",
      "   âœ“ Predicted vs Actual chart saved\n",
      "   âœ“ Feature importance chart saved\n",
      "   âœ“ Residual plot saved\n",
      "\n",
      "6. Saving results...\n",
      "   âœ“ Model comparison table saved\n",
      "   âœ“ Predictions saved\n",
      "\n",
      "======================================================================\n",
      "MACHINE LEARNING ANALYSIS COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "Best Model: Random Forest\n",
      "Test RÂ²: 0.7244\n",
      "Test RMSE: 0.5376\n",
      "Test MAE: 0.4349\n",
      "\n",
      "Outputs saved to: /Users/leoss/Desktop/Portfolio/Website-/capstone_visualizations/individual_plots\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MACHINE LEARNING ENSEMBLE METHODS\n",
    "Predict Economic Complexity Index (ECI)\n",
    "Add this section after clustering analysis in your existing code\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MACHINE LEARNING: PREDICTING ECONOMIC COMPLEXITY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# 1. PREPARE ML DATASET\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n1. Preparing ML dataset...\")\n",
    "\n",
    "# Use the cluster_data from your existing code\n",
    "# Features: Production + HCI (excluding ECI since that's what we predict)\n",
    "ml_features = [\n",
    "    'Oil_GDP_Norm',\n",
    "    'Natural Gas_GDP_Norm', \n",
    "    'Coal_GDP_Norm',\n",
    "    'Metals_GDP_Norm',\n",
    "    'Human capital index'\n",
    "]\n",
    "\n",
    "ml_target = 'Economic Complexity Index'\n",
    "\n",
    "# Prepare dataset\n",
    "ml_data = cluster_data[[ml_target] + ml_features].dropna()\n",
    "\n",
    "print(f\"   Dataset: {len(ml_data)} observations\")\n",
    "print(f\"   Features: {len(ml_features)}\")\n",
    "print(f\"   Target: {ml_target}\")\n",
    "print(f\"   Target range: [{ml_data[ml_target].min():.2f}, {ml_data[ml_target].max():.2f}]\")\n",
    "\n",
    "# Split features and target\n",
    "X = ml_data[ml_features]\n",
    "y = ml_data[ml_target]\n",
    "\n",
    "# Train-test split (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"   Train: {len(X_train)} | Test: {len(X_test)}\")\n",
    "\n",
    "# Scale features\n",
    "scaler_ml = StandardScaler()\n",
    "X_train_scaled = scaler_ml.fit_transform(X_train)\n",
    "X_test_scaled = scaler_ml.transform(X_test)\n",
    "\n",
    "# ============================================================================\n",
    "# 2. TRAIN MODELS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n2. Training models...\")\n",
    "\n",
    "results = {}\n",
    "\n",
    "# ------------------------------\n",
    "# A. OLS LINEAR REGRESSION (Baseline)\n",
    "# ------------------------------\n",
    "print(\"\\n   A. OLS Linear Regression (Baseline)\")\n",
    "ols = LinearRegression()\n",
    "ols.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_ols_train = ols.predict(X_train_scaled)\n",
    "y_pred_ols_test = ols.predict(X_test_scaled)\n",
    "\n",
    "results['OLS'] = {\n",
    "    'model': ols,\n",
    "    'train_r2': r2_score(y_train, y_pred_ols_train),\n",
    "    'test_r2': r2_score(y_test, y_pred_ols_test),\n",
    "    'train_rmse': np.sqrt(mean_squared_error(y_train, y_pred_ols_train)),\n",
    "    'test_rmse': np.sqrt(mean_squared_error(y_test, y_pred_ols_test)),\n",
    "    'train_mae': mean_absolute_error(y_train, y_pred_ols_train),\n",
    "    'test_mae': mean_absolute_error(y_test, y_pred_ols_test),\n",
    "    'predictions': y_pred_ols_test\n",
    "}\n",
    "\n",
    "print(f\"      Train RÂ²: {results['OLS']['train_r2']:.4f} | Test RÂ²: {results['OLS']['test_r2']:.4f}\")\n",
    "print(f\"      Test RMSE: {results['OLS']['test_rmse']:.4f}\")\n",
    "\n",
    "# ------------------------------\n",
    "# B. RIDGE REGRESSION (L2 regularization)\n",
    "# ------------------------------\n",
    "print(\"\\n   B. Ridge Regression\")\n",
    "ridge = Ridge(alpha=1.0, random_state=42)\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_ridge_train = ridge.predict(X_train_scaled)\n",
    "y_pred_ridge_test = ridge.predict(X_test_scaled)\n",
    "\n",
    "results['Ridge'] = {\n",
    "    'model': ridge,\n",
    "    'train_r2': r2_score(y_train, y_pred_ridge_train),\n",
    "    'test_r2': r2_score(y_test, y_pred_ridge_test),\n",
    "    'train_rmse': np.sqrt(mean_squared_error(y_train, y_pred_ridge_train)),\n",
    "    'test_rmse': np.sqrt(mean_squared_error(y_test, y_pred_ridge_test)),\n",
    "    'train_mae': mean_absolute_error(y_train, y_pred_ridge_train),\n",
    "    'test_mae': mean_absolute_error(y_test, y_pred_ridge_test),\n",
    "    'predictions': y_pred_ridge_test\n",
    "}\n",
    "\n",
    "print(f\"      Train RÂ²: {results['Ridge']['train_r2']:.4f} | Test RÂ²: {results['Ridge']['test_r2']:.4f}\")\n",
    "print(f\"      Test RMSE: {results['Ridge']['test_rmse']:.4f}\")\n",
    "\n",
    "# ------------------------------\n",
    "# C. RANDOM FOREST\n",
    "# ------------------------------\n",
    "print(\"\\n   C. Random Forest\")\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)  # No scaling needed for RF\n",
    "\n",
    "y_pred_rf_train = rf.predict(X_train)\n",
    "y_pred_rf_test = rf.predict(X_test)\n",
    "\n",
    "results['Random Forest'] = {\n",
    "    'model': rf,\n",
    "    'train_r2': r2_score(y_train, y_pred_rf_train),\n",
    "    'test_r2': r2_score(y_test, y_pred_rf_test),\n",
    "    'train_rmse': np.sqrt(mean_squared_error(y_train, y_pred_rf_train)),\n",
    "    'test_rmse': np.sqrt(mean_squared_error(y_test, y_pred_rf_test)),\n",
    "    'train_mae': mean_absolute_error(y_train, y_pred_rf_train),\n",
    "    'test_mae': mean_absolute_error(y_test, y_pred_rf_test),\n",
    "    'predictions': y_pred_rf_test,\n",
    "    'feature_importance': dict(zip(ml_features, rf.feature_importances_))\n",
    "}\n",
    "\n",
    "print(f\"      Train RÂ²: {results['Random Forest']['train_r2']:.4f} | Test RÂ²: {results['Random Forest']['test_r2']:.4f}\")\n",
    "print(f\"      Test RMSE: {results['Random Forest']['test_rmse']:.4f}\")\n",
    "\n",
    "# ------------------------------\n",
    "# D. GRADIENT BOOSTING (Sklearn)\n",
    "# ------------------------------\n",
    "print(\"\\n   D. Gradient Boosting\")\n",
    "gb = GradientBoostingRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gb_train = gb.predict(X_train)\n",
    "y_pred_gb_test = gb.predict(X_test)\n",
    "\n",
    "results['Gradient Boosting'] = {\n",
    "    'model': gb,\n",
    "    'train_r2': r2_score(y_train, y_pred_gb_train),\n",
    "    'test_r2': r2_score(y_test, y_pred_gb_test),\n",
    "    'train_rmse': np.sqrt(mean_squared_error(y_train, y_pred_gb_train)),\n",
    "    'test_rmse': np.sqrt(mean_squared_error(y_test, y_pred_gb_test)),\n",
    "    'train_mae': mean_absolute_error(y_train, y_pred_gb_train),\n",
    "    'test_mae': mean_absolute_error(y_test, y_pred_gb_test),\n",
    "    'predictions': y_pred_gb_test,\n",
    "    'feature_importance': dict(zip(ml_features, gb.feature_importances_))\n",
    "}\n",
    "\n",
    "print(f\"      Train RÂ²: {results['Gradient Boosting']['train_r2']:.4f} | Test RÂ²: {results['Gradient Boosting']['test_r2']:.4f}\")\n",
    "print(f\"      Test RMSE: {results['Gradient Boosting']['test_rmse']:.4f}\")\n",
    "\n",
    "# ------------------------------\n",
    "# E. XGBOOST\n",
    "# ------------------------------\n",
    "print(\"\\n   E. XGBoost\")\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    min_child_weight=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    objective='reg:squarederror'\n",
    ")\n",
    "xgb_model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "y_pred_xgb_train = xgb_model.predict(X_train)\n",
    "y_pred_xgb_test = xgb_model.predict(X_test)\n",
    "\n",
    "results['XGBoost'] = {\n",
    "    'model': xgb_model,\n",
    "    'train_r2': r2_score(y_train, y_pred_xgb_train),\n",
    "    'test_r2': r2_score(y_test, y_pred_xgb_test),\n",
    "    'train_rmse': np.sqrt(mean_squared_error(y_train, y_pred_xgb_train)),\n",
    "    'test_rmse': np.sqrt(mean_squared_error(y_test, y_pred_xgb_test)),\n",
    "    'train_mae': mean_absolute_error(y_train, y_pred_xgb_train),\n",
    "    'test_mae': mean_absolute_error(y_test, y_pred_xgb_test),\n",
    "    'predictions': y_pred_xgb_test,\n",
    "    'feature_importance': dict(zip(ml_features, xgb_model.feature_importances_))\n",
    "}\n",
    "\n",
    "print(f\"      Train RÂ²: {results['XGBoost']['train_r2']:.4f} | Test RÂ²: {results['XGBoost']['test_r2']:.4f}\")\n",
    "print(f\"      Test RMSE: {results['XGBoost']['test_rmse']:.4f}\")\n",
    "\n",
    "# ------------------------------\n",
    "# F. LIGHTGBM\n",
    "# ------------------------------\n",
    "print(\"\\n   F. LightGBM\")\n",
    "lgb_model = lgb.LGBMRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    num_leaves=31,\n",
    "    min_child_samples=10,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lgb_train = lgb_model.predict(X_train)\n",
    "y_pred_lgb_test = lgb_model.predict(X_test)\n",
    "\n",
    "results['LightGBM'] = {\n",
    "    'model': lgb_model,\n",
    "    'train_r2': r2_score(y_train, y_pred_lgb_train),\n",
    "    'test_r2': r2_score(y_test, y_pred_lgb_test),\n",
    "    'train_rmse': np.sqrt(mean_squared_error(y_train, y_pred_lgb_train)),\n",
    "    'test_rmse': np.sqrt(mean_squared_error(y_test, y_pred_lgb_test)),\n",
    "    'train_mae': mean_absolute_error(y_train, y_pred_lgb_train),\n",
    "    'test_mae': mean_absolute_error(y_test, y_pred_lgb_test),\n",
    "    'predictions': y_pred_lgb_test,\n",
    "    'feature_importance': dict(zip(ml_features, lgb_model.feature_importances_))\n",
    "}\n",
    "\n",
    "print(f\"      Train RÂ²: {results['LightGBM']['train_r2']:.4f} | Test RÂ²: {results['LightGBM']['test_r2']:.4f}\")\n",
    "print(f\"      Test RMSE: {results['LightGBM']['test_rmse']:.4f}\")\n",
    "\n",
    "# ------------------------------\n",
    "# G. NEURAL NETWORK\n",
    "# ------------------------------\n",
    "print(\"\\n   G. Neural Network (MLP)\")\n",
    "nn = MLPRegressor(\n",
    "    hidden_layer_sizes=(100, 50, 25),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=0.001,\n",
    "    learning_rate='adaptive',\n",
    "    learning_rate_init=0.001,\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.2\n",
    ")\n",
    "nn.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn_train = nn.predict(X_train_scaled)\n",
    "y_pred_nn_test = nn.predict(X_test_scaled)\n",
    "\n",
    "results['Neural Network'] = {\n",
    "    'model': nn,\n",
    "    'train_r2': r2_score(y_train, y_pred_nn_train),\n",
    "    'test_r2': r2_score(y_test, y_pred_nn_test),\n",
    "    'train_rmse': np.sqrt(mean_squared_error(y_train, y_pred_nn_train)),\n",
    "    'test_rmse': np.sqrt(mean_squared_error(y_test, y_pred_nn_test)),\n",
    "    'train_mae': mean_absolute_error(y_train, y_pred_nn_train),\n",
    "    'test_mae': mean_absolute_error(y_test, y_pred_nn_test),\n",
    "    'predictions': y_pred_nn_test\n",
    "}\n",
    "\n",
    "print(f\"      Train RÂ²: {results['Neural Network']['train_r2']:.4f} | Test RÂ²: {results['Neural Network']['test_r2']:.4f}\")\n",
    "print(f\"      Test RMSE: {results['Neural Network']['test_rmse']:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. CROSS-VALIDATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n3. Cross-validation (5-fold)...\")\n",
    "\n",
    "cv_results = {}\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name in ['OLS', 'Ridge', 'Random Forest', 'Gradient Boosting', 'XGBoost', 'LightGBM', 'Neural Network']:\n",
    "    model = results[name]['model']\n",
    "    \n",
    "    # Use scaled data for linear models and NN\n",
    "    if name in ['OLS', 'Ridge', 'Neural Network']:\n",
    "        X_cv = X_train_scaled\n",
    "    else:\n",
    "        X_cv = X_train\n",
    "    \n",
    "    cv_scores = cross_val_score(model, X_cv, y_train, cv=kf, scoring='r2')\n",
    "    cv_results[name] = {\n",
    "        'mean_cv_r2': cv_scores.mean(),\n",
    "        'std_cv_r2': cv_scores.std()\n",
    "    }\n",
    "    \n",
    "    print(f\"   {name}: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. MODEL COMPARISON TABLE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n4. Creating model comparison table...\")\n",
    "\n",
    "comparison_data = []\n",
    "for name, res in results.items():\n",
    "    comparison_data.append({\n",
    "        'Model': name,\n",
    "        'Train RÂ²': res['train_r2'],\n",
    "        'Test RÂ²': res['test_r2'],\n",
    "        'CV RÂ²': cv_results[name]['mean_cv_r2'],\n",
    "        'Test RMSE': res['test_rmse'],\n",
    "        'Test MAE': res['test_mae'],\n",
    "        'Overfit': res['train_r2'] - res['test_r2']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values('Test RÂ²', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*90)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*90)\n",
    "\n",
    "# ============================================================================\n",
    "# 5. VISUALIZATIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n5. Creating visualizations...\")\n",
    "\n",
    "# ------------------------------\n",
    "# A. MODEL PERFORMANCE COMPARISON\n",
    "# ------------------------------\n",
    "\n",
    "fig_comparison = go.Figure()\n",
    "\n",
    "models = comparison_df['Model'].tolist()\n",
    "colors = ['#002A54', '#E30613', '#2ecc71', '#3498db', '#9b59b6', '#f39c12', '#e74c3c']\n",
    "\n",
    "# Test RÂ²\n",
    "fig_comparison.add_trace(go.Bar(\n",
    "    name='Test RÂ²',\n",
    "    x=models,\n",
    "    y=comparison_df['Test RÂ²'],\n",
    "    marker_color=colors,\n",
    "    text=[f\"{x:.3f}\" for x in comparison_df['Test RÂ²']],\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "fig_comparison.update_layout(\n",
    "    title={'text': \"Model Performance Comparison (Test RÂ²)\", 'x': 0.5, 'font': {'size': 20}},\n",
    "    xaxis_title=\"Model\",\n",
    "    yaxis_title=\"RÂ² Score\",\n",
    "    template='plotly_white',\n",
    "    height=500,\n",
    "    yaxis=dict(range=[0, max(comparison_df['Test RÂ²']) * 1.15]),\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig_comparison.write_html(os.path.join(output_dir, 'ml_model_comparison.html'))\n",
    "print(\"   âœ“ Model comparison chart saved\")\n",
    "\n",
    "# ------------------------------\n",
    "# B. PREDICTED VS ACTUAL (Best Model)\n",
    "# ------------------------------\n",
    "\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "best_predictions = results[best_model_name]['predictions']\n",
    "\n",
    "fig_pred_actual = go.Figure()\n",
    "\n",
    "# Perfect prediction line\n",
    "min_val = min(y_test.min(), best_predictions.min())\n",
    "max_val = max(y_test.max(), best_predictions.max())\n",
    "fig_pred_actual.add_trace(go.Scatter(\n",
    "    x=[min_val, max_val],\n",
    "    y=[min_val, max_val],\n",
    "    mode='lines',\n",
    "    name='Perfect Prediction',\n",
    "    line=dict(color='red', dash='dash', width=2)\n",
    "))\n",
    "\n",
    "# Actual predictions\n",
    "fig_pred_actual.add_trace(go.Scatter(\n",
    "    x=y_test,\n",
    "    y=best_predictions,\n",
    "    mode='markers',\n",
    "    name='Predictions',\n",
    "    marker=dict(size=8, color='#002A54', opacity=0.6),\n",
    "    text=[f\"Actual: {a:.2f}<br>Predicted: {p:.2f}\" for a, p in zip(y_test, best_predictions)],\n",
    "    hovertemplate='%{text}<extra></extra>'\n",
    "))\n",
    "\n",
    "fig_pred_actual.update_layout(\n",
    "    title={'text': f\"Predicted vs Actual ECI - {best_model_name}<br>(Test RÂ² = {results[best_model_name]['test_r2']:.3f})\",\n",
    "           'x': 0.5, 'font': {'size': 18}},\n",
    "    xaxis_title=\"Actual ECI\",\n",
    "    yaxis_title=\"Predicted ECI\",\n",
    "    template='plotly_white',\n",
    "    height=600,\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig_pred_actual.write_html(os.path.join(output_dir, 'ml_predicted_vs_actual.html'))\n",
    "print(\"   âœ“ Predicted vs Actual chart saved\")\n",
    "\n",
    "# ------------------------------\n",
    "# C. FEATURE IMPORTANCE (Tree-based models)\n",
    "# ------------------------------\n",
    "\n",
    "# Get feature importances from best tree-based model\n",
    "tree_models = ['Random Forest', 'Gradient Boosting', 'XGBoost', 'LightGBM']\n",
    "best_tree_model = None\n",
    "best_tree_r2 = 0\n",
    "\n",
    "for model_name in tree_models:\n",
    "    if results[model_name]['test_r2'] > best_tree_r2:\n",
    "        best_tree_r2 = results[model_name]['test_r2']\n",
    "        best_tree_model = model_name\n",
    "\n",
    "if best_tree_model:\n",
    "    importances = results[best_tree_model]['feature_importance']\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': list(importances.keys()),\n",
    "        'Importance': list(importances.values())\n",
    "    }).sort_values('Importance', ascending=True)\n",
    "    \n",
    "    fig_importance = go.Figure()\n",
    "    fig_importance.add_trace(go.Bar(\n",
    "        x=importance_df['Importance'],\n",
    "        y=importance_df['Feature'],\n",
    "        orientation='h',\n",
    "        marker_color='#E30613',\n",
    "        text=[f\"{x:.3f}\" for x in importance_df['Importance']],\n",
    "        textposition='outside'\n",
    "    ))\n",
    "    \n",
    "    fig_importance.update_layout(\n",
    "        title={'text': f\"Feature Importance - {best_tree_model}\", 'x': 0.5, 'font': {'size': 20}},\n",
    "        xaxis_title=\"Importance\",\n",
    "        yaxis_title=\"Feature\",\n",
    "        template='plotly_white',\n",
    "        height=500,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    fig_importance.write_html(os.path.join(output_dir, 'ml_feature_importance.html'))\n",
    "    print(\"   âœ“ Feature importance chart saved\")\n",
    "\n",
    "# ------------------------------\n",
    "# D. RESIDUAL PLOT (Best Model)\n",
    "# ------------------------------\n",
    "\n",
    "residuals = y_test - best_predictions\n",
    "\n",
    "fig_residuals = go.Figure()\n",
    "\n",
    "fig_residuals.add_trace(go.Scatter(\n",
    "    x=best_predictions,\n",
    "    y=residuals,\n",
    "    mode='markers',\n",
    "    marker=dict(size=8, color='#002A54', opacity=0.6),\n",
    "    text=[f\"Predicted: {p:.2f}<br>Residual: {r:.2f}\" for p, r in zip(best_predictions, residuals)],\n",
    "    hovertemplate='%{text}<extra></extra>'\n",
    "))\n",
    "\n",
    "fig_residuals.add_hline(y=0, line_dash=\"dash\", line_color=\"red\", line_width=2)\n",
    "\n",
    "fig_residuals.update_layout(\n",
    "    title={'text': f\"Residual Plot - {best_model_name}\", 'x': 0.5, 'font': {'size': 20}},\n",
    "    xaxis_title=\"Predicted ECI\",\n",
    "    yaxis_title=\"Residuals\",\n",
    "    template='plotly_white',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig_residuals.write_html(os.path.join(output_dir, 'ml_residuals.html'))\n",
    "print(\"   âœ“ Residual plot saved\")\n",
    "\n",
    "# ============================================================================\n",
    "# 6. SAVE RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n6. Saving results...\")\n",
    "\n",
    "# Save comparison table\n",
    "comparison_df.to_csv(os.path.join(output_dir, 'ml_model_comparison.csv'), index=False)\n",
    "print(\"   âœ“ Model comparison table saved\")\n",
    "\n",
    "# Save predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Actual_ECI': y_test,\n",
    "    f'{best_model_name}_Predicted': best_predictions,\n",
    "    'Residual': residuals\n",
    "})\n",
    "predictions_df.to_csv(os.path.join(output_dir, 'ml_predictions.csv'), index=False)\n",
    "print(\"   âœ“ Predictions saved\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MACHINE LEARNING ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"Test RÂ²: {results[best_model_name]['test_r2']:.4f}\")\n",
    "print(f\"Test RMSE: {results[best_model_name]['test_rmse']:.4f}\")\n",
    "print(f\"Test MAE: {results[best_model_name]['test_mae']:.4f}\")\n",
    "print(\"\\nOutputs saved to:\", output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
