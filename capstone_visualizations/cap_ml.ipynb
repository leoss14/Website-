{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "844813a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ML ANALYSIS: PREDICTING ECONOMIC COMPLEXITY\n",
      "Panel Data with Temporal Train/Test Split\n",
      "======================================================================\n",
      "\n",
      "1. Loading data...\n",
      "   Master data: 3150 rows, 126 countries\n",
      "   Years: 1995 - 2019\n",
      "   Merged data: 3150 rows\n",
      "\n",
      "2. Defining feature sets...\n",
      "   Resource Curse Model: 9 features\n",
      "   Full Structural Model: 18 features\n",
      "\n",
      "3. Preparing train/test split...\n",
      "\n",
      "   RESOURCE CURSE MODEL:\n",
      "   Train: 2646 obs (1995-2015)\n",
      "   Test: 504 obs (2016-2019)\n",
      "   Train countries: 126\n",
      "   Test countries: 126\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Trade pct of GDP', 'Gross fixed capital formation all Constant prices Percent of GDP', 'Access to electricity pct of population', 'Urban population pct of total population', 'Domestic credit to private sector pct of GDP', 'Inflation consumer prices annual pct'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 217\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Test countries: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_rc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountry Code\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# Prepare Full Model dataset\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m df_full \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCountry Code\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCountry Name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfeatures_full\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    218\u001b[0m df_full \u001b[38;5;241m=\u001b[39m df_full\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m    220\u001b[0m train_full \u001b[38;5;241m=\u001b[39m df_full[df_full[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m TRAIN_END_YEAR]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Trade pct of GDP', 'Gross fixed capital formation all Constant prices Percent of GDP', 'Access to electricity pct of population', 'Urban population pct of total population', 'Domestic credit to private sector pct of GDP', 'Inflation consumer prices annual pct'] not in index\""
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "IMPROVED ML ANALYSIS FOR ECONOMIC COMPLEXITY\n",
    "- Panel data (all years, not just 2019)\n",
    "- Temporal train/test split (train: 1995-2015, test: 2016-2019)\n",
    "- Two model specifications: Resource Curse vs Full Structural\n",
    "- SHAP for interpretability\n",
    "- Proper handling of missing data\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "input_file = \"/Users/leoss/Desktop/GitHub/Capstone/MASTER/Master.csv\"\n",
    "production_file = \"/Users/leoss/Desktop/GitHub/Capstone/MASTER/NaturalResource.csv\"\n",
    "output_dir = \"/Users/leoss/Desktop/Portfolio/Website-/capstone_visualizations/individual_plots/ml\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ML ANALYSIS: PREDICTING ECONOMIC COMPLEXITY\")\n",
    "print(\"Panel Data with Temporal Train/Test Split\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# 1. LOAD AND PREPARE DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n1. Loading data...\")\n",
    "\n",
    "df_master = pd.read_csv(input_file)\n",
    "df_prod = pd.read_csv(production_file)\n",
    "\n",
    "print(f\"   Master data: {len(df_master)} rows, {df_master['Country Code'].nunique()} countries\")\n",
    "print(f\"   Years: {df_master['Year'].min()} - {df_master['Year'].max()}\")\n",
    "\n",
    "# Process production data to get resource categories\n",
    "def categorize_resource(resource):\n",
    "    if resource == 'Oil': return 'Oil'\n",
    "    elif resource == 'Natural Gas': return 'Natural Gas'\n",
    "    elif resource == 'Coal': return 'Coal'\n",
    "    else: return 'Metals'\n",
    "\n",
    "df_prod['Resource_Category'] = df_prod['Resource'].apply(categorize_resource)\n",
    "\n",
    "prod_agg = df_prod.groupby(['Country Name', 'Year', 'Resource_Category'])['Production_TotalValue'].sum().reset_index()\n",
    "prod_wide = prod_agg.pivot_table(\n",
    "    index=['Country Name', 'Year'], \n",
    "    columns='Resource_Category', \n",
    "    values='Production_TotalValue', \n",
    "    fill_value=0\n",
    ").reset_index()\n",
    "# Clean column names\n",
    "df_master.columns = df_master.columns.str.replace('â€”', '-')\n",
    "# Merge production with master\n",
    "df = df_master.merge(prod_wide, on=['Country Name', 'Year'], how='left')\n",
    "\n",
    "# Fill missing production values with 0\n",
    "for col in ['Oil', 'Natural Gas', 'Coal', 'Metals']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(0)\n",
    "\n",
    "# Calculate GDP-normalized resource values\n",
    "df['GDP_total'] = df['GDP per capita (constant prices, PPP)'] * df['Population']\n",
    "for res in ['Oil', 'Natural Gas', 'Coal', 'Metals']:\n",
    "    if res in df.columns:\n",
    "        df[f'{res}_GDP_Pct'] = (df[res] / df['GDP_total']) * 100\n",
    "        df[f'{res}_GDP_Pct'] = df[f'{res}_GDP_Pct'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "df['Total_Resources_GDP_Pct'] = df[['Oil_GDP_Pct', 'Natural Gas_GDP_Pct', 'Coal_GDP_Pct', 'Metals_GDP_Pct']].sum(axis=1)\n",
    "\n",
    "print(f\"   Merged data: {len(df)} rows\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. DEFINE FEATURE SETS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n2. Defining feature sets...\")\n",
    "\n",
    "# Target variable\n",
    "target = 'Economic Complexity Index'\n",
    "\n",
    "# FEATURE SET A: Resource Curse Model\n",
    "# Tests: Do natural resources hurt economic complexity, controlling for institutions?\n",
    "features_resource_curse = [\n",
    "    # Resource dependency\n",
    "    'Oil_GDP_Pct',\n",
    "    'Natural Gas_GDP_Pct', \n",
    "    'Coal_GDP_Pct',\n",
    "    'Metals_GDP_Pct',\n",
    "    # Human capital (key mediator)\n",
    "    'Human capital index',\n",
    "    # Institutions (key for resource curse theory)\n",
    "    'Rule of law index',\n",
    "    'Property rights',\n",
    "    'Political corruption index',\n",
    "    # Control\n",
    "    'Landlocked'\n",
    "]\n",
    "\n",
    "# FEATURE SET B: Full Structural Model\n",
    "# Tests: What explains economic complexity variation comprehensively?\n",
    "features_full = [\n",
    "    # Resources\n",
    "    'Oil_GDP_Pct',\n",
    "    'Natural Gas_GDP_Pct', \n",
    "    'Coal_GDP_Pct',\n",
    "    'Metals_GDP_Pct',\n",
    "    # Economic structure\n",
    "    'Manufacturing',\n",
    "    'Agriculture',\n",
    "    'Trade (% of GDP)',\n",
    "    'Gross fixed capital formation, all, Constant prices, Percent of GDP',\n",
    "    # Human capital\n",
    "    'Human capital index',\n",
    "    'Access to electricity (% of population)',\n",
    "    'Urban population (% of total population)',\n",
    "    # Institutions\n",
    "    'Rule of law index',\n",
    "    'Property rights',\n",
    "    'Political corruption index',\n",
    "    'Political stability - estimate',\n",
    "    # Financial\n",
    "    'Domestic credit to private sector (% of GDP)',\n",
    "    'Inflation, consumer prices (annual %)',\n",
    "    # Controls\n",
    "    'Landlocked',\n",
    "]\n",
    "\n",
    "# Clean feature names for display\n",
    "feature_names_clean = {\n",
    "    'Oil_GDP_Pct': 'Oil (% GDP)',\n",
    "    'Natural Gas_GDP_Pct': 'Natural Gas (% GDP)',\n",
    "    'Coal_GDP_Pct': 'Coal (% GDP)',\n",
    "    'Metals_GDP_Pct': 'Metals (% GDP)',\n",
    "    'Human capital index': 'Human Capital',\n",
    "    'Rule of law index': 'Rule of Law',\n",
    "    'Property rights': 'Property Rights',\n",
    "    'Political corruption index': 'Political Corruption',\n",
    "    'Political stability - estimate': 'Political Stability',\n",
    "    'Landlocked': 'Landlocked',\n",
    "    'Manufacturing': 'Manufacturing (% GDP)',\n",
    "    'Agriculture': 'Agriculture (% GDP)',\n",
    "    'Trade (% of GDP)': 'Trade Openness',\n",
    "    'Gross fixed capital formation, all, Constant prices, Percent of GDP': 'Investment (% GDP)',\n",
    "    'Access to electricity (% of population)': 'Electricity Access',\n",
    "    'Urban population (% of total population)': 'Urbanization',\n",
    "    'Domestic credit to private sector (% of GDP)': 'Private Credit',\n",
    "    'Inflation, consumer prices (annual %)': 'Inflation'\n",
    "}\n",
    "\n",
    "# Define cleaning function\n",
    "def clean_name(s):\n",
    "    return (s.replace('â€”', '-')\n",
    "             .replace('(', '')\n",
    "             .replace(')', '')\n",
    "             .replace('%', 'pct')\n",
    "             .replace(',', ''))\n",
    "\n",
    "# Apply to dataframe columns\n",
    "df_master.columns = [clean_name(c) for c in df_master.columns]\n",
    "\n",
    "# Apply to feature lists\n",
    "features_resource_curse = [clean_name(f) for f in features_resource_curse]\n",
    "features_full = [clean_name(f) for f in features_full]\n",
    "\n",
    "# Apply to display names dict\n",
    "feature_names_clean = {clean_name(k): v for k, v in feature_names_clean.items()}\n",
    "\n",
    "print(f\"   Resource Curse Model: {len(features_resource_curse)} features\")\n",
    "print(f\"   Full Structural Model: {len(features_full)} features\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. PREPARE DATASETS WITH TEMPORAL SPLIT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n3. Preparing train/test split...\")\n",
    "\n",
    "# Temporal split: Train on 1995-2015, Test on 2016-2019\n",
    "TRAIN_END_YEAR = 2015\n",
    "\n",
    "# Prepare Resource Curse dataset\n",
    "df_rc = df[['Country Code', 'Country Name', 'Year', target] + features_resource_curse].copy()\n",
    "df_rc = df_rc.dropna()\n",
    "\n",
    "train_rc = df_rc[df_rc['Year'] <= TRAIN_END_YEAR]\n",
    "test_rc = df_rc[df_rc['Year'] > TRAIN_END_YEAR]\n",
    "\n",
    "X_train_rc = train_rc[features_resource_curse]\n",
    "y_train_rc = train_rc[target]\n",
    "X_test_rc = test_rc[features_resource_curse]\n",
    "y_test_rc = test_rc[target]\n",
    "\n",
    "print(f\"\\n   RESOURCE CURSE MODEL:\")\n",
    "print(f\"   Train: {len(train_rc)} obs ({train_rc['Year'].min()}-{train_rc['Year'].max()})\")\n",
    "print(f\"   Test: {len(test_rc)} obs ({test_rc['Year'].min()}-{test_rc['Year'].max()})\")\n",
    "print(f\"   Train countries: {train_rc['Country Code'].nunique()}\")\n",
    "print(f\"   Test countries: {test_rc['Country Code'].nunique()}\")\n",
    "\n",
    "# Prepare Full Model dataset\n",
    "df_full = df[['Country Code', 'Country Name', 'Year', target] + features_full].copy()\n",
    "df_full = df_full.dropna()\n",
    "\n",
    "train_full = df_full[df_full['Year'] <= TRAIN_END_YEAR]\n",
    "test_full = df_full[df_full['Year'] > TRAIN_END_YEAR]\n",
    "\n",
    "X_train_full = train_full[features_full]\n",
    "y_train_full = train_full[target]\n",
    "X_test_full = test_full[features_full]\n",
    "y_test_full = test_full[target]\n",
    "\n",
    "print(f\"\\n   FULL STRUCTURAL MODEL:\")\n",
    "print(f\"   Train: {len(train_full)} obs ({train_full['Year'].min()}-{train_full['Year'].max()})\")\n",
    "print(f\"   Test: {len(test_full)} obs ({test_full['Year'].min()}-{test_full['Year'].max()})\")\n",
    "print(f\"   Train countries: {train_full['Country Code'].nunique()}\")\n",
    "print(f\"   Test countries: {test_full['Country Code'].nunique()}\")\n",
    "\n",
    "# Scale features\n",
    "scaler_rc = StandardScaler()\n",
    "X_train_rc_scaled = scaler_rc.fit_transform(X_train_rc)\n",
    "X_test_rc_scaled = scaler_rc.transform(X_test_rc)\n",
    "\n",
    "scaler_full = StandardScaler()\n",
    "X_train_full_scaled = scaler_full.fit_transform(X_train_full)\n",
    "X_test_full_scaled = scaler_full.transform(X_test_full)\n",
    "\n",
    "# ============================================================================\n",
    "# 4. TRAIN MODELS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n4. Training models...\")\n",
    "\n",
    "def train_and_evaluate(X_train, X_test, y_train, y_test, X_train_scaled, X_test_scaled, model_name):\n",
    "    \"\"\"Train multiple models and return results\"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Models that need scaling\n",
    "    models_scaled = {\n",
    "        'Ridge': Ridge(alpha=1.0, random_state=42),\n",
    "        'Lasso': Lasso(alpha=0.1, random_state=42),\n",
    "        'ElasticNet': ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42)\n",
    "    }\n",
    "    \n",
    "    # Models that don't need scaling\n",
    "    models_unscaled = {\n",
    "        'Random Forest': RandomForestRegressor(\n",
    "            n_estimators=200, max_depth=10, min_samples_split=10,\n",
    "            min_samples_leaf=5, random_state=42, n_jobs=-1\n",
    "        ),\n",
    "        'Gradient Boosting': GradientBoostingRegressor(\n",
    "            n_estimators=200, learning_rate=0.05, max_depth=5,\n",
    "            min_samples_split=10, min_samples_leaf=5, random_state=42\n",
    "        ),\n",
    "        'XGBoost': xgb.XGBRegressor(\n",
    "            n_estimators=200, learning_rate=0.05, max_depth=5,\n",
    "            min_child_weight=5, subsample=0.8, colsample_bytree=0.8,\n",
    "            random_state=42, objective='reg:squarederror', verbosity=0\n",
    "        ),\n",
    "        'LightGBM': lgb.LGBMRegressor(\n",
    "            n_estimators=200, learning_rate=0.05, max_depth=5,\n",
    "            num_leaves=31, min_child_samples=10, subsample=0.8,\n",
    "            colsample_bytree=0.8, random_state=42, verbose=-1\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    # Train scaled models\n",
    "    for name, model in models_scaled.items():\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred_train = model.predict(X_train_scaled)\n",
    "        y_pred_test = model.predict(X_test_scaled)\n",
    "        \n",
    "        results[name] = {\n",
    "            'model': model,\n",
    "            'train_r2': r2_score(y_train, y_pred_train),\n",
    "            'test_r2': r2_score(y_test, y_pred_test),\n",
    "            'test_rmse': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "            'test_mae': mean_absolute_error(y_test, y_pred_test),\n",
    "            'predictions': y_pred_test,\n",
    "            'scaled': True\n",
    "        }\n",
    "        \n",
    "        # Get coefficients for linear models\n",
    "        if hasattr(model, 'coef_'):\n",
    "            results[name]['coefficients'] = model.coef_\n",
    "    \n",
    "    # Train unscaled models\n",
    "    for name, model in models_unscaled.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        \n",
    "        results[name] = {\n",
    "            'model': model,\n",
    "            'train_r2': r2_score(y_train, y_pred_train),\n",
    "            'test_r2': r2_score(y_test, y_pred_test),\n",
    "            'test_rmse': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "            'test_mae': mean_absolute_error(y_test, y_pred_test),\n",
    "            'predictions': y_pred_test,\n",
    "            'scaled': False\n",
    "        }\n",
    "        \n",
    "        # Get feature importance for tree models\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            results[name]['feature_importance'] = model.feature_importances_\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Train Resource Curse models\n",
    "print(\"\\n   Training Resource Curse models...\")\n",
    "results_rc = train_and_evaluate(\n",
    "    X_train_rc, X_test_rc, y_train_rc, y_test_rc,\n",
    "    X_train_rc_scaled, X_test_rc_scaled, \"Resource Curse\"\n",
    ")\n",
    "\n",
    "# Train Full models\n",
    "print(\"   Training Full Structural models...\")\n",
    "results_full = train_and_evaluate(\n",
    "    X_train_full, X_test_full, y_train_full, y_test_full,\n",
    "    X_train_full_scaled, X_test_full_scaled, \"Full Structural\"\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# 5. CROSS-VALIDATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n5. Cross-validation (5-fold)...\")\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def run_cv(results, X_train, X_train_scaled, y_train):\n",
    "    cv_results = {}\n",
    "    for name, res in results.items():\n",
    "        if res['scaled']:\n",
    "            X_cv = X_train_scaled\n",
    "        else:\n",
    "            X_cv = X_train\n",
    "        \n",
    "        cv_scores = cross_val_score(res['model'], X_cv, y_train, cv=kf, scoring='r2')\n",
    "        cv_results[name] = {\n",
    "            'mean': cv_scores.mean(),\n",
    "            'std': cv_scores.std()\n",
    "        }\n",
    "    return cv_results\n",
    "\n",
    "cv_rc = run_cv(results_rc, X_train_rc, X_train_rc_scaled, y_train_rc)\n",
    "cv_full = run_cv(results_full, X_train_full, X_train_full_scaled, y_train_full)\n",
    "\n",
    "# ============================================================================\n",
    "# 6. RESULTS SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON - RESOURCE CURSE MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "comparison_rc = []\n",
    "for name, res in results_rc.items():\n",
    "    comparison_rc.append({\n",
    "        'Model': name,\n",
    "        'Train RÂ²': res['train_r2'],\n",
    "        'Test RÂ²': res['test_r2'],\n",
    "        'CV RÂ²': cv_rc[name]['mean'],\n",
    "        'Test RMSE': res['test_rmse'],\n",
    "        'Overfit': res['train_r2'] - res['test_r2']\n",
    "    })\n",
    "\n",
    "df_comp_rc = pd.DataFrame(comparison_rc).sort_values('Test RÂ²', ascending=False)\n",
    "print(df_comp_rc.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON - FULL STRUCTURAL MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "comparison_full = []\n",
    "for name, res in results_full.items():\n",
    "    comparison_full.append({\n",
    "        'Model': name,\n",
    "        'Train RÂ²': res['train_r2'],\n",
    "        'Test RÂ²': res['test_r2'],\n",
    "        'CV RÂ²': cv_full[name]['mean'],\n",
    "        'Test RMSE': res['test_rmse'],\n",
    "        'Overfit': res['train_r2'] - res['test_r2']\n",
    "    })\n",
    "\n",
    "df_comp_full = pd.DataFrame(comparison_full).sort_values('Test RÂ²', ascending=False)\n",
    "print(df_comp_full.to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# 7. FEATURE IMPORTANCE / COEFFICIENTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get best tree model for each\n",
    "best_tree_rc = df_comp_rc[df_comp_rc['Model'].isin(['Random Forest', 'Gradient Boosting', 'XGBoost', 'LightGBM'])].iloc[0]['Model']\n",
    "best_tree_full = df_comp_full[df_comp_full['Model'].isin(['Random Forest', 'Gradient Boosting', 'XGBoost', 'LightGBM'])].iloc[0]['Model']\n",
    "\n",
    "print(f\"\\n   Best tree model (Resource Curse): {best_tree_rc}\")\n",
    "print(f\"   Best tree model (Full): {best_tree_full}\")\n",
    "\n",
    "# Ridge coefficients (interpretable)\n",
    "print(\"\\n   RIDGE COEFFICIENTS (Resource Curse Model):\")\n",
    "ridge_coefs_rc = pd.DataFrame({\n",
    "    'Feature': features_resource_curse,\n",
    "    'Coefficient': results_rc['Ridge']['coefficients']\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "print(ridge_coefs_rc.to_string(index=False))\n",
    "\n",
    "print(\"\\n   RIDGE COEFFICIENTS (Full Model):\")\n",
    "ridge_coefs_full = pd.DataFrame({\n",
    "    'Feature': features_full,\n",
    "    'Coefficient': results_full['Ridge']['coefficients']\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "print(ridge_coefs_full.to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# 8. VISUALIZATIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n8. Creating visualizations...\")\n",
    "\n",
    "# ------------------------------\n",
    "# A. MODEL COMPARISON CHART\n",
    "# ------------------------------\n",
    "\n",
    "fig_comp = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('Resource Curse Model', 'Full Structural Model')\n",
    ")\n",
    "\n",
    "# Resource Curse\n",
    "df_comp_rc_sorted = df_comp_rc.sort_values('Test RÂ²', ascending=True)\n",
    "fig_comp.add_trace(\n",
    "    go.Bar(\n",
    "        y=df_comp_rc_sorted['Model'],\n",
    "        x=df_comp_rc_sorted['Test RÂ²'],\n",
    "        orientation='h',\n",
    "        marker_color='#002A54',\n",
    "        text=[f\"{x:.3f}\" for x in df_comp_rc_sorted['Test RÂ²']],\n",
    "        textposition='outside',\n",
    "        name='Resource Curse'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Full Model\n",
    "df_comp_full_sorted = df_comp_full.sort_values('Test RÂ²', ascending=True)\n",
    "fig_comp.add_trace(\n",
    "    go.Bar(\n",
    "        y=df_comp_full_sorted['Model'],\n",
    "        x=df_comp_full_sorted['Test RÂ²'],\n",
    "        orientation='h',\n",
    "        marker_color='#E30613',\n",
    "        text=[f\"{x:.3f}\" for x in df_comp_full_sorted['Test RÂ²']],\n",
    "        textposition='outside',\n",
    "        name='Full Model'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig_comp.update_layout(\n",
    "    title=dict(text='Model Performance Comparison (Test RÂ²)', x=0.5, font=dict(size=18)),\n",
    "    height=500,\n",
    "    showlegend=False,\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig_comp.update_xaxes(range=[0, 1])\n",
    "\n",
    "fig_comp.write_html(os.path.join(output_dir, 'ml_model_comparison.html'))\n",
    "print(\"   âœ“ Model comparison chart saved\")\n",
    "\n",
    "# ------------------------------\n",
    "# B. FEATURE IMPORTANCE (Tree Models)\n",
    "# ------------------------------\n",
    "\n",
    "# Resource Curse Model\n",
    "importance_rc = pd.DataFrame({\n",
    "    'Feature': [feature_names_clean.get(f, f) for f in features_resource_curse],\n",
    "    'Importance': results_rc[best_tree_rc]['feature_importance']\n",
    "}).sort_values('Importance', ascending=True)\n",
    "\n",
    "fig_imp_rc = go.Figure()\n",
    "fig_imp_rc.add_trace(go.Bar(\n",
    "    y=importance_rc['Feature'],\n",
    "    x=importance_rc['Importance'],\n",
    "    orientation='h',\n",
    "    marker_color='#002A54',\n",
    "    text=[f\"{x:.3f}\" for x in importance_rc['Importance']],\n",
    "    textposition='outside'\n",
    "))\n",
    "fig_imp_rc.update_layout(\n",
    "    title=dict(text=f'Feature Importance - Resource Curse Model ({best_tree_rc})', x=0.5),\n",
    "    xaxis_title='Importance',\n",
    "    height=500,\n",
    "    template='plotly_white',\n",
    "    margin=dict(l=150)\n",
    ")\n",
    "fig_imp_rc.write_html(os.path.join(output_dir, 'ml_feature_importance_resource_curse.html'))\n",
    "\n",
    "# Full Model\n",
    "importance_full = pd.DataFrame({\n",
    "    'Feature': [feature_names_clean.get(f, f) for f in features_full],\n",
    "    'Importance': results_full[best_tree_full]['feature_importance']\n",
    "}).sort_values('Importance', ascending=True)\n",
    "\n",
    "fig_imp_full = go.Figure()\n",
    "fig_imp_full.add_trace(go.Bar(\n",
    "    y=importance_full['Feature'],\n",
    "    x=importance_full['Importance'],\n",
    "    orientation='h',\n",
    "    marker_color='#E30613',\n",
    "    text=[f\"{x:.3f}\" for x in importance_full['Importance']],\n",
    "    textposition='outside'\n",
    "))\n",
    "fig_imp_full.update_layout(\n",
    "    title=dict(text=f'Feature Importance - Full Model ({best_tree_full})', x=0.5),\n",
    "    xaxis_title='Importance',\n",
    "    height=600,\n",
    "    template='plotly_white',\n",
    "    margin=dict(l=150)\n",
    ")\n",
    "fig_imp_full.write_html(os.path.join(output_dir, 'ml_feature_importance_full.html'))\n",
    "print(\"   âœ“ Feature importance charts saved\")\n",
    "\n",
    "# ------------------------------\n",
    "# C. COEFFICIENT PLOT (Ridge)\n",
    "# ------------------------------\n",
    "\n",
    "# Resource Curse coefficients\n",
    "coef_rc = pd.DataFrame({\n",
    "    'Feature': [feature_names_clean.get(f, f) for f in features_resource_curse],\n",
    "    'Coefficient': results_rc['Ridge']['coefficients']\n",
    "}).sort_values('Coefficient')\n",
    "\n",
    "fig_coef_rc = go.Figure()\n",
    "fig_coef_rc.add_trace(go.Bar(\n",
    "    y=coef_rc['Feature'],\n",
    "    x=coef_rc['Coefficient'],\n",
    "    orientation='h',\n",
    "    marker_color=['#22c55e' if c > 0 else '#ef4444' for c in coef_rc['Coefficient']],\n",
    "    text=[f\"{x:.3f}\" for x in coef_rc['Coefficient']],\n",
    "    textposition='outside'\n",
    "))\n",
    "fig_coef_rc.add_vline(x=0, line_dash='dash', line_color='black')\n",
    "fig_coef_rc.update_layout(\n",
    "    title=dict(text='Ridge Coefficients - Resource Curse Model<br><sup>Standardized: 1 SD increase in X â†’ Î² change in ECI</sup>', x=0.5),\n",
    "    xaxis_title='Coefficient (Standardized)',\n",
    "    height=500,\n",
    "    template='plotly_white',\n",
    "    margin=dict(l=150)\n",
    ")\n",
    "fig_coef_rc.write_html(os.path.join(output_dir, 'ml_coefficients_resource_curse.html'))\n",
    "print(\"   âœ“ Coefficient plots saved\")\n",
    "\n",
    "# ------------------------------\n",
    "# D. PREDICTED VS ACTUAL\n",
    "# ------------------------------\n",
    "\n",
    "best_model_rc = df_comp_rc.iloc[0]['Model']\n",
    "best_model_full = df_comp_full.iloc[0]['Model']\n",
    "\n",
    "fig_pred = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=(\n",
    "        f'Resource Curse Model ({best_model_rc})',\n",
    "        f'Full Model ({best_model_full})'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Resource Curse\n",
    "y_pred_rc = results_rc[best_model_rc]['predictions']\n",
    "fig_pred.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_test_rc, y=y_pred_rc,\n",
    "        mode='markers',\n",
    "        marker=dict(color='#002A54', opacity=0.5),\n",
    "        name='Predictions'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Full Model\n",
    "y_pred_full = results_full[best_model_full]['predictions']\n",
    "fig_pred.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_test_full, y=y_pred_full,\n",
    "        mode='markers',\n",
    "        marker=dict(color='#E30613', opacity=0.5),\n",
    "        name='Predictions'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Add perfect prediction lines\n",
    "for col in [1, 2]:\n",
    "    fig_pred.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[-3, 3], y=[-3, 3],\n",
    "            mode='lines',\n",
    "            line=dict(color='black', dash='dash'),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=col\n",
    "    )\n",
    "\n",
    "fig_pred.update_layout(\n",
    "    title=dict(text='Predicted vs Actual Economic Complexity Index', x=0.5, font=dict(size=18)),\n",
    "    height=500,\n",
    "    showlegend=False,\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig_pred.update_xaxes(title_text='Actual ECI', range=[-3, 3])\n",
    "fig_pred.update_yaxes(title_text='Predicted ECI', range=[-3, 3])\n",
    "\n",
    "fig_pred.write_html(os.path.join(output_dir, 'ml_predicted_vs_actual.html'))\n",
    "print(\"   âœ“ Predicted vs Actual chart saved\")\n",
    "\n",
    "# ------------------------------\n",
    "# E. RESIDUAL ANALYSIS BY COUNTRY\n",
    "# ------------------------------\n",
    "\n",
    "# Add predictions to test data\n",
    "test_rc_results = test_rc.copy()\n",
    "test_rc_results['Predicted'] = y_pred_rc\n",
    "test_rc_results['Residual'] = test_rc_results[target] - test_rc_results['Predicted']\n",
    "\n",
    "# Countries with largest residuals (model failures)\n",
    "worst_predictions = test_rc_results.groupby('Country Name').agg({\n",
    "    'Residual': lambda x: x.abs().mean(),\n",
    "    target: 'mean',\n",
    "    'Predicted': 'mean'\n",
    "}).sort_values('Residual', ascending=False).head(15)\n",
    "\n",
    "fig_residual = go.Figure()\n",
    "fig_residual.add_trace(go.Bar(\n",
    "    y=worst_predictions.index[::-1],\n",
    "    x=worst_predictions['Residual'][::-1],\n",
    "    orientation='h',\n",
    "    marker_color='#f59e0b',\n",
    "    text=[f\"{x:.2f}\" for x in worst_predictions['Residual'][::-1]],\n",
    "    textposition='outside'\n",
    "))\n",
    "fig_residual.update_layout(\n",
    "    title=dict(text='Countries with Largest Prediction Errors (Mean Absolute Residual)', x=0.5),\n",
    "    xaxis_title='Mean Absolute Residual',\n",
    "    height=500,\n",
    "    template='plotly_white',\n",
    "    margin=dict(l=150)\n",
    ")\n",
    "fig_residual.write_html(os.path.join(output_dir, 'ml_residuals_by_country.html'))\n",
    "print(\"   âœ“ Residual analysis saved\")\n",
    "\n",
    "# ============================================================================\n",
    "# 9. SHAP ANALYSIS (if available)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n9. SHAP analysis...\")\n",
    "\n",
    "try:\n",
    "    import shap\n",
    "    \n",
    "    # Use best tree model for SHAP\n",
    "    best_model = results_rc[best_tree_rc]['model']\n",
    "    \n",
    "    # Create explainer\n",
    "    explainer = shap.TreeExplainer(best_model)\n",
    "    shap_values = explainer.shap_values(X_test_rc)\n",
    "    \n",
    "    # Create SHAP summary data\n",
    "    shap_df = pd.DataFrame({\n",
    "        'Feature': [feature_names_clean.get(f, f) for f in features_resource_curse],\n",
    "        'Mean_SHAP': np.abs(shap_values).mean(axis=0)\n",
    "    }).sort_values('Mean_SHAP', ascending=True)\n",
    "    \n",
    "    fig_shap = go.Figure()\n",
    "    fig_shap.add_trace(go.Bar(\n",
    "        y=shap_df['Feature'],\n",
    "        x=shap_df['Mean_SHAP'],\n",
    "        orientation='h',\n",
    "        marker_color='#9b59b6',\n",
    "        text=[f\"{x:.3f}\" for x in shap_df['Mean_SHAP']],\n",
    "        textposition='outside'\n",
    "    ))\n",
    "    fig_shap.update_layout(\n",
    "        title=dict(text=f'SHAP Feature Importance - {best_tree_rc}', x=0.5),\n",
    "        xaxis_title='Mean |SHAP Value|',\n",
    "        height=500,\n",
    "        template='plotly_white',\n",
    "        margin=dict(l=150)\n",
    "    )\n",
    "    fig_shap.write_html(os.path.join(output_dir, 'ml_shap_importance.html'))\n",
    "    print(\"   âœ“ SHAP analysis saved\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"   âš  SHAP not installed. Run: pip install shap\")\n",
    "except Exception as e:\n",
    "    print(f\"   âš  SHAP error: {e}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 10. SAVE RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n10. Saving results...\")\n",
    "\n",
    "# Save comparison tables\n",
    "df_comp_rc.to_csv(os.path.join(output_dir, 'ml_comparison_resource_curse.csv'), index=False)\n",
    "df_comp_full.to_csv(os.path.join(output_dir, 'ml_comparison_full.csv'), index=False)\n",
    "\n",
    "# Save coefficients\n",
    "ridge_coefs_rc.to_csv(os.path.join(output_dir, 'ml_ridge_coefficients_rc.csv'), index=False)\n",
    "ridge_coefs_full.to_csv(os.path.join(output_dir, 'ml_ridge_coefficients_full.csv'), index=False)\n",
    "\n",
    "# Save feature importance\n",
    "importance_rc.to_csv(os.path.join(output_dir, 'ml_feature_importance_rc.csv'), index=False)\n",
    "importance_full.to_csv(os.path.join(output_dir, 'ml_feature_importance_full.csv'), index=False)\n",
    "\n",
    "# Save predictions\n",
    "test_rc_results[['Country Code', 'Country Name', 'Year', target, 'Predicted', 'Residual']].to_csv(\n",
    "    os.path.join(output_dir, 'ml_predictions.csv'), index=False\n",
    ")\n",
    "\n",
    "print(\"   âœ“ All results saved\")\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… ML ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nðŸ“Š RESOURCE CURSE MODEL\")\n",
    "print(f\"   Best model: {df_comp_rc.iloc[0]['Model']}\")\n",
    "print(f\"   Test RÂ²: {df_comp_rc.iloc[0]['Test RÂ²']:.3f}\")\n",
    "print(f\"   Features: {len(features_resource_curse)}\")\n",
    "\n",
    "print(f\"\\nðŸ“Š FULL STRUCTURAL MODEL\")\n",
    "print(f\"   Best model: {df_comp_full.iloc[0]['Model']}\")\n",
    "print(f\"   Test RÂ²: {df_comp_full.iloc[0]['Test RÂ²']:.3f}\")\n",
    "print(f\"   Features: {len(features_full)}\")\n",
    "\n",
    "print(f\"\\nðŸ”‘ KEY FINDINGS (Ridge Coefficients):\")\n",
    "top_positive = ridge_coefs_rc[ridge_coefs_rc['Coefficient'] > 0].nlargest(3, 'Coefficient')\n",
    "top_negative = ridge_coefs_rc[ridge_coefs_rc['Coefficient'] < 0].nsmallest(3, 'Coefficient')\n",
    "\n",
    "print(f\"   Strongest POSITIVE effects on ECI:\")\n",
    "for _, row in top_positive.iterrows():\n",
    "    print(f\"      {row['Feature']}: +{row['Coefficient']:.3f}\")\n",
    "\n",
    "print(f\"   Strongest NEGATIVE effects on ECI:\")\n",
    "for _, row in top_negative.iterrows():\n",
    "    print(f\"      {row['Feature']}: {row['Coefficient']:.3f}\")\n",
    "\n",
    "print(f\"\\nðŸ“ Outputs saved to: {output_dir}\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
