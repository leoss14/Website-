{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "844813a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ML ANALYSIS: PREDICTING ECONOMIC COMPLEXITY\n",
      "Panel Data with Temporal Split (Train: ‚â§2013, Test: 2014+)\n",
      "Including High Resource Country Interactions\n",
      "======================================================================\n",
      "\n",
      "1. Loading data...\n",
      "   Master data: 3150 rows, 126 countries\n",
      "   Years: 1995 - 2019\n",
      "\n",
      "2. Creating high resource country dummy and interactions...\n",
      "   High resource countries: 54\n",
      "   Other countries: 72\n",
      "   Merged data: 3150 rows\n",
      "\n",
      "3. Defining feature sets...\n",
      "\n",
      "Checking feature availability...\n",
      "   ‚úì All features found\n",
      "\n",
      "   Resource Curse (baseline): 8 features\n",
      "   Resource Curse (with interactions): 10 features (incl. HCI√óResources)\n",
      "   Full Structural: 17 features\n",
      "\n",
      "4. Preparing train/test split...\n",
      "\n",
      "   RESOURCE CURSE (BASELINE):\n",
      "   Train: 2394 obs, Test: 756 obs\n",
      "\n",
      "   RESOURCE CURSE (WITH INTERACTIONS):\n",
      "   Train: 2394 obs, Test: 756 obs\n",
      "   High Resource in test: 54 countries\n",
      "\n",
      "   FULL STRUCTURAL MODEL:\n",
      "   Train: 2394 obs, Test: 756 obs\n",
      "\n",
      "5. Training models...\n",
      "\n",
      "   Training Resource Curse (baseline)...\n",
      "   Training Resource Curse (with interactions)...\n",
      "   Training Full Structural...\n",
      "\n",
      "6. Cross-validation (5-fold)...\n",
      "\n",
      "======================================================================\n",
      "MODEL COMPARISON - RESOURCE CURSE (BASELINE)\n",
      "======================================================================\n",
      "            Model  Train R¬≤  Test R¬≤    CV R¬≤  Test RMSE  Overfit\n",
      "          XGBoost  0.964305 0.803927 0.925624   0.455613 0.160378\n",
      "         LightGBM  0.961655 0.798523 0.924267   0.461848 0.163132\n",
      "Gradient Boosting  0.964355 0.796470 0.922314   0.464195 0.167885\n",
      "    Random Forest  0.954881 0.777575 0.916541   0.485265 0.177307\n",
      "            Ridge  0.719492 0.625933 0.715837   0.629305 0.093559\n",
      "       ElasticNet  0.703831 0.625637 0.702441   0.629554 0.078193\n",
      "            Lasso  0.686382 0.613880 0.685330   0.639363 0.072503\n",
      "\n",
      "======================================================================\n",
      "MODEL COMPARISON - RESOURCE CURSE (WITH INTERACTIONS)\n",
      "======================================================================\n",
      "            Model  Train R¬≤  Test R¬≤    CV R¬≤  Test RMSE  Overfit\n",
      "          XGBoost  0.967311 0.815633 0.926370   0.441802 0.151678\n",
      "         LightGBM  0.964676 0.811376 0.925220   0.446874 0.153300\n",
      "Gradient Boosting  0.967185 0.802295 0.924265   0.457505 0.164890\n",
      "    Random Forest  0.959557 0.792394 0.921741   0.468820 0.167163\n",
      "            Ridge  0.724593 0.645988 0.720885   0.612203 0.078605\n",
      "       ElasticNet  0.710355 0.645336 0.708778   0.612766 0.065019\n",
      "            Lasso  0.693828 0.630535 0.692423   0.625422 0.063293\n",
      "\n",
      "======================================================================\n",
      "MODEL COMPARISON - FULL STRUCTURAL MODEL\n",
      "======================================================================\n",
      "            Model  Train R¬≤  Test R¬≤    CV R¬≤  Test RMSE  Overfit\n",
      "    Random Forest  0.970564 0.890607 0.941067   0.340315 0.079957\n",
      "          XGBoost  0.979341 0.886154 0.942560   0.347173 0.093187\n",
      "         LightGBM  0.977148 0.885803 0.942404   0.347707 0.091344\n",
      "Gradient Boosting  0.980247 0.881719 0.941416   0.353871 0.098528\n",
      "            Ridge  0.794366 0.737039 0.790558   0.527633 0.057327\n",
      "       ElasticNet  0.768610 0.734102 0.766272   0.530571 0.034508\n",
      "            Lasso  0.743144 0.715056 0.740948   0.549245 0.028088\n",
      "\n",
      "======================================================================\n",
      "INTERACTION EFFECTS ANALYSIS (RIDGE COEFFICIENTS)\n",
      "======================================================================\n",
      "\n",
      "   RESOURCE CURSE + INTERACTIONS MODEL:\n",
      "             Feature  Coefficient\n",
      " Human capital index     0.593210\n",
      "   Rule of law index     0.301632\n",
      "HCI_x_TotalResources    -0.273859\n",
      "      Metals_GDP_Pct    -0.130472\n",
      "         Oil_GDP_Pct     0.090285\n",
      " Natural Gas_GDP_Pct     0.079417\n",
      "       High_Resource    -0.078362\n",
      "        Coal_GDP_Pct    -0.023989\n",
      "     Property rights    -0.019128\n",
      "          Landlocked     0.012763\n",
      "\n",
      "--------------------------------------------------\n",
      "INTERPRETATION OF INTERACTION TERMS:\n",
      "--------------------------------------------------\n",
      "\n",
      "   Base effect of Oil (all countries):        0.0903\n",
      "   Additional effect for High Resource:       0.0000\n",
      "   TOTAL effect for High Resource countries:  0.0903\n",
      "\n",
      "   Base effect of Natural Gas:                0.0794\n",
      "   Additional effect for High Resource:       0.0000\n",
      "   TOTAL effect for High Resource countries:  0.0794\n",
      "\n",
      "   Base effect of Metals:                     -0.1305\n",
      "   Additional effect for High Resource:       0.0000\n",
      "   TOTAL effect for High Resource countries:  -0.1305\n",
      "\n",
      "   High Resource dummy (intercept shift):     -0.0784\n",
      "\n",
      "   HCI √ó Total Resources interaction:         -0.2739\n",
      "   ‚Üí Human capital returns DIMINISHED in resource-rich contexts\n",
      "\n",
      "======================================================================\n",
      "FEATURE ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "   Best tree model (RC baseline): XGBoost\n",
      "   Best tree model (RC + interactions): XGBoost\n",
      "   Best tree model (Full): Random Forest\n",
      "\n",
      "   RIDGE COEFFICIENTS (Resource Curse Baseline):\n",
      "            Feature  Coefficient\n",
      "Human capital index     0.597881\n",
      "  Rule of law index     0.312849\n",
      "     Metals_GDP_Pct    -0.218302\n",
      "        Oil_GDP_Pct    -0.139437\n",
      "       Coal_GDP_Pct    -0.056940\n",
      "Natural Gas_GDP_Pct    -0.041429\n",
      "    Property rights    -0.016962\n",
      "         Landlocked    -0.000007\n",
      "\n",
      "7. Creating visualizations...\n",
      "   ‚úì Model comparison chart saved\n",
      "   ‚úì Interaction coefficient plot saved\n",
      "   ‚úì Feature importance (interactions) saved\n",
      "\n",
      "8. SHAP analysis...\n",
      "   ‚úì SHAP analysis saved\n",
      "\n",
      "9. Saving results...\n",
      "   ‚úì All results saved\n",
      "\n",
      "======================================================================\n",
      "‚úÖ ML ANALYSIS COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "üìä RESOURCE CURSE (BASELINE)\n",
      "   Best model: XGBoost\n",
      "   Test R¬≤: 0.804\n",
      "\n",
      "üìä RESOURCE CURSE (WITH INTERACTIONS)\n",
      "   Best model: XGBoost\n",
      "   Test R¬≤: 0.816\n",
      "\n",
      "üìä FULL STRUCTURAL MODEL\n",
      "   Best model: Random Forest\n",
      "   Test R¬≤: 0.891\n",
      "\n",
      "üîë INTERACTION EFFECT:\n",
      "   R¬≤ improvement from interactions: +0.012\n",
      "   ‚Üí Interactions ADD predictive value\n",
      "\n",
      "üìÅ Outputs saved to: /Users/leoss/Desktop/Portfolio/Website-/capstone_visualizations/individual_plots/ml\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "IMPROVED ML ANALYSIS FOR ECONOMIC COMPLEXITY\n",
    "- Panel data (all years, not just 2019)\n",
    "- Temporal train/test split (train: 1995-2013, test: 2014-2019)\n",
    "- Two model specifications: Resource Curse vs Full Structural\n",
    "- HIGH RESOURCE COUNTRY interactions\n",
    "- SHAP for interpretability\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "input_file = \"/Users/leoss/Desktop/GitHub/Capstone/MASTER/Master.csv\"\n",
    "production_file = \"/Users/leoss/Desktop/GitHub/Capstone/MASTER/NaturalResource.csv\"\n",
    "output_dir = \"/Users/leoss/Desktop/Portfolio/Website-/capstone_visualizations/individual_plots/ml\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Temporal split configuration\n",
    "TRAIN_END_YEAR = 2013  # Train: <=2013, Test: 2014-2019\n",
    "\n",
    "# High resource country list\n",
    "HIGH_RESOURCE_COUNTRIES = [\n",
    "    'AGO', 'ARE', 'AZE', 'BFA', 'BHR', 'BOL', 'CHL', 'CIV', 'CMR',\n",
    "    'COD', 'COG', 'DZA', 'ECU', 'EGY', 'ETH', 'GAB', 'GHA', 'GIN',\n",
    "    'GNQ', 'IDN', 'IRN', 'IRQ', 'KAZ', 'KEN', 'KWT', 'LAO', 'LBR',\n",
    "    'LBY', 'MDG', 'MLI', 'MMR', 'MNG', 'MOZ', 'MWI', 'MYS', 'NER',\n",
    "    'NGA', 'OMN', 'PNG', 'QAT', 'RUS', 'RWA', 'SAU', 'TCD', 'TGO',\n",
    "    'TTO', 'TZA', 'UGA', 'UZB', 'VEN', 'VNM', 'YEM', 'ZMB', 'ZWE'\n",
    "]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ML ANALYSIS: PREDICTING ECONOMIC COMPLEXITY\")\n",
    "print(f\"Panel Data with Temporal Split (Train: ‚â§{TRAIN_END_YEAR}, Test: {TRAIN_END_YEAR+1}+)\")\n",
    "print(\"Including High Resource Country Interactions\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# 1. DEFINE HELPER FUNCTIONS AND MAPPINGS FIRST\n",
    "# ============================================================================\n",
    "\n",
    "def clean_name(s):\n",
    "    \"\"\"Clean column names to remove special characters\"\"\"\n",
    "    return (s.replace('‚Äî', '-')\n",
    "             .replace('(', '')\n",
    "             .replace(')', '')\n",
    "             .replace('%', 'pct')\n",
    "             .replace(',', ''))\n",
    "\n",
    "# Clean feature names for display\n",
    "feature_names_display = {\n",
    "    'Oil_GDP_Pct': 'Oil (% GDP)',\n",
    "    'Natural Gas_GDP_Pct': 'Natural Gas (% GDP)',\n",
    "    'Coal_GDP_Pct': 'Coal (% GDP)',\n",
    "    'Metals_GDP_Pct': 'Metals (% GDP)',\n",
    "    'Human capital index': 'Human Capital',\n",
    "    'Rule of law index': 'Rule of Law',\n",
    "    'Property rights': 'Property Rights',\n",
    "    'Political corruption index': 'Political Corruption',\n",
    "    'Political stability - estimate': 'Political Stability',\n",
    "    'Landlocked': 'Landlocked',\n",
    "    'Manufacturing': 'Manufacturing (% GDP)',\n",
    "    'Agriculture': 'Agriculture (% GDP)',\n",
    "    'Trade pct of GDP': 'Trade Openness',\n",
    "    'Gross fixed capital formation all Constant prices Percent of GDP': 'Investment (% GDP)',\n",
    "    'Access to electricity pct of population': 'Electricity Access',\n",
    "    'Urban population pct of total population': 'Urbanization',\n",
    "    'Domestic credit to private sector pct of GDP': 'Private Credit',\n",
    "    'Inflation consumer prices annual pct': 'Inflation',\n",
    "    # Interaction terms\n",
    "    'High_Resource': 'High Resource Country',\n",
    "    'Oil_GDP_Pct_x_HighRes': 'Oil √ó High Resource',\n",
    "    'NatGas_GDP_Pct_x_HighRes': 'Nat Gas √ó High Resource',\n",
    "    'Coal_GDP_Pct_x_HighRes': 'Coal √ó High Resource',\n",
    "    'Metals_GDP_Pct_x_HighRes': 'Metals √ó High Resource',\n",
    "    'Total_Resources_x_HighRes': 'Total Resources √ó High Resource',\n",
    "    'HCI_x_TotalResources': 'Human Capital √ó Total Resources',\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# 2. LOAD AND PREPARE DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n1. Loading data...\")\n",
    "\n",
    "df_master = pd.read_csv(input_file)\n",
    "\n",
    "# Apply column name cleaning\n",
    "df_master.columns = [clean_name(c) for c in df_master.columns]\n",
    "\n",
    "df_prod = pd.read_csv(production_file)\n",
    "\n",
    "print(f\"   Master data: {len(df_master)} rows, {df_master['Country Code'].nunique()} countries\")\n",
    "print(f\"   Years: {df_master['Year'].min()} - {df_master['Year'].max()}\")\n",
    "\n",
    "# Process production data to get resource categories\n",
    "def categorize_resource(resource):\n",
    "    if resource == 'Oil': return 'Oil'\n",
    "    elif resource == 'Natural Gas': return 'Natural Gas'\n",
    "    elif resource == 'Coal': return 'Coal'\n",
    "    else: return 'Metals'\n",
    "\n",
    "df_prod['Resource_Category'] = df_prod['Resource'].apply(categorize_resource)\n",
    "\n",
    "prod_agg = df_prod.groupby(['Country Name', 'Year', 'Resource_Category'])['Production_TotalValue'].sum().reset_index()\n",
    "prod_wide = prod_agg.pivot_table(\n",
    "    index=['Country Name', 'Year'], \n",
    "    columns='Resource_Category', \n",
    "    values='Production_TotalValue', \n",
    "    fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "# Merge production with master\n",
    "df = df_master.merge(prod_wide, on=['Country Name', 'Year'], how='left')\n",
    "\n",
    "# Fill missing production values with 0\n",
    "for col in ['Oil', 'Natural Gas', 'Coal', 'Metals']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(0)\n",
    "\n",
    "# Calculate GDP-normalized resource values\n",
    "df['GDP_total'] = df['GDP per capita constant prices PPP'] * df['Population']\n",
    "for res in ['Oil', 'Natural Gas', 'Coal', 'Metals']:\n",
    "    if res in df.columns:\n",
    "        df[f'{res}_GDP_Pct'] = (df[res] / df['GDP_total']) * 100\n",
    "        df[f'{res}_GDP_Pct'] = df[f'{res}_GDP_Pct'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "df['Total_Resources_GDP_Pct'] = df[['Oil_GDP_Pct', 'Natural Gas_GDP_Pct', 'Coal_GDP_Pct', 'Metals_GDP_Pct']].sum(axis=1)\n",
    "\n",
    "# ============================================================================\n",
    "# 3. CREATE HIGH RESOURCE DUMMY AND INTERACTIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n2. Creating high resource country dummy and interactions...\")\n",
    "\n",
    "# Create dummy\n",
    "df['High_Resource'] = df['Country Code'].isin(HIGH_RESOURCE_COUNTRIES).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# HCI √ó Total Resources interaction (tests if human capital returns differ by resource intensity)\n",
    "df['HCI_x_TotalResources'] = df['Human capital index'] * df['Total_Resources_GDP_Pct']\n",
    "\n",
    "n_high_res = df[df['High_Resource'] == 1]['Country Code'].nunique()\n",
    "n_other = df[df['High_Resource'] == 0]['Country Code'].nunique()\n",
    "print(f\"   High resource countries: {n_high_res}\")\n",
    "print(f\"   Other countries: {n_other}\")\n",
    "\n",
    "print(f\"   Merged data: {len(df)} rows\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. DEFINE FEATURE SETS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n3. Defining feature sets...\")\n",
    "\n",
    "# Target variable\n",
    "target = 'Economic Complexity Index'\n",
    "\n",
    "# Model 1: Resource Curse (baseline - no interactions)\n",
    "features_resource_curse_raw = [\n",
    "    'Oil_GDP_Pct',\n",
    "    'Natural Gas_GDP_Pct', \n",
    "    'Coal_GDP_Pct',\n",
    "    'Metals_GDP_Pct',\n",
    "    'Human capital index',\n",
    "    'Rule of law index',\n",
    "    'Property rights',\n",
    "    'Landlocked'\n",
    "]\n",
    "\n",
    "# Model 2: Resource Curse WITH High Resource dummy and interactions\n",
    "features_rc_interactions = [\n",
    "    'Oil_GDP_Pct',\n",
    "    'Natural Gas_GDP_Pct', \n",
    "    'Coal_GDP_Pct',\n",
    "    'Metals_GDP_Pct',\n",
    "    'High_Resource',\n",
    "    'Human capital index',\n",
    "    'HCI_x_TotalResources',  \n",
    "    'Rule of law index',\n",
    "    'Property rights',\n",
    "    'Landlocked'\n",
    "]\n",
    "\n",
    "# Model 3: Full Structural (no interactions)\n",
    "features_full_raw = [\n",
    "    'Oil_GDP_Pct',\n",
    "    'Natural Gas_GDP_Pct', \n",
    "    'Coal_GDP_Pct',\n",
    "    'Metals_GDP_Pct',\n",
    "    'Manufacturing',\n",
    "    'Agriculture',\n",
    "    'Trade (% of GDP)',\n",
    "    'Gross fixed capital formation, all, Constant prices, Percent of GDP',\n",
    "    'Human capital index',\n",
    "    'Access to electricity (% of population)',\n",
    "    'Urban population (% of total population)',\n",
    "    'Rule of law index',\n",
    "    'Property rights',\n",
    "    'Political stability ‚Äî estimate',\n",
    "    'Domestic credit to private sector (% of GDP)',\n",
    "    'Inflation, consumer prices (annual %)',\n",
    "    'Landlocked',\n",
    "]\n",
    "\n",
    "# Clean feature names to match cleaned column names\n",
    "features_resource_curse = [clean_name(f) for f in features_resource_curse_raw]\n",
    "features_full = [clean_name(f) for f in features_full_raw]\n",
    "# Interaction features don't need cleaning (already clean)\n",
    "\n",
    "# Also clean the display names dictionary keys\n",
    "feature_names_clean = {clean_name(k): v for k, v in feature_names_display.items()}\n",
    "\n",
    "# Verify features exist in dataframe\n",
    "print(\"\\nChecking feature availability...\")\n",
    "all_features = set(features_resource_curse + features_rc_interactions + features_full)\n",
    "missing = [f for f in all_features if f not in df.columns]\n",
    "\n",
    "if missing:\n",
    "    print(f\"   ‚ö† Missing: {missing}\")\n",
    "else:\n",
    "    print(\"   ‚úì All features found\")\n",
    "\n",
    "print(f\"\\n   Resource Curse (baseline): {len(features_resource_curse)} features\")\n",
    "print(f\"   Resource Curse (with interactions): {len(features_rc_interactions)} features (incl. HCI√óResources)\")\n",
    "print(f\"   Full Structural: {len(features_full)} features\")\n",
    "\n",
    "# ============================================================================\n",
    "# 5. PREPARE DATASETS WITH TEMPORAL SPLIT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n4. Preparing train/test split...\")\n",
    "\n",
    "# --- Resource Curse Baseline ---\n",
    "df_rc = df[['Country Code', 'Country Name', 'Year', target] + features_resource_curse].copy()\n",
    "df_rc = df_rc.dropna()\n",
    "\n",
    "train_rc = df_rc[df_rc['Year'] <= TRAIN_END_YEAR]\n",
    "test_rc = df_rc[df_rc['Year'] > TRAIN_END_YEAR]\n",
    "\n",
    "X_train_rc = train_rc[features_resource_curse]\n",
    "y_train_rc = train_rc[target]\n",
    "X_test_rc = test_rc[features_resource_curse]\n",
    "y_test_rc = test_rc[target]\n",
    "\n",
    "print(f\"\\n   RESOURCE CURSE (BASELINE):\")\n",
    "print(f\"   Train: {len(train_rc)} obs, Test: {len(test_rc)} obs\")\n",
    "\n",
    "# --- Resource Curse WITH Interactions ---\n",
    "df_rc_int = df[['Country Code', 'Country Name', 'Year', target] + features_rc_interactions].copy()\n",
    "df_rc_int = df_rc_int.dropna()\n",
    "\n",
    "train_rc_int = df_rc_int[df_rc_int['Year'] <= TRAIN_END_YEAR]\n",
    "test_rc_int = df_rc_int[df_rc_int['Year'] > TRAIN_END_YEAR]\n",
    "\n",
    "X_train_rc_int = train_rc_int[features_rc_interactions]\n",
    "y_train_rc_int = train_rc_int[target]\n",
    "X_test_rc_int = test_rc_int[features_rc_interactions]\n",
    "y_test_rc_int = test_rc_int[target]\n",
    "\n",
    "print(f\"\\n   RESOURCE CURSE (WITH INTERACTIONS):\")\n",
    "print(f\"   Train: {len(train_rc_int)} obs, Test: {len(test_rc_int)} obs\")\n",
    "print(f\"   High Resource in test: {test_rc_int[test_rc_int['Country Code'].isin(HIGH_RESOURCE_COUNTRIES)]['Country Code'].nunique()} countries\")\n",
    "\n",
    "# --- Full Model ---\n",
    "df_full = df[['Country Code', 'Country Name', 'Year', target] + features_full].copy()\n",
    "df_full = df_full.dropna()\n",
    "\n",
    "train_full = df_full[df_full['Year'] <= TRAIN_END_YEAR]\n",
    "test_full = df_full[df_full['Year'] > TRAIN_END_YEAR]\n",
    "\n",
    "X_train_full = train_full[features_full]\n",
    "y_train_full = train_full[target]\n",
    "X_test_full = test_full[features_full]\n",
    "y_test_full = test_full[target]\n",
    "\n",
    "print(f\"\\n   FULL STRUCTURAL MODEL:\")\n",
    "print(f\"   Train: {len(train_full)} obs, Test: {len(test_full)} obs\")\n",
    "\n",
    "# Scale features\n",
    "scaler_rc = StandardScaler()\n",
    "X_train_rc_scaled = scaler_rc.fit_transform(X_train_rc)\n",
    "X_test_rc_scaled = scaler_rc.transform(X_test_rc)\n",
    "\n",
    "scaler_rc_int = StandardScaler()\n",
    "X_train_rc_int_scaled = scaler_rc_int.fit_transform(X_train_rc_int)\n",
    "X_test_rc_int_scaled = scaler_rc_int.transform(X_test_rc_int)\n",
    "\n",
    "scaler_full = StandardScaler()\n",
    "X_train_full_scaled = scaler_full.fit_transform(X_train_full)\n",
    "X_test_full_scaled = scaler_full.transform(X_test_full)\n",
    "\n",
    "# ============================================================================\n",
    "# 6. TRAIN MODELS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n5. Training models...\")\n",
    "\n",
    "def train_and_evaluate(X_train, X_test, y_train, y_test, X_train_scaled, X_test_scaled, model_name):\n",
    "    \"\"\"Train multiple models and return results\"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Models that need scaling\n",
    "    models_scaled = {\n",
    "        'Ridge': Ridge(alpha=1.0, random_state=42),\n",
    "        'Lasso': Lasso(alpha=0.1, random_state=42),\n",
    "        'ElasticNet': ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42)\n",
    "    }\n",
    "    \n",
    "    # Models that don't need scaling\n",
    "    models_unscaled = {\n",
    "        'Random Forest': RandomForestRegressor(\n",
    "            n_estimators=200, max_depth=10, min_samples_split=10,\n",
    "            min_samples_leaf=5, random_state=42, n_jobs=-1\n",
    "        ),\n",
    "        'Gradient Boosting': GradientBoostingRegressor(\n",
    "            n_estimators=200, learning_rate=0.05, max_depth=5,\n",
    "            min_samples_split=10, min_samples_leaf=5, random_state=42\n",
    "        ),\n",
    "        'XGBoost': xgb.XGBRegressor(\n",
    "            n_estimators=200, learning_rate=0.05, max_depth=5,\n",
    "            min_child_weight=5, subsample=0.8, colsample_bytree=0.8,\n",
    "            random_state=42, objective='reg:squarederror', verbosity=0\n",
    "        ),\n",
    "        'LightGBM': lgb.LGBMRegressor(\n",
    "            n_estimators=200, learning_rate=0.05, max_depth=5,\n",
    "            num_leaves=31, min_child_samples=10, subsample=0.8,\n",
    "            colsample_bytree=0.8, random_state=42, verbose=-1\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    # Train scaled models\n",
    "    for name, model in models_scaled.items():\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred_train = model.predict(X_train_scaled)\n",
    "        y_pred_test = model.predict(X_test_scaled)\n",
    "        \n",
    "        results[name] = {\n",
    "            'model': model,\n",
    "            'train_r2': r2_score(y_train, y_pred_train),\n",
    "            'test_r2': r2_score(y_test, y_pred_test),\n",
    "            'test_rmse': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "            'test_mae': mean_absolute_error(y_test, y_pred_test),\n",
    "            'predictions': y_pred_test,\n",
    "            'scaled': True\n",
    "        }\n",
    "        \n",
    "        if hasattr(model, 'coef_'):\n",
    "            results[name]['coefficients'] = model.coef_\n",
    "    \n",
    "    # Train unscaled models\n",
    "    for name, model in models_unscaled.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        \n",
    "        results[name] = {\n",
    "            'model': model,\n",
    "            'train_r2': r2_score(y_train, y_pred_train),\n",
    "            'test_r2': r2_score(y_test, y_pred_test),\n",
    "            'test_rmse': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "            'test_mae': mean_absolute_error(y_test, y_pred_test),\n",
    "            'predictions': y_pred_test,\n",
    "            'scaled': False\n",
    "        }\n",
    "        \n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            results[name]['feature_importance'] = model.feature_importances_\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Train all three models\n",
    "print(\"\\n   Training Resource Curse (baseline)...\")\n",
    "results_rc = train_and_evaluate(\n",
    "    X_train_rc, X_test_rc, y_train_rc, y_test_rc,\n",
    "    X_train_rc_scaled, X_test_rc_scaled, \"Resource Curse\"\n",
    ")\n",
    "\n",
    "print(\"   Training Resource Curse (with interactions)...\")\n",
    "results_rc_int = train_and_evaluate(\n",
    "    X_train_rc_int, X_test_rc_int, y_train_rc_int, y_test_rc_int,\n",
    "    X_train_rc_int_scaled, X_test_rc_int_scaled, \"Resource Curse + Interactions\"\n",
    ")\n",
    "\n",
    "print(\"   Training Full Structural...\")\n",
    "results_full = train_and_evaluate(\n",
    "    X_train_full, X_test_full, y_train_full, y_test_full,\n",
    "    X_train_full_scaled, X_test_full_scaled, \"Full Structural\"\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# 7. CROSS-VALIDATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n6. Cross-validation (5-fold)...\")\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def run_cv(results, X_train, X_train_scaled, y_train):\n",
    "    cv_results = {}\n",
    "    for name, res in results.items():\n",
    "        if res['scaled']:\n",
    "            X_cv = X_train_scaled\n",
    "        else:\n",
    "            X_cv = X_train\n",
    "        \n",
    "        cv_scores = cross_val_score(res['model'], X_cv, y_train, cv=kf, scoring='r2')\n",
    "        cv_results[name] = {\n",
    "            'mean': cv_scores.mean(),\n",
    "            'std': cv_scores.std()\n",
    "        }\n",
    "    return cv_results\n",
    "\n",
    "cv_rc = run_cv(results_rc, X_train_rc, X_train_rc_scaled, y_train_rc)\n",
    "cv_rc_int = run_cv(results_rc_int, X_train_rc_int, X_train_rc_int_scaled, y_train_rc_int)\n",
    "cv_full = run_cv(results_full, X_train_full, X_train_full_scaled, y_train_full)\n",
    "\n",
    "# ============================================================================\n",
    "# 8. RESULTS SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON - RESOURCE CURSE (BASELINE)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "comparison_rc = []\n",
    "for name, res in results_rc.items():\n",
    "    comparison_rc.append({\n",
    "        'Model': name,\n",
    "        'Train R¬≤': res['train_r2'],\n",
    "        'Test R¬≤': res['test_r2'],\n",
    "        'CV R¬≤': cv_rc[name]['mean'],\n",
    "        'Test RMSE': res['test_rmse'],\n",
    "        'Overfit': res['train_r2'] - res['test_r2']\n",
    "    })\n",
    "\n",
    "df_comp_rc = pd.DataFrame(comparison_rc).sort_values('Test R¬≤', ascending=False)\n",
    "print(df_comp_rc.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON - RESOURCE CURSE (WITH INTERACTIONS)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "comparison_rc_int = []\n",
    "for name, res in results_rc_int.items():\n",
    "    comparison_rc_int.append({\n",
    "        'Model': name,\n",
    "        'Train R¬≤': res['train_r2'],\n",
    "        'Test R¬≤': res['test_r2'],\n",
    "        'CV R¬≤': cv_rc_int[name]['mean'],\n",
    "        'Test RMSE': res['test_rmse'],\n",
    "        'Overfit': res['train_r2'] - res['test_r2']\n",
    "    })\n",
    "\n",
    "df_comp_rc_int = pd.DataFrame(comparison_rc_int).sort_values('Test R¬≤', ascending=False)\n",
    "print(df_comp_rc_int.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON - FULL STRUCTURAL MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "comparison_full = []\n",
    "for name, res in results_full.items():\n",
    "    comparison_full.append({\n",
    "        'Model': name,\n",
    "        'Train R¬≤': res['train_r2'],\n",
    "        'Test R¬≤': res['test_r2'],\n",
    "        'CV R¬≤': cv_full[name]['mean'],\n",
    "        'Test RMSE': res['test_rmse'],\n",
    "        'Overfit': res['train_r2'] - res['test_r2']\n",
    "    })\n",
    "\n",
    "df_comp_full = pd.DataFrame(comparison_full).sort_values('Test R¬≤', ascending=False)\n",
    "print(df_comp_full.to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# 9. INTERACTION EFFECTS ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INTERACTION EFFECTS ANALYSIS (RIDGE COEFFICIENTS)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Ridge coefficients for interaction model\n",
    "ridge_coefs_int = pd.DataFrame({\n",
    "    'Feature': features_rc_interactions,\n",
    "    'Coefficient': results_rc_int['Ridge']['coefficients']\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(\"\\n   RESOURCE CURSE + INTERACTIONS MODEL:\")\n",
    "print(ridge_coefs_int.to_string(index=False))\n",
    "\n",
    "# Interpretation\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"INTERPRETATION OF INTERACTION TERMS:\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Extract key coefficients\n",
    "coef_dict = dict(zip(features_rc_interactions, results_rc_int['Ridge']['coefficients']))\n",
    "\n",
    "print(f\"\\n   Base effect of Oil (all countries):        {coef_dict.get('Oil_GDP_Pct', 0):.4f}\")\n",
    "print(f\"   Additional effect for High Resource:       {coef_dict.get('Oil_GDP_Pct_x_HighRes', 0):.4f}\")\n",
    "print(f\"   TOTAL effect for High Resource countries:  {coef_dict.get('Oil_GDP_Pct', 0) + coef_dict.get('Oil_GDP_Pct_x_HighRes', 0):.4f}\")\n",
    "\n",
    "print(f\"\\n   Base effect of Natural Gas:                {coef_dict.get('Natural Gas_GDP_Pct', 0):.4f}\")\n",
    "print(f\"   Additional effect for High Resource:       {coef_dict.get('NatGas_GDP_Pct_x_HighRes', 0):.4f}\")\n",
    "print(f\"   TOTAL effect for High Resource countries:  {coef_dict.get('Natural Gas_GDP_Pct', 0) + coef_dict.get('NatGas_GDP_Pct_x_HighRes', 0):.4f}\")\n",
    "\n",
    "print(f\"\\n   Base effect of Metals:                     {coef_dict.get('Metals_GDP_Pct', 0):.4f}\")\n",
    "print(f\"   Additional effect for High Resource:       {coef_dict.get('Metals_GDP_Pct_x_HighRes', 0):.4f}\")\n",
    "print(f\"   TOTAL effect for High Resource countries:  {coef_dict.get('Metals_GDP_Pct', 0) + coef_dict.get('Metals_GDP_Pct_x_HighRes', 0):.4f}\")\n",
    "\n",
    "print(f\"\\n   High Resource dummy (intercept shift):     {coef_dict.get('High_Resource', 0):.4f}\")\n",
    "\n",
    "print(f\"\\n   HCI √ó Total Resources interaction:         {coef_dict.get('HCI_x_TotalResources', 0):.4f}\")\n",
    "if coef_dict.get('HCI_x_TotalResources', 0) > 0:\n",
    "    print(f\"   ‚Üí Human capital returns AMPLIFIED in resource-rich contexts\")\n",
    "else:\n",
    "    print(f\"   ‚Üí Human capital returns DIMINISHED in resource-rich contexts\")\n",
    "\n",
    "# ============================================================================\n",
    "# 10. FEATURE IMPORTANCE / COEFFICIENTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get best tree model for each\n",
    "tree_models = ['Random Forest', 'Gradient Boosting', 'XGBoost', 'LightGBM']\n",
    "best_tree_rc = df_comp_rc[df_comp_rc['Model'].isin(tree_models)].iloc[0]['Model']\n",
    "best_tree_rc_int = df_comp_rc_int[df_comp_rc_int['Model'].isin(tree_models)].iloc[0]['Model']\n",
    "best_tree_full = df_comp_full[df_comp_full['Model'].isin(tree_models)].iloc[0]['Model']\n",
    "\n",
    "print(f\"\\n   Best tree model (RC baseline): {best_tree_rc}\")\n",
    "print(f\"   Best tree model (RC + interactions): {best_tree_rc_int}\")\n",
    "print(f\"   Best tree model (Full): {best_tree_full}\")\n",
    "\n",
    "# Ridge coefficients (baseline)\n",
    "print(\"\\n   RIDGE COEFFICIENTS (Resource Curse Baseline):\")\n",
    "ridge_coefs_rc = pd.DataFrame({\n",
    "    'Feature': features_resource_curse,\n",
    "    'Coefficient': results_rc['Ridge']['coefficients']\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "print(ridge_coefs_rc.to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# 11. VISUALIZATIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n7. Creating visualizations...\")\n",
    "\n",
    "# ------------------------------\n",
    "# A. MODEL COMPARISON (all 3)\n",
    "# ------------------------------\n",
    "\n",
    "fig_comp = make_subplots(\n",
    "    rows=1, cols=3,\n",
    "    subplot_titles=('RC Baseline', 'RC + Interactions', 'Full Structural')\n",
    ")\n",
    "\n",
    "# RC Baseline\n",
    "df_comp_rc_sorted = df_comp_rc.sort_values('Test R¬≤', ascending=True)\n",
    "fig_comp.add_trace(\n",
    "    go.Bar(\n",
    "        y=df_comp_rc_sorted['Model'],\n",
    "        x=df_comp_rc_sorted['Test R¬≤'],\n",
    "        orientation='h',\n",
    "        marker_color='#002A54',\n",
    "        text=[f\"{x:.3f}\" for x in df_comp_rc_sorted['Test R¬≤']],\n",
    "        textposition='outside',\n",
    "        name='RC Baseline'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# RC + Interactions\n",
    "df_comp_rc_int_sorted = df_comp_rc_int.sort_values('Test R¬≤', ascending=True)\n",
    "fig_comp.add_trace(\n",
    "    go.Bar(\n",
    "        y=df_comp_rc_int_sorted['Model'],\n",
    "        x=df_comp_rc_int_sorted['Test R¬≤'],\n",
    "        orientation='h',\n",
    "        marker_color='#6B8E23',\n",
    "        text=[f\"{x:.3f}\" for x in df_comp_rc_int_sorted['Test R¬≤']],\n",
    "        textposition='outside',\n",
    "        name='RC + Interactions'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Full Model\n",
    "df_comp_full_sorted = df_comp_full.sort_values('Test R¬≤', ascending=True)\n",
    "fig_comp.add_trace(\n",
    "    go.Bar(\n",
    "        y=df_comp_full_sorted['Model'],\n",
    "        x=df_comp_full_sorted['Test R¬≤'],\n",
    "        orientation='h',\n",
    "        marker_color='#E30613',\n",
    "        text=[f\"{x:.3f}\" for x in df_comp_full_sorted['Test R¬≤']],\n",
    "        textposition='outside',\n",
    "        name='Full Model'\n",
    "    ),\n",
    "    row=1, col=3\n",
    ")\n",
    "\n",
    "fig_comp.update_layout(\n",
    "    title=dict(text='Model Performance Comparison (Test R¬≤)', x=0.5, font=dict(size=18)),\n",
    "    height=500,\n",
    "    showlegend=False,\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig_comp.update_xaxes(range=[0, 1])\n",
    "\n",
    "fig_comp.write_html(os.path.join(output_dir, 'ml_model_comparison.html'))\n",
    "print(\"   ‚úì Model comparison chart saved\")\n",
    "\n",
    "# ------------------------------\n",
    "# B. INTERACTION COEFFICIENTS PLOT\n",
    "# ------------------------------\n",
    "\n",
    "coef_int = pd.DataFrame({\n",
    "    'Feature': [feature_names_clean.get(f, f) for f in features_rc_interactions],\n",
    "    'Coefficient': results_rc_int['Ridge']['coefficients']\n",
    "}).sort_values('Coefficient')\n",
    "\n",
    "fig_coef_int = go.Figure()\n",
    "fig_coef_int.add_trace(go.Bar(\n",
    "    y=coef_int['Feature'],\n",
    "    x=coef_int['Coefficient'],\n",
    "    orientation='h',\n",
    "    marker_color=['#22c55e' if c > 0 else '#ef4444' for c in coef_int['Coefficient']],\n",
    "    text=[f\"{x:.3f}\" for x in coef_int['Coefficient']],\n",
    "    textposition='outside'\n",
    "))\n",
    "fig_coef_int.add_vline(x=0, line_dash='dash', line_color='black')\n",
    "fig_coef_int.update_layout(\n",
    "    title=dict(text='Ridge Coefficients - Resource Curse with Interactions<br><sup>Standardized coefficients</sup>', x=0.5),\n",
    "    xaxis_title='Coefficient (Standardized)',\n",
    "    height=600,\n",
    "    template='plotly_white',\n",
    "    margin=dict(l=200)\n",
    ")\n",
    "fig_coef_int.write_html(os.path.join(output_dir, 'ml_coefficients_interactions.html'))\n",
    "print(\"   ‚úì Interaction coefficient plot saved\")\n",
    "\n",
    "# ------------------------------\n",
    "# C. FEATURE IMPORTANCE (Interaction Model)\n",
    "# ------------------------------\n",
    "\n",
    "importance_int = pd.DataFrame({\n",
    "    'Feature': [feature_names_clean.get(f, f) for f in features_rc_interactions],\n",
    "    'Importance': results_rc_int[best_tree_rc_int]['feature_importance']\n",
    "}).sort_values('Importance', ascending=True)\n",
    "\n",
    "fig_imp_int = go.Figure()\n",
    "fig_imp_int.add_trace(go.Bar(\n",
    "    y=importance_int['Feature'],\n",
    "    x=importance_int['Importance'],\n",
    "    orientation='h',\n",
    "    marker_color='#6B8E23',\n",
    "    text=[f\"{x:.3f}\" for x in importance_int['Importance']],\n",
    "    textposition='outside'\n",
    "))\n",
    "fig_imp_int.update_layout(\n",
    "    title=dict(text=f'Feature Importance - RC + Interactions ({best_tree_rc_int})', x=0.5),\n",
    "    xaxis_title='Importance',\n",
    "    height=600,\n",
    "    template='plotly_white',\n",
    "    margin=dict(l=200)\n",
    ")\n",
    "fig_imp_int.write_html(os.path.join(output_dir, 'ml_feature_importance_interactions.html'))\n",
    "print(\"   ‚úì Feature importance (interactions) saved\")\n",
    "\n",
    "# ------------------------------\n",
    "# D. SHAP ANALYSIS (Interaction Model)\n",
    "# ------------------------------\n",
    "\n",
    "print(\"\\n8. SHAP analysis...\")\n",
    "\n",
    "try:\n",
    "    import shap\n",
    "    \n",
    "    # Use LightGBM for SHAP (more stable than XGBoost)\n",
    "    best_model_shap = results_rc_int['LightGBM']['model']\n",
    "    \n",
    "    explainer = shap.TreeExplainer(best_model_shap)\n",
    "    shap_values = explainer.shap_values(X_test_rc_int.astype(float))\n",
    "    \n",
    "    shap_df = pd.DataFrame({\n",
    "        'Feature': [feature_names_clean.get(f, f) for f in features_rc_interactions],\n",
    "        'Mean_SHAP': np.abs(shap_values).mean(axis=0)\n",
    "    }).sort_values('Mean_SHAP', ascending=True)\n",
    "    \n",
    "    fig_shap = go.Figure()\n",
    "    fig_shap.add_trace(go.Bar(\n",
    "        y=shap_df['Feature'],\n",
    "        x=shap_df['Mean_SHAP'],\n",
    "        orientation='h',\n",
    "        marker_color='#9b59b6',\n",
    "        text=[f\"{x:.3f}\" for x in shap_df['Mean_SHAP']],\n",
    "        textposition='outside'\n",
    "    ))\n",
    "    fig_shap.update_layout(\n",
    "        title=dict(text='SHAP Feature Importance - RC + Interactions (LightGBM)', x=0.5),\n",
    "        xaxis_title='Mean |SHAP Value|',\n",
    "        height=600,\n",
    "        template='plotly_white',\n",
    "        margin=dict(l=200)\n",
    "    )\n",
    "    fig_shap.write_html(os.path.join(output_dir, 'ml_shap_importance.html'))\n",
    "    print(\"   ‚úì SHAP analysis saved\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"   ‚ö† SHAP not installed.\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ö† SHAP error: {e}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 12. SAVE RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n9. Saving results...\")\n",
    "\n",
    "# Save comparison tables\n",
    "df_comp_rc.to_csv(os.path.join(output_dir, 'ml_comparison_resource_curse.csv'), index=False)\n",
    "df_comp_rc_int.to_csv(os.path.join(output_dir, 'ml_comparison_rc_interactions.csv'), index=False)\n",
    "df_comp_full.to_csv(os.path.join(output_dir, 'ml_comparison_full.csv'), index=False)\n",
    "\n",
    "# Save coefficients\n",
    "ridge_coefs_rc.to_csv(os.path.join(output_dir, 'ml_ridge_coefficients_rc.csv'), index=False)\n",
    "ridge_coefs_int.to_csv(os.path.join(output_dir, 'ml_ridge_coefficients_interactions.csv'), index=False)\n",
    "\n",
    "# Save feature importance\n",
    "importance_int.to_csv(os.path.join(output_dir, 'ml_feature_importance_interactions.csv'), index=False)\n",
    "\n",
    "print(\"   ‚úì All results saved\")\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ ML ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìä RESOURCE CURSE (BASELINE)\")\n",
    "print(f\"   Best model: {df_comp_rc.iloc[0]['Model']}\")\n",
    "print(f\"   Test R¬≤: {df_comp_rc.iloc[0]['Test R¬≤']:.3f}\")\n",
    "\n",
    "print(f\"\\nüìä RESOURCE CURSE (WITH INTERACTIONS)\")\n",
    "print(f\"   Best model: {df_comp_rc_int.iloc[0]['Model']}\")\n",
    "print(f\"   Test R¬≤: {df_comp_rc_int.iloc[0]['Test R¬≤']:.3f}\")\n",
    "\n",
    "print(f\"\\nüìä FULL STRUCTURAL MODEL\")\n",
    "print(f\"   Best model: {df_comp_full.iloc[0]['Model']}\")\n",
    "print(f\"   Test R¬≤: {df_comp_full.iloc[0]['Test R¬≤']:.3f}\")\n",
    "\n",
    "# Key finding: does interaction improve?\n",
    "baseline_r2 = df_comp_rc.iloc[0]['Test R¬≤']\n",
    "interaction_r2 = df_comp_rc_int.iloc[0]['Test R¬≤']\n",
    "improvement = interaction_r2 - baseline_r2\n",
    "\n",
    "print(f\"\\nüîë INTERACTION EFFECT:\")\n",
    "print(f\"   R¬≤ improvement from interactions: {improvement:+.3f}\")\n",
    "if improvement > 0.01:\n",
    "    print(f\"   ‚Üí Interactions ADD predictive value\")\n",
    "else:\n",
    "    print(f\"   ‚Üí Interactions provide MINIMAL improvement\")\n",
    "\n",
    "print(f\"\\nüìÅ Outputs saved to: {output_dir}\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
