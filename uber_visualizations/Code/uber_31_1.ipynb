{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e8e2718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "UBER COMPREHENSIVE ANALYSIS: 2018 ‚Üí 2025 (METHODOLOGICALLY FIXED)\n",
      "======================================================================\n",
      "\n",
      "Configuration:\n",
      "  Sample size: 20,000,000 trips per year\n",
      "  Clusters: 6\n",
      "\n",
      "======================================================================\n",
      "LOADING ZONE CENTROIDS\n",
      "======================================================================\n",
      "‚úì Loaded 263 zones\n",
      "\n",
      "======================================================================\n",
      "PART 1: 2018 UBER ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "[1.1] Loading 2018 data...\n",
      "  Total rows: 19,808,094\n",
      "  Uber trips: 4,502,999 (22.7%)\n",
      "\n",
      "[1.2] Processing temporal and geographic features...\n",
      "\n",
      "[1.3] Clustering on geographic coordinates...\n",
      "  Cluster distribution:\n",
      "    Cluster 0 - Manhattan: Yorkville East: 765,644 ( 17.0%)\n",
      "    Cluster 1 - Brooklyn: Borough Park: 388,895 (  8.6%)\n",
      "    Cluster 2 - Queens: Jamaica: 369,831 (  8.2%)\n",
      "    Cluster 3 - Manhattan: Gramercy: 1,882,965 ( 41.7%)\n",
      "    Cluster 4 - Bronx: East Tremont: 477,419 ( 10.6%)\n",
      "    Cluster 5 - Brooklyn: Ocean Hill: 626,327 ( 13.9%)\n",
      "\n",
      "======================================================================\n",
      "PART 2: 2025 UBER ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "[2.1] Loading 2025 data...\n",
      "  Total rows: 20,405,666\n",
      "  Uber trips: 15,356,455 (75.3%)\n",
      "\n",
      "[2.2] Processing temporal and geographic features...\n",
      "\n",
      "[2.3] Clustering on geographic coordinates...\n",
      "  Cluster distribution:\n",
      "    Cluster 0 - Manhattan: Murray Hill: 5,996,328 ( 38.9%)\n",
      "    Cluster 1 - Bronx: Claremont/Bathgate: 2,713,198 ( 17.6%)\n",
      "    Cluster 2 - Brooklyn: Prospect-Lefferts Gardens: 3,180,936 ( 20.7%)\n",
      "    Cluster 3 - Queens: Baisley Park: 1,353,333 (  8.8%)\n",
      "    Cluster 4 - Queens: Elmhurst: 1,824,961 ( 11.8%)\n",
      "    Cluster 5 - Staten Island: Grymes Hill/Clifton: 332,575 (  2.2%)\n",
      "\n",
      "======================================================================\n",
      "MATCHING CLUSTERS BY GEOGRAPHIC PROXIMITY\n",
      "======================================================================\n",
      "\n",
      "üìç Cluster Matching Results:\n",
      "  2018 Cluster                                                 ‚Üí 2025 Cluster                                                   Shift (km)\n",
      "  =======================================================================================================================================\n",
      "  Manhattan: Yorkville East                                    ‚Üí Queens: Elmhurst                                                     7.52\n",
      "  Brooklyn: Borough Park                                       ‚Üí Staten Island: Grymes Hill/Clifton                                  12.03\n",
      "  Queens: Jamaica                                              ‚Üí Queens: Baisley Park                                                 2.82\n",
      "  Manhattan: Gramercy                                          ‚Üí Manhattan: Murray Hill                                               1.34\n",
      "  Bronx: East Tremont                                          ‚Üí Bronx: Claremont/Bathgate                                            0.80\n",
      "  Brooklyn: Ocean Hill                                         ‚Üí Brooklyn: Prospect-Lefferts Gardens                                  3.31\n",
      "\n",
      "======================================================================\n",
      "PART 3: CREATING VISUALIZATIONS\n",
      "======================================================================\n",
      "\n",
      "[3.1] Creating cluster maps...\n",
      "  ‚úì Saved: 1_uber_2018_clusters.html\n",
      "  ‚úì Saved: 2_uber_2025_clusters.html\n",
      "\n",
      "[3.2] Creating top zones comparison...\n",
      "  ‚úì Saved: 3_top_zones_comparison.html\n",
      "\n",
      "[3.3] Creating temporal analysis...\n",
      "  ‚úì Saved: 4_hourly_patterns.html\n",
      "\n",
      "[3.4] Creating day-of-week analysis...\n",
      "  ‚úì Saved: 5_daily_patterns.html\n",
      "\n",
      "[3.5] Creating demand heatmaps...\n",
      "  ‚úì Saved: 6_demand_heatmaps.html\n",
      "\n",
      "[3.6] Creating borough analysis...\n",
      "  ‚úì Saved: 7_borough_analysis.html\n",
      "\n",
      "[3.7] Creating properly matched cluster shift map...\n",
      "  ‚úì Saved: 8_cluster_shifts_PROPER.html\n",
      "\n",
      "======================================================================\n",
      "PART 4: CALCULATING METRICS\n",
      "======================================================================\n",
      "\n",
      "‚úì Saved: 9_comprehensive_summary.csv\n",
      "‚úì Saved: 10_top_50_zones.csv\n",
      "\n",
      "======================================================================\n",
      "‚úÖ ANALYSIS COMPLETE - METHODOLOGICALLY SOUND\n",
      "======================================================================\n",
      "\n",
      "üìÇ Generated 10 Files:\n",
      "  1. uber_2018_clusters.html - 2018 map\n",
      "  2. uber_2025_clusters.html - 2025 map\n",
      "  3. top_zones_comparison.html - Top 20 zones\n",
      "  4. hourly_patterns.html - Hour-by-hour\n",
      "  5. daily_patterns.html - Day-of-week\n",
      "  6. demand_heatmaps.html - Hour x Day\n",
      "  7. borough_analysis.html - By borough\n",
      "  8. cluster_shifts_PROPER.html - ‚ú® PROPERLY MATCHED SHIFTS\n",
      "  9. comprehensive_summary.csv - Key metrics\n",
      "  10. top_50_zones.csv - Detailed zone data\n",
      "\n",
      "üéØ Key Findings:\n",
      "  ‚Ä¢ Market share: 22.7% ‚Üí 75.3%\n",
      "  ‚Ä¢ Concentration: 0.3268 ‚Üí 0.3754\n",
      "  ‚Ä¢ Avg cluster shift: 4.64 km (properly matched)\n",
      "  ‚Ä¢ Peak hour: 18:00 ‚Üí 18:00\n",
      "\n",
      "‚úÖ Methodological Improvements:\n",
      "  ‚Ä¢ Clusters matched by geographic proximity (not index)\n",
      "  ‚Ä¢ Consistent naming based on nearest zone\n",
      "  ‚Ä¢ Arrows only connect properly matched clusters\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "UBER GEOGRAPHIC EVOLUTION: COMPREHENSIVE ANALYSIS (PROPERLY FIXED)\n",
    "- Clusters matched by geographic proximity (not index)\n",
    "- Consistent naming based on nearest major zone\n",
    "- Methodologically sound comparisons\n",
    "\"\"\"\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "import gc\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"UBER COMPREHENSIVE ANALYSIS: 2018 ‚Üí 2025 (METHODOLOGICALLY FIXED)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "SAMPLE_SIZE = 20_000_000\n",
    "N_CLUSTERS = 6\n",
    "\n",
    "OUTPUT_DIR = '/Users/leoss/Desktop/Portfolio/Website-/Uber/outputs/'\n",
    "PATH_2018 = '/Users/leoss/Desktop/Portfolio/Website-/Uber/data/fhv_tripdata_2018-01.parquet'\n",
    "PATH_2025 = '/Users/leoss/Desktop/Portfolio/Website-/Uber/data/fhvhv_tripdata_2025-01.parquet'\n",
    "PATH_CENTROIDS = '/Users/leoss/Desktop/Portfolio/Website-/Uber/data/zone_centroids.csv'\n",
    "\n",
    "UBER_2018_BASES = ['B02512', 'B02598', 'B02617', 'B02682', 'B02764', 'B02765', 'B02835', 'B02836']\n",
    "UBER_2025_LICENSE = 'HV0003'\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Sample size: {SAMPLE_SIZE:,} trips per year\")\n",
    "print(f\"  Clusters: {N_CLUSTERS}\")\n",
    "\n",
    "# ============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def name_cluster_by_location(center_lat, center_lon, zone_centroids):\n",
    "    \"\"\"Name cluster based on nearest major zone.\"\"\"\n",
    "    zone_distances = np.sqrt(\n",
    "        (zone_centroids['latitude'] - center_lat)**2 + \n",
    "        (zone_centroids['longitude'] - center_lon)**2\n",
    "    )\n",
    "    nearest_idx = zone_distances.idxmin()\n",
    "    nearest_zone = zone_centroids.iloc[nearest_idx]\n",
    "    return f\"{nearest_zone['borough']}: {nearest_zone['zone_name']}\"\n",
    "\n",
    "def match_clusters_by_proximity(centers_2018, centers_2025):\n",
    "    \"\"\"Match 2018 to 2025 clusters by geographic proximity.\"\"\"\n",
    "    distances = cdist(centers_2018, centers_2025, metric='euclidean')\n",
    "    matches = {}\n",
    "    used_2025 = set()\n",
    "    \n",
    "    pairs = []\n",
    "    for i in range(len(centers_2018)):\n",
    "        for j in range(len(centers_2025)):\n",
    "            if j not in used_2025:\n",
    "                pairs.append((i, j, distances[i, j]))\n",
    "    \n",
    "    pairs.sort(key=lambda x: x[2])\n",
    "    \n",
    "    for i, j, dist in pairs:\n",
    "        if i not in matches and j not in used_2025:\n",
    "            matches[i] = j\n",
    "            used_2025.add(j)\n",
    "    \n",
    "    return matches\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD ZONE CENTROIDS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LOADING ZONE CENTROIDS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "zone_centroids = pd.read_csv(PATH_CENTROIDS)\n",
    "print(f\"‚úì Loaded {len(zone_centroids)} zones\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 1: 2018 UBER DATA\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 1: 2018 UBER ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n[1.1] Loading 2018 data...\")\n",
    "table_2018 = pq.read_table(PATH_2018, columns=[])\n",
    "total_2018 = table_2018.num_rows\n",
    "print(f\"  Total rows: {total_2018:,}\")\n",
    "\n",
    "columns_2018 = ['pickup_datetime', 'PUlocationID', 'dispatching_base_num']\n",
    "table_2018 = pq.read_table(PATH_2018, columns=columns_2018)\n",
    "\n",
    "df_2018_full = table_2018.to_pandas()\n",
    "df_2018_full = df_2018_full[df_2018_full['dispatching_base_num'].isin(UBER_2018_BASES)].copy()\n",
    "\n",
    "uber_count_2018 = len(df_2018_full)\n",
    "print(f\"  Uber trips: {uber_count_2018:,} ({100*uber_count_2018/total_2018:.1f}%)\")\n",
    "\n",
    "df_2018 = df_2018_full.sample(n=min(SAMPLE_SIZE, uber_count_2018), random_state=42)\n",
    "del df_2018_full, table_2018\n",
    "gc.collect()\n",
    "\n",
    "print(\"\\n[1.2] Processing temporal and geographic features...\")\n",
    "df_2018['pickup_datetime'] = pd.to_datetime(df_2018['pickup_datetime'])\n",
    "df_2018['hour'] = df_2018['pickup_datetime'].dt.hour\n",
    "df_2018['day_of_week'] = df_2018['pickup_datetime'].dt.dayofweek\n",
    "df_2018['day_name'] = df_2018['pickup_datetime'].dt.day_name()\n",
    "\n",
    "df_2018 = df_2018.dropna(subset=['PUlocationID'])\n",
    "df_2018['PUlocationID'] = df_2018['PUlocationID'].astype(int)\n",
    "df_2018 = df_2018.merge(\n",
    "    zone_centroids[['zone_id', 'zone_name', 'borough', 'latitude', 'longitude']], \n",
    "    left_on='PUlocationID',\n",
    "    right_on='zone_id',\n",
    "    how='left'\n",
    ")\n",
    "df_2018 = df_2018.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "print(\"\\n[1.3] Clustering on geographic coordinates...\")\n",
    "coords_2018 = df_2018[['latitude', 'longitude']].values\n",
    "kmeans_2018 = KMeans(n_clusters=N_CLUSTERS, random_state=42, n_init=10)\n",
    "df_2018['cluster'] = kmeans_2018.fit_predict(coords_2018)\n",
    "\n",
    "# Name clusters by nearest major zone\n",
    "cluster_names_2018 = {}\n",
    "for i in range(N_CLUSTERS):\n",
    "    lat, lon = kmeans_2018.cluster_centers_[i]\n",
    "    cluster_names_2018[i] = name_cluster_by_location(lat, lon, zone_centroids)\n",
    "\n",
    "df_2018['cluster_name'] = df_2018['cluster'].map(cluster_names_2018)\n",
    "\n",
    "cluster_counts_2018 = df_2018['cluster'].value_counts().sort_index()\n",
    "print(f\"  Cluster distribution:\")\n",
    "for i, count in enumerate(cluster_counts_2018):\n",
    "    pct = 100 * count / len(df_2018)\n",
    "    print(f\"    Cluster {i} - {cluster_names_2018[i]}: {count:>7,} ({pct:>5.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 2: 2025 UBER DATA\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 2: 2025 UBER ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n[2.1] Loading 2025 data...\")\n",
    "table_2025 = pq.read_table(PATH_2025, columns=[])\n",
    "total_2025 = table_2025.num_rows\n",
    "print(f\"  Total rows: {total_2025:,}\")\n",
    "\n",
    "columns_2025 = ['pickup_datetime', 'PULocationID', 'hvfhs_license_num']\n",
    "table_2025 = pq.read_table(PATH_2025, columns=columns_2025)\n",
    "\n",
    "df_2025_full = table_2025.to_pandas()\n",
    "df_2025_full = df_2025_full[df_2025_full['hvfhs_license_num'] == UBER_2025_LICENSE].copy()\n",
    "\n",
    "uber_count_2025 = len(df_2025_full)\n",
    "print(f\"  Uber trips: {uber_count_2025:,} ({100*uber_count_2025/total_2025:.1f}%)\")\n",
    "\n",
    "df_2025 = df_2025_full.sample(n=min(SAMPLE_SIZE, uber_count_2025), random_state=42)\n",
    "del df_2025_full, table_2025\n",
    "gc.collect()\n",
    "\n",
    "print(\"\\n[2.2] Processing temporal and geographic features...\")\n",
    "df_2025['pickup_datetime'] = pd.to_datetime(df_2025['pickup_datetime'])\n",
    "df_2025['hour'] = df_2025['pickup_datetime'].dt.hour\n",
    "df_2025['day_of_week'] = df_2025['pickup_datetime'].dt.dayofweek\n",
    "df_2025['day_name'] = df_2025['pickup_datetime'].dt.day_name()\n",
    "\n",
    "df_2025 = df_2025.dropna(subset=['PULocationID'])\n",
    "df_2025['PULocationID'] = df_2025['PULocationID'].astype(int)\n",
    "df_2025 = df_2025.merge(\n",
    "    zone_centroids[['zone_id', 'zone_name', 'borough', 'latitude', 'longitude']], \n",
    "    left_on='PULocationID',\n",
    "    right_on='zone_id',\n",
    "    how='left'\n",
    ")\n",
    "df_2025 = df_2025.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "print(\"\\n[2.3] Clustering on geographic coordinates...\")\n",
    "coords_2025 = df_2025[['latitude', 'longitude']].values\n",
    "kmeans_2025 = KMeans(n_clusters=N_CLUSTERS, random_state=42, n_init=10)\n",
    "df_2025['cluster'] = kmeans_2025.fit_predict(coords_2025)\n",
    "\n",
    "# Name clusters by nearest major zone\n",
    "cluster_names_2025 = {}\n",
    "for i in range(N_CLUSTERS):\n",
    "    lat, lon = kmeans_2025.cluster_centers_[i]\n",
    "    cluster_names_2025[i] = name_cluster_by_location(lat, lon, zone_centroids)\n",
    "\n",
    "df_2025['cluster_name'] = df_2025['cluster'].map(cluster_names_2025)\n",
    "\n",
    "cluster_counts_2025 = df_2025['cluster'].value_counts().sort_index()\n",
    "print(f\"  Cluster distribution:\")\n",
    "for i, count in enumerate(cluster_counts_2025):\n",
    "    pct = 100 * count / len(df_2025)\n",
    "    print(f\"    Cluster {i} - {cluster_names_2025[i]}: {count:>7,} ({pct:>5.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# MATCH CLUSTERS PROPERLY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MATCHING CLUSTERS BY GEOGRAPHIC PROXIMITY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "centers_2018 = kmeans_2018.cluster_centers_\n",
    "centers_2025 = kmeans_2025.cluster_centers_\n",
    "\n",
    "cluster_matches = match_clusters_by_proximity(centers_2018, centers_2025)\n",
    "\n",
    "print(f\"\\nüìç Cluster Matching Results:\")\n",
    "print(f\"  {'2018 Cluster':<60} ‚Üí {'2025 Cluster':<60} {'Shift (km)':>12}\")\n",
    "print(\"  \" + \"=\"*135)\n",
    "\n",
    "for idx_2018, idx_2025 in sorted(cluster_matches.items()):\n",
    "    lat1, lon1 = centers_2018[idx_2018]\n",
    "    lat2, lon2 = centers_2025[idx_2025]\n",
    "    distance_km = np.sqrt((lat2-lat1)**2 + (lon2-lon1)**2) * 111\n",
    "    \n",
    "    name_2018 = cluster_names_2018[idx_2018]\n",
    "    name_2025 = cluster_names_2025[idx_2025]\n",
    "    \n",
    "    print(f\"  {name_2018:<60} ‚Üí {name_2025:<60} {distance_km:>12.2f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 3: VISUALIZATIONS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 3: CREATING VISUALIZATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 3.1: Cluster maps\n",
    "print(\"\\n[3.1] Creating cluster maps...\")\n",
    "\n",
    "def create_cluster_map(df, centers, cluster_names, title):\n",
    "    viz_sample = df.sample(n=min(15_000, len(df)), random_state=42)\n",
    "    \n",
    "    fig = px.scatter_map(\n",
    "        viz_sample,\n",
    "        lat='latitude',\n",
    "        lon='longitude',\n",
    "        color='cluster_name',\n",
    "        color_discrete_sequence=px.colors.qualitative.Bold,\n",
    "        zoom=10,\n",
    "        title=title,\n",
    "        map_style='carto-positron',\n",
    "        height=700,\n",
    "        width=1200,\n",
    "        hover_data={'zone_name': True, 'cluster_name': True, 'borough': True}\n",
    "    )\n",
    "    \n",
    "    # Add clean numbered centroids\n",
    "    for i, (lat, lon) in enumerate(centers):\n",
    "        fig.add_trace(go.Scattermap(\n",
    "            lat=[lat],\n",
    "            lon=[lon],\n",
    "            mode='markers+text',\n",
    "            marker=dict(size=18, color='black', opacity=0.8),\n",
    "            text=f\"{i}\",\n",
    "            textfont=dict(size=12, color='white', family='Arial Black'),\n",
    "            textposition='middle center',\n",
    "            name=cluster_names[i],\n",
    "            showlegend=False,\n",
    "            hovertemplate=f'<b>Cluster {i}</b><br>{cluster_names[i]}<extra></extra>'\n",
    "        ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        font=dict(size=12),\n",
    "        title_font=dict(size=18),\n",
    "        legend=dict(title=\"Clusters\", yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01,\n",
    "                   bgcolor=\"rgba(255,255,255,0.9)\")\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "fig_2018 = create_cluster_map(df_2018, centers_2018, cluster_names_2018, \n",
    "                               '2018 Uber: Geographic Demand Clusters')\n",
    "fig_2018.write_html(OUTPUT_DIR + '1_uber_2018_clusters.html')\n",
    "print(f\"  ‚úì Saved: 1_uber_2018_clusters.html\")\n",
    "\n",
    "fig_2025 = create_cluster_map(df_2025, centers_2025, cluster_names_2025, \n",
    "                               '2025 Uber: Geographic Demand Clusters')\n",
    "fig_2025.write_html(OUTPUT_DIR + '2_uber_2025_clusters.html')\n",
    "print(f\"  ‚úì Saved: 2_uber_2025_clusters.html\")\n",
    "\n",
    "# 3.2: Top zones\n",
    "print(\"\\n[3.2] Creating top zones comparison...\")\n",
    "\n",
    "zone_counts_2018 = df_2018.groupby(['zone_id', 'zone_name', 'borough']).size().reset_index(name='count_2018')\n",
    "zone_counts_2025 = df_2025.groupby(['zone_id', 'zone_name', 'borough']).size().reset_index(name='count_2025')\n",
    "\n",
    "zone_comparison = zone_counts_2018.merge(zone_counts_2025, on=['zone_id', 'zone_name', 'borough'], how='outer').fillna(0)\n",
    "zone_comparison['change'] = zone_comparison['count_2025'] - zone_comparison['count_2018']\n",
    "\n",
    "top_zones = zone_comparison.nlargest(20, 'count_2025')\n",
    "\n",
    "fig_top_zones = go.Figure()\n",
    "fig_top_zones.add_trace(go.Bar(\n",
    "    name='2018',\n",
    "    y=top_zones['zone_name'] + ' (' + top_zones['borough'] + ')',\n",
    "    x=top_zones['count_2018'],\n",
    "    orientation='h',\n",
    "    marker_color='#ff6b6b',\n",
    "    text=top_zones['count_2018'].astype(int),\n",
    "    textposition='outside'\n",
    "))\n",
    "fig_top_zones.add_trace(go.Bar(\n",
    "    name='2025',\n",
    "    y=top_zones['zone_name'] + ' (' + top_zones['borough'] + ')',\n",
    "    x=top_zones['count_2025'],\n",
    "    orientation='h',\n",
    "    marker_color='#4ecdc4',\n",
    "    text=top_zones['count_2025'].astype(int),\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "fig_top_zones.update_layout(\n",
    "    title='Top 20 Pickup Zones: 2018 vs 2025',\n",
    "    xaxis_title='Number of Trips',\n",
    "    barmode='group',\n",
    "    height=800,\n",
    "    width=1200,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig_top_zones.write_html(OUTPUT_DIR + '3_top_zones_comparison.html')\n",
    "print(f\"  ‚úì Saved: 3_top_zones_comparison.html\")\n",
    "\n",
    "# 3.3: Hourly patterns\n",
    "print(\"\\n[3.3] Creating temporal analysis...\")\n",
    "\n",
    "hourly_2018 = df_2018.groupby('hour').size()\n",
    "hourly_2025 = df_2025.groupby('hour').size()\n",
    "\n",
    "fig_hourly = go.Figure()\n",
    "fig_hourly.add_trace(go.Scatter(x=hourly_2018.index, y=hourly_2018.values, name='2018',\n",
    "                                mode='lines+markers', line=dict(color='#ff6b6b', width=3)))\n",
    "fig_hourly.add_trace(go.Scatter(x=hourly_2025.index, y=hourly_2025.values, name='2025',\n",
    "                                mode='lines+markers', line=dict(color='#4ecdc4', width=3)))\n",
    "\n",
    "fig_hourly.update_layout(\n",
    "    title='Hourly Demand Pattern: 2018 vs 2025',\n",
    "    xaxis_title='Hour of Day',\n",
    "    yaxis_title='Number of Trips',\n",
    "    template='plotly_white',\n",
    "    height=500,\n",
    "    width=1200,\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig_hourly.write_html(OUTPUT_DIR + '4_hourly_patterns.html')\n",
    "print(f\"  ‚úì Saved: 4_hourly_patterns.html\")\n",
    "\n",
    "# 3.4: Daily patterns\n",
    "print(\"\\n[3.4] Creating day-of-week analysis...\")\n",
    "\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "daily_2018 = df_2018.groupby('day_name').size().reindex(day_order)\n",
    "daily_2025 = df_2025.groupby('day_name').size().reindex(day_order)\n",
    "\n",
    "fig_daily = go.Figure()\n",
    "fig_daily.add_trace(go.Bar(name='2018', x=day_order, y=daily_2018.values, marker_color='#ff6b6b'))\n",
    "fig_daily.add_trace(go.Bar(name='2025', x=day_order, y=daily_2025.values, marker_color='#4ecdc4'))\n",
    "\n",
    "fig_daily.update_layout(\n",
    "    title='Weekly Demand Pattern: 2018 vs 2025',\n",
    "    xaxis_title='Day of Week',\n",
    "    yaxis_title='Number of Trips',\n",
    "    barmode='group',\n",
    "    template='plotly_white',\n",
    "    height=500,\n",
    "    width=1200\n",
    ")\n",
    "\n",
    "fig_daily.write_html(OUTPUT_DIR + '5_daily_patterns.html')\n",
    "print(f\"  ‚úì Saved: 5_daily_patterns.html\")\n",
    "\n",
    "# 3.5: Heatmaps\n",
    "print(\"\\n[3.5] Creating demand heatmaps...\")\n",
    "\n",
    "fig_heat = make_subplots(rows=2, cols=1, subplot_titles=('2018', '2025'), vertical_spacing=0.12)\n",
    "\n",
    "for df, row, year in [(df_2018, 1, '2018'), (df_2025, 2, '2025')]:\n",
    "    pivot = df.groupby(['day_name', 'hour']).size().reset_index(name='trips')\n",
    "    pivot_table = pivot.pivot(index='day_name', columns='hour', values='trips').reindex(day_order)\n",
    "    \n",
    "    fig_heat.add_trace(go.Heatmap(\n",
    "        z=pivot_table.values,\n",
    "        x=pivot_table.columns,\n",
    "        y=pivot_table.index,\n",
    "        colorscale='Viridis',\n",
    "        showscale=(row==2)\n",
    "    ), row=row, col=1)\n",
    "\n",
    "fig_heat.update_layout(title='Demand Heatmaps: Hour x Day', height=700, width=1200)\n",
    "fig_heat.write_html(OUTPUT_DIR + '6_demand_heatmaps.html')\n",
    "print(f\"  ‚úì Saved: 6_demand_heatmaps.html\")\n",
    "\n",
    "# 3.6: Borough analysis\n",
    "print(\"\\n[3.6] Creating borough analysis...\")\n",
    "\n",
    "borough_2018 = df_2018.groupby('borough').size()\n",
    "borough_2025 = df_2025.groupby('borough').size()\n",
    "\n",
    "fig_borough = go.Figure()\n",
    "fig_borough.add_trace(go.Bar(name='2018', x=borough_2018.index, y=borough_2018.values, marker_color='#ff6b6b'))\n",
    "fig_borough.add_trace(go.Bar(name='2025', x=borough_2025.index, y=borough_2025.values, marker_color='#4ecdc4'))\n",
    "\n",
    "fig_borough.update_layout(\n",
    "    title='Demand by Borough: 2018 vs 2025',\n",
    "    xaxis_title='Borough',\n",
    "    yaxis_title='Number of Trips',\n",
    "    barmode='group',\n",
    "    template='plotly_white',\n",
    "    height=500,\n",
    "    width=1000\n",
    ")\n",
    "\n",
    "fig_borough.write_html(OUTPUT_DIR + '7_borough_analysis.html')\n",
    "print(f\"  ‚úì Saved: 7_borough_analysis.html\")\n",
    "\n",
    "# 3.7: PROPERLY MATCHED CLUSTER SHIFTS\n",
    "print(\"\\n[3.7] Creating properly matched cluster shift map...\")\n",
    "\n",
    "fig_shifts = go.Figure()\n",
    "\n",
    "# Add 2018 centers\n",
    "for i in range(len(centers_2018)):\n",
    "    fig_shifts.add_trace(go.Scattermap(\n",
    "        lat=[centers_2018[i, 0]],\n",
    "        lon=[centers_2018[i, 1]],\n",
    "        mode='markers+text',\n",
    "        marker=dict(size=25, color='#ff6b6b', opacity=0.8),\n",
    "        text=f\"18-{i}\",\n",
    "        textfont=dict(size=10, color='white', family='Arial Black'),\n",
    "        textposition='middle center',\n",
    "        name=f'2018: {cluster_names_2018[i]}',\n",
    "        hovertemplate=f'<b>2018 Cluster {i}</b><br>{cluster_names_2018[i]}<extra></extra>'\n",
    "    ))\n",
    "\n",
    "# Add 2025 centers\n",
    "for i in range(len(centers_2025)):\n",
    "    fig_shifts.add_trace(go.Scattermap(\n",
    "        lat=[centers_2025[i, 0]],\n",
    "        lon=[centers_2025[i, 1]],\n",
    "        mode='markers+text',\n",
    "        marker=dict(size=25, color='#4ecdc4', opacity=0.8),\n",
    "        text=f\"25-{i}\",\n",
    "        textfont=dict(size=10, color='white', family='Arial Black'),\n",
    "        textposition='middle center',\n",
    "        name=f'2025: {cluster_names_2025[i]}',\n",
    "        hovertemplate=f'<b>2025 Cluster {i}</b><br>{cluster_names_2025[i]}<extra></extra>'\n",
    "    ))\n",
    "\n",
    "# Draw arrows ONLY between properly matched clusters\n",
    "for idx_2018, idx_2025 in cluster_matches.items():\n",
    "    lat1, lon1 = centers_2018[idx_2018]\n",
    "    lat2, lon2 = centers_2025[idx_2025]\n",
    "    distance_km = np.sqrt((lat2-lat1)**2 + (lon2-lon1)**2) * 111\n",
    "    \n",
    "    fig_shifts.add_trace(go.Scattermap(\n",
    "        lat=[lat1, lat2],\n",
    "        lon=[lon1, lon2],\n",
    "        mode='lines',\n",
    "        line=dict(width=3, color='black'),\n",
    "        showlegend=False,\n",
    "        hovertemplate=f'<b>Shift: {distance_km:.2f} km</b><br>' +\n",
    "                     f'From: {cluster_names_2018[idx_2018]}<br>' +\n",
    "                     f'To: {cluster_names_2025[idx_2025]}<extra></extra>'\n",
    "    ))\n",
    "\n",
    "fig_shifts.update_layout(\n",
    "    title='Cluster Center Shifts: 2018 ‚Üí 2025 (Properly Matched by Geographic Proximity)',\n",
    "    map_style='carto-positron',\n",
    "    map_zoom=10,\n",
    "    map_center=dict(lat=40.75, lon=-73.95),\n",
    "    height=800,\n",
    "    width=1400,\n",
    "    legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01, bgcolor=\"rgba(255,255,255,0.9)\")\n",
    ")\n",
    "\n",
    "fig_shifts.write_html(OUTPUT_DIR + '8_cluster_shifts_PROPER.html')\n",
    "print(f\"  ‚úì Saved: 8_cluster_shifts_PROPER.html\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 4: METRICS & SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 4: CALCULATING METRICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def gini_coefficient(counts):\n",
    "    sorted_counts = np.sort(counts)\n",
    "    n = len(sorted_counts)\n",
    "    cumsum = np.cumsum(sorted_counts)\n",
    "    return (2 * np.sum((np.arange(1, n+1)) * sorted_counts)) / (n * cumsum[-1]) - (n + 1) / n\n",
    "\n",
    "gini_2018 = gini_coefficient(cluster_counts_2018.values)\n",
    "gini_2025 = gini_coefficient(cluster_counts_2025.values)\n",
    "\n",
    "peak_hour_2018 = df_2018.groupby('hour').size().idxmax()\n",
    "peak_hour_2025 = df_2025.groupby('hour').size().idxmax()\n",
    "\n",
    "top_zone_2018 = df_2018.groupby('zone_name').size().idxmax()\n",
    "top_zone_2025 = df_2025.groupby('zone_name').size().idxmax()\n",
    "\n",
    "# Calculate average shift for matched clusters\n",
    "matched_shifts = [\n",
    "    np.sqrt((centers_2025[idx_2025, 0] - centers_2018[idx_2018, 0])**2 + \n",
    "            (centers_2025[idx_2025, 1] - centers_2018[idx_2018, 1])**2) * 111\n",
    "    for idx_2018, idx_2025 in cluster_matches.items()\n",
    "]\n",
    "avg_shift = np.mean(matched_shifts)\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    'Metric': [\n",
    "        'Total Trips (All Companies)',\n",
    "        'Uber Trips',\n",
    "        'Uber Market Share (%)',\n",
    "        'Sample Size',\n",
    "        'Unique Zones',\n",
    "        'Top Pickup Zone',\n",
    "        'Peak Hour',\n",
    "        'Most Active Day',\n",
    "        'Gini Coefficient',\n",
    "        'Avg Cluster Shift (km)'\n",
    "    ],\n",
    "    '2018': [\n",
    "        f'{total_2018:,}',\n",
    "        f'{uber_count_2018:,}',\n",
    "        f'{100*uber_count_2018/total_2018:.1f}',\n",
    "        f'{len(df_2018):,}',\n",
    "        df_2018['zone_id'].nunique(),\n",
    "        top_zone_2018,\n",
    "        f'{peak_hour_2018}:00',\n",
    "        df_2018.groupby('day_name').size().idxmax(),\n",
    "        f'{gini_2018:.4f}',\n",
    "        '-'\n",
    "    ],\n",
    "    '2025': [\n",
    "        f'{total_2025:,}',\n",
    "        f'{uber_count_2025:,}',\n",
    "        f'{100*uber_count_2025/total_2025:.1f}',\n",
    "        f'{len(df_2025):,}',\n",
    "        df_2025['zone_id'].nunique(),\n",
    "        top_zone_2025,\n",
    "        f'{peak_hour_2025}:00',\n",
    "        df_2025.groupby('day_name').size().idxmax(),\n",
    "        f'{gini_2025:.4f}',\n",
    "        f'{avg_shift:.2f}'\n",
    "    ]\n",
    "})\n",
    "\n",
    "summary.to_csv(OUTPUT_DIR + '9_comprehensive_summary.csv', index=False)\n",
    "print(f\"\\n‚úì Saved: 9_comprehensive_summary.csv\")\n",
    "\n",
    "zone_comparison.sort_values('count_2025', ascending=False).head(50).to_csv(\n",
    "    OUTPUT_DIR + '10_top_50_zones.csv', index=False\n",
    ")\n",
    "print(f\"‚úì Saved: 10_top_50_zones.csv\")\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ ANALYSIS COMPLETE - METHODOLOGICALLY SOUND\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìÇ Generated 10 Files:\")\n",
    "print(f\"  1. uber_2018_clusters.html - 2018 map\")\n",
    "print(f\"  2. uber_2025_clusters.html - 2025 map\")\n",
    "print(f\"  3. top_zones_comparison.html - Top 20 zones\")\n",
    "print(f\"  4. hourly_patterns.html - Hour-by-hour\")\n",
    "print(f\"  5. daily_patterns.html - Day-of-week\")\n",
    "print(f\"  6. demand_heatmaps.html - Hour x Day\")\n",
    "print(f\"  7. borough_analysis.html - By borough\")\n",
    "print(f\"  8. cluster_shifts_PROPER.html - ‚ú® PROPERLY MATCHED SHIFTS\")\n",
    "print(f\"  9. comprehensive_summary.csv - Key metrics\")\n",
    "print(f\"  10. top_50_zones.csv - Detailed zone data\")\n",
    "\n",
    "print(f\"\\nüéØ Key Findings:\")\n",
    "print(f\"  ‚Ä¢ Market share: {100*uber_count_2018/total_2018:.1f}% ‚Üí {100*uber_count_2025/total_2025:.1f}%\")\n",
    "print(f\"  ‚Ä¢ Concentration: {gini_2018:.4f} ‚Üí {gini_2025:.4f}\")\n",
    "print(f\"  ‚Ä¢ Avg cluster shift: {avg_shift:.2f} km (properly matched)\")\n",
    "print(f\"  ‚Ä¢ Peak hour: {peak_hour_2018}:00 ‚Üí {peak_hour_2025}:00\")\n",
    "\n",
    "print(\"\\n‚úÖ Methodological Improvements:\")\n",
    "print(\"  ‚Ä¢ Clusters matched by geographic proximity (not index)\")\n",
    "print(\"  ‚Ä¢ Consistent naming based on nearest zone\")\n",
    "print(\"  ‚Ä¢ Arrows only connect properly matched clusters\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c136e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
